,id,submitter,authors,title,comments,journal-ref,doi,report-no,categories,license,abstract,versions,update_date,authors_parsed
1367349,2010.11019,Pranaydeep Singh,Pranaydeep Singh and Els Lefever,"LT3 at SemEval-2020 Task 9: Cross-lingual Embeddings for Sentiment
  Analysis of Hinglish Social Media Text",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper describes our contribution to the SemEval-2020 Task 9 on Sentiment
Analysis for Code-mixed Social Media Text. We investigated two approaches to
solve the task of Hinglish sentiment analysis. The first approach uses
cross-lingual embeddings resulting from projecting Hinglish and pre-trained
English FastText word embeddings in the same space. The second approach
incorporates pre-trained English embeddings that are incrementally retrained
with a set of Hinglish tweets. The results show that the second approach
performs best, with an F1-score of 70.52% on the held-out test data.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 14:03:16 GMT'}]",2020-10-22,"[['Singh', 'Pranaydeep', ''], ['Lefever', 'Els', '']]"
1366999,2010.10669,Ram\'on Fernandez Astudillo,"Ramon Fernandez Astudillo, Miguel Ballesteros, Tahira Naseem, Austin
  Blodgett, Radu Florian",Transition-based Parsing with Stack-Transformers,"Accepted to Findings of EMNLP2020, open review
  https://openreview.net/forum?id=b36spsuUAde, code
  https://github.com/IBM/transition-amr-parser",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Modeling the parser state is key to good performance in transition-based
parsing. Recurrent Neural Networks considerably improved the performance of
transition-based systems by modelling the global state, e.g. stack-LSTM
parsers, or local state modeling of contextualized features, e.g. Bi-LSTM
parsers. Given the success of Transformer architectures in recent parsing
systems, this work explores modifications of the sequence-to-sequence
Transformer architecture to model either global or local parser states in
transition-based parsing. We show that modifications of the cross attention
mechanism of the Transformer considerably strengthen performance both on
dependency and Abstract Meaning Representation (AMR) parsing tasks,
particularly for smaller models or limited training data.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 23:20:31 GMT'}]",2020-10-22,"[['Astudillo', 'Ramon Fernandez', ''], ['Ballesteros', 'Miguel', ''], ['Naseem', 'Tahira', ''], ['Blodgett', 'Austin', ''], ['Florian', 'Radu', '']]"
1367024,2010.10694,Erica Cooper,"Antoine Perquin, Erica Cooper, Junichi Yamagishi",Grapheme or phoneme? An Analysis of Tacotron's Embedded Representations,Submitted to ICASSP 2021,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  End-to-end models, particularly Tacotron-based ones, are currently a popular
solution for text-to-speech synthesis. They allow the production of
high-quality synthesized speech with little to no text preprocessing. Phoneme
inputs are usually preferred over graphemes in order to limit the amount of
pronunciation errors. In this work we show that, in the case of a well-curated
French dataset, graphemes can be used as input without increasing the amount of
pronunciation errors. Furthermore, we perform an analysis of the representation
learned by the Tacotron model and show that the contextual grapheme embeddings
encode phoneme information, and that they can be used for grapheme-to-phoneme
conversion and phoneme control of synthetic speech.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 00:58:29 GMT'}]",2020-10-22,"[['Perquin', 'Antoine', ''], ['Cooper', 'Erica', ''], ['Yamagishi', 'Junichi', '']]"
1367396,2010.11066,Chenyu You,"Chenyu You, Nuo Chen, Yuexian Zou","Contextualized Attention-based Knowledge Transfer for Spoken
  Conversational Question Answering",,,,,cs.CL cs.AI cs.IR cs.LG cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Spoken conversational question answering (SCQA) requires machines to model
complex dialogue flow given the speech utterances and text corpora. Different
from traditional text question answering (QA) tasks, SCQA involves audio signal
processing, passage comprehension, and contextual understanding. However, ASR
systems introduce unexpected noisy signals to the transcriptions, which result
in performance degradation on SCQA. To overcome the problem, we propose CADNet,
a novel contextualized attention-based distillation approach, which applies
both cross-attention and self-attention to obtain ASR-robust contextualized
embedding representations of the passage and dialogue history for performance
improvements. We also introduce the spoken conventional knowledge distillation
framework to distill the ASR-robust knowledge from the estimated probabilities
of the teacher model to the student. We conduct extensive experiments on the
Spoken-CoQA dataset and demonstrate that our approach achieves remarkable
performance in this task.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 15:17:18 GMT'}]",2020-10-22,"[['You', 'Chenyu', ''], ['Chen', 'Nuo', ''], ['Zou', 'Yuexian', '']]"
1367384,2010.11054,Jiaming Luo,"Jiaming Luo, Frederik Hartmann, Enrico Santus, Yuan Cao, Regina
  Barzilay",Deciphering Undersegmented Ancient Scripts Using Phonetic Prior,"TACL 2020, pre-MIT Press publication version",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Most undeciphered lost languages exhibit two characteristics that pose
significant decipherment challenges: (1) the scripts are not fully segmented
into words; (2) the closest known language is not determined. We propose a
decipherment model that handles both of these challenges by building on rich
linguistic constraints reflecting consistent patterns in historical sound
change. We capture the natural phonological geometry by learning character
embeddings based on the International Phonetic Alphabet (IPA). The resulting
generative framework jointly models word segmentation and cognate alignment,
informed by phonological constraints. We evaluate the model on both deciphered
languages (Gothic, Ugaritic) and an undeciphered one (Iberian). The experiments
show that incorporating phonetic geometry leads to clear and consistent gains.
Additionally, we propose a measure for language closeness which correctly
identifies related languages for Gothic and Ugaritic. For Iberian, the method
does not show strong evidence supporting Basque as a related language,
concurring with the favored position by the current scholarship.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 15:03:52 GMT'}]",2020-10-22,"[['Luo', 'Jiaming', ''], ['Hartmann', 'Frederik', ''], ['Santus', 'Enrico', ''], ['Cao', 'Yuan', ''], ['Barzilay', 'Regina', '']]"
1367405,2010.11075,Nils Barlaug,"Nils Barlaug, Jon Atle Gulla",Neural Networks for Entity Matching,Under review in TKDD,,,,cs.DB cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Entity matching is the problem of identifying which records refer to the same
real-world entity. It has been actively researched for decades, and a variety
of different approaches have been developed. Even today, it remains a
challenging problem, and there is still generous room for improvement. In
recent years we have seen new methods based upon deep learning techniques for
natural language processing emerge.
  In this survey, we present how neural networks have been used for entity
matching. Specifically, we identify which steps of the entity matching process
existing work have targeted using neural networks, and provide an overview of
the different techniques used at each step. We also discuss contributions from
deep learning in entity matching compared to traditional methods, and propose a
taxonomy of deep neural networks for entity matching.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 15:36:03 GMT'}]",2020-10-22,"[['Barlaug', 'Nils', ''], ['Gulla', 'Jon Atle', '']]"
1226995,2001.01582,Hossein Amirkhani,"Razieh Baradaran, Razieh Ghiasi, and Hossein Amirkhani",A Survey on Machine Reading Comprehension Systems,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Machine reading comprehension is a challenging task and hot topic in natural
language processing. Its goal is to develop systems to answer the questions
regarding a given context. In this paper, we present a comprehensive survey on
different aspects of machine reading comprehension systems, including their
approaches, structures, input/outputs, and research novelties. We illustrate
the recent trends in this field based on 241 reviewed papers from 2016 to 2020.
Our investigations demonstrate that the focus of research has changed in recent
years from answer extraction to answer generation, from single to
multi-document reading comprehension, and from learning from scratch to using
pre-trained embeddings. We also discuss the popular datasets and the evaluation
metrics in this field. The paper ends with investigating the most cited papers
and their contributions.
","[{'version': 'v1', 'created': 'Mon, 6 Jan 2020 13:54:06 GMT'}, {'version': 'v2', 'created': 'Tue, 20 Oct 2020 20:50:51 GMT'}]",2020-10-22,"[['Baradaran', 'Razieh', ''], ['Ghiasi', 'Razieh', ''], ['Amirkhani', 'Hossein', '']]"
1367397,2010.11067,Chenyu You,"Chenyu You, Nuo Chen, Yuexian Zou","Knowledge Distillation for Improved Accuracy in Spoken Question
  Answering",,,,,cs.CL cs.AI cs.IR cs.LG cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Spoken question answering (SQA) is a challenging task that requires the
machine to fully understand the complex spoken documents. Automatic speech
recognition (ASR) plays a significant role in the development of QA systems.
However, the recent work shows that ASR systems generate highly noisy
transcripts, which critically limit the capability of machine comprehension on
the SQA task. To address the issue, we present a novel distillation framework.
Specifically, we devise a training strategy to perform knowledge distillation
(KD) from spoken documents and written counterparts. Our work makes a step
towards distilling knowledge from the language model as a supervision signal to
lead to better student accuracy by reducing the misalignment between automatic
and manual transcriptions. Experiments demonstrate that our approach
outperforms several state-of-the-art language models on the Spoken-SQuAD
dataset.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 15:18:01 GMT'}]",2020-10-22,"[['You', 'Chenyu', ''], ['Chen', 'Nuo', ''], ['Zou', 'Yuexian', '']]"
1367500,2010.11170,Ozan \.Irsoy,"Tianze Shi, Igor Malioutov, Ozan \.Irsoy",Semantic Role Labeling as Syntactic Dependency Parsing,Appeared in EMNLP 2020,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We reduce the task of (span-based) PropBank-style semantic role labeling
(SRL) to syntactic dependency parsing. Our approach is motivated by our
empirical analysis that shows three common syntactic patterns account for over
98% of the SRL annotations for both English and Chinese data. Based on this
observation, we present a conversion scheme that packs SRL annotations into
dependency tree representations through joint labels that permit highly
accurate recovery back to the original format. This representation allows us to
train statistical dependency parsers to tackle SRL and achieve competitive
performance with the current state of the art. Our findings show the promise of
syntactic dependency trees in encoding semantic role relations within their
syntactic domain of locality, and point to potential further integration of
syntactic methods into semantic role labeling in the future.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 17:46:11 GMT'}]",2020-10-22,"[['Shi', 'Tianze', ''], ['Malioutov', 'Igor', ''], ['İrsoy', 'Ozan', '']]"
1367478,2010.11148,Jiahui Yu,"Jiahui Yu, Chung-Cheng Chiu, Bo Li, Shuo-yiin Chang, Tara N. Sainath,
  Yanzhang He, Arun Narayanan, Wei Han, Anmol Gulati, Yonghui Wu, Ruoming Pang","FastEmit: Low-latency Streaming ASR with Sequence-level Emission
  Regularization",tech report,,,,eess.AS cs.AI cs.CL cs.LG cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Streaming automatic speech recognition (ASR) aims to emit each hypothesized
word as quickly and accurately as possible. However, emitting fast without
degrading quality, as measured by word error rate (WER), is highly challenging.
Existing approaches including Early and Late Penalties and Constrained
Alignments penalize emission delay by manipulating per-token or per-frame
probability prediction in sequence transducer models. While being successful in
reducing delay, these approaches suffer from significant accuracy regression
and also require additional word alignment information from an existing model.
In this work, we propose a sequence-level emission regularization method, named
FastEmit, that applies latency regularization directly on per-sequence
probability in training transducer models, and does not require any alignment.
We demonstrate that FastEmit is more suitable to the sequence-level
optimization of transducer models for streaming ASR by applying it on various
end-to-end streaming ASR networks including RNN-Transducer,
Transformer-Transducer, ConvNet-Transducer and Conformer-Transducer. We achieve
150-300 ms latency reduction with significantly better accuracy over previous
techniques on a Voice Search test set. FastEmit also improves streaming ASR
accuracy from 4.4%/8.9% to 3.1%/7.5% WER, meanwhile reduces 90th percentile
latency from 210 ms to only 30 ms on LibriSpeech.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 17:05:01 GMT'}]",2020-10-22,"[['Yu', 'Jiahui', ''], ['Chiu', 'Chung-Cheng', ''], ['Li', 'Bo', ''], ['Chang', 'Shuo-yiin', ''], ['Sainath', 'Tara N.', ''], ['He', 'Yanzhang', ''], ['Narayanan', 'Arun', ''], ['Han', 'Wei', ''], ['Gulati', 'Anmol', ''], ['Wu', 'Yonghui', ''], ['Pang', 'Ruoming', '']]"
1367470,2010.11140,Yan Zeng,Yan Zeng and Jian-Yun Nie,"Generalized Conditioned Dialogue Generation Based on Pre-trained
  Language Model","9 pages, 2 figures",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We investigate the general problem of conditioned dialogue, in which a
condition label is used as input to designate the type of the target response
such as a persona. A major challenge for conditioned dialogue generation is the
lack of substantial dialogue data labeled with conditions. Thus, we propose to
complement the labeled dialogue data with labeled non-dialogue text data, and
fine-tune BERT based on them. Our fine-tuning approach utilizes BERT for both
encoder and decoder via different input representations and self-attention
masks in order to distinguish the source and target side. On the target
(generation) side, we use a new attention routing mechanism to choose between
generating a generic word or condition-related word at each position. Our model
is instantiated to persona- and topic-related dialogue. Experimental results in
both cases show that our approach can produce significantly better responses
than the state-of-the-art baselines.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 16:56:49 GMT'}]",2020-10-22,"[['Zeng', 'Yan', ''], ['Nie', 'Jian-Yun', '']]"
1367467,2010.11137,Yan Zeng,Yan Zeng and Jian-Yun Nie,Multi-Domain Dialogue State Tracking based on State Graph,"9 pages, 3 figures",,,,cs.CL cs.AI cs.HC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We investigate the problem of multi-domain Dialogue State Tracking (DST) with
open vocabulary, which aims to extract the state from the dialogue. Existing
approaches usually concatenate previous dialogue state with dialogue history as
the input to a bi-directional Transformer encoder. They rely on the
self-attention mechanism of Transformer to connect tokens in them. However,
attention may be paid to spurious connections, leading to wrong inference. In
this paper, we propose to construct a dialogue state graph in which domains,
slots and values from the previous dialogue state are connected properly.
Through training, the graph node and edge embeddings can encode co-occurrence
relations between domain-domain, slot-slot and domain-slot, reflecting the
strong transition paths in general dialogue. The state graph, encoded with
relational-GCN, is fused into the Transformer encoder. Experimental results
show that our approach achieves a new state of the art on the task while
remaining efficient. It outperforms existing open-vocabulary DST approaches.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 16:55:18 GMT'}]",2020-10-22,"[['Zeng', 'Yan', ''], ['Nie', 'Jian-Yun', '']]"
1367462,2010.11132,Te I,"Daniel Li, Te I, Naveen Arivazhagan, Colin Cherry, Dirk Padfield",Sentence Boundary Augmentation For Neural Machine Translation Robustness,"5 pages, 4 figures",,,,cs.CL cs.LG cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Neural Machine Translation (NMT) models have demonstrated strong state of the
art performance on translation tasks where well-formed training and evaluation
data are provided, but they remain sensitive to inputs that include errors of
various types. Specifically, in the context of long-form speech translation
systems, where the input transcripts come from Automatic Speech Recognition
(ASR), the NMT models have to handle errors including phoneme substitutions,
grammatical structure, and sentence boundaries, all of which pose challenges to
NMT robustness. Through in-depth error analysis, we show that sentence boundary
segmentation has the largest impact on quality, and we develop a simple data
augmentation strategy to improve segmentation robustness.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 16:44:48 GMT'}]",2020-10-22,"[['Li', 'Daniel', ''], ['I', 'Te', ''], ['Arivazhagan', 'Naveen', ''], ['Cherry', 'Colin', ''], ['Padfield', 'Dirk', '']]"
1367455,2010.11125,Angela Fan,"Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky,
  Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav
  Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky, Sergey Edunov,
  Edouard Grave, Michael Auli, Armand Joulin",Beyond English-Centric Multilingual Machine Translation,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Existing work in translation demonstrated the potential of massively
multilingual machine translation by training a single model able to translate
between any pair of languages. However, much of this work is English-Centric by
training only on data which was translated from or to English. While this is
supported by large sources of training data, it does not reflect translation
needs worldwide. In this work, we create a true Many-to-Many multilingual
translation model that can translate directly between any pair of 100
languages. We build and open source a training dataset that covers thousands of
language directions with supervised data, created through large-scale mining.
Then, we explore how to effectively increase model capacity through a
combination of dense scaling and language-specific sparse parameters to create
high quality models. Our focus on non-English-Centric models brings gains of
more than 10 BLEU when directly translating between non-English directions
while performing competitively to the best single systems of WMT. We
open-source our scripts so that others may reproduce the data, evaluation, and
final M2M-100 model.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 17:01:23 GMT'}]",2020-10-22,"[['Fan', 'Angela', ''], ['Bhosale', 'Shruti', ''], ['Schwenk', 'Holger', ''], ['Ma', 'Zhiyi', ''], ['El-Kishky', 'Ahmed', ''], ['Goyal', 'Siddharth', ''], ['Baines', 'Mandeep', ''], ['Celebi', 'Onur', ''], ['Wenzek', 'Guillaume', ''], ['Chaudhary', 'Vishrav', ''], ['Goyal', 'Naman', ''], ['Birch', 'Tom', ''], ['Liptchinsky', 'Vitaliy', ''], ['Edunov', 'Sergey', ''], ['Grave', 'Edouard', ''], ['Auli', 'Michael', ''], ['Joulin', 'Armand', '']]"
1367483,2010.11153,Tsz Kin Lam,"Tsz Kin Lam, Shigehiko Schamoni, Stefan Riezler",Cascaded Models With Cyclic Feedback For Direct Speech Translation,"5 pages, 1 figure",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Direct speech translation describes a scenario where only speech inputs and
corresponding translations are available. Such data are notoriously limited. We
present a technique that allows cascades of automatic speech recognition (ASR)
and machine translation (MT) to exploit in-domain direct speech translation
data in addition to out-of-domain MT and ASR data. After pre-training MT and
ASR, we use a feedback cycle where the downstream performance of the MT system
is used as a signal to improve the ASR system by self-training, and the MT
component is fine-tuned on multiple ASR outputs, making it more tolerant
towards spelling variations. A comparison to end-to-end speech translation
using components of identical architecture and the same data shows gains of up
to 3.8 BLEU points on LibriVoxDeEn and up to 5.1 BLEU points on CoVoST for
German-to-English speech translation.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 17:18:51 GMT'}]",2020-10-22,"[['Lam', 'Tsz Kin', ''], ['Schamoni', 'Shigehiko', ''], ['Riezler', 'Stefan', '']]"
1367453,2010.11123,Daniel Ajisafe,"Daniel Ajisafe, Oluwabukola Adegboro, Esther Oduntan, Tayo Arulogun","Towards End-to-End Training of Automatic Speech Recognition for Nigerian
  Pidgin",To appear in ICASSP 2021,,,,eess.AS cs.AI cs.CL cs.LG cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Nigerian Pidgin remains one of the most popular languages in West Africa.
With at least 75 million speakers along the West African coast, the language
has spread to diasporic communities through Nigerian immigrants in England,
Canada, and America, amongst others. In contrast, the language remains an
under-resourced one in the field of natural language processing, particularly
on speech recognition and translation tasks. In this work, we present the first
parallel (speech-to-text) data on Nigerian pidgin. We also trained the first
end-to-end speech recognition system (QuartzNet and Jasper model) on this
language which were both optimized using Connectionist Temporal Classification
(CTC) loss. With baseline results, we were able to achieve a low word error
rate (WER) of 0.77% using a greedy decoder on our dataset. Finally, we
open-source the data and code along with this publication in order to encourage
future research in this direction.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 16:32:58 GMT'}]",2020-10-22,"[['Ajisafe', 'Daniel', ''], ['Adegboro', 'Oluwabukola', ''], ['Oduntan', 'Esther', ''], ['Arulogun', 'Tayo', '']]"
1367449,2010.11119,Torsten Scholak,"Torsten Scholak, Raymond Li, Dzmitry Bahdanau, Harm de Vries, Chris
  Pal",DuoRAT: Towards Simpler Text-to-SQL Models,Code is available at https://github.com/ElementAI/duorat,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent research has shown that neural text-to-SQL models can effectively
translate natural language questions into corresponding SQL queries on unseen
databases. Working mostly on the Spider dataset, researchers have been
proposing increasingly sophisticated modelling approaches to the problem.
Contrary to this trend, in this paper we identify the aspects in which
text-to-SQL models can be simplified. We begin by building DuoRAT, a
re-implementation of the state-of-the-art RAT-SQL model that unlike RAT-SQL is
using only relation-aware or vanilla transformers as the building blocks. We
perform several ablation experiments using DuoRAT as the baseline model. Our
experiments confirm the usefulness of some of the techniques and point out the
redundancy of others, including structural SQL features and features that link
the question with the schema.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 16:27:49 GMT'}]",2020-10-22,"[['Scholak', 'Torsten', ''], ['Li', 'Raymond', ''], ['Bahdanau', 'Dzmitry', ''], ['de Vries', 'Harm', ''], ['Pal', 'Chris', '']]"
1367422,2010.11092,Rian Adam Rajagede,Rian Adam Rajagede and Rochana Prih Hastuti,Stacking Neural Network Models for Automatic Short Answer Scoring,"submitted to The 5th International Conference on Information
  Technology and Digital Applications 2020",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automatic short answer scoring is one of the text classification problems to
assess students' answers during exams automatically. Several challenges can
arise in making an automatic short answer scoring system, one of which is the
quantity and quality of the data. The data labeling process is not easy because
it requires a human annotator who is an expert in their field. Further, the
data imbalance process is also a challenge because the number of labels for
correct answers is always much less than the wrong answers. In this paper, we
propose the use of a stacking model based on neural network and XGBoost for
classification process with sentence embedding feature. We also propose to use
data upsampling method to handle imbalance classes and hyperparameters
optimization algorithm to find a robust model automatically. We use Ukara 1.0
Challenge dataset and our best model obtained an F1-score of 0.821 exceeding
the previous work at the same dataset.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 16:00:09 GMT'}]",2020-10-22,"[['Rajagede', 'Rian Adam', ''], ['Hastuti', 'Rochana Prih', '']]"
1367421,2010.11091,Mohiuddin Md Abdul Qudar,"Mohiuddin Md Abdul Qudar, Vijay Mago","TweetBERT: A Pretrained Language Representation Model for Twitter Text
  Analysis",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Twitter is a well-known microblogging social site where users express their
views and opinions in real-time. As a result, tweets tend to contain valuable
information. With the advancements of deep learning in the domain of natural
language processing, extracting meaningful information from tweets has become a
growing interest among natural language researchers. Applying existing language
representation models to extract information from Twitter does not often
produce good results. Moreover, there is no existing language representation
models for text analysis specific to the social media domain. Hence, in this
article, we introduce two TweetBERT models, which are domain specific language
presentation models, pre-trained on millions of tweets. We show that the
TweetBERT models significantly outperform the traditional BERT models in
Twitter text mining tasks by more than 7% on each Twitter dataset. We also
provide an extensive analysis by evaluating seven BERT models on 31 different
datasets. Our results validate our hypothesis that continuously training
language models on twitter corpus help performance with Twitter.
","[{'version': 'v1', 'created': 'Sat, 17 Oct 2020 00:45:02 GMT'}]",2020-10-22,"[['Qudar', 'Mohiuddin Md Abdul', ''], ['Mago', 'Vijay', '']]"
1367419,2010.11089,U\u{g}ur Merto\u{g}lu,U\u{g}ur Merto\u{g}lu Burkay Gen\c{c},Lexicon generation for detecting fake news,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  With the digitization of media, an immense amount of news data has been
generated by online sources, including mainstream media outlets as well as
social networks. However, the ease of production and distribution resulted in
circulation of fake news as well as credible, authentic news. The pervasive
dissemination of fake news has extreme negative impacts on individuals and
society. Therefore, fake news detection has recently become an emerging topic
as an interdisciplinary research field that is attracting significant attention
from many research disciplines, including social sciences and linguistics. In
this study, we propose a method primarily based on lexicons including a scoring
system to facilitate the detection of the fake news in Turkish. We contribute
to the literature by collecting a novel, large scale, and credible dataset of
Turkish news, and by constructing the first fake news detection lexicon for
Turkish.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 20:39:57 GMT'}]",2020-10-22,"[['Genç', 'Uğur Mertoğlu Burkay', '']]"
1367415,2010.11085,Sai Muralidhar Jayanthi,"Sai Muralidhar Jayanthi, Danish Pruthi, Graham Neubig",NeuSpell: A Neural Spelling Correction Toolkit,Accepted at EMNLP 2020 (system demonstrations),,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We introduce NeuSpell, an open-source toolkit for spelling correction in
English. Our toolkit comprises ten different models, and benchmarks them on
naturally occurring misspellings from multiple sources. We find that many
systems do not adequately leverage the context around the misspelt token. To
remedy this, (i) we train neural models using spelling errors in context,
synthetically constructed by reverse engineering isolated misspellings; and
(ii) use contextual representations. By training on our synthetic examples,
correction rates improve by 9% (absolute) compared to the case when models are
trained on randomly sampled character perturbations. Using richer contextual
representations boosts the correction rate by another 3%. Our toolkit enables
practitioners to use our proposed and existing spelling correction systems,
both via a unified command line, as well as a web interface. Among many
potential applications, we demonstrate the utility of our spell-checkers in
combating adversarial misspellings. The toolkit can be accessed at
neuspell.github.io. Code and pretrained models are available at
http://github.com/neuspell/neuspell.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 15:53:29 GMT'}]",2020-10-22,"[['Jayanthi', 'Sai Muralidhar', ''], ['Pruthi', 'Danish', ''], ['Neubig', 'Graham', '']]"
1367410,2010.11080,Tao Yu,"Tao Yu, Shafiq Joty",Online Conversation Disentanglement with Pointer Networks,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Huge amounts of textual conversations occur online every day, where multiple
conversations take place concurrently. Interleaved conversations lead to
difficulties in not only following the ongoing discussions but also extracting
relevant information from simultaneous messages. Conversation disentanglement
aims to separate intermingled messages into detached conversations. However,
existing disentanglement methods rely mostly on handcrafted features that are
dataset specific, which hinders generalization and adaptability. In this work,
we propose an end-to-end online framework for conversation disentanglement that
avoids time-consuming domain-specific feature engineering. We design a novel
way to embed the whole utterance that comprises timestamp, speaker, and message
text, and proposes a custom attention mechanism that models disentanglement as
a pointing problem while effectively capturing inter-utterance interactions in
an end-to-end fashion. We also introduce a joint-learning objective to better
capture contextual information. Our experiments on the Ubuntu IRC dataset show
that our method achieves state-of-the-art performance in both link and
conversation prediction tasks.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 15:43:07 GMT'}]",2020-10-22,"[['Yu', 'Tao', ''], ['Joty', 'Shafiq', '']]"
1319317,2007.07803,Anant Khandelwal,Anant Khandelwal,Fine-Tune Longformer for Jointly Predicting Rumor Stance and Veracity,"10 pages, 2 figures, 6 tables; Accepted at ACM CoDS-COMAD 2021",,10.1145/3430984.3431007,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Increased usage of social media caused the popularity of news and events
which are not even verified, resulting in spread of rumors allover the web. Due
to widely available social media platforms and increased usage caused the data
to be available in huge amounts.The manual methods to process such large data
is costly and time-taking, so there has been an increased attention to process
and verify such content automatically for the presence of rumors. A lot of
research studies reveal that to identify the stances of posts in the discussion
thread of such events and news is an important preceding step before identify
the rumor veracity. In this paper,we propose a multi-task learning framework
for jointly predicting rumor stance and veracity on the dataset released at
SemEval 2019 RumorEval: Determining rumor veracity and support for
rumors(SemEval 2019 Task 7), which includes social media rumors stem from a
variety of breaking news stories from Reddit as well as Twit-ter. Our framework
consists of two parts: a) The bottom part of our framework classifies the
stance for each post in the conversation thread discussing a rumor via
modelling the multi-turn conversation and make each post aware of its
neighboring posts. b) The upper part predicts the rumor veracity of the
conversation thread with stance evolution obtained from the bottom part.
Experimental results on SemEval 2019 Task 7 dataset show that our method
outperforms previous methods on both rumor stance classification and veracity
prediction
","[{'version': 'v1', 'created': 'Wed, 15 Jul 2020 17:09:17 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 11:25:20 GMT'}]",2020-10-23,"[['Khandelwal', 'Anant', '']]"
1365058,2010.08728,Jin Xu,"Jin Xu, Yinuo Guo, Junfeng Hu","Incorporate Semantic Structures into Machine Translation Evaluation via
  UCCA",WMT2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Copying mechanism has been commonly used in neural paraphrasing networks and
other text generation tasks, in which some important words in the input
sequence are preserved in the output sequence. Similarly, in machine
translation, we notice that there are certain words or phrases appearing in all
good translations of one source text, and these words tend to convey important
semantic information. Therefore, in this work, we define words carrying
important semantic meanings in sentences as semantic core words. Moreover, we
propose an MT evaluation approach named Semantically Weighted Sentence
Similarity (SWSS). It leverages the power of UCCA to identify semantic core
words, and then calculates sentence similarity scores on the overlap of
semantic core words. Experimental results show that SWSS can consistently
improve the performance of popular MT evaluation metrics which are based on
lexical similarity.
","[{'version': 'v1', 'created': 'Sat, 17 Oct 2020 06:47:58 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 03:38:19 GMT'}]",2020-10-23,"[['Xu', 'Jin', ''], ['Guo', 'Yinuo', ''], ['Hu', 'Junfeng', '']]"
1142383,1906.10197,Kanishk Gandhi,Kanishk Gandhi and Brenden M. Lake,Mutual exclusivity as a challenge for deep neural networks,"Published in Advances in Neural Information Processing Systems
  (NeurIPS) 33",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Strong inductive biases allow children to learn in fast and adaptable ways.
Children use the mutual exclusivity (ME) bias to help disambiguate how words
map to referents, assuming that if an object has one label then it does not
need another. In this paper, we investigate whether or not standard neural
architectures have an ME bias, demonstrating that they lack this learning
assumption. Moreover, we show that their inductive biases are poorly matched to
lifelong learning formulations of classification and translation. We
demonstrate that there is a compelling case for designing neural networks that
reason by mutual exclusivity, which remains an open challenge.
","[{'version': 'v1', 'created': 'Mon, 24 Jun 2019 19:47:05 GMT'}, {'version': 'v2', 'created': 'Fri, 6 Dec 2019 18:51:28 GMT'}, {'version': 'v3', 'created': 'Wed, 21 Oct 2020 21:50:33 GMT'}]",2020-10-23,"[['Gandhi', 'Kanishk', ''], ['Lake', 'Brenden M.', '']]"
1367934,2010.11604,Changzhen Ji,"Changzhen Ji, Conghui Zhu and Tiejun Zhao",AI-lead Court Debate Case Investigation,"4 pages, 2 figures",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The multi-role judicial debate composed of the plaintiff, defendant, and
judge is an important part of the judicial trial. Different from other types of
dialogue, questions are raised by the judge, The plaintiff, plaintiff's agent
defendant, and defendant's agent would be to debating so that the trial can
proceed in an orderly manner. Question generation is an important task in
Natural Language Generation. In the judicial trial, it can help the judge raise
efficient questions so that the judge has a clearer understanding of the case.
In this work, we propose an innovative end-to-end question generation
model-Trial Brain Model (TBM) to build a Trial Brain, it can generate the
questions the judge wants to ask through the historical dialogue between the
plaintiff and the defendant. Unlike prior efforts in natural language
generation, our model can learn the judge's questioning intention through
predefined knowledge. We do experiments on real-world datasets, the
experimental results show that our model can provide a more accurate question
in the multi-role court debate scene.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 11:05:14 GMT'}]",2020-10-23,"[['Ji', 'Changzhen', ''], ['Zhu', 'Conghui', ''], ['Zhao', 'Tiejun', '']]"
1333495,2008.05773,Yu Wu,"Sanyuan Chen, Yu Wu, Zhuo Chen, Jian Wu, Jinyu Li, Takuya Yoshioka,
  Chengyi Wang, Shujie Liu, Ming Zhou",Continuous Speech Separation with Conformer,,,,,eess.AS cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Continuous speech separation plays a vital role in complicated speech related
tasks such as conversation transcription. The separation model extracts a
single speaker signal from a mixed speech. In this paper, we use transformer
and conformer in lieu of recurrent neural networks in the separation system, as
we believe capturing global information with the self-attention based method is
crucial for the speech separation. Evaluating on the LibriCSS dataset, the
conformer separation model achieves state of the art results, with a relative
23.5% word error rate (WER) reduction from bi-directional LSTM (BLSTM) in the
utterance-wise evaluation and a 15.4% WER reduction in the continuous
evaluation.
","[{'version': 'v1', 'created': 'Thu, 13 Aug 2020 09:36:05 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 12:38:51 GMT'}]",2020-10-23,"[['Chen', 'Sanyuan', ''], ['Wu', 'Yu', ''], ['Chen', 'Zhuo', ''], ['Wu', 'Jian', ''], ['Li', 'Jinyu', ''], ['Yoshioka', 'Takuya', ''], ['Wang', 'Chengyi', ''], ['Liu', 'Shujie', ''], ['Zhou', 'Ming', '']]"
1204524,1911.05930,Ruobing Xie,"Ruobing Xie, Yanan Lu, Fen Lin, Leyu Lin",FAQ-based Question Answering via Knowledge Anchors,"12 pages, accepted by NLPCC-2020",NLPCC-2020,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Question answering (QA) aims to understand questions and find appropriate
answers. In real-world QA systems, Frequently Asked Question (FAQ) based QA is
usually a practical and effective solution, especially for some complicated
questions (e.g., How and Why). Recent years have witnessed the great successes
of knowledge graphs (KGs) in KBQA systems, while there are still few works
focusing on making full use of KGs in FAQ-based QA. In this paper, we propose a
novel Knowledge Anchor based Question Answering (KAQA) framework for FAQ-based
QA to better understand questions and retrieve more appropriate answers. More
specifically, KAQA mainly consists of three modules: knowledge graph
construction, query anchoring and query-document matching. We consider entities
and triples of KGs in texts as knowledge anchors to precisely capture the core
semantics, which brings in higher precision and better interpretability. The
multi-channel matching strategy also enables most sentence matching models to
be flexibly plugged in our KAQA framework to fit different real-world
computation limitations. In experiments, we evaluate our models on both offline
and online query-document matching tasks on a real-world FAQ-based QA system in
WeChat Search, with detailed analysis, ablation tests and case studies. The
significant improvements confirm the effectiveness and robustness of the KAQA
framework in real-world FAQ-based QA.
","[{'version': 'v1', 'created': 'Thu, 14 Nov 2019 04:18:55 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 07:50:31 GMT'}]",2020-10-23,"[['Xie', 'Ruobing', ''], ['Lu', 'Yanan', ''], ['Lin', 'Fen', ''], ['Lin', 'Leyu', '']]"
1367923,2010.11593,Hari Krishna Vydana Mr,"Hari Krishna Vydana, Lukas Burget, Jan Cernocky",A Technical Report: BUT Speech Translation Systems,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The paper describes the BUT's speech translation systems. The systems are
English$\longrightarrow$German offline speech translation systems. The systems
are based on our previous works \cite{Jointly_trained_transformers}. Though
End-to-End and cascade~(ASR-MT) spoken language translation~(SLT) systems are
reaching comparable performances, a large degradation is observed when
translating ASR hypothesis compared to the oracle input text. To reduce this
performance degradation, we have jointly-trained ASR and MT modules with ASR
objective as an auxiliary loss. Both the networks are connected through the
neural hidden representations. This model has an End-to-End differentiable path
with respect to the final objective function and also utilizes the ASR
objective for better optimization. During the inference both the modules(i.e.,
ASR and MT) are connected through the hidden representations corresponding to
the n-best hypotheses. Ensembling with independently trained ASR and MT models
have further improved the performance of the system.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 10:52:31 GMT'}]",2020-10-23,"[['Vydana', 'Hari Krishna', ''], ['Burget', 'Lukas', ''], ['Cernocky', 'Jan', '']]"
1367908,2010.11578,Navita Goyal,"Navita Goyal, Balaji Vasan Srinivasan, Anandhavelu N, Abhilasha
  Sancheti","Multi-dimensional Style Transfer for Partially Annotated Data using
  Language Models as Discriminators",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Style transfer has been widely explored in natural language generation with
non-parallel corpus by directly or indirectly extracting a notion of style from
source and target domain corpus. A common aspect among the existing approaches
is the prerequisite of joint annotations across all the stylistic dimensions
under consideration. Availability of such dataset across a combination of
styles is a limiting factor in extending state-of-the art style transfer setups
to multiple style dimensions. While cascading single-dimensional models across
multiple styles is a possibility, it suffers from content loss, especially when
the style dimensions are not completely independent of each other. In our work,
we attempt to relax this restriction on requirement of jointly annotated data
across multiple styles being inspected and make use of independently acquired
data across different style dimensions without any additional annotations. We
initialize an encoder-decoder setup with large transformer-based language
models pre-trained on a generic corpus and enhance its re-writing capability to
multiple styles by employing multiple language models as discriminators.
Through quantitative and qualitative evaluation, we show the ability of our
model to control for styles across multiple style-dimensions while preserving
content of the input text and compare it against baselines which involve
cascaded state-of-the-art uni-dimensional style transfer models.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 10:16:29 GMT'}]",2020-10-23,"[['Goyal', 'Navita', ''], ['Srinivasan', 'Balaji Vasan', ''], ['N', 'Anandhavelu', ''], ['Sancheti', 'Abhilasha', '']]"
1367892,2010.11562,Amit Gajbhiye,"Amit Gajbhiye, Thomas Winterbottom, Noura Al Moubayed, and Steven
  Bradley",Bilinear Fusion of Commonsense Knowledge with Attention-Based NLI Models,"Published in Lecture Notes in Computer Science, Springer
  International Publishing",,10.1007/978-3-030-61609-0_50,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We consider the task of incorporating real-world commonsense knowledge into
deep Natural Language Inference (NLI) models. Existing external knowledge
incorporation methods are limited to lexical level knowledge and lack
generalization across NLI models, datasets, and commonsense knowledge sources.
To address these issues, we propose a novel NLI model-independent neural
framework, BiCAM. BiCAM incorporates real-world commonsense knowledge into NLI
models. Combined with convolutional feature detectors and bilinear feature
fusion, BiCAM provides a conceptually simple mechanism that generalizes well.
Quantitative evaluations with two state-of-the-art NLI baselines on SNLI and
SciTail datasets in conjunction with ConceptNet and Aristo Tuple KGs show that
BiCAM considerably improves the accuracy the incorporated NLI baselines. For
example, our BiECAM model, an instance of BiCAM, on the challenging SciTail
dataset, improves the accuracy of incorporated baselines by 7.0% with
ConceptNet, and 8.0% with Aristo Tuple KG.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 09:38:08 GMT'}]",2020-10-23,"[['Gajbhiye', 'Amit', ''], ['Winterbottom', 'Thomas', ''], ['Moubayed', 'Noura Al', ''], ['Bradley', 'Steven', '']]"
1274117,2004.09347,Abhishek Niranjan,"Abhishek Niranjan, Mukesh Sharma, Sai Bharath Chandra Gutha, M Ali
  Basha Shaik","WHALETRANS: E2E WHisper to nAturaL spEech conversion using modified
  TRANSformer network",,,,,eess.AS cs.CL cs.LG cs.SD stat.ML,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  We investigate whisper-to-natural-speech conversion using
sequence-to-sequence approach by proposing modified transformer architecture.
We investigate different features like mel frequency cepstral coefficients and
smoothed spectral features. The proposed networks are trained end-to-end using
supervised approach for feature-to-feature transformation. Further, We also
investigate the effectiveness of embedded auxiliary decoder used after N
encoder sub-layers, and is trained with the frame-level objective function for
identifying source phoneme labels. We show results on wTIMIT and CHAINS
datasets by measuring word error rate using end-to-end ASR and also BLEU scores
for the generated speech. In addition, we measure spectral shape of it by
measuring formant distributions w.r.t. the reference speech, as formant
divergence metric. We have found whisper-to-natural converted speech formants
probability distribution is similar to the ground-truth distribution. To the
authors' best knowledge, this is the first time modified transformer has been
applied for whisper-to-natural-speech conversion and vice versa.
","[{'version': 'v1', 'created': 'Mon, 20 Apr 2020 14:47:46 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 07:08:37 GMT'}]",2020-10-23,"[['Niranjan', 'Abhishek', ''], ['Sharma', 'Mukesh', ''], ['Gutha', 'Sai Bharath Chandra', ''], ['Shaik', 'M Ali Basha', '']]"
1367854,2010.11524,Tatiana Likhomanenko,"Tatiana Likhomanenko, Qiantong Xu, Jacob Kahn, Gabriel Synnaeve, Ronan
  Collobert",slimIPL: Language-Model-Free Iterative Pseudo-Labeling,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent results in end-to-end ASR have demonstrated the efficacy of simple
pseudo-labeling for semi-supervised models trained both with Connectionist
Temporal Classification (CTC) and Sequence-to-Sequence (seq2seq) losses.
Iterative Pseudo-Labeling (IPL), which continuously trains a single model using
pseudo-labels iteratively re-generated as the model learns, has been shown to
further increase performance in ASR. We improve upon the IPL algorithm: as the
model learns, we propose to iteratively re-generate transcriptions with hard
labels (the most probable tokens) assignments, that is without a language
model. We call this approach Language-Model-Free IPL (slimIPL) and we give a
resultant training setup for CTC and seq2seq models. At inference, our
experiments show that decoding with a strong language model is more beneficial
with slimIPL than IPL, asIPL exhibits some language model over-fitting issues.
Compared to prior work on semi-supervised and unsupervised approaches, slimIPL
not only simplifies the training process, but also achieves competitive and
state-of-the-art results on LibriSpeech test sets in both standard and
low-resource settings.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 08:36:33 GMT'}]",2020-10-23,"[['Likhomanenko', 'Tatiana', ''], ['Xu', 'Qiantong', ''], ['Kahn', 'Jacob', ''], ['Synnaeve', 'Gabriel', ''], ['Collobert', 'Ronan', '']]"
1278659,2004.13889,Tasnim Mohiuddin,"Tasnim Mohiuddin, M Saiful Bari, and Shafiq Joty","LNMap: Departures from Isomorphic Assumption in Bilingual Lexicon
  Induction Through Non-Linear Mapping in Latent Space",EMNLP 2020 accepted paper,,,,cs.CL cs.LG,http://creativecommons.org/publicdomain/zero/1.0/,"  Most of the successful and predominant methods for bilingual lexicon
induction (BLI) are mapping-based, where a linear mapping function is learned
with the assumption that the word embedding spaces of different languages
exhibit similar geometric structures (i.e., approximately isomorphic). However,
several recent studies have criticized this simplified assumption showing that
it does not hold in general even for closely related languages. In this work,
we propose a novel semi-supervised method to learn cross-lingual word
embeddings for BLI. Our model is independent of the isomorphic assumption and
uses nonlinear mapping in the latent space of two independently trained
auto-encoders. Through extensive experiments on fifteen (15) different language
pairs (in both directions) comprising resource-rich and low-resource languages
from two different datasets, we demonstrate that our method outperforms
existing models by a good margin. Ablation studies show the importance of
different model components and the necessity of non-linear mapping.
","[{'version': 'v1', 'created': 'Tue, 28 Apr 2020 23:28:26 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 00:42:16 GMT'}]",2020-10-23,"[['Mohiuddin', 'Tasnim', ''], ['Bari', 'M Saiful', ''], ['Joty', 'Shafiq', '']]"
1367883,2010.11553,Hrituraj Singh,"Hrituraj Singh, Gaurav Verma, Balaji Vasan Srinivasan","Incorporating Stylistic Lexical Preferences in Generative Language
  Models",To Appear in Findings of EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While recent advances in language modeling have resulted in powerful
generation models, their generation style remains implicitly dependent on the
training data and can not emulate a specific target style. Leveraging the
generative capabilities of a transformer-based language models, we present an
approach to induce certain target-author attributes by incorporating continuous
multi-dimensional lexical preferences of an author into generative language
models. We introduce rewarding strategies in a reinforcement learning framework
that encourages the use of words across multiple categorical dimensions, to
varying extents. Our experiments demonstrate that the proposed approach can
generate text that distinctively aligns with a given target author's lexical
style. We conduct quantitative and qualitative comparisons with competitive and
relevant baselines to illustrate the benefits of the proposed approach.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 09:24:05 GMT'}]",2020-10-23,"[['Singh', 'Hrituraj', ''], ['Verma', 'Gaurav', ''], ['Srinivasan', 'Balaji Vasan', '']]"
1367878,2010.11548,Artem Kramov,"S.D. Pogorilyy, A.A. Kramov",Method of noun phrase detection in Ukrainian texts,"25 pages, in Ukrainian, 5 figures, 2 tables",Control Systems and Computers. 2019. Issue 5. P. 48-59,10.15407/csc.2019.05.048,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Introduction. The area of natural language processing considers AI-complete
tasks that cannot be solved using traditional algorithmic actions. Such tasks
are commonly implemented with the usage of machine learning methodology and
means of computer linguistics. One of the preprocessing tasks of a text is the
search of noun phrases. The accuracy of this task has implications for the
effectiveness of many other tasks in the area of natural language processing.
In spite of the active development of research in the area of natural language
processing, the investigation of the search for noun phrases within Ukrainian
texts are still at an early stage. Results. The different methods of noun
phrases detection have been analyzed. The expediency of the representation of
sentences as a tree structure has been justified. The key disadvantage of many
methods of noun phrase detection is the severe dependence of the effectiveness
of their detection from the features of a certain language. Taking into account
the unified format of sentence processing and the availability of the trained
model for the building of sentence trees for Ukrainian texts, the Universal
Dependency model has been chosen. The complex method of noun phrases detection
in Ukrainian texts utilizing Universal Dependencies means and named-entity
recognition model has been suggested. Experimental verification of the
effectiveness of the suggested method on the corpus of Ukrainian news has been
performed. Different metrics of method accuracy have been calculated.
Conclusions. The results obtained can indicate that the suggested method can be
used to find noun phrases in Ukrainian texts. An accuracy increase of the
method can be made with the usage of appropriate named-entity recognition
models according to a subject area.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 09:20:24 GMT'}]",2020-10-23,"[['Pogorilyy', 'S. D.', ''], ['Kramov', 'A. A.', '']]"
1206964,1911.08370,Vladimir Vargas-Calder\'on,"Vladimir Vargas-Calder\'on and Nicol\'as Parra-A. and Jorge E. Camargo
  and Herbert Vinck-Posada","Event detection in Colombian security Twitter news using fine-grained
  latent topic analysis","pre-print exposed at CATAI (Bogot\'a, Colombia)",,,,cs.SI cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Cultural and social dynamics are important concepts that must be understood
in order to grasp what a community cares about. To that end, an excellent
source of information on what occurs in a community is the news, especially in
recent years, when mass media giants use social networks to communicate and
interact with their audience. In this work, we use a method to discover latent
topics in tweets from Colombian Twitter news accounts in order to identify the
most prominent events in the country. We pay particular attention to security,
violence and crime-related tweets because of the violent environment that
surrounds Colombian society. The latent topic discovery method that we use
builds vector representations of the tweets by using FastText and finds
clusters of tweets through the K-means clustering algorithm. The number of
clusters is found by measuring the $C_V$ coherence for a range of number of
topics of the Latent Dirichlet Allocation (LDA) model. We finally use Uniform
Manifold Approximation and Projection (UMAP) for dimensionality reduction to
visualise the tweets vectors. Once the clusters related to security, violence
and crime are identified, we proceed to apply the same method within each
cluster to perform a fine-grained analysis in which specific events mentioned
in the news are grouped together. Our method is able to discover event-specific
sets of news, which is the baseline to perform an extensive analysis of how
people engage in Twitter threads on the different types of news, with an
emphasis on security, violence and crime-related tweets.
","[{'version': 'v1', 'created': 'Tue, 19 Nov 2019 15:58:14 GMT'}]",2020-10-23,"[['Vargas-Calderón', 'Vladimir', ''], ['Parra-A.', 'Nicolás', ''], ['Camargo', 'Jorge E.', ''], ['Vinck-Posada', 'Herbert', '']]"
1366378,2010.10048,Renjie Zheng,"Renjie Zheng, Mingbo Ma, Baigong Zheng, Kaibo Liu, Jiahong Yuan,
  Kenneth Church, Liang Huang","Fluent and Low-latency Simultaneous Speech-to-Speech Translation with
  Self-adaptive Training","10 pages, accepted by Findings of EMNLP 2020",Findings of EMNLP 2020,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Simultaneous speech-to-speech translation is widely useful but extremely
challenging, since it needs to generate target-language speech concurrently
with the source-language speech, with only a few seconds delay. In addition, it
needs to continuously translate a stream of sentences, but all recent solutions
merely focus on the single-sentence scenario. As a result, current approaches
accumulate latencies progressively when the speaker talks faster, and introduce
unnatural pauses when the speaker talks slower. To overcome these issues, we
propose Self-Adaptive Translation (SAT) which flexibly adjusts the length of
translations to accommodate different source speech rates. At similar levels of
translation quality (as measured by BLEU), our method generates more fluent
target speech (as measured by the naturalness metric MOS) with substantially
lower latency than the baseline, in both Zh <-> En directions.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 06:02:15 GMT'}, {'version': 'v2', 'created': 'Wed, 21 Oct 2020 19:12:17 GMT'}]",2020-10-23,"[['Zheng', 'Renjie', ''], ['Ma', 'Mingbo', ''], ['Zheng', 'Baigong', ''], ['Liu', 'Kaibo', ''], ['Yuan', 'Jiahong', ''], ['Church', 'Kenneth', ''], ['Huang', 'Liang', '']]"
1367869,2010.11539,Changzhen Ji,"Changzhen Ji, Xin Zhou, Yating Zhang, Xiaozhong Liu, Changlong Sun,
  Conghui Zhu and Tiejun Zhao",Cross Copy Network for Dialogue Generation,"11 pages, 4 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In the past few years, audiences from different fields witness the
achievements of sequence-to-sequence models (e.g., LSTM+attention, Pointer
Generator Networks, and Transformer) to enhance dialogue content generation.
While content fluency and accuracy often serve as the major indicators for
model training, dialogue logics, carrying critical information for some
particular domains, are often ignored. Take customer service and court debate
dialogue as examples, compatible logics can be observed across different
dialogue instances, and this information can provide vital evidence for
utterance generation. In this paper, we propose a novel network architecture -
Cross Copy Networks(CCN) to explore the current dialog context and similar
dialogue instances' logical structure simultaneously. Experiments with two
tasks, court debate and customer service content generation, proved that the
proposed algorithm is superior to existing state-of-art content generation
models.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 09:03:23 GMT'}]",2020-10-23,"[['Ji', 'Changzhen', ''], ['Zhou', 'Xin', ''], ['Zhang', 'Yating', ''], ['Liu', 'Xiaozhong', ''], ['Sun', 'Changlong', ''], ['Zhu', 'Conghui', ''], ['Zhao', 'Tiejun', '']]"
1367904,2010.11574,Jan Christian Blaise Cruz,"Jan Christian Blaise Cruz, Jose Kristian Resabal, James Lin, Dan John
  Velasco and Charibeth Cheng","Investigating the True Performance of Transformers in Low-Resource
  Languages: A Case Study in Automatic Corpus Creation","Code and data available at
  https://github.com/jcblaisecruz02/Filipino-Text-Benchmarks",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Transformers represent the state-of-the-art in Natural Language Processing
(NLP) in recent years, proving effective even in tasks done in low-resource
languages. While pretrained transformers for these languages can be made, it is
challenging to measure their true performance and capacity due to the lack of
hard benchmark datasets, as well as the difficulty and cost of producing them.
In this paper, we present three contributions: First, we propose a methodology
for automatically producing Natural Language Inference (NLI) benchmark datasets
for low-resource languages using published news articles. Through this, we
create and release NewsPH-NLI, the first sentence entailment benchmark dataset
in the low-resource Filipino language. Second, we produce new pretrained
transformers based on the ELECTRA technique to further alleviate the resource
scarcity in Filipino, benchmarking them on our dataset against other
commonly-used transfer learning techniques. Lastly, we perform analyses on
transfer learning techniques to shed light on their true performance when
operating in low-data domains through the use of degradation tests.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 10:09:10 GMT'}]",2020-10-23,"[['Cruz', 'Jan Christian Blaise', ''], ['Resabal', 'Jose Kristian', ''], ['Lin', 'James', ''], ['Velasco', 'Dan John', ''], ['Cheng', 'Charibeth', '']]"
1363409,2010.07079,Emily Dinan,"Jing Xu, Da Ju, Margaret Li, Y-Lan Boureau, Jason Weston, Emily Dinan",Recipes for Safety in Open-domain Chatbots,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Models trained on large unlabeled corpora of human interactions will learn
patterns and mimic behaviors therein, which include offensive or otherwise
toxic behavior and unwanted biases. We investigate a variety of methods to
mitigate these issues in the context of open-domain generative dialogue models.
We introduce a new human-and-model-in-the-loop framework for both training
safer models and for evaluating them, as well as a novel method to distill
safety considerations inside generative models without the use of an external
classifier at deployment time. We conduct experiments comparing these methods
and find our new techniques are (i) safer than existing models as measured by
automatic and human evaluations while (ii) maintaining usability metrics such
as engagingness relative to the state of the art. We then discuss the
limitations of this work by analyzing failure cases of our models.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 13:26:39 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 16:56:50 GMT'}]",2020-10-23,"[['Xu', 'Jing', ''], ['Ju', 'Da', ''], ['Li', 'Margaret', ''], ['Boureau', 'Y-Lan', ''], ['Weston', 'Jason', ''], ['Dinan', 'Emily', '']]"
1305991,2006.11477,Michael Auli,"Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli","wav2vec 2.0: A Framework for Self-Supervised Learning of Speech
  Representations",,,,,cs.CL cs.LG cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We show for the first time that learning powerful representations from speech
audio alone followed by fine-tuning on transcribed speech can outperform the
best semi-supervised methods while being conceptually simpler. wav2vec 2.0
masks the speech input in the latent space and solves a contrastive task
defined over a quantization of the latent representations which are jointly
learned. Experiments using all labeled data of Librispeech achieve 1.8/3.3 WER
on the clean/other test sets. When lowering the amount of labeled data to one
hour, wav2vec 2.0 outperforms the previous state of the art on the 100 hour
subset while using 100 times less labeled data. Using just ten minutes of
labeled data and pre-training on 53k hours of unlabeled data still achieves
4.8/8.2 WER. This demonstrates the feasibility of speech recognition with
limited amounts of labeled data.
","[{'version': 'v1', 'created': 'Sat, 20 Jun 2020 02:35:02 GMT'}, {'version': 'v2', 'created': 'Tue, 22 Sep 2020 04:26:03 GMT'}, {'version': 'v3', 'created': 'Thu, 22 Oct 2020 06:09:10 GMT'}]",2020-10-23,"[['Baevski', 'Alexei', ''], ['Zhou', 'Henry', ''], ['Mohamed', 'Abdelrahman', ''], ['Auli', 'Michael', '']]"
1362320,2010.05990,Jordan J. Bird,"Jordan J. Bird, Anik\'o Ek\'art, Diego R. Faria","Chatbot Interaction with Artificial Intelligence: Human Data
  Augmentation with T5 and Language Transformer Ensemble for Text
  Classification","18 pages, 10 figures, 8 tables",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this work, we present the Chatbot Interaction with Artificial Intelligence
(CI-AI) framework as an approach to the training of deep learning chatbots for
task classification. The intelligent system augments human-sourced data via
artificial paraphrasing in order to generate a large set of training data for
further classical, attention, and language transformation-based learning
approaches for Natural Language Processing. Human beings are asked to
paraphrase commands and questions for task identification for further execution
of a machine. The commands and questions are split into training and validation
sets. A total of 483 responses were recorded. Secondly, the training set is
paraphrased by the T5 model in order to augment it with further data. Seven
state-of-the-art transformer-based text classification algorithms (BERT,
DistilBERT, RoBERTa, DistilRoBERTa, XLM, XLM-RoBERTa, and XLNet) are
benchmarked for both sets after fine-tuning on the training data for two
epochs. We find that all models are improved when training data is augmented by
the T5 model, with an average increase of classification accuracy by 4.01%. The
best result was the RoBERTa model trained on T5 augmented data which achieved
98.96% classification accuracy. Finally, we found that an ensemble of the five
best-performing transformer models via Logistic Regression of output label
predictions led to an accuracy of 99.59% on the dataset of human responses. A
highly-performing model allows the intelligent system to interpret human
commands at the social-interaction level through a chatbot-like interface (e.g.
""Robot, can we have a conversation?"") and allows for better accessibility to AI
by non-technical users.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 19:37:18 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 14:33:08 GMT'}]",2020-10-23,"[['Bird', 'Jordan J.', ''], ['Ekárt', 'Anikó', ''], ['Faria', 'Diego R.', '']]"
1338905,2008.11183,Vladimir Vargas-Calder\'on,"Vladimir Vargas-Calder\'on and Juan S. Fl\'orez and Leonel F. Ardila
  and Nicolas Parra-A. and Jorge E. Camargo and Nelson Vargas",Learning from students' perception on professors through opinion mining,,,,,cs.CL cs.CY cs.NA math.NA,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Students' perception of classes measured through their opinions on teaching
surveys allows to identify deficiencies and problems, both in the environment
and in the learning methodologies. The purpose of this paper is to study,
through sentiment analysis using natural language processing (NLP) and machine
learning (ML) techniques, those opinions in order to identify topics that are
relevant for students, as well as predicting the associated sentiment via
polarity analysis. As a result, it is implemented, trained and tested two
algorithms to predict the associated sentiment as well as the relevant topics
of such opinions. The combination of both approaches then becomes useful to
identify specific properties of the students' opinions associated with each
sentiment label (positive, negative or neutral opinions) and topic.
Furthermore, we explore the possibility that students' perception surveys are
carried out without closed questions, relying on the information that students
can provide through open questions where they express their opinions about
their classes.
","[{'version': 'v1', 'created': 'Tue, 25 Aug 2020 17:36:45 GMT'}]",2020-10-23,"[['Vargas-Calderón', 'Vladimir', ''], ['Flórez', 'Juan S.', ''], ['Ardila', 'Leonel F.', ''], ['Parra-A.', 'Nicolas', ''], ['Camargo', 'Jorge E.', ''], ['Vargas', 'Nelson', '']]"
1368077,2010.11747,Ivana Kvapilikova,"Ivana Kvapil\'ikov\'a, Tom Kocmi, Ond\v{r}ej Bojar","CUNI Systems for the Unsupervised and Very Low Resource Translation Task
  in WMT20",WMT20,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents a description of CUNI systems submitted to the WMT20 task
on unsupervised and very low-resource supervised machine translation between
German and Upper Sorbian. We experimented with training on synthetic data and
pre-training on a related language pair. In the fully unsupervised scenario, we
achieved 25.5 and 23.7 BLEU translating from and into Upper Sorbian,
respectively. Our low-resource systems relied on transfer learning from
German-Czech parallel data and achieved 57.4 BLEU and 56.1 BLEU, which is an
improvement of 10 BLEU points over the baseline trained only on the available
small German-Upper Sorbian parallel corpus.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 14:04:01 GMT'}]",2020-10-23,"[['Kvapilíková', 'Ivana', ''], ['Kocmi', 'Tom', ''], ['Bojar', 'Ondřej', '']]"
1298666,2006.04152,Canwen Xu,"Wangchunshu Zhou and Canwen Xu and Tao Ge and Julian McAuley and Ke Xu
  and Furu Wei",BERT Loses Patience: Fast and Robust Inference with Early Exit,NeurIPS 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we propose Patience-based Early Exit, a straightforward yet
effective inference method that can be used as a plug-and-play technique to
simultaneously improve the efficiency and robustness of a pretrained language
model (PLM). To achieve this, our approach couples an internal-classifier with
each layer of a PLM and dynamically stops inference when the intermediate
predictions of the internal classifiers remain unchanged for a pre-defined
number of steps. Our approach improves inference efficiency as it allows the
model to make a prediction with fewer layers. Meanwhile, experimental results
with an ALBERT model show that our method can improve the accuracy and
robustness of the model by preventing it from overthinking and exploiting
multiple classifiers for prediction, yielding a better accuracy-speed trade-off
compared to existing early exit methods.
","[{'version': 'v1', 'created': 'Sun, 7 Jun 2020 13:38:32 GMT'}, {'version': 'v2', 'created': 'Mon, 29 Jun 2020 04:46:19 GMT'}, {'version': 'v3', 'created': 'Thu, 22 Oct 2020 06:37:36 GMT'}]",2020-10-23,"[['Zhou', 'Wangchunshu', ''], ['Xu', 'Canwen', ''], ['Ge', 'Tao', ''], ['McAuley', 'Julian', ''], ['Xu', 'Ke', ''], ['Wei', 'Furu', '']]"
1342550,2009.01047,Vahid Behzadan,Bibek Upadhayay and Vahid Behzadan,"Sentimental LIAR: Extended Corpus and Deep Learning Models for Fake
  Claim Classification",Accepted for publication in the proceedings of IEEE ISI '20,,,,cs.CL cs.LG cs.SI stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The rampant integration of social media in our every day lives and culture
has given rise to fast and easier access to the flow of information than ever
in human history. However, the inherently unsupervised nature of social media
platforms has also made it easier to spread false information and fake news.
Furthermore, the high volume and velocity of information flow in such platforms
make manual supervision and control of information propagation infeasible. This
paper aims to address this issue by proposing a novel deep learning approach
for automated detection of false short-text claims on social media. We first
introduce Sentimental LIAR, which extends the LIAR dataset of short claims by
adding features based on sentiment and emotion analysis of claims. Furthermore,
we propose a novel deep learning architecture based on the BERT-Base language
model for classification of claims as genuine or fake. Our results demonstrate
that the proposed architecture trained on Sentimental LIAR can achieve an
accuracy of 70%, which is an improvement of ~30% over previously reported
results for the LIAR benchmark.
","[{'version': 'v1', 'created': 'Tue, 1 Sep 2020 02:48:11 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 04:57:21 GMT'}]",2020-10-23,"[['Upadhayay', 'Bibek', ''], ['Behzadan', 'Vahid', '']]"
1347870,2009.06367,Benjamin Krause,"Ben Krause, Akhilesh Deepak Gotmare, Bryan McCann, Nitish Shirish
  Keskar, Shafiq Joty, Richard Socher, Nazneen Fatema Rajani",GeDi: Generative Discriminator Guided Sequence Generation,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While large-scale language models (LMs) are able to imitate the distribution
of natural language well enough to generate realistic text, it is difficult to
control which regions of the distribution they generate. This is especially
problematic because datasets used for training large LMs usually contain
significant toxicity, hate, bias, and negativity. We propose GeDi as an
efficient method for using smaller LMs as generative discriminators to guide
generation from large LMs to make them safer and more controllable. GeDi guides
generation at each step by computing classification probabilities for all
possible next tokens via Bayes rule by normalizing over two class-conditional
distributions; one conditioned on the desired attribute, or control code, and
another conditioned on the undesired attribute, or anti control code. We find
that GeDi gives stronger controllability than the state of the art method while
also achieving generation speeds more than 30 times faster. Additionally,
training GeDi on only four topics allows us to controllably generate new topics
zero-shot from just a keyword, unlocking a new capability that previous
controllable generation methods do not have. Lastly, we show that GeDi can make
GPT-2 (1.5B parameters) significantly less toxic without sacrificing linguistic
quality, making it by far the most practical existing method for detoxifying
large language models while maintaining a fast generation speed.
","[{'version': 'v1', 'created': 'Mon, 14 Sep 2020 17:45:36 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 14:14:09 GMT'}]",2020-10-23,"[['Krause', 'Ben', ''], ['Gotmare', 'Akhilesh Deepak', ''], ['McCann', 'Bryan', ''], ['Keskar', 'Nitish Shirish', ''], ['Joty', 'Shafiq', ''], ['Socher', 'Richard', ''], ['Rajani', 'Nazneen Fatema', '']]"
1348326,2009.06823,Zhenglun Kong,"Wei Niu, Zhenglun Kong, Geng Yuan, Weiwen Jiang, Jiexiong Guan, Caiwen
  Ding, Pu Zhao, Sijia Liu, Bin Ren, Yanzhi Wang",Real-Time Execution of Large-scale Language Models on Mobile,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pre-trained large-scale language models have increasingly demonstrated high
accuracy on many natural language processing (NLP) tasks. However, the limited
weight storage and computational speed on hardware platforms have impeded the
popularity of pre-trained models, especially in the era of edge computing. In
this paper, we seek to find the best model structure of BERT for a given
computation size to match specific devices. We propose the first compiler-aware
neural architecture optimization framework. Our framework can guarantee the
identified model to meet both resource and real-time specifications of mobile
devices, thus achieving real-time execution of large transformer-based models
like BERT variants. We evaluate our model on several NLP tasks, achieving
competitive results on well-known benchmarks with lower latency on mobile
devices. Specifically, our model is 5.2x faster on CPU and 4.1x faster on GPU
with 0.5-2% accuracy loss compared with BERT-base. Our overall framework
achieves up to 7.8x speedup compared with TensorFlow-Lite with only minor
accuracy loss.
","[{'version': 'v1', 'created': 'Tue, 15 Sep 2020 01:59:17 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 17:53:07 GMT'}]",2020-10-23,"[['Niu', 'Wei', ''], ['Kong', 'Zhenglun', ''], ['Yuan', 'Geng', ''], ['Jiang', 'Weiwen', ''], ['Guan', 'Jiexiong', ''], ['Ding', 'Caiwen', ''], ['Zhao', 'Pu', ''], ['Liu', 'Sijia', ''], ['Ren', 'Bin', ''], ['Wang', 'Yanzhi', '']]"
1349119,2009.07616,Junfan Chen,"Junfan Chen, Richong Zhang, Yongyi Mao, Jie Xu",Parallel Interactive Networks for Multi-Domain Dialogue State Generation,Accepted by EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The dependencies between system and user utterances in the same turn and
across different turns are not fully considered in existing multidomain
dialogue state tracking (MDST) models. In this study, we argue that the
incorporation of these dependencies is crucial for the design of MDST and
propose Parallel Interactive Networks (PIN) to model these dependencies.
Specifically, we integrate an interactive encoder to jointly model the in-turn
dependencies and cross-turn dependencies. The slot-level context is introduced
to extract more expressive features for different slots. And a distributed copy
mechanism is utilized to selectively copy words from historical system
utterances or historical user utterances. Empirical studies demonstrated the
superiority of the proposed PIN model.
","[{'version': 'v1', 'created': 'Wed, 16 Sep 2020 11:54:15 GMT'}, {'version': 'v2', 'created': 'Sat, 3 Oct 2020 07:32:21 GMT'}, {'version': 'v3', 'created': 'Thu, 22 Oct 2020 14:19:12 GMT'}]",2020-10-23,"[['Chen', 'Junfan', ''], ['Zhang', 'Richong', ''], ['Mao', 'Yongyi', ''], ['Xu', 'Jie', '']]"
1368075,2010.11745,Gabriel Synnaeve,"Tatiana Likhomanenko, Qiantong Xu, Vineel Pratap, Paden Tomasello,
  Jacob Kahn, Gilad Avidov, Ronan Collobert, Gabriel Synnaeve",Rethinking Evaluation in ASR: Are Our Models Robust Enough?,,,,,cs.LG cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Is pushing numbers on a single benchmark valuable in automatic speech
recognition? Research results in acoustic modeling are typically evaluated
based on performance on a single dataset. While the research community has
coalesced around various benchmarks, we set out to understand generalization
performance in acoustic modeling across datasets -- in particular, if models
trained on a single dataset transfer to other (possibly out-of-domain)
datasets. Further, we demonstrate that when a large enough set of benchmarks is
used, average word error rate (WER) performance over them provides a good proxy
for performance on real-world data. Finally, we show that training a single
acoustic model on the most widely-used datasets -- combined -- reaches
competitive performance on both research and real-world benchmarks.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 14:01:32 GMT'}]",2020-10-23,"[['Likhomanenko', 'Tatiana', ''], ['Xu', 'Qiantong', ''], ['Pratap', 'Vineel', ''], ['Tomasello', 'Paden', ''], ['Kahn', 'Jacob', ''], ['Avidov', 'Gilad', ''], ['Collobert', 'Ronan', ''], ['Synnaeve', 'Gabriel', '']]"
1367969,2010.11639,Li-Hsin Chang,"Li-Hsin Chang, Sampo Pyysalo, Jenna Kanerva, Filip Ginter",Towards Fully Bilingual Deep Language Modeling,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language models based on deep neural networks have facilitated great advances
in natural language processing and understanding tasks in recent years. While
models covering a large number of languages have been introduced, their
multilinguality has come at a cost in terms of monolingual performance, and the
best-performing models at most tasks not involving cross-lingual transfer
remain monolingual. In this paper, we consider the question of whether it is
possible to pre-train a bilingual model for two remotely related languages
without compromising performance at either language. We collect pre-training
data, create a Finnish-English bilingual BERT model and evaluate its
performance on datasets used to evaluate the corresponding monolingual models.
Our bilingual model performs on par with Google's original English BERT on GLUE
and nearly matches the performance of monolingual Finnish BERT on a range of
Finnish NLP tasks, clearly outperforming multilingual BERT. We find that when
the model vocabulary size is increased, the BERT-Base architecture has
sufficient capacity to learn two remotely related languages to a level where it
achieves comparable performance with monolingual models, demonstrating the
feasibility of training fully bilingual deep language models. The model and all
tools involved in its creation are freely available at
https://github.com/TurkuNLP/biBERT
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 12:22:50 GMT'}]",2020-10-23,"[['Chang', 'Li-Hsin', ''], ['Pyysalo', 'Sampo', ''], ['Kanerva', 'Jenna', ''], ['Ginter', 'Filip', '']]"
1355405,2009.13902,Soujanya Poria,"Deepanway Ghosal, Navonil Majumder, Rada Mihalcea, Soujanya Poria",Utterance-level Dialogue Understanding: An Empirical Study,,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  The recent abundance of conversational data on the Web and elsewhere calls
for effective NLP systems for dialog understanding. Complete utterance-level
understanding often requires context understanding, defined by nearby
utterances. In recent years, a number of approaches have been proposed for
various utterance-level dialogue understanding tasks. Most of these approaches
account for the context for effective understanding. In this paper, we explore
and quantify the role of context for different aspects of a dialogue, namely
emotion, intent, and dialogue act identification, using state-of-the-art dialog
understanding methods as baselines. Specifically, we employ various
perturbations to distort the context of a given utterance and study its impact
on the different tasks and baselines. This provides us with insights into the
fundamental contextual controlling factors of different aspects of a dialogue.
Such insights can inspire more effective dialogue understanding models, and
provide support for future text generation approaches. The implementation
pertaining to this work is available at
https://github.com/declare-lab/dialogue-understanding.
","[{'version': 'v1', 'created': 'Tue, 29 Sep 2020 09:50:21 GMT'}, {'version': 'v2', 'created': 'Thu, 1 Oct 2020 16:12:59 GMT'}, {'version': 'v3', 'created': 'Sun, 11 Oct 2020 14:38:07 GMT'}, {'version': 'v4', 'created': 'Mon, 19 Oct 2020 03:03:05 GMT'}, {'version': 'v5', 'created': 'Thu, 22 Oct 2020 11:16:56 GMT'}]",2020-10-23,"[['Ghosal', 'Deepanway', ''], ['Majumder', 'Navonil', ''], ['Mihalcea', 'Rada', ''], ['Poria', 'Soujanya', '']]"
1357391,2010.01061,Nils Rethmeier,Nils Rethmeier and Isabelle Augenstein,"Long-Tail Zero and Few-Shot Learning via Contrastive Pretraining on and
  for Small Data",added citations to current work,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  For natural language processing (NLP) tasks such as sentiment or topic
classification, currently prevailing approaches heavily rely on pretraining
large self-supervised models on massive external data resources. However, this
methodology is being critiqued for: exceptional compute and pretraining data
requirements; diminishing returns on both large and small datasets; and
importantly, favourable evaluation settings that overestimate performance
differences. The core belief behind current methodology, coined `the bitter
lesson' by R. Sutton, is that `compute scale-up beats data and
compute-efficient algorithms', neglecting that progress in compute hardware
scale-up is based almost entirely on the miniaturisation of resource
consumption. We thus approach pretraining from a miniaturisation perspective,
such as not to require massive external data sources and models, or learned
translations from continuous input embeddings to discrete labels. To minimise
overly favourable evaluation, we examine learning on a long-tailed,
low-resource, multi-label text classification dataset with noisy, highly sparse
labels and many rare concepts. To this end, we propose a novel
`dataset-internal' contrastive autoencoding approach to self-supervised
pretraining and demonstrate marked improvements in zero-shot, few-shot and
solely supervised learning performance; even under an unfavorable low-resource
scenario, and without defaulting to large-scale external datasets for
self-supervision. We also find empirical evidence that zero and few-shot
learning markedly benefit from adding more `dataset-internal', self-supervised
training signals, which is of practical importance when retrieving or computing
on large external sources of such signals is infeasible.
","[{'version': 'v1', 'created': 'Fri, 2 Oct 2020 15:41:57 GMT'}, {'version': 'v2', 'created': 'Wed, 21 Oct 2020 18:24:13 GMT'}]",2020-10-23,"[['Rethmeier', 'Nils', ''], ['Augenstein', 'Isabelle', '']]"
1368031,2010.11701,Philipp Sadler,Philipp Sadler,Spatial Attention as an Interface for Image Captioning Models,"A thesis submitted in fulfillment of the requirements for the degree
  Master of Science in Cognitive Systems",,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The internal workings of modern deep learning models stay often unclear to an
external observer, although spatial attention mechanisms are involved. The idea
of this work is to translate these spatial attentions into natural language to
provide a simpler access to the model's function. Thus, I took a neural image
captioning model and measured the reactions to external modification in its
spatial attention for three different interface methods: a fixation over the
whole generation process, a fixation for the first time-steps and an addition
to the generator's attention. The experimental results for bounding box based
spatial attention vectors have shown that the captioning model reacts to method
dependent changes in up to 52.65% and includes in 9.00% of the cases object
categories, which were otherwise unmentioned. Afterwards, I established such a
link to a hierarchical co-attention network for visual question answering by
extraction of its word, phrase and question level spatial attentions. Here,
generated captions for the word level included details of the question-answer
pairs in up to 55.20% of the cases. This work indicates that spatial attention
seen as an external interface for image caption generators is an useful method
to access visual functions in natural language.
","[{'version': 'v1', 'created': 'Tue, 29 Sep 2020 16:04:08 GMT'}]",2020-10-23,"[['Sadler', 'Philipp', '']]"
1185948,1910.02029,Arun Balajee Vasudevan,"Arun Balajee Vasudevan, Dengxin Dai, Luc Van Gool","Talk2Nav: Long-Range Vision-and-Language Navigation with Dual Attention
  and Spatial Memory","Accepted to IJCV 2020, 20 pages, 10 Figures, Demo Video:
  https://people.ee.ethz.ch/~arunv/resources/talk2nav.mp4",,10.1007/s11263-020-01374-3,,cs.CV cs.CL cs.RO,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The role of robots in society keeps expanding, bringing with it the necessity
of interacting and communicating with humans. In order to keep such interaction
intuitive, we provide automatic wayfinding based on verbal navigational
instructions. Our first contribution is the creation of a large-scale dataset
with verbal navigation instructions. To this end, we have developed an
interactive visual navigation environment based on Google Street View; we
further design an annotation method to highlight mined anchor landmarks and
local directions between them in order to help annotators formulate typical,
human references to those. The annotation task was crowdsourced on the AMT
platform, to construct a new Talk2Nav dataset with $10,714$ routes. Our second
contribution is a new learning method. Inspired by spatial cognition research
on the mental conceptualization of navigational instructions, we introduce a
soft dual attention mechanism defined over the segmented language instructions
to jointly extract two partial instructions -- one for matching the next
upcoming visual landmark and the other for matching the local directions to the
next landmark. On the similar lines, we also introduce spatial memory scheme to
encode the local directional transitions. Our work takes advantage of the
advance in two lines of research: mental formalization of verbal navigational
instructions and training neural network agents for automatic way finding.
Extensive experiments show that our method significantly outperforms previous
navigation methods. For demo video, dataset and code, please refer to our
project page: https://www.trace.ethz.ch/publications/2019/talk2nav/index.html
","[{'version': 'v1', 'created': 'Fri, 4 Oct 2019 16:44:59 GMT'}, {'version': 'v2', 'created': 'Mon, 3 Feb 2020 11:25:09 GMT'}, {'version': 'v3', 'created': 'Thu, 22 Oct 2020 12:03:18 GMT'}]",2020-10-23,"[['Vasudevan', 'Arun Balajee', ''], ['Dai', 'Dengxin', ''], ['Van Gool', 'Luc', '']]"
1368013,2010.11683,Xiang Dai,Xiang Dai and Heike Adel,An Analysis of Simple Data Augmentation for Named Entity Recognition,COLING 2020,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Simple yet effective data augmentation techniques have been proposed for
sentence-level and sentence-pair natural language processing tasks. Inspired by
these efforts, we design and compare data augmentation for named entity
recognition, which is usually modeled as a token-level sequence labeling
problem. Through experiments on two data sets from the biomedical and materials
science domains (i2b2-2010 and MaSciP), we show that simple augmentation can
boost performance for both recurrent and transformer-based models, especially
for small training sets.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 13:21:03 GMT'}]",2020-10-23,"[['Dai', 'Xiang', ''], ['Adel', 'Heike', '']]"
1361469,2010.05139,Yiran Chen,"Yiran Chen, Pengfei Liu, Ming Zhong, Zi-Yi Dou, Danqing Wang, Xipeng
  Qiu and Xuanjing Huang","CDEvalSumm: An Empirical Study of Cross-Dataset Evaluation for Neural
  Summarization Systems","13 pages, Findings of EMNLP2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Neural network-based models augmented with unsupervised pre-trained knowledge
have achieved impressive performance on text summarization. However, most
existing evaluation methods are limited to an in-domain setting, where
summarizers are trained and evaluated on the same dataset. We argue that this
approach can narrow our understanding of the generalization ability for
different summarization systems. In this paper, we perform an in-depth analysis
of characteristics of different datasets and investigate the performance of
different summarization models under a cross-dataset setting, in which a
summarizer trained on one corpus will be evaluated on a range of out-of-domain
corpora. A comprehensive study of 11 representative summarization systems on 5
datasets from different domains reveals the effect of model architectures and
generation ways (i.e. abstractive and extractive) on model generalization
ability. Further, experimental results shed light on the limitations of
existing summarizers. Brief introduction and supplementary code can be found in
https://github.com/zide05/CDEvalSumm.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 02:19:15 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 12:11:46 GMT'}]",2020-10-23,"[['Chen', 'Yiran', ''], ['Liu', 'Pengfei', ''], ['Zhong', 'Ming', ''], ['Dou', 'Zi-Yi', ''], ['Wang', 'Danqing', ''], ['Qiu', 'Xipeng', ''], ['Huang', 'Xuanjing', '']]"
1361808,2010.05478,Tanya Goyal,"Tanya Goyal, Greg Durrett",Evaluating Factuality in Generation with Dependency-level Entailment,Findings of Emnlp 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite significant progress in text generation models, a serious limitation
is their tendency to produce text that is factually inconsistent with
information in the input. Recent work has studied whether textual entailment
systems can be used to identify factual errors; however, these sentence-level
entailment models are trained to solve a different problem than generation
filtering and they do not localize which part of a generation is non-factual.
In this paper, we propose a new formulation of entailment that decomposes it at
the level of dependency arcs. Rather than focusing on aggregate decisions, we
instead ask whether the semantic relationship manifested by individual
dependency arcs in the generated output is supported by the input. Human
judgments on this task are difficult to obtain; we therefore propose a method
to automatically create data based on existing entailment or paraphrase
corpora. Experiments show that our dependency arc entailment model trained on
this data can identify factual inconsistencies in paraphrasing and
summarization better than sentence-level methods or those based on question
generation, while additionally localizing the erroneous parts of the
generation.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 06:43:10 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 06:35:58 GMT'}]",2020-10-23,"[['Goyal', 'Tanya', ''], ['Durrett', 'Greg', '']]"
1362070,2010.05740,Yanjie Gou,"Yanjie Gou, Yinjie Lei, Lingqiao Liu","Contextualize Knowledge Bases with Transformer for End-to-end
  Task-Oriented Dialogue Systems",Third version of this work; Correct some typos,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent studies try to build task-oriented dialogue systems in an end-to-end
manner and the existing works make great progress on this task. However, there
is still an issue need to be further considered, i.e., how to effectively
represent the knowledge bases and incorporate that into dialogue systems. To
solve this issue, we design a novel Transformer-based Context-aware Memory
Generator to model the entities in knowledge bases, which can produce entity
representations with perceiving all the relevant entities and dialogue history.
Furthermore, we propose Context-aware Memory Enhanced Transformer (CMET), which
can effectively aggregate information from the dialogue history and knowledge
bases to generate more accurate responses. Through extensive experiments, our
method can achieve superior performance over the state-of-the-art methods.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 14:34:07 GMT'}, {'version': 'v2', 'created': 'Tue, 20 Oct 2020 09:37:22 GMT'}, {'version': 'v3', 'created': 'Thu, 22 Oct 2020 13:37:40 GMT'}]",2020-10-23,"[['Gou', 'Yanjie', ''], ['Lei', 'Yinjie', ''], ['Liu', 'Lingqiao', '']]"
1367996,2010.11666,Pavel Kalaidin,"Nadezhda Zueva, Madina Kabirova, Pavel Kalaidin",Reducing Unintended Identity Bias in Russian Hate Speech Detection,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Toxicity has become a grave problem for many online communities and has been
growing across many languages, including Russian. Hate speech creates an
environment of intimidation, discrimination, and may even incite some
real-world violence. Both researchers and social platforms have been focused on
developing models to detect toxicity in online communication for a while now. A
common problem of these models is the presence of bias towards some words (e.g.
woman, black, jew) that are not toxic, but serve as triggers for the classifier
due to model caveats. In this paper, we describe our efforts towards
classifying hate speech in Russian, and propose simple techniques of reducing
unintended bias, such as generating training data with language models using
terms and words related to protected identities as context and applying word
dropout to such words.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 12:54:14 GMT'}]",2020-10-23,"[['Zueva', 'Nadezhda', ''], ['Kabirova', 'Madina', ''], ['Kalaidin', 'Pavel', '']]"
1368061,2010.11731,Akbar Karimi,"Akbar Karimi, Leonardo Rossi, Andrea Prati",Improving BERT Performance for Aspect-Based Sentiment Analysis,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Aspect-Based Sentiment Analysis (ABSA) studies the consumer opinion on the
market products. It involves examining the type of sentiments as well as
sentiment targets expressed in product reviews. Analyzing the language used in
a review is a difficult task that requires a deep understanding of the
language. In recent years, deep language models, such as BERT
\cite{devlin2019bert}, have shown great progress in this regard. In this work,
we propose two simple modules called Parallel Aggregation and Hierarchical
Aggregation to be utilized on top of BERT for two main ABSA tasks namely Aspect
Extraction (AE) and Aspect Sentiment Classification (ASC) in order to improve
the model's performance. We show that applying the proposed models eliminates
the need for further training of the BERT model. The source code is available
on the Web for further research and reproduction of the results.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 13:52:18 GMT'}]",2020-10-23,"[['Karimi', 'Akbar', ''], ['Rossi', 'Leonardo', ''], ['Prati', 'Andrea', '']]"
1367852,2010.11522,Jiaoyan Chen,"Ziheng Zhang and Jiaoyan Chen and Xi Chen and Hualuo Liu and Yuejia
  Xiang and Bo Liu and Yefeng Zheng",An Industry Evaluation of Embedding-based Entity Alignment,,Coling'2020,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Embedding-based entity alignment has been widely investigated in recent
years, but most proposed methods still rely on an ideal supervised learning
setting with a large number of unbiased seed mappings for training and
validation, which significantly limits their usage. In this study, we evaluate
those state-of-the-art methods in an industrial context, where the impact of
seed mappings with different sizes and different biases is explored. Besides
the popular benchmarks from DBpedia and Wikidata, we contribute and evaluate a
new industrial benchmark that is extracted from two heterogeneous knowledge
graphs (KGs) under deployment for medical applications. The experimental
results enable the analysis of the advantages and disadvantages of these
alignment methods and the further discussion of suitable strategies for their
industrial deployment.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 08:33:58 GMT'}]",2020-10-23,"[['Zhang', 'Ziheng', ''], ['Chen', 'Jiaoyan', ''], ['Chen', 'Xi', ''], ['Liu', 'Hualuo', ''], ['Xiang', 'Yuejia', ''], ['Liu', 'Bo', ''], ['Zheng', 'Yefeng', '']]"
1368094,2010.11764,Aman Madaan,"Aman Madaan, Dheeraj Rajagopal, Yiming Yang, Abhilasha Ravichander,
  Eduard Hovy, Shrimai Prabhumoye",EIGEN: Event Influence GENeration using Pre-trained Language Models,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Reasoning about events and tracking their influences is fundamental to
understanding processes. In this paper, we present EIGEN - a method to leverage
pre-trained language models to generate event influences conditioned on a
context, nature of their influence, and the distance in a reasoning chain. We
also derive a new dataset for research and evaluation of methods for event
influence generation. EIGEN outperforms strong baselines both in terms of
automated evaluation metrics (by 10 ROUGE points) and human judgments on
closeness to reference and relevance of generations. Furthermore, we show that
the event influences generated by EIGEN improve the performance on a ""what-if""
Question Answering (WIQA) benchmark (over 3% F1), especially for questions that
require background knowledge and multi-hop reasoning.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 14:36:04 GMT'}]",2020-10-23,"[['Madaan', 'Aman', ''], ['Rajagopal', 'Dheeraj', ''], ['Yang', 'Yiming', ''], ['Ravichander', 'Abhilasha', ''], ['Hovy', 'Eduard', ''], ['Prabhumoye', 'Shrimai', '']]"
1227793,2001.02380,Yang Liu,Amir Zeldes and Yang Liu,A Neural Approach to Discourse Relation Signal Detection,"33 pages, 7 figures. Submitted to Dialogue & Discourse (D&D);
  Addressed reviewers' comments: strengthened arguments, added references,
  corrected typos etc",,10.5087/dad,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Previous data-driven work investigating the types and distributions of
discourse relation signals, including discourse markers such as 'however' or
phrases such as 'as a result' has focused on the relative frequencies of signal
words within and outside text from each discourse relation. Such approaches do
not allow us to quantify the signaling strength of individual instances of a
signal on a scale (e.g. more or less discourse-relevant instances of 'and'), to
assess the distribution of ambiguity for signals, or to identify words that
hinder discourse relation identification in context ('anti-signals' or
'distractors'). In this paper we present a data-driven approach to signal
detection using a distantly supervised neural network and develop a metric,
Delta s (or 'delta-softmax'), to quantify signaling strength. Ranging between
-1 and 1 and relying on recent advances in contextualized words embeddings, the
metric represents each word's positive or negative contribution to the
identifiability of a relation in specific instances in context. Based on an
English corpus annotated for discourse relations using Rhetorical Structure
Theory and signal type annotations anchored to specific tokens, our analysis
examines the reliability of the metric, the places where it overlaps with and
differs from human judgments, and the implications for identifying features
that neural models may need in order to perform better on automatic discourse
relation classification.
","[{'version': 'v1', 'created': 'Wed, 8 Jan 2020 05:14:49 GMT'}, {'version': 'v2', 'created': 'Wed, 11 Mar 2020 19:56:42 GMT'}]",2020-10-23,"[['Zeldes', 'Amir', ''], ['Liu', 'Yang', '']]"
1367713,2010.11383,Li Wanli,Wanli Li and Tieyun Qian,"Exploit Multiple Reference Graphs for Semi-supervised Relation
  Extraction",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Manual annotation of the labeled data for relation extraction is
time-consuming and labor-intensive. Semi-supervised methods can offer helping
hands for this problem and have aroused great research interests. Existing work
focuses on mapping the unlabeled samples to the classes to augment the labeled
dataset. However, it is hard to find an overall good mapping function,
especially for the samples with complicated syntactic components in one
sentence.
  To tackle this limitation, we propose to build the connection between the
unlabeled data and the labeled ones rather than directly mapping the unlabeled
samples to the classes. Specifically, we first use three kinds of information
to construct reference graphs, including entity reference, verb reference, and
semantics reference. The goal is to semantically or lexically connect the
unlabeled sample(s) to the labeled one(s). Then, we develop a Multiple
Reference Graph (MRefG) model to exploit the reference information for better
recognizing high-quality unlabeled samples. The effectiveness of our method is
demonstrated by extensive comparison experiments with the state-of-the-art
baselines on two public datasets.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 02:14:27 GMT'}]",2020-10-23,"[['Li', 'Wanli', ''], ['Qian', 'Tieyun', '']]"
1367704,2010.11374,Devendra Singh Sachan,"Devendra Singh Sachan and Lingfei Wu and Mrinmaya Sachan and William
  Hamilton",Stronger Transformers for Neural Multi-Hop Question Generation,Code will be made available,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Prior work on automated question generation has almost exclusively focused on
generating simple questions whose answers can be extracted from a single
document. However, there is an increasing interest in developing systems that
are capable of more complex multi-hop question generation, where answering the
questions requires reasoning over multiple documents. In this work, we
introduce a series of strong transformer models for multi-hop question
generation, including a graph-augmented transformer that leverages relations
between entities in the text. While prior work has emphasized the importance of
graph-based models, we show that we can substantially outperform the
state-of-the-art by 5 BLEU points using a standard transformer architecture. We
further demonstrate that graph-based augmentations can provide complimentary
improvements on top of this foundation. Interestingly, we find that several
important factors--such as the inclusion of an auxiliary contrastive objective
and data filtering could have larger impacts on performance. We hope that our
stronger baselines and analysis provide a constructive foundation for future
work in this area.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 01:51:09 GMT'}]",2020-10-23,"[['Sachan', 'Devendra Singh', ''], ['Wu', 'Lingfei', ''], ['Sachan', 'Mrinmaya', ''], ['Hamilton', 'William', '']]"
1367692,2010.11362,Rithesh Kumar,"Rithesh Kumar, Kundan Kumar, Vicki Anand, Yoshua Bengio, Aaron
  Courville",NU-GAN: High resolution neural upsampling with GAN,,,,,cs.SD cs.AI cs.CL cs.LG eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we propose NU-GAN, a new method for resampling audio from
lower to higher sampling rates (upsampling). Audio upsampling is an important
problem since productionizing generative speech technology requires operating
at high sampling rates. Such applications use audio at a resolution of 44.1 kHz
or 48 kHz, whereas current speech synthesis methods are equipped to handle a
maximum of 24 kHz resolution. NU-GAN takes a leap towards solving audio
upsampling as a separate component in the text-to-speech (TTS) pipeline by
leveraging techniques for audio generation using GANs. ABX preference tests
indicate that our NU-GAN resampler is capable of resampling 22 kHz to 44.1 kHz
audio that is distinguishable from original audio only 7.4% higher than random
chance for single speaker dataset, and 10.8% higher than chance for
multi-speaker dataset.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 01:00:23 GMT'}]",2020-10-23,"[['Kumar', 'Rithesh', ''], ['Kumar', 'Kundan', ''], ['Anand', 'Vicki', ''], ['Bengio', 'Yoshua', ''], ['Courville', 'Aaron', '']]"
1367688,2010.11358,Aaron Baier-Reinio,Aaron Baier-Reinio and Hans De Sterck,"N-ODE Transformer: A Depth-Adaptive Variant of the Transformer Using
  Neural Ordinary Differential Equations",,,,,cs.LG cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We use neural ordinary differential equations to formulate a variant of the
Transformer that is depth-adaptive in the sense that an input-dependent number
of time steps is taken by the ordinary differential equation solver. Our goal
in proposing the N-ODE Transformer is to investigate whether its
depth-adaptivity may aid in overcoming some specific known theoretical
limitations of the Transformer in handling nonlocal effects. Specifically, we
consider the simple problem of determining the parity of a binary sequence, for
which the standard Transformer has known limitations that can only be overcome
by using a sufficiently large number of layers or attention heads. We find,
however, that the depth-adaptivity of the N-ODE Transformer does not provide a
remedy for the inherently nonlocal nature of the parity problem, and provide
explanations for why this is so. Next, we pursue regularization of the N-ODE
Transformer by penalizing the arclength of the ODE trajectories, but find that
this fails to improve the accuracy or efficiency of the N-ODE Transformer on
the challenging parity problem. We suggest future avenues of research for
modifications and extensions of the N-ODE Transformer that may lead to improved
accuracy and efficiency for sequence modelling tasks such as neural machine
translation.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 00:48:24 GMT'}]",2020-10-23,"[['Baier-Reinio', 'Aaron', ''], ['De Sterck', 'Hans', '']]"
1367681,2010.11351,Minghan Li,"M. Li, H. Bai, L. Tan, K. Xiong, M. Li, J. Lin","Latte-Mix: Measuring Sentence Semantic Similarity with Latent
  Categorical Mixtures",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Measuring sentence semantic similarity using pre-trained language models such
as BERT generally yields unsatisfactory zero-shot performance, and one main
reason is ineffective token aggregation methods such as mean pooling. In this
paper, we demonstrate under a Bayesian framework that distance between
primitive statistics such as the mean of word embeddings are fundamentally
flawed for capturing sentence-level semantic similarity. To remedy this issue,
we propose to learn a categorical variational autoencoder (VAE) based on
off-the-shelf pre-trained language models. We theoretically prove that
measuring the distance between the latent categorical mixtures, namely
Latte-Mix, can better reflect the true sentence semantic similarity. In
addition, our Bayesian framework provides explanations for why models finetuned
on labelled sentence pairs have better zero-shot performance. We also
empirically demonstrate that these finetuned models could be further improved
by Latte-Mix. Our method not only yields the state-of-the-art zero-shot
performance on semantic similarity datasets such as STS, but also enjoy the
benefits of fast training and having small memory footprints.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 23:45:18 GMT'}]",2020-10-23,"[['Li', 'M.', ''], ['Bai', 'H.', ''], ['Tan', 'L.', ''], ['Xiong', 'K.', ''], ['Li', 'M.', ''], ['Lin', 'J.', '']]"
1367679,2010.11349,Xie Chen,"Xie Chen, Sarangarajan Parthasarathy, William Gale, Shuangyu Chang,
  Michael Zeng","LSTM-LM with Long-Term History for First-Pass Decoding in Conversational
  Speech Recognition",5 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  LSTM language models (LSTM-LMs) have been proven to be powerful and yielded
significant performance improvements over count based n-gram LMs in modern
speech recognition systems. Due to its infinite history states and
computational load, most previous studies focus on applying LSTM-LMs in the
second-pass for rescoring purpose. Recent work shows that it is feasible and
computationally affordable to adopt the LSTM-LMs in the first-pass decoding
within a dynamic (or tree based) decoder framework. In this work, the LSTM-LM
is composed with a WFST decoder on-the-fly for the first-pass decoding.
Furthermore, motivated by the long-term history nature of LSTM-LMs, the use of
context beyond the current utterance is explored for the first-pass decoding in
conversational speech recognition. The context information is captured by the
hidden states of LSTM-LMs across utterance and can be used to guide the
first-pass search effectively. The experimental results in our internal meeting
transcription system show that significant performance improvements can be
obtained by incorporating the contextual information with LSTM-LMs in the
first-pass decoding, compared to applying the contextual information in the
second-pass rescoring.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 23:40:26 GMT'}]",2020-10-23,"[['Chen', 'Xie', ''], ['Parthasarathy', 'Sarangarajan', ''], ['Gale', 'William', ''], ['Chang', 'Shuangyu', ''], ['Zeng', 'Michael', '']]"
1367668,2010.11338,Yun Tang,"Yun Tang, Juan Pino, Changhan Wang, Xutai Ma, Dmitriy Genzel","A General Multi-Task Learning Framework to Leverage Text Data for Speech
  to Text Tasks",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Attention-based sequence-to-sequence modeling provides a powerful and elegant
solution for applications that need to map one sequence to a different
sequence. Its success heavily relies on the availability of large amounts of
training data. This presents a challenge for speech applications where labelled
speech data is very expensive to obtain, such as automatic speech recognition
(ASR) and speech translation (ST). In this study, we propose a general
multi-task learning framework to leverage text data for ASR and ST tasks. Two
auxiliary tasks, a denoising autoencoder task and machine translation task, are
proposed to be co-trained with ASR and ST tasks respectively. We demonstrate
that representing text input as phoneme sequences can reduce the difference
between speech and text inputs, and enhance the knowledge transfer from text
corpora to the speech to text tasks. Our experiments show that the proposed
method achieves a relative 10~15% word error rate reduction on the English
Librispeech task, and improves the speech translation quality on the MuST-C
tasks by 4.2~11.1 BLEU.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 22:40:43 GMT'}]",2020-10-23,"[['Tang', 'Yun', ''], ['Pino', 'Juan', ''], ['Wang', 'Changhan', ''], ['Ma', 'Xutai', ''], ['Genzel', 'Dmitriy', '']]"
1367664,2010.11334,Chiyu Zhang,"Muhammad Abdul-Mageed, Chiyu Zhang, Houda Bouamor and Nizar Habash",NADI 2020: The First Nuanced Arabic Dialect Identification Shared Task,Accepted in WANLP 2020,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  We present the results and findings of the First Nuanced Arabic Dialect
Identification Shared Task (NADI). The shared task includes two subtasks:
country level dialect identification (Subtask 1) and province level sub-dialect
identification (Subtask 2). The data for the shared task covers a total of 100
provinces from 21 Arab countries, and are collected from the Twitter domain. As
such, NADI is the first shared task to target naturally-occurring fine-grained
dialectal text at the sub-country level. A total of 61 teams from 25 countries
registered to participate in the tasks, thus reflecting the interest of the
community in this area. We received 47 submissions for Subtask 1 from 18 teams
and 9 submissions to Subtask 2 from 9 teams.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 22:14:28 GMT'}]",2020-10-23,"[['Abdul-Mageed', 'Muhammad', ''], ['Zhang', 'Chiyu', ''], ['Bouamor', 'Houda', ''], ['Habash', 'Nizar', '']]"
1367663,2010.11333,Yogarshi Vyas,"Yogarshi Vyas, Miguel Ballesteros",Linking Entities to Unseen Knowledge Bases with Arbitrary Schemas,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In entity linking, mentions of named entities in raw text are disambiguated
against a knowledge base (KB). This work focuses on linking to unseen KBs that
do not have training data and whose schema is unknown during training. Our
approach relies on methods to flexibly convert entities from arbitrary KBs with
several attribute-value pairs into flat strings, which we use in conjunction
with state-of-the-art models for zero-shot linking. To improve the
generalization of our model, we use two regularization schemes based on
shuffling of entity attributes and handling of unseen attributes. Experiments
on English datasets where models are trained on the CoNLL dataset, and tested
on the TAC-KBP 2010 dataset show that our models outperform baseline models by
over 12 points of accuracy. Unlike prior work, our approach also allows for
seamlessly combining multiple training datasets. We test this ability by adding
both a completely different dataset (Wikia), as well as increasing amount of
training data from the TAC-KBP 2010 training set. Our models perform favorably
across the board.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 22:07:31 GMT'}]",2020-10-23,"[['Vyas', 'Yogarshi', ''], ['Ballesteros', 'Miguel', '']]"
1367655,2010.11325,Rui Feng,"Rui Feng, Jie Yuan, Chao Zhang","Probing and Fine-tuning Reading Comprehension Models for Few-shot Event
  Extraction",,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  We study the problem of event extraction from text data, which requires both
detecting target event types and their arguments. Typically, both the event
detection and argument detection subtasks are formulated as supervised sequence
labeling problems. We argue that the event extraction models so trained are
inherently label-hungry, and can generalize poorly across domains and text
genres.We propose a reading comprehension framework for event
extraction.Specifically, we formulate event detection as a textual entailment
prediction problem, and argument detection as a question answer-ing problem. By
constructing proper query templates, our approach can effectively distill rich
knowledge about tasks and label semantics from pretrained reading comprehension
models. Moreover, our model can be fine-tuned with a small amount of data to
boost its performance. Our experiment results show that our method performs
strongly for zero-shot and few-shot event extraction, and it achieves
state-of-the-art performance on the ACE 2005 benchmark when trained with full
supervision.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 21:48:39 GMT'}]",2020-10-23,"[['Feng', 'Rui', ''], ['Yuan', 'Jie', ''], ['Zhang', 'Chao', '']]"
1367714,2010.11384,Gabriele Pergola,"Gabriele Pergola, Lin Gui, Yulan He","A Disentangled Adversarial Neural Topic Model for Separating Opinions
  from Plots in User Reviews","12 pages, 4 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The flexibility of the inference process in Variational Autoencoders (VAEs)
has recently led to revising traditional probabilistic topic models giving rise
to Neural Topic Models (NTM). Although these approaches have achieved
significant results, surprisingly very little work has been done on how to
disentangle the latent topics. Existing topic models when applied to reviews
may extract topics associated with writers' subjective opinions mixed with
those related to factual descriptions such as plot summaries in movie and book
reviews. It is thus desirable to automatically separate opinion topics from
plot/neutral ones enabling a better interpretability. In this paper, we propose
a neural topic model combined with adversarial training to disentangle opinion
topics from plot and neutral ones. We conduct an extensive experimental
assessment introducing a new collection of movie and book reviews paired with
their plots, namely MOBO dataset, showing an improved coherence and variety of
topics, a consistent disentanglement rate, and sentiment classification
performance superior to other supervised topic models.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 02:15:13 GMT'}]",2020-10-23,"[['Pergola', 'Gabriele', ''], ['Gui', 'Lin', ''], ['He', 'Yulan', '']]"
1368114,2010.11784,Fangyu Liu,"Fangyu Liu, Ehsan Shareghi, Zaiqiao Meng, Marco Basaldella, Nigel
  Collier",Self-alignment Pre-training for Biomedical Entity Representations,8 pages. work in progress,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite the widespread success of self-supervised learning via masked
language models, learning representations directly from text to accurately
capture complex and fine-grained semantic relationships in the biomedical
domain remains as a challenge. Addressing this is of paramount importance for
tasks such as entity linking where complex relational knowledge is pivotal. We
propose SapBERT, a pre-training scheme based on BERT. It self-aligns the
representation space of biomedical entities with a metric learning objective
function leveraging UMLS, a collection of biomedical ontologies with >4M
concepts. Our experimental results on six medical entity linking benchmarking
datasets demonstrate that SapBERT outperforms many domain-specific BERT-based
variants such as BioBERT, BlueBERT and PubMedBERT, achieving the
state-of-the-art (SOTA) performances.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 14:59:57 GMT'}]",2020-10-23,"[['Liu', 'Fangyu', ''], ['Shareghi', 'Ehsan', ''], ['Meng', 'Zaiqiao', ''], ['Basaldella', 'Marco', ''], ['Collier', 'Nigel', '']]"
1367583,2010.11253,Rico Angell,"Rico Angell, Nicholas Monath, Sunil Mohan, Nishant Yadav and Andrew
  McCallum",Clustering-based Inference for Zero-Shot Biomedical Entity Linking,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Due to large number of entities in biomedical knowledge bases, only a small
fraction of entities have corresponding labelled training data. This
necessitates a zero-shot entity linking model which is able to link mentions of
unseen entities using learned representations of entities. Existing zero-shot
entity linking models however link each mention independently, ignoring the
inter/intra-document relationships between the entity mentions. These relations
can be very useful for linking mentions in biomedical text where linking
decisions are often difficult due mentions having a generic or a highly
specialized form. In this paper, we introduce a model in which linking
decisions can be made not merely by linking to a KB entity but also by grouping
multiple mentions together via clustering and jointly making linking
predictions. In experiments on the largest publicly available biomedical
dataset, we improve the best independent prediction for zero-shot entity
linking by 2.5 points of accuracy, and our joint inference model further
improves entity linking by 1.8 points.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 19:16:27 GMT'}]",2020-10-23,"[['Angell', 'Rico', ''], ['Monath', 'Nicholas', ''], ['Mohan', 'Sunil', ''], ['Yadav', 'Nishant', ''], ['McCallum', 'Andrew', '']]"
1367577,2010.11247,Renjie Zheng,"Junkun Chen, Renjie Zheng, Atsuhito Kita, Mingbo Ma, Liang Huang",Improving Simultaneous Translation with Pseudo References,6 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Simultaneous translation is vastly different from full-sentence translation,
in the sense that it starts translation before the source sentence ends, with
only a few words delay. However, due to the lack of large scale and publicly
available simultaneous translation datasets, most simultaneous translation
systems still train with ordinary full-sentence parallel corpora which are not
suitable for the simultaneous scenario due to the existence of unnecessary
long-distance reorderings. Instead of expensive, time-consuming annotation, we
propose a novel method that rewrites the target side of existing full-sentence
corpus into simultaneous-style translation. Experiments on Chinese-to-English
translation demonstrate about +2.7 BLEU improvements with the addition of newly
generated pseudo references.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 19:03:06 GMT'}]",2020-10-23,"[['Chen', 'Junkun', ''], ['Zheng', 'Renjie', ''], ['Kita', 'Atsuhito', ''], ['Ma', 'Mingbo', ''], ['Huang', 'Liang', '']]"
1367576,2010.11246,Tianze Shi,"Tianze Shi, Chen Zhao, Jordan Boyd-Graber, Hal Daum\'e III and Lillian
  Lee","On the Potential of Lexico-logical Alignments for Semantic Parsing to
  SQL Queries",Findings of ACL: EMNLP 2020,Findings of ACL: EMNLP 2020,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large-scale semantic parsing datasets annotated with logical forms have
enabled major advances in supervised approaches. But can richer supervision
help even more? To explore the utility of fine-grained, lexical-level
supervision, we introduce Squall, a dataset that enriches 11,276
WikiTableQuestions English-language questions with manually created SQL
equivalents plus alignments between SQL and question fragments. Our annotation
enables new training possibilities for encoder-decoder models, including
approaches from machine translation previously precluded by the absence of
alignments. We propose and test two methods: (1) supervised attention; (2)
adopting an auxiliary objective of disambiguating references in the input
queries to table columns. In 5-fold cross validation, these strategies improve
over strong baselines by 4.4% execution accuracy. Oracle experiments suggest
that annotated alignments can support further accuracy gains of up to 23.9%.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 19:01:00 GMT'}]",2020-10-23,"[['Shi', 'Tianze', ''], ['Zhao', 'Chen', ''], ['Boyd-Graber', 'Jordan', ''], ['Daumé', 'Hal', 'III'], ['Lee', 'Lillian', '']]"
1367568,2010.11238,Sirigireddy Dhana Laxmi,"Sirigireddy Dhanalaxmi, Rohit Agarwal, Aman Sinha",Detection of COVID-19 informative tweets using RoBERTa,,,,,cs.CL cs.SI,http://creativecommons.org/publicdomain/zero/1.0/,"  Social media such as Twitter is a hotspot of user-generated information. In
this ongoing Covid-19 pandemic, there has been an abundance of data on social
media which can be classified as informative and uninformative content. In this
paper, we present our work to detect informative Covid-19 English tweets using
RoBERTa model as a part of the W-NUT workshop 2020. We show the efficacy of our
model on a public dataset with an F1-score of 0.89 on the validation dataset
and 0.87 on the leaderboard.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 18:43:13 GMT'}]",2020-10-23,"[['Dhanalaxmi', 'Sirigireddy', ''], ['Agarwal', 'Rohit', ''], ['Sinha', 'Aman', '']]"
1367560,2010.11230,Mohammad Kachuee Mr.,"Mohammad Kachuee, Hao Yuan, Young-Bum Kim, Sungjin Lee","Self-Supervised Contrastive Learning for Efficient User Satisfaction
  Prediction in Conversational Agents",,,,,cs.LG cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Turn-level user satisfaction is one of the most important performance metrics
for conversational agents. It can be used to monitor the agent's performance
and provide insights about defective user experiences. Moreover, a powerful
satisfaction model can be used as an objective function that a conversational
agent continuously optimizes for. While end-to-end deep learning has shown
promising results, having access to a large number of reliable annotated
samples required by these methods remains challenging. In a large-scale
conversational system, there is a growing number of newly developed skills,
making the traditional data collection, annotation, and modeling process
impractical due to the required annotation costs as well as the turnaround
times. In this paper, we suggest a self-supervised contrastive learning
approach that leverages the pool of unlabeled data to learn user-agent
interactions. We show that the pre-trained models using the self-supervised
objective are transferable to the user satisfaction prediction. In addition, we
propose a novel few-shot transfer learning approach that ensures better
transferability for very small sample sizes. The suggested few-shot method does
not require any inner loop optimization process and is scalable to very large
datasets and complex models. Based on our experiments using real-world data
from a large-scale commercial system, the suggested approach is able to
significantly reduce the required number of annotations, while improving the
generalization on unseen out-of-domain skills.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 18:10:58 GMT'}]",2020-10-23,"[['Kachuee', 'Mohammad', ''], ['Yuan', 'Hao', ''], ['Kim', 'Young-Bum', ''], ['Lee', 'Sungjin', '']]"
1367196,2010.10866,Cl\'ement Rebuffel,"Cl\'ement Rebuffel, Laure Soulier, Geoffrey Scoutheeten, Patrick
  Gallinari","PARENTing via Model-Agnostic Reinforcement Learning to Correct
  Pathological Behaviors in Data-to-Text Generation","Accepted at the 13th International Conference on Natural Language
  Generation (INLG 2020)",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In language generation models conditioned by structured data, the classical
training via maximum likelihood almost always leads models to pick up on
dataset divergence (i.e., hallucinations or omissions), and to incorporate them
erroneously in their own generations at inference. In this work, we build ontop
of previous Reinforcement Learning based approaches and show that a
model-agnostic framework relying on the recently introduced PARENT metric is
efficient at reducing both hallucinations and omissions. Evaluations on the
widely used WikiBIO and WebNLG benchmarks demonstrate the effectiveness of this
framework compared to state-of-the-art models.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 09:49:47 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 13:00:20 GMT'}]",2020-10-23,"[['Rebuffel', 'Clément', ''], ['Soulier', 'Laure', ''], ['Scoutheeten', 'Geoffrey', ''], ['Gallinari', 'Patrick', '']]"
1367222,2010.10892,Yang Jiao,Yang Jiao,"BERT for Joint Multichannel Speech Dereverberation with Spatial-aware
  Tasks",,,,,eess.AS cs.CL cs.LG cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a method for joint multichannel speech dereverberation with two
spatial-aware tasks: direction-of-arrival (DOA) estimation and speech
separation. The proposed method addresses involved tasks as a sequence to
sequence mapping problem, which is general enough for a variety of front-end
speech enhancement tasks. The proposed method is inspired by the excellent
sequence modeling capability of bidirectional encoder representation from
transformers (BERT). Instead of utilizing explicit representations from
pretraining in a self-supervised manner, we utilizes transformer encoded hidden
representations in a supervised manner. Both multichannel spectral magnitude
and spectral phase information of varying length utterances are encoded.
Experimental result demonstrates the effectiveness of the proposed method.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 11:05:17 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 02:41:39 GMT'}]",2020-10-23,"[['Jiao', 'Yang', '']]"
1367236,2010.10906,Branden Chan,"Branden Chan, Stefan Schweter, Timo M\""oller",German's Next Language Model,Accepted by COLING2020 Industry Track,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this work we present the experiments which lead to the creation of our
BERT and ELECTRA based German language models, GBERT and GELECTRA. By varying
the input training data, model size, and the presence of Whole Word Masking
(WWM) we were able to attain SoTA performance across a set of document
classification and named entity recognition (NER) tasks for both models of base
and large size. We adopt an evaluation driven approach in training these models
and our results indicate that both adding more data and utilizing WWM improve
model performance. By benchmarking against existing German models, we show that
these models are the best German models to date. Our trained models will be
made publicly available to the research community.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 11:28:23 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 08:39:30 GMT'}]",2020-10-23,"[['Chan', 'Branden', ''], ['Schweter', 'Stefan', ''], ['Möller', 'Timo', '']]"
772506,1609.07028,Ruobing Xie,"Ruobing Xie, Zhiyuan Liu, Huanbo Luan, Maosong Sun",Image-embodied Knowledge Representation Learning,7 pages; Accepted by IJCAI-2017,IJCAI-2017,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Entity images could provide significant visual information for knowledge
representation learning. Most conventional methods learn knowledge
representations merely from structured triples, ignoring rich visual
information extracted from entity images. In this paper, we propose a novel
Image-embodied Knowledge Representation Learning model (IKRL), where knowledge
representations are learned with both triple facts and images. More
specifically, we first construct representations for all images of an entity
with a neural image encoder. These image representations are then integrated
into an aggregated image-based representation via an attention-based method. We
evaluate our IKRL models on knowledge graph completion and triple
classification. Experimental results demonstrate that our models outperform all
baselines on both tasks, which indicates the significance of visual information
for knowledge representations and the capability of our models in learning
knowledge representations with images.
","[{'version': 'v1', 'created': 'Thu, 22 Sep 2016 15:37:45 GMT'}, {'version': 'v2', 'created': 'Mon, 22 May 2017 08:14:27 GMT'}]",2020-10-23,"[['Xie', 'Ruobing', ''], ['Liu', 'Zhiyuan', ''], ['Luan', 'Huanbo', ''], ['Sun', 'Maosong', '']]"
1292326,2005.12531,Dongyang Dai,"Dongyang Dai, Li Chen, Yuping Wang, Mu Wang, Rui Xia, Xuchen Song,
  Zhiyong Wu, Yuxuan Wang","Noise Robust TTS for Low Resource Speakers using Pre-trained Model and
  Speech Enhancement",,,,,eess.AS cs.CL cs.LG cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  With the popularity of deep neural network, speech synthesis task has
achieved significant improvements based on the end-to-end encoder-decoder
framework in the recent days. More and more applications relying on speech
synthesis technology have been widely used in our daily life. Robust speech
synthesis model depends on high quality and customized data which needs lots of
collecting efforts. It is worth investigating how to take advantage of
low-quality and low resource voice data which can be easily obtained from the
Internet for usage of synthesizing personalized voice. In this paper, the
proposed end-to-end speech synthesis model uses both speaker embedding and
noise representation as conditional inputs to model speaker and noise
information respectively. Firstly, the speech synthesis model is pre-trained
with both multi-speaker clean data and noisy augmented data; then the
pre-trained model is adapted on noisy low-resource new speaker data; finally,
by setting the clean speech condition, the model can synthesize the new
speaker's clean voice. Experimental results show that the speech generated by
the proposed approach has better subjective evaluation results than the method
directly fine-tuning pre-trained multi-speaker speech synthesis model with
denoised new speaker data.
","[{'version': 'v1', 'created': 'Tue, 26 May 2020 06:14:06 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 11:36:56 GMT'}]",2020-10-23,"[['Dai', 'Dongyang', ''], ['Chen', 'Li', ''], ['Wang', 'Yuping', ''], ['Wang', 'Mu', ''], ['Xia', 'Rui', ''], ['Song', 'Xuchen', ''], ['Wu', 'Zhiyong', ''], ['Wang', 'Yuxuan', '']]"
1367652,2010.11322,Jonathan Pilault,"Jaehong Park, Jonathan Pilault and Christopher Pal",Learning to Summarize Long Texts with Memory Compression and Transfer,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  We introduce Mem2Mem, a memory-to-memory mechanism for hierarchical recurrent
neural network based encoder decoder architectures and we explore its use for
abstractive document summarization. Mem2Mem transfers ""memories"" via
readable/writable external memory modules that augment both the encoder and
decoder. Our memory regularization compresses an encoded input article into a
more compact set of sentence representations. Most importantly, the memory
compression step performs implicit extraction without labels, sidestepping
issues with suboptimal ground-truth data and exposure bias of hybrid
extractive-abstractive summarization techniques. By allowing the decoder to
read/write over the encoded input memory, the model learns to read salient
information about the input article while keeping track of what has been
generated. Our Mem2Mem approach yields results that are competitive with state
of the art transformer based summarization methods, but with 16 times fewer
parameters
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 21:45:44 GMT'}]",2020-10-23,"[['Park', 'Jaehong', ''], ['Pilault', 'Jonathan', ''], ['Pal', 'Christopher', '']]"
1367836,2010.11506,Lingkai Kong,"Lingkai Kong, Haoming Jiang, Yuchen Zhuang, Jie Lyu, Tuo Zhao, Chao
  Zhang","Calibrated Language Model Fine-Tuning for In- and Out-of-Distribution
  Data",EMNLP2020 long paper,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Fine-tuned pre-trained language models can suffer from severe miscalibration
for both in-distribution and out-of-distribution (OOD) data due to
over-parameterization. To mitigate this issue, we propose a regularized
fine-tuning method. Our method introduces two types of regularization for
better calibration: (1) On-manifold regularization, which generates pseudo
on-manifold samples through interpolation within the data manifold. Augmented
training with these pseudo samples imposes a smoothness regularization to
improve in-distribution calibration. (2) Off-manifold regularization, which
encourages the model to output uniform distributions for pseudo off-manifold
samples to address the over-confidence issue for OOD data. Our experiments
demonstrate that the proposed method outperforms existing calibration methods
for text classification in terms of expectation calibration error,
misclassification detection, and OOD detection on six datasets. Our code can be
found at https://github.com/Lingkai-Kong/Calibrated-BERT-Fine-Tuning.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 07:48:38 GMT'}]",2020-10-23,"[['Kong', 'Lingkai', ''], ['Jiang', 'Haoming', ''], ['Zhuang', 'Yuchen', ''], ['Lyu', 'Jie', ''], ['Zhao', 'Tuo', ''], ['Zhang', 'Chao', '']]"
1367716,2010.11386,Jheng-Hong Yang,"Sheng-Chieh Lin, Jheng-Hong Yang, Jimmy Lin","Distilling Dense Representations for Ranking using Tightly-Coupled
  Teachers",,,,,cs.IR cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present an approach to ranking with dense representations that applies
knowledge distillation to improve the recently proposed late-interaction
ColBERT model. Specifically, we distill the knowledge from ColBERT's expressive
MaxSim operator for computing relevance scores into a simple dot product, thus
enabling single-step ANN search. Our key insight is that during distillation,
tight coupling between the teacher model and the student model enables more
flexible distillation strategies and yields better learned representations. We
empirically show that our approach improves query latency and greatly reduces
the onerous storage requirements of ColBERT, while only making modest
sacrifices in terms of effectiveness. By combining our dense representations
with sparse representations derived from document expansion, we are able to
approach the effectiveness of a standard cross-encoder reranker using BERT that
is orders of magnitude slower.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 02:26:01 GMT'}]",2020-10-23,"[['Lin', 'Sheng-Chieh', ''], ['Yang', 'Jheng-Hong', ''], ['Lin', 'Jimmy', '']]"
1367775,2010.11445,Mingbo Ma,"Junkun Chen, Mingbo Ma, Renjie Zheng, Liang Huang",MAM: Masked Acoustic Modeling for End-to-End Speech-to-Text Translation,10 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  End-to-end Speech-to-text Translation (E2E- ST), which directly translates
source language speech to target language text, is widely useful in practice,
but traditional cascaded approaches (ASR+MT) often suffer from error
propagation in the pipeline. On the other hand, existing end-to-end solutions
heavily depend on the source language transcriptions for pre-training or
multi-task training with Automatic Speech Recognition (ASR). We instead propose
a simple technique to learn a robust speech encoder in a self-supervised
fashion only on the speech side, which can utilize speech data without
transcription. This technique, termed Masked Acoustic Modeling (MAM), can also
perform pre-training, for the first time, on any acoustic signals (including
non-speech ones) without annotation. Compared with current state-of-the-art
models on ST, our technique achieves +1.4 BLEU improvement without using
transcriptions, and +1.2 BLEU using transcriptions. The pre-training of MAM
with arbitrary acoustic signals also boosts the downstream speech-related
tasks.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 05:02:06 GMT'}]",2020-10-23,"[['Chen', 'Junkun', ''], ['Ma', 'Mingbo', ''], ['Zheng', 'Renjie', ''], ['Huang', 'Liang', '']]"
1367820,2010.11490,Christophe Cerisara,"Christophe Cerisara (SYNALP), Pavel Kral, Ladislav Lenc","On the Effects of Using word2vec Representations in Neural Networks for
  Dialogue Act Recognition",,"Computer Speech and Language, Elsevier, 2018, 47, pp.175 - 193",10.1016/j.csl.2017.07.009,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Dialogue act recognition is an important component of a large number of
natural language processing pipelines. Many research works have been carried
out in this area, but relatively few investigate deep neural networks and word
embeddings. This is surprising, given that both of these techniques have proven
exceptionally good in most other language-related domains. We propose in this
work a new deep neural network that explores recurrent models to capture word
sequences within sentences, and further study the impact of pretrained word
embeddings. We validate this model on three languages: English, French and
Czech. The performance of the proposed approach is consistent across these
languages and it is comparable to the state-of-the-art results in English. More
importantly, we confirm that deep neural networks indeed outperform a Maximum
Entropy classifier, which was expected. However , and this is more surprising,
we also found that standard word2vec em-beddings do not seem to bring valuable
information for this task and the proposed model, whatever the size of the
training corpus is. We thus further analyse the resulting embeddings and
conclude that a possible explanation may be related to the mismatch between the
type of lexical-semantic information captured by the word2vec embeddings, and
the kind of relations between words that is the most useful for the dialogue
act recognition task.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 07:21:17 GMT'}]",2020-10-23,"[['Cerisara', 'Christophe', '', 'SYNALP'], ['Kral', 'Pavel', ''], ['Lenc', 'Ladislav', '']]"
1368266,2010.11936,Tomasz Stanis{\l}awek,Rafal Powalski and Tomasz Stanislawek,UniCase -- Rethinking Casing in Language Models,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we introduce a new approach to dealing with the problem of
case-sensitiveness in Language Modelling (LM). We propose simple architecture
modification to the RoBERTa language model, accompanied by a new tokenization
strategy, which we named Unified Case LM (UniCase). We tested our solution on
the GLUE benchmark, which led to increased performance by 0.42 points.
Moreover, we prove that the UniCase model works much better when we have to
deal with text data, where all tokens are uppercased (+5.88 point).
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 17:58:44 GMT'}]",2020-10-23,"[['Powalski', 'Rafal', ''], ['Stanislawek', 'Tomasz', '']]"
1368260,2010.11930,Rodrigo Nogueira,"Ronak Pradeep, Xueguang Ma, Rodrigo Nogueira, Jimmy Lin",Scientific Claim Verification with VERT5ERINI,,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This work describes the adaptation of a pretrained sequence-to-sequence model
to the task of scientific claim verification in the biomedical domain. We
propose VERT5ERINI that exploits T5 for abstract retrieval, sentence selection
and label prediction, which are three critical sub-tasks of claim verification.
We evaluate our pipeline on SCIFACT, a newly curated dataset that requires
models to not just predict the veracity of claims but also provide relevant
sentences from a corpus of scientific literature that support this decision.
Empirically, our pipeline outperforms a strong baseline in each of the three
steps. Finally, we show VERT5ERINI's ability to generalize to two new datasets
of COVID-19 claims using evidence from the ever-expanding CORD-19 corpus.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 17:56:33 GMT'}]",2020-10-23,"[['Pradeep', 'Ronak', ''], ['Ma', 'Xueguang', ''], ['Nogueira', 'Rodrigo', ''], ['Lin', 'Jimmy', '']]"
1368248,2010.11918,"Andreas R\""uckl\'e","Andreas R\""uckl\'e, Gregor Geigle, Max Glockner, Tilman Beck, Jonas
  Pfeiffer, Nils Reimers, Iryna Gurevych",AdapterDrop: On the Efficiency of Adapters in Transformers,,,,,cs.LG cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Massively pre-trained transformer models are computationally expensive to
fine-tune, slow for inference, and have large storage requirements. Recent
approaches tackle these shortcomings by training smaller models, dynamically
reducing the model size, and by training light-weight adapters. In this paper,
we propose AdapterDrop, removing adapters from lower transformer layers during
training and inference, which incorporates concepts from all three directions.
We show that AdapterDrop can dynamically reduce the computational overhead when
performing inference over multiple tasks simultaneously, with minimal decrease
in task performances. We further prune adapters from AdapterFusion, which
improves the inference efficiency while maintaining the task performances
entirely.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 17:49:42 GMT'}]",2020-10-23,"[['Rücklé', 'Andreas', ''], ['Geigle', 'Gregor', ''], ['Glockner', 'Max', ''], ['Beck', 'Tilman', ''], ['Pfeiffer', 'Jonas', ''], ['Reimers', 'Nils', ''], ['Gurevych', 'Iryna', '']]"
1367717,2010.11387,George Boateng,George Boateng,Kwame: A Bilingual AI Teaching Assistant for Online SuaCode Courses,,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Introductory hands-on courses such as our smartphone-based coding courses,
SuaCode require a lot of support for students to accomplish learning goals.
Online environments make it even more difficult to get assistance especially
more recently because of COVID-19. Given the multilingual context of our
students (learners across 38 African countries), in this work, we developed an
AI Teaching Assistant (Kwame) that provides answers to students' coding
questions from our SuaCode courses in English and French. Kwame is a
Sentence-BERT(SBERT)-based question-answering (QA) system that we trained and
evaluated using question-answer pairs created from our course's quizzes and
students' questions in past cohorts. It finds the paragraph most semantically
similar to the question via cosine similarity. We compared the system with
TF-IDF and Universal Sentence Encoder. Our results showed that SBERT performed
the worst for the duration of 6 secs per question but the best for accuracy and
fine-tuning on our course data improved the result.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 02:26:12 GMT'}]",2020-10-23,"[['Boateng', 'George', '']]"
1368199,2010.11869,Lei Xu,"Lei Xu, Ivan Ramirez, Kalyan Veeramachaneni","Rewriting Meaningful Sentences via Conditional BERT Sampling and an
  application on fooling text classifiers",,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Most adversarial attack methods that are designed to deceive a text
classifier change the text classifier's prediction by modifying a few words or
characters. Few try to attack classifiers by rewriting a whole sentence, due to
the difficulties inherent in sentence-level rephrasing as well as the problem
of setting the criteria for legitimate rewriting.
  In this paper, we explore the problem of creating adversarial examples with
sentence-level rewriting. We design a new sampling method, named
ParaphraseSampler, to efficiently rewrite the original sentence in multiple
ways. Then we propose a new criteria for modification, called a sentence-level
threaten model. This criteria allows for both word- and sentence-level changes,
and can be adjusted independently in two dimensions: semantic similarity and
grammatical quality. Experimental results show that many of these rewritten
sentences are misclassified by the classifier. On all 6 datasets, our
ParaphraseSampler achieves a better attack success rate than our baseline.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 17:03:13 GMT'}]",2020-10-23,"[['Xu', 'Lei', ''], ['Ramirez', 'Ivan', ''], ['Veeramachaneni', 'Kalyan', '']]"
1368189,2010.11859,Nikolay Bogoychev Dr,Nikolay Bogoychev,Not all parameters are born equal: Attention is mostly what you need,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Transformers are widely used in state-of-the-art machine translation, but the
key to their success is still unknown. To gain insight into this, we consider
three groups of parameters: embeddings, attention, and feed forward neural
network (FFN) layers. We examine the relative importance of each by performing
an ablation study where we initialise them at random and freeze them, so that
their weights do not change over the course of the training. Through this, we
show that the attention and FFN are equally important and fulfil the same
functionality in a model. We show that the decision about whether a component
is frozen or allowed to train is at least as important for the final model
performance as its number of parameters. At the same time, the number of
parameters alone is not indicative of a component's importance. Finally, while
the embedding layer is the least essential for machine translation tasks, it is
the most important component for language modelling tasks.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 16:49:18 GMT'}]",2020-10-23,"[['Bogoychev', 'Nikolay', '']]"
1367811,2010.11481,Yu-An Chung,Yu-An Chung and Yonatan Belinkov and James Glass,Similarity Analysis of Self-Supervised Speech Representations,,,,,eess.AS cs.CL cs.LG cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Self-supervised speech representation learning has recently been a prosperous
research topic. Many algorithms have been proposed for learning useful
representations from large-scale unlabeled data, and their applications to a
wide range of speech tasks have also been investigated. However, there has been
little research focusing on understanding the properties of existing
approaches. In this work, we aim to provide a comparative study of some of the
most representative self-supervised algorithms. Specifically, we quantify the
similarities between different self-supervised representations using existing
similarity measures. We also design probing tasks to study the correlation
between the models' pre-training loss and the amount of specific speech
information contained in their learned representations. In addition to showing
how various self-supervised models behave differently given the same input, our
study also finds that the training objective has a higher impact on
representation similarity than architectural choices such as building blocks
(RNN/Transformer/CNN) and directionality (uni/bidirectional). Our results also
suggest that there exists a strong correlation between pre-training loss and
downstream performance for some self-supervised algorithms.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 07:02:21 GMT'}]",2020-10-23,"[['Chung', 'Yu-An', ''], ['Belinkov', 'Yonatan', ''], ['Glass', 'James', '']]"
1368245,2010.11915,Akari Asai,Akari Asai and Eunsol Choi,"Challenges in Information Seeking QA:Unanswerable Questions and
  Paragraph Retrieval",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent progress in pretrained language model ""solved"" many reading
comprehension benchmark datasets. Yet information-seeking Question Answering
(QA) datasets, where questions are written without the evidence document,
remain unsolved. We analyze two such datasets (Natural Questions and TyDi QA)
to identify remaining headrooms: paragraph selection and answerability
classification, i.e. determining whether the paired evidence document contains
the answer to the query or not. In other words, given a gold paragraph and
knowing whether it contains an answer or not, models easily outperform a single
annotator in both datasets. After identifying unanswerability as a bottleneck,
we further inspect what makes questions unanswerable. Our study points to
avenues for future research, both for dataset creation and model development.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 17:48:17 GMT'}]",2020-10-23,"[['Asai', 'Akari', ''], ['Choi', 'Eunsol', '']]"
1368185,2010.11855,Michael Wick,"Michael L. Wick, Kate Silverstein, Jean-Baptiste Tristan, Adam Pocock,
  Mark Johnson","Detecting and Exorcising Statistical Demons from Language Models with
  Anti-Models of Negative Data",,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  It's been said that ""Language Models are Unsupervised Multitask Learners.""
Indeed, self-supervised language models trained on ""positive"" examples of
English text generalize in desirable ways to many natural language tasks. But
if such models can stray so far from an initial self-supervision objective, a
wayward model might generalize in undesirable ways too, say to nonsensical
""negative"" examples of unnatural language. A key question in this work is: do
language models trained on (positive) training data also generalize to
(negative) test data? We use this question as a contrivance to assess the
extent to which language models learn undesirable properties of text, such as
n-grams, that might interfere with the learning of more desirable properties of
text, such as syntax. We find that within a model family, as the number of
parameters, training epochs, and data set size increase, so does a model's
ability to generalize to negative n-gram data, indicating standard
self-supervision generalizes too far. We propose a form of inductive bias that
attenuates such undesirable signals with negative data distributions
automatically learned from positive data. We apply the method to remove n-gram
signals from LSTMs and find that doing so causes them to favor syntactic
signals, as demonstrated by large error reductions (up to 46% on the hardest
cases) on a syntactic subject-verb agreement task.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 16:45:32 GMT'}]",2020-10-23,"[['Wick', 'Michael L.', ''], ['Silverstein', 'Kate', ''], ['Tristan', 'Jean-Baptiste', ''], ['Pocock', 'Adam', ''], ['Johnson', 'Mark', '']]"
1368121,2010.11791,Ivan Vuli\'c,Matthew Henderson and Ivan Vuli\'c,ConVEx: Data-Efficient and Few-Shot Slot Labeling,,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  We propose ConVEx (Conversational Value Extractor), an efficient pretraining
and fine-tuning neural approach for slot-labeling dialog tasks. Instead of
relying on more general pretraining objectives from prior work (e.g., language
modeling, response selection), ConVEx's pretraining objective, a novel pairwise
cloze task using Reddit data, is well aligned with its intended usage on
sequence labeling tasks. This enables learning domain-specific slot labelers by
simply fine-tuning decoding layers of the pretrained general-purpose sequence
labeling model, while the majority of the pretrained model's parameters are
kept frozen. We report state-of-the-art performance of ConVEx across a range of
diverse domains and data sets for dialog slot-labeling, with the largest gains
in the most challenging, few-shot setups. We believe that ConVEx's reduced
pretraining times (i.e., only 18 hours on 12 GPUs) and cost, along with its
efficient fine-tuning and strong performance, promise wider portability and
scalability for data-efficient sequence-labeling tasks in general.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 15:13:35 GMT'}]",2020-10-23,"[['Henderson', 'Matthew', ''], ['Vulić', 'Ivan', '']]"
1368183,2010.11853,Johannes E. M. Mosig,"Johannes E. M. Mosig, Shikib Mehri, Thomas Kober",STAR: A Schema-Guided Dialog Dataset for Transfer Learning,"Equal contribution: Johannes E. M. Mosig, Shikib Mehri",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present STAR, a schema-guided task-oriented dialog dataset consisting of
127,833 utterances and knowledge base queries across 5,820 task-oriented
dialogs in 13 domains that is especially designed to facilitate task and domain
transfer learning in task-oriented dialog. Furthermore, we propose a scalable
crowd-sourcing paradigm to collect arbitrarily large datasets of the same
quality as STAR. Moreover, we introduce novel schema-guided dialog models that
use an explicit description of the task(s) to generalize from known to unknown
tasks. We demonstrate the effectiveness of these models, particularly for
zero-shot generalization across tasks and domains.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 16:45:00 GMT'}]",2020-10-23,"[['Mosig', 'Johannes E. M.', ''], ['Mehri', 'Shikib', ''], ['Kober', 'Thomas', '']]"
1368148,2010.11818,Hao Zheng,Hao Zheng and Mirella Lapata,Compositional Generalization via Semantic Tagging,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Although neural sequence-to-sequence models have been successfully applied to
semantic parsing, they struggle to perform well on query-based data splits that
require \emph{composition generalization}, an ability of systematically
generalizing to unseen composition of seen components. Motivated by the
explicitly built-in compositionality in traditional statistical semantic
parsing, we propose a new decoding framework that preserves the expressivity
and generality of sequence-to-sequence models while featuring explicit
lexicon-style alignments and disentangled information processing. Specifically,
we decompose decoding into two phases where an input utterance is first tagged
with semantic symbols representing the meanings of its individual words, and
then a sequence-to-sequence model is used to predict the final meaning
representation conditioning on the utterance and the predicted tag sequence.
Experimental results on three semantic parsing datasets with query-based splits
show that the proposed approach consistently improves compositional
generalization of sequence-to-sequence models across different model
architectures, domains and semantic formalisms.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 15:55:15 GMT'}]",2020-10-23,"[['Zheng', 'Hao', ''], ['Lapata', 'Mirella', '']]"
1366748,2010.10418,Swarnadeep Saha,"Swarnadeep Saha, Yixin Nie, Mohit Bansal",ConjNLI: Natural Language Inference Over Conjunctive Sentences,EMNLP 2020 (14 pages),,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Reasoning about conjuncts in conjunctive sentences is important for a deeper
understanding of conjunctions in English and also how their usages and
semantics differ from conjunctive and disjunctive boolean logic. Existing NLI
stress tests do not consider non-boolean usages of conjunctions and use
templates for testing such model knowledge. Hence, we introduce ConjNLI, a
challenge stress-test for natural language inference over conjunctive
sentences, where the premise differs from the hypothesis by conjuncts removed,
added, or replaced. These sentences contain single and multiple instances of
coordinating conjunctions (""and"", ""or"", ""but"", ""nor"") with quantifiers,
negations, and requiring diverse boolean and non-boolean inferences over
conjuncts. We find that large-scale pre-trained language models like RoBERTa do
not understand conjunctive semantics well and resort to shallow heuristics to
make inferences over such sentences. As some initial solutions, we first
present an iterative adversarial fine-tuning method that uses synthetically
created training data based on boolean and non-boolean heuristics. We also
propose a direct model advancement by making RoBERTa aware of predicate
semantic roles. While we observe some performance gains, ConjNLI is still
challenging for current methods, thus encouraging interesting future work for
better understanding of conjunctions. Our data and code are publicly available
at: https://github.com/swarnaHub/ConjNLI
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 16:29:13 GMT'}, {'version': 'v2', 'created': 'Wed, 21 Oct 2020 21:49:00 GMT'}]",2020-10-23,"[['Saha', 'Swarnadeep', ''], ['Nie', 'Yixin', ''], ['Bansal', 'Mohit', '']]"
1367873,2010.11543,Jee-Weon Jung,"Jee-weon Jung, Hee-Soo Heo, Ha-Jin Yu, Joon Son Chung",Graph Attention Networks for Speaker Verification,"5 pages, 1 figure, 2 tables, submitted to ICASSP 2021 as a conference
  paper",,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This work presents a novel back-end framework for speaker verification using
graph attention networks. Segment-wise speaker embeddings extracted from
multiple crops within an utterance are interpreted as node representations of a
graph. The proposed framework inputs segment-wise speaker embeddings from an
enrollment and a test utterance and directly outputs a similarity score. We
first construct a graph using segment-wise speaker embeddings and then input
these to graph attention networks. After a few graph attention layers with
residual connections, each node is projected into a one-dimensional space using
affine transform, followed by a readout operation resulting in a scalar
similarity score. To enable successful adaptation for speaker verification, we
propose techniques such as separating trainable weights for attention map
calculations between segment-wise speaker embeddings from different utterances.
The effectiveness of the proposed framework is validated using three different
speaker embedding extractors trained with different architectures and objective
functions. Experimental results demonstrate consistent improvement over various
baseline back-end classifiers, with an average equal error rate improvement of
20% over the cosine similarity back-end without test time augmentation.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 09:08:02 GMT'}]",2020-10-24,"[['Jung', 'Jee-weon', ''], ['Heo', 'Hee-Soo', ''], ['Yu', 'Ha-Jin', ''], ['Chung', 'Joon Son', '']]"
1368133,2010.11803,Zeqian Li,"Zeqian Li, Jacob Whitehill","Compositional embedding models for speaker identification and
  diarization with simultaneous speech from 2+ speakers",,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a new method for speaker diarization that can handle overlapping
speech with 2+ people. Our method is based on compositional embeddings [1]:
Like standard speaker embedding methods such as x-vector [2], compositional
embedding models contain a function f that separates speech from different
speakers. In addition, they include a composition function g to compute
set-union operations in the embedding space so as to infer the set of speakers
within the input audio. In an experiment on multi-person speaker identification
using synthesized LibriSpeech data, the proposed method outperforms traditional
embedding methods that are only trained to separate single speakers (not
speaker sets). In a speaker diarization experiment on the AMI Headset Mix
corpus, we achieve state-of-the-art accuracy (DER=22.93%), slightly higher than
the previous best result (23.82% from [3]).
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 15:33:36 GMT'}]",2020-10-24,"[['Li', 'Zeqian', ''], ['Whitehill', 'Jacob', '']]"
1368269,2010.11939,Chu-Cheng Lin,"Chu-Cheng Lin and Aaron Jaech and Xin Li and Matt Gormley and Jason
  Eisner",Autoregressive Modeling is Misspecified for Some Sequence Distributions,,,,,cs.LG cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Should sequences be modeled autoregressively---one symbol at a time? How much
computation is needed to predict the next symbol? While local normalization is
cheap, this also limits its power. We point out that some probability
distributions over discrete sequences cannot be well-approximated by any
autoregressive model whose runtime and parameter size grow polynomially in the
sequence length---even though their unnormalized sequence probabilities are
efficient to compute exactly. Intuitively, the probability of the next symbol
can be expensive to compute or approximate (even via randomized algorithms)
when it marginalizes over exponentially many possible futures, which is in
general $\mathrm{NP}$-hard. Our result is conditional on the widely believed
hypothesis that $\mathrm{NP} \nsubseteq \mathrm{P/poly}$ (without which the
polynomial hierarchy would collapse at the second level). This theoretical
observation serves as a caution to the viewpoint that pumping up parameter size
is a straightforward way to improve autoregressive models (e.g., in language
modeling). It also suggests that globally normalized (energy-based) models may
sometimes outperform locally normalized (autoregressive) models, as we
demonstrate experimentally for language modeling.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 17:59:09 GMT'}]",2020-10-24,"[['Lin', 'Chu-Cheng', ''], ['Jaech', 'Aaron', ''], ['Li', 'Xin', ''], ['Gormley', 'Matt', ''], ['Eisner', 'Jason', '']]"
1260776,2003.10421,"Eric M\""uller-Budack","Eric M\""uller-Budack, Jonas Theiner, Sebastian Diering, Maximilian
  Idahl, Ralph Ewerth","Multimodal Analytics for Real-world News using Measures of Cross-modal
  Entity Consistency","Accepted for publication in: International Conference on Multimedia
  Retrieval (ICMR), Dublin, 2020",,,,cs.CL cs.IR cs.MM,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The World Wide Web has become a popular source for gathering information and
news. Multimodal information, e.g., enriching text with photos, is typically
used to convey the news more effectively or to attract attention. Photo content
can range from decorative, depict additional important information, or can even
contain misleading information. Therefore, automatic approaches to quantify
cross-modal consistency of entity representation can support human assessors to
evaluate the overall multimodal message, for instance, with regard to bias or
sentiment. In some cases such measures could give hints to detect fake news,
which is an increasingly important topic in today's society. In this paper, we
introduce a novel task of cross-modal consistency verification in real-world
news and present a multimodal approach to quantify the entity coherence between
image and text. Named entity linking is applied to extract persons, locations,
and events from news texts. Several measures are suggested to calculate
cross-modal similarity for these entities using state of the art approaches. In
contrast to previous work, our system automatically gathers example data from
the Web and is applicable to real-world news. Results on two novel datasets
that cover different languages, topics, and domains demonstrate the feasibility
of our approach. Datasets and code are publicly available to foster research
towards this new direction.
","[{'version': 'v1', 'created': 'Mon, 23 Mar 2020 17:49:06 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 09:22:53 GMT'}]",2020-10-26,"[['Müller-Budack', 'Eric', ''], ['Theiner', 'Jonas', ''], ['Diering', 'Sebastian', ''], ['Idahl', 'Maximilian', ''], ['Ewerth', 'Ralph', '']]"
1268577,2004.03807,Abhinav Ramesh Kashyap,"Abhinav Ramesh Kashyap, Min-Yen Kan",SciWING -- A Software Toolkit for Scientific Document Processing,"6 pages, 3 figures, First Workshop on Scholarly Document Processing -
  SDP@EMNLP 2020",,,,cs.DL cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We introduce SciWING, an open-source software toolkit which provides access
to pre-trained models for scientific document processing tasks, inclusive of
citation string parsing and logical structure recovery. SciWING enables
researchers to rapidly experiment with different models by swapping and
stacking different modules. It also enables them declare and run models from a
configuration file. It enables researchers to perform production-ready transfer
learning from general, pre-trained transformers (i.e., BERT, SciBERT etc), and
aids development of end-user applications. It includes ready-to-use web and
terminal-based applications and demonstrations (Available from
http://sciwing.io).
","[{'version': 'v1', 'created': 'Wed, 8 Apr 2020 04:43:37 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 07:27:01 GMT'}]",2020-10-26,"[['Kashyap', 'Abhinav Ramesh', ''], ['Kan', 'Min-Yen', '']]"
1278000,2004.13230,Marjan Albooyeh,"Marjan Albooyeh, Rishab Goel, Seyed Mehran Kazemi",Out-of-Sample Representation Learning for Multi-Relational Graphs,,,,,cs.LG cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Many important problems can be formulated as reasoning in knowledge graphs.
Representation learning has proved extremely effective for transductive
reasoning, in which one needs to make new predictions for already observed
entities. This is true for both attributed graphs(where each entity has an
initial feature vector) and non-attributed graphs (where the only initial
information derives from known relations with other entities). For
out-of-sample reasoning, where one needs to make predictions for entities that
were unseen at training time, much prior work considers attributed graph.
However, this problem is surprisingly under-explored for non-attributed graphs.
In this paper, we study the out-of-sample representation learning problem for
non-attributed knowledge graphs, create benchmark datasets for this task,
develop several models and baselines, and provide empirical analyses and
comparisons of the proposed models and baselines.
","[{'version': 'v1', 'created': 'Tue, 28 Apr 2020 00:53:01 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 16:22:50 GMT'}]",2020-10-26,"[['Albooyeh', 'Marjan', ''], ['Goel', 'Rishab', ''], ['Kazemi', 'Seyed Mehran', '']]"
1213482,1912.01586,Tongfei Chen,"Yunmo Chen, Tongfei Chen, Seth Ebner, Aaron Steven White, Benjamin Van
  Durme",Reading the Manual: Event Extraction as Definition Comprehension,Accepted at the EMNLP 2020 Workshop on Structured Prediction for NLP,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We ask whether text understanding has progressed to where we may extract
event information through incremental refinement of bleached statements derived
from annotation manuals. Such a capability would allow for the trivial
construction and extension of an extraction framework by intended end-users
through declarations such as, ""Some person was born in some location at some
time."" We introduce an example of a model that employs such statements, with
experiments illustrating we can extract events under closed ontologies and
generalize to unseen event types simply by reading new definitions.
","[{'version': 'v1', 'created': 'Tue, 3 Dec 2019 18:31:42 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 02:27:24 GMT'}]",2020-10-26,"[['Chen', 'Yunmo', ''], ['Chen', 'Tongfei', ''], ['Ebner', 'Seth', ''], ['White', 'Aaron Steven', ''], ['Van Durme', 'Benjamin', '']]"
1276843,2004.12073,Sho Takase,Sho Takase and Sosuke Kobayashi,All Word Embeddings from One Embedding,NeurIPS 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In neural network-based models for natural language processing (NLP), the
largest part of the parameters often consists of word embeddings. Conventional
models prepare a large embedding matrix whose size depends on the vocabulary
size. Therefore, storing these models in memory and disk storage is costly. In
this study, to reduce the total number of parameters, the embeddings for all
words are represented by transforming a shared embedding. The proposed method,
ALONE (all word embeddings from one), constructs the embedding of a word by
modifying the shared embedding with a filter vector, which is word-specific but
non-trainable. Then, we input the constructed embedding into a feed-forward
neural network to increase its expressiveness. Naively, the filter vectors
occupy the same memory size as the conventional embedding matrix, which depends
on the vocabulary size. To solve this issue, we also introduce a
memory-efficient filter construction approach. We indicate our ALONE can be
used as word representation sufficiently through an experiment on the
reconstruction of pre-trained word embeddings. In addition, we also conduct
experiments on NLP application tasks: machine translation and summarization. We
combined ALONE with the current state-of-the-art encoder-decoder model, the
Transformer, and achieved comparable scores on WMT 2014 English-to-German
translation and DUC 2004 very short summarization with less parameters.
","[{'version': 'v1', 'created': 'Sat, 25 Apr 2020 07:38:08 GMT'}, {'version': 'v2', 'created': 'Mon, 25 May 2020 03:36:32 GMT'}, {'version': 'v3', 'created': 'Fri, 23 Oct 2020 03:12:12 GMT'}]",2020-10-26,"[['Takase', 'Sho', ''], ['Kobayashi', 'Sosuke', '']]"
968940,1804.07247,Dominic Seyler,"Dominic Seyler, Lunan Li, ChengXiang Zhai","Semantic Text Analysis for Detection of Compromised Accounts on Social
  Networks",,,,,cs.SI cs.CL cs.CR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Compromised accounts on social networks are regular user accounts that have
been taken over by an entity with malicious intent. Since the adversary
exploits the already established trust of a compromised account, it is crucial
to detect these accounts to limit the damage they can cause. We propose a novel
general framework for semantic analysis of text messages coming out from an
account to detect compromised accounts. Our framework is built on the
observation that normal users will use language that is measurably different
from the language that an adversary would use when the account is compromised.
We propose to use the difference of language models of users and adversaries to
define novel interpretable semantic features for measuring semantic incoherence
in a message stream. We study the effectiveness of the proposed semantic
features using a Twitter data set. Evaluation results show that the proposed
framework is effective for discovering compromised accounts on social networks
and a KL-divergence-based language model feature works best.
","[{'version': 'v1', 'created': 'Thu, 19 Apr 2018 16:06:29 GMT'}, {'version': 'v2', 'created': 'Wed, 5 Feb 2020 18:06:25 GMT'}, {'version': 'v3', 'created': 'Wed, 6 May 2020 21:26:02 GMT'}, {'version': 'v4', 'created': 'Fri, 23 Oct 2020 15:56:27 GMT'}]",2020-10-26,"[['Seyler', 'Dominic', ''], ['Li', 'Lunan', ''], ['Zhai', 'ChengXiang', '']]"
1246550,2002.09127,Eric Yuan,"Ashutosh Adhikari, Xingdi Yuan, Marc-Alexandre C\^ot\'e, Mikul\'a\v{s}
  Zelinka, Marc-Antoine Rondeau, Romain Laroche, Pascal Poupart, Jian Tang,
  Adam Trischler, William L. Hamilton",Learning Dynamic Belief Graphs to Generalize on Text-Based Games,NeurIPS 2020 cameraready version,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Playing text-based games requires skills in processing natural language and
sequential decision making. Achieving human-level performance on text-based
games remains an open challenge, and prior research has largely relied on
hand-crafted structured representations and heuristics. In this work, we
investigate how an agent can plan and generalize in text-based games using
graph-structured representations learned end-to-end from raw text. We propose a
novel graph-aided transformer agent (GATA) that infers and updates latent
belief graphs during planning to enable effective action selection by capturing
the underlying game dynamics. GATA is trained using a combination of
reinforcement and self-supervised learning. Our work demonstrates that the
learned graph-based representations help agents converge to better policies
than their text-only counterparts and facilitate effective generalization
across game configurations. Experiments on 500+ unique games from the TextWorld
suite show that our best agent outperforms text-based baselines by an average
of 24.2%.
","[{'version': 'v1', 'created': 'Fri, 21 Feb 2020 04:38:37 GMT'}, {'version': 'v2', 'created': 'Thu, 18 Jun 2020 16:22:16 GMT'}, {'version': 'v3', 'created': 'Thu, 22 Oct 2020 20:01:55 GMT'}]",2020-10-26,"[['Adhikari', 'Ashutosh', ''], ['Yuan', 'Xingdi', ''], ['Côté', 'Marc-Alexandre', ''], ['Zelinka', 'Mikuláš', ''], ['Rondeau', 'Marc-Antoine', ''], ['Laroche', 'Romain', ''], ['Poupart', 'Pascal', ''], ['Tang', 'Jian', ''], ['Trischler', 'Adam', ''], ['Hamilton', 'William L.', '']]"
1236729,2001.11316,Akbar Karimi,"Akbar Karimi, Leonardo Rossi, Andrea Prati",Adversarial Training for Aspect-Based Sentiment Analysis with BERT,,,,,cs.LG cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Aspect-Based Sentiment Analysis (ABSA) deals with the extraction of
sentiments and their targets. Collecting labeled data for this task in order to
help neural networks generalize better can be laborious and time-consuming. As
an alternative, similar data to the real-world examples can be produced
artificially through an adversarial process which is carried out in the
embedding space. Although these examples are not real sentences, they have been
shown to act as a regularization method which can make neural networks more
robust. In this work, we apply adversarial training, which was put forward by
Goodfellow et al. (2014), to the post-trained BERT (BERT-PT) language model
proposed by Xu et al. (2019) on the two major tasks of Aspect Extraction and
Aspect Sentiment Classification in sentiment analysis. After improving the
results of post-trained BERT by an ablation study, we propose a novel
architecture called BERT Adversarial Training (BAT) to utilize adversarial
training in ABSA. The proposed model outperforms post-trained BERT in both
tasks. To the best of our knowledge, this is the first study on the application
of adversarial training in ABSA.
","[{'version': 'v1', 'created': 'Thu, 30 Jan 2020 13:53:58 GMT'}, {'version': 'v2', 'created': 'Fri, 31 Jan 2020 12:33:57 GMT'}, {'version': 'v3', 'created': 'Thu, 22 Oct 2020 13:39:32 GMT'}, {'version': 'v4', 'created': 'Fri, 23 Oct 2020 07:39:17 GMT'}]",2020-10-26,"[['Karimi', 'Akbar', ''], ['Rossi', 'Leonardo', ''], ['Prati', 'Andrea', '']]"
1276896,2004.12126,Hongyu Lin,"Hongyu Lin, Yaojie Lu, Jialong Tang, Xianpei Han, Le Sun, Zhicheng
  Wei, Nicholas Jing Yuan","A Rigorous Study on Named Entity Recognition: Can Fine-tuning Pretrained
  Model Lead to the Promised Land?",Accepted to EMNLP2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Fine-tuning pretrained model has achieved promising performance on standard
NER benchmarks. Generally, these benchmarks are blessed with strong name
regularity, high mention coverage and sufficient context diversity.
Unfortunately, when scaling NER to open situations, these advantages may no
longer exist. And therefore it raises a critical question of whether previous
creditable approaches can still work well when facing these challenges. As
there is no currently available dataset to investigate this problem, this paper
proposes to conduct randomization test on standard benchmarks. Specifically, we
erase name regularity, mention coverage and context diversity respectively from
the benchmarks, in order to explore their impact on the generalization ability
of models. To further verify our conclusions, we also construct a new open NER
dataset that focuses on entity types with weaker name regularity and lower
mention coverage to verify our conclusion. From both randomization test and
empirical experiments, we draw the conclusions that 1) name regularity is
critical for the models to generalize to unseen mentions; 2) high mention
coverage may undermine the model generalization ability and 3) context patterns
may not require enormous data to capture when using pretrained encoders.
","[{'version': 'v1', 'created': 'Sat, 25 Apr 2020 12:30:16 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 07:06:06 GMT'}]",2020-10-26,"[['Lin', 'Hongyu', ''], ['Lu', 'Yaojie', ''], ['Tang', 'Jialong', ''], ['Han', 'Xianpei', ''], ['Sun', 'Le', ''], ['Wei', 'Zhicheng', ''], ['Yuan', 'Nicholas Jing', '']]"
1267950,2004.03180,Mamoru Komachi,"Aizhan Imankulova, Masahiro Kaneko, Tosho Hirasawa and Mamoru Komachi",Towards Multimodal Simultaneous Neural Machine Translation,10 pages; WMT 2020,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Simultaneous translation involves translating a sentence before the speaker's
utterance is completed in order to realize real-time understanding in multiple
languages. This task is significantly more challenging than the general full
sentence translation because of the shortage of input information during
decoding. To alleviate this shortage, we propose multimodal simultaneous neural
machine translation (MSNMT), which leverages visual information as an
additional modality. Our experiments with the Multi30k dataset showed that
MSNMT significantly outperforms its text-only counterpart in more timely
translation situations with low latency. Furthermore, we verified the
importance of visual information during decoding by performing an adversarial
evaluation of MSNMT, where we studied how models behaved with incongruent input
modality and analyzed the effect of different word order between source and
target languages.
","[{'version': 'v1', 'created': 'Tue, 7 Apr 2020 08:02:21 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 04:38:38 GMT'}]",2020-10-26,"[['Imankulova', 'Aizhan', ''], ['Kaneko', 'Masahiro', ''], ['Hirasawa', 'Tosho', ''], ['Komachi', 'Mamoru', '']]"
1368731,2010.12401,Gaurish Thakkar Mr,"Gaurish Thakkar, Marcis Pinnis","Pretraining and Fine-Tuning Strategies for Sentiment Analysis of Latvian
  Tweets",,,10.3233/FAIA200602,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we present various pre-training strategies that aid in
im-proving the accuracy of the sentiment classification task. We, at first,
pre-trainlanguage representation models using these strategies and then
fine-tune them onthe downstream task. Experimental results on a time-balanced
tweet evaluation setshow the improvement over the previous technique. We
achieve 76% accuracy forsentiment analysis on Latvian tweets, which is a
substantial improvement over pre-vious work
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 13:45:33 GMT'}]",2020-10-26,"[['Thakkar', 'Gaurish', ''], ['Pinnis', 'Marcis', '']]"
1368857,2010.12527,Peng Qi,"Peng Qi, Haejun Lee, Oghenetegiri ""TG"" Sido, Christopher D. Manning","Retrieve, Rerank, Read, then Iterate: Answering Open-Domain Questions of
  Arbitrary Complexity from Text",Peng Qi and Haejun Lee contributed equally,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Current approaches to open-domain question answering often make crucial
assumptions that prevent them from generalizing to real-world settings,
including the access to parameterized retrieval systems well-tuned for the
task, access to structured metadata like knowledge bases and web links, or a
priori knowledge of the complexity of questions to be answered (e.g.,
single-hop or multi-hop). To address these limitations, we propose a unified
system to answer open-domain questions of arbitrary complexity directly from
text that works with off-the-shelf retrieval systems on arbitrary text
collections. We employ a single multi-task model to perform all the necessary
subtasks---retrieving supporting facts, reranking them, and predicting the
answer from all retrieved documents---in an iterative fashion. To emulate a
more realistic setting, we also constructed a new unified benchmark by
collecting about 200 multi-hop questions that require three Wikipedia pages to
answer, and combining them with existing datasets. We show that our model not
only outperforms state-of-the-art systems on several existing benchmarks that
exclusively feature single-hop or multi-hop open-domain questions, but also
achieves strong performance on the new benchmark.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 16:51:09 GMT'}]",2020-10-26,"[['Qi', 'Peng', ''], ['Lee', 'Haejun', ''], ['Sido', 'Oghenetegiri ""TG""', ''], ['Manning', 'Christopher D.', '']]"
1368635,2010.12305,Lukas Lange,"Lukas Lange, Heike Adel, Jannik Str\""otgen, Dietrich Klakow",Adversarial Learning of Feature-based Meta-Embeddings,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Certain embedding types outperform others in different scenarios, e.g.,
subword-based embeddings can model rare words well and domain-specific
embeddings can better represent in-domain terms. Therefore, recent works
consider attention-based meta-embeddings to combine different embedding types.
We demonstrate that these methods have two shortcomings: First, the attention
weights are calculated without knowledge of word properties. Second, the
different embedding types can form clusters in the common embedding space,
preventing the computation of a meaningful average of different embeddings and
thus, reducing performance. We propose to solve these problems by using
feature-based meta-embeddings learned with adversarial training. Our
experiments and analysis on sentence classification and sequence tagging tasks
show that our approach is effective. We set the new state of the art on various
datasets across languages and domains.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 11:16:53 GMT'}]",2020-10-26,"[['Lange', 'Lukas', ''], ['Adel', 'Heike', ''], ['Strötgen', 'Jannik', ''], ['Klakow', 'Dietrich', '']]"
1368613,2010.12283,Minjeong Kim,"Minjeong Kim, Gyuwan Kim, Sang-Woo Lee, Jung-Woo Ha","ST-BERT: Cross-modal Language Model Pre-training For End-to-end Spoken
  Language Understanding","5 pages, 2 figures",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language model pre-training has shown promising results in various downstream
tasks. In this context, we introduce a cross-modal pre-trained language model,
called Speech-Text BERT (ST-BERT), to tackle end-to-end spoken language
understanding (E2E SLU) tasks. Taking phoneme posterior and subword-level text
as an input, ST-BERT learns a contextualized cross-modal alignment via our two
proposed pre-training tasks: Cross-modal Masked Language Modeling (CM-MLM) and
Cross-modal Conditioned Language Modeling (CM-CLM). Experimental results on
three benchmarks present that our approach is effective for various SLU
datasets and shows a surprisingly marginal performance degradation even when 1%
of the training data are available. Also, our method shows further SLU
performance gain via domain-adaptive pre-training with domain-specific
speech-text pair data.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 10:28:20 GMT'}]",2020-10-26,"[['Kim', 'Minjeong', ''], ['Kim', 'Gyuwan', ''], ['Lee', 'Sang-Woo', ''], ['Ha', 'Jung-Woo', '']]"
1368602,2010.12272,Zhen Ke,"Zhen Ke, Liang Shi, Erli Meng, Bin Wang, Xipeng Qiu",Pre-trained Model for Chinese Word Segmentation with Meta Learning,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent researches show that pre-trained models such as BERT (Devlin et al.,
2019) are beneficial for Chinese Word Segmentation tasks. However, existing
approaches usually finetune pre-trained models directly on a separate
downstream Chinese Word Segmentation corpus. These recent methods don't fully
utilize the prior knowledge of existing segmentation corpora, and don't regard
the discrepancy between the pre-training tasks and the downstream Chinese Word
Segmentation tasks. In this work, we propose a Pre-Trained Model for Chinese
Word Segmentation, which can be abbreviated as PTM-CWS. PTM-CWS model employs a
unified architecture for different segmentation criteria, and is pre-trained on
a joint multi-criteria corpus with meta learning algorithm. Empirical results
show that our PTM-CWS model can utilize the existing prior segmentation
knowledge, reduce the discrepancy between the pre-training tasks and the
downstream Chinese Word Segmentation tasks, and achieve new state-of-the-art
performance on twelve Chinese Word Segmentation corpora.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 10:00:46 GMT'}]",2020-10-26,"[['Ke', 'Zhen', ''], ['Shi', 'Liang', ''], ['Meng', 'Erli', ''], ['Wang', 'Bin', ''], ['Qiu', 'Xipeng', '']]"
1368597,2010.12267,Xinsheng Wang,"Xinsheng Wang, Siyuan Feng, Jihua Zhu, Mark Hasegawa-Johnson, Odette
  Scharenborg",Show and Speak: Directly Synthesize Spoken Description of Images,,,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper proposes a new model, referred to as the show and speak (SAS)
model that, for the first time, is able to directly synthesize spoken
descriptions of images, bypassing the need for any text or phonemes. The basic
structure of SAS is an encoder-decoder architecture that takes an image as
input and predicts the spectrogram of speech that describes this image. The
final speech audio is obtained from the predicted spectrogram via WaveNet.
Extensive experiments on the public benchmark database Flickr8k demonstrate
that the proposed SAS is able to synthesize natural spoken descriptions for
images, indicating that synthesizing spoken descriptions for images while
bypassing text and phonemes is feasible.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 09:53:01 GMT'}]",2020-10-26,"[['Wang', 'Xinsheng', ''], ['Feng', 'Siyuan', ''], ['Zhu', 'Jihua', ''], ['Hasegawa-Johnson', 'Mark', ''], ['Scharenborg', 'Odette', '']]"
1368581,2010.12251,Sunghyun Park,"Sunghyun Park, Han Li, Ameen Patel, Sidharth Mudgal, Sungjin Lee,
  Young-Bum Kim, Spyros Matsoukas, Ruhi Sarikaya","A Scalable Framework for Learning From Implicit User Feedback to Improve
  Natural Language Understanding in Large-Scale Conversational AI Systems",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Natural Language Understanding (NLU) is an established component within a
conversational AI or digital assistant system, and it is responsible for
producing semantic understanding of a user request. We propose a scalable and
automatic approach for improving NLU in a large-scale conversational AI system
by leveraging implicit user feedback, with an insight that user interaction
data and dialog context have rich information embedded from which user
satisfaction and intention can be inferred. In particular, we propose a general
domain-agnostic framework for curating new supervision data for improving NLU
from live production traffic. With an extensive set of experiments, we show the
results of applying the framework and improving NLU for a large-scale
production system and show its impact across 10 domains.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 09:23:44 GMT'}]",2020-10-26,"[['Park', 'Sunghyun', ''], ['Li', 'Han', ''], ['Patel', 'Ameen', ''], ['Mudgal', 'Sidharth', ''], ['Lee', 'Sungjin', ''], ['Kim', 'Young-Bum', ''], ['Matsoukas', 'Spyros', ''], ['Sarikaya', 'Ruhi', '']]"
1368561,2010.12231,Wen-Chin Huang,"Wen-Chin Huang, Yi-Chiao Wu, Tomoki Hayashi, Tomoki Toda","Any-to-One Sequence-to-Sequence Voice Conversion using Self-Supervised
  Discrete Speech Representations",Submitted to ICASSP 2021,,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present a novel approach to any-to-one (A2O) voice conversion (VC) in a
sequence-to-sequence (seq2seq) framework. A2O VC aims to convert any speaker,
including those unseen during training, to a fixed target speaker. We utilize
vq-wav2vec (VQW2V), a discretized self-supervised speech representation that
was learned from massive unlabeled data, which is assumed to be
speaker-independent and well corresponds to underlying linguistic contents.
Given a training dataset of the target speaker, we extract VQW2V and acoustic
features to estimate a seq2seq mapping function from the former to the latter.
With the help of a pretraining method and a newly designed postprocessing
technique, our model can be generalized to only 5 min of data, even
outperforming the same model trained with parallel data.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 08:34:52 GMT'}]",2020-10-26,"[['Huang', 'Wen-Chin', ''], ['Wu', 'Yi-Chiao', ''], ['Hayashi', 'Tomoki', ''], ['Toda', 'Tomoki', '']]"
1368528,2010.12198,Abhinav Ramesh Kashyap,"Abhinav Ramesh Kashyap, Devamanyu Hazarika, Min-Yen Kan, Roger
  Zimmermann",Domain Divergences: a Survey and Empirical Analysis,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Domain divergence plays a significant role in estimating the performance of a
model when applied to new domains. While there is significant literature on
divergence measures, choosing an appropriate divergence measures remains
difficult for researchers. We address this shortcoming by both surveying the
literature and through an empirical study. We contribute a taxonomy of
divergence measures consisting of three groups -- Information-theoretic,
Geometric, and Higher-order measures -- and identify the relationships between
them. We then ground the use of divergence measures in three different
application groups -- 1) Data Selection, 2) Learning Representation, and 3)
Decisions in the Wild. From this, we identify that Information-theoretic
measures are prevalent for 1) and 3), and higher-order measures are common for
2). To further help researchers, we validate these uses empirically through a
correlation analysis of performance drops. We consider the current contextual
word representations (CWR) to contrast with the older word distribution based
representations for this analysis. We find that traditional measures over word
distributions still serve as strong baselines, while higher-order measures with
CWR are effective.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 07:12:52 GMT'}]",2020-10-26,"[['Kashyap', 'Abhinav Ramesh', ''], ['Hazarika', 'Devamanyu', ''], ['Kan', 'Min-Yen', ''], ['Zimmermann', 'Roger', '']]"
1368513,2010.12183,Weizhe Lin,"Zhilin Wang, Weizhe Lin, Xiaodong Wu","Identifying Similar Movie Characters Quickly but Effectively Using
  Non-exhaustive Pair-wise Attention",10 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Identifying similar movie characters is a captivating task that can be our
first step to understand the commonalities between human characteristics and
experiences. Here, we seek to identify similar movie character descriptions and
evaluate our findings based on whether they belong to a common fan-curated
trope (theme). Rather than simply comparing the embedding representation of
character description, we use a pair-wise attention model to make use of
complex word/span-level relationships across the two character descriptions to
predict the similarity of the two characters. Naively, such a model would
require the exhaustive comparison of each character to all other characters,
which is an O(n^2) operation with respect to the number of characters, making
it unfeasible to be used in practice. We reduced this into an O(n) operation
using a two-step approach that involves choosing only a tiny fraction of
character-pairs to perform pairwise attention on while still being effective in
this task. Our approach performs at least 9-27% better than methods based on
state-of-the-art paragraph embedding representations.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 06:28:25 GMT'}]",2020-10-26,"[['Wang', 'Zhilin', ''], ['Lin', 'Weizhe', ''], ['Wu', 'Xiaodong', '']]"
1368510,2010.12180,Sanyuan Chen,"Sanyuan Chen, Yu Wu, Zhuo Chen, Takuya Yoshioka, Shujie Liu, Jinyu Li","Don't shoot butterfly with rifles: Multi-channel Continuous Speech
  Separation with Early Exit Transformer",,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  With its strong modeling capacity that comes from a multi-head and
multi-layer structure, Transformer is a very powerful model for learning a
sequential representation and has been successfully applied to speech
separation recently. However, multi-channel speech separation sometimes does
not necessarily need such a heavy structure for all time frames especially when
the cross-talker challenge happens only occasionally. For example, in
conversation scenarios, most regions contain only a single active speaker,
where the separation task downgrades to a single speaker enhancement problem.
It turns out that using a very deep network structure for dealing with signals
with a low overlap ratio not only negatively affects the inference efficiency
but also hurts the separation performance. To deal with this problem, we
propose an early exit mechanism, which enables the Transformer model to handle
different cases with adaptive depth. Experimental results indicate that not
only does the early exit mechanism accelerate the inference, but it also
improves the accuracy.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 06:21:11 GMT'}]",2020-10-26,"[['Chen', 'Sanyuan', ''], ['Wu', 'Yu', ''], ['Chen', 'Zhuo', ''], ['Yoshioka', 'Takuya', ''], ['Liu', 'Shujie', ''], ['Li', 'Jinyu', '']]"
1368504,2010.12174,Rubungo Andre Niyongabo,Rubungo Andre Niyongabo and Hong Qu and Julia Kreutzer and Li Huang,"KINNEWS and KIRNEWS: Benchmarking Cross-Lingual Text Classification for
  Kinyarwanda and Kirundi",COLING 2020,,,,cs.CL cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent progress in text classification has been focused on high-resource
languages such as English and Chinese. For low-resource languages, amongst them
most African languages, the lack of well-annotated data and effective
preprocessing, is hindering the progress and the transfer of successful
methods. In this paper, we introduce two news datasets (KINNEWS and KIRNEWS)
for multi-class classification of news articles in Kinyarwanda and Kirundi, two
low-resource African languages. The two languages are mutually intelligible,
but while Kinyarwanda has been studied in Natural Language Processing (NLP) to
some extent, this work constitutes the first study on Kirundi. Along with the
datasets, we provide statistics, guidelines for preprocessing, and monolingual
and cross-lingual baseline models. Our experiments show that training
embeddings on the relatively higher-resourced Kinyarwanda yields successful
cross-lingual transfer to Kirundi. In addition, the design of the created
datasets allows for a wider use in NLP beyond text classification in future
studies, such as representation learning, cross-lingual learning with more
distant languages, or as base for new annotations for tasks such as parsing,
POS tagging, and NER. The datasets, stopwords, and pre-trained embeddings are
publicly available at https://github.com/Andrews2017/KINNEWS-and-KIRNEWS-Corpus .
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 05:37:42 GMT'}]",2020-10-26,"[['Niyongabo', 'Rubungo Andre', ''], ['Qu', 'Hong', ''], ['Kreutzer', 'Julia', ''], ['Huang', 'Li', '']]"
1368486,2010.12156,Fei Zhao,"Fei Zhao, Zhen Wu, Xinyu Dai",Attention Transfer Network for Aspect-level Sentiment Classification,Accept to COLING 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Aspect-level sentiment classification (ASC) aims to detect the sentiment
polarity of a given opinion target in a sentence. In neural network-based
methods for ASC, most works employ the attention mechanism to capture the
corresponding sentiment words of the opinion target, then aggregate them as
evidence to infer the sentiment of the target. However, aspect-level datasets
are all relatively small-scale due to the complexity of annotation. Data
scarcity causes the attention mechanism sometimes to fail to focus on the
corresponding sentiment words of the target, which finally weakens the
performance of neural models. To address the issue, we propose a novel
Attention Transfer Network (ATN) in this paper, which can successfully exploit
attention knowledge from resource-rich document-level sentiment classification
datasets to improve the attention capability of the aspect-level sentiment
classification task. In the ATN model, we design two different methods to
transfer attention knowledge and conduct experiments on two ASC benchmark
datasets. Extensive experimental results show that our methods consistently
outperform state-of-the-art works. Further analysis also validates the
effectiveness of ATN.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 04:26:33 GMT'}]",2020-10-26,"[['Zhao', 'Fei', ''], ['Wu', 'Zhen', ''], ['Dai', 'Xinyu', '']]"
1368485,2010.12155,Menglong Xu,"Menglong Xu, Shengqiang Li, Xiao-Lei Zhang","Transformer-based End-to-End Speech Recognition with Local Dense
  Synthesizer Attention","5 pages, 3 figures",,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, several studies reported that dot-product selfattention (SA) may
not be indispensable to the state-of-theart Transformer models. Motivated by
the fact that dense synthesizer attention (DSA), which dispenses with dot
products and pairwise interactions, achieved competitive results in many
language processing tasks, in this paper, we first propose a DSA-based speech
recognition, as an alternative to SA. To reduce the computational complexity
and improve the performance, we further propose local DSA (LDSA) to restrict
the attention scope of DSA to a local range around the current central frame
for speech recognition. Finally, we combine LDSA with SA to extract the local
and global information simultaneously. Experimental results on the Ai-shell1
Mandarine speech recognition corpus show that the proposed LDSA-Transformer
achieves a character error rate (CER) of 6.49%, which is slightly better than
that of the SA-Transformer. Meanwhile, the LDSA-Transformer requires less
computation than the SATransformer. The proposed combination method not only
achieves a CER of 6.18%, which significantly outperforms the SA-Transformer,
but also has roughly the same number of parameters and computational complexity
as the latter. The implementation of the multi-head LDSA is available at
https://github.com/mlxu995/multihead-LDSA.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 04:13:44 GMT'}]",2020-10-26,"[['Xu', 'Menglong', ''], ['Li', 'Shengqiang', ''], ['Zhang', 'Xiao-Lei', '']]"
1368478,2010.12148,Yu-Kun Li,"Dongling Xiao, Yu-Kun Li, Han Zhang, Yu Sun, Hao Tian, Hua Wu and
  Haifeng Wang","ERNIE-Gram: Pre-Training with Explicitly N-Gram Masked Language Modeling
  for Natural Language Understanding",work-in-progress,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Coarse-grained linguistic information, such as name entities or phrases,
facilitates adequately representation learning in pre-training. Previous works
mainly focus on extending the objective of BERT's Masked Language Modeling
(MLM) from masking individual tokens to contiguous sequences of n tokens. We
argue that such continuously masking method neglects to model the
inner-dependencies and inter-relation of coarse-grained information. As an
alternative, we propose ERNIE-Gram, an explicitly n-gram masking method to
enhance the integration of coarse-grained information for pre-training. In
ERNIE-Gram, n-grams are masked and predicted directly using explicit n-gram
identities rather than contiguous sequences of tokens. Furthermore, ERNIE-Gram
employs a generator model to sample plausible n-gram identities as optional
n-gram masks and predict them in both coarse-grained and fine-grained manners
to enable comprehensive n-gram prediction and relation modeling. We pre-train
ERNIE-Gram on English and Chinese text corpora and fine-tune on 19 downstream
tasks. Experimental results show that ERNIE-Gram outperforms previous
pre-training models like XLNet and RoBERTa by a large margin, and achieves
comparable results with state-of-the-art methods.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 03:42:20 GMT'}]",2020-10-26,"[['Xiao', 'Dongling', ''], ['Li', 'Yu-Kun', ''], ['Zhang', 'Han', ''], ['Sun', 'Yu', ''], ['Tian', 'Hao', ''], ['Wu', 'Hua', ''], ['Wang', 'Haifeng', '']]"
1368466,2010.12136,Bowen Li,"Bowen Li, Xiaojuan Qi, Philip H. S. Torr, Thomas Lukasiewicz","Lightweight Generative Adversarial Networks for Text-Guided Image
  Manipulation",NeurIPS 2020,,,,cs.CV cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a novel lightweight generative adversarial network for efficient
image manipulation using natural language descriptions. To achieve this, a new
word-level discriminator is proposed, which provides the generator with
fine-grained training feedback at word-level, to facilitate training a
lightweight generator that has a small number of parameters, but can still
correctly focus on specific visual attributes of an image, and then edit them
without affecting other contents that are not described in the text.
Furthermore, thanks to the explicit training signal related to each word, the
discriminator can also be simplified to have a lightweight structure. Compared
with the state of the art, our method has a much smaller number of parameters,
but still achieves a competitive manipulation performance. Extensive
experimental results demonstrate that our method can better disentangle
different visual attributes, then correctly map them to corresponding semantic
words, and thus achieve a more accurate image modification using natural
language descriptions.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 02:43:02 GMT'}]",2020-10-26,"[['Li', 'Bowen', ''], ['Qi', 'Xiaojuan', ''], ['Torr', 'Philip H. S.', ''], ['Lukasiewicz', 'Thomas', '']]"
1368451,2010.12121,Feiliang Ren,"Feiliang Ren, Juchen Li, Huihui Zhang, Shilei Liu, Bochao Li, Ruicheng
  Ming, Yujia Bai",Knowledge Graph Embedding with Atrous Convolution and Residual Learning,"12pages, 2 figures",,,,cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Knowledge graph embedding is an important task and it will benefit lots of
downstream applications. Currently, deep neural networks based methods achieve
state-of-the-art performance. However, most of these existing methods are very
complex and need much time for training and inference. To address this issue,
we propose a simple but effective atrous convolution based knowledge graph
embedding method. Compared with existing state-of-the-art methods, our method
has following main characteristics. First, it effectively increases feature
interactions by using atrous convolutions. Second, to address the original
information forgotten issue and vanishing/exploding gradient issue, it uses the
residual learning method. Third, it has simpler structure but much higher
parameter efficiency. We evaluate our method on six benchmark datasets with
different evaluation metrics. Extensive experiments show that our model is very
effective. On these diverse datasets, it achieves better results than the
compared state-of-the-art methods on most of evaluation metrics. The source
codes of our model could be found at https://github.com/neukg/AcrE.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 00:57:23 GMT'}]",2020-10-26,"[['Ren', 'Feiliang', ''], ['Li', 'Juchen', ''], ['Zhang', 'Huihui', ''], ['Liu', 'Shilei', ''], ['Li', 'Bochao', ''], ['Ming', 'Ruicheng', ''], ['Bai', 'Yujia', '']]"
1368434,2010.12104,Siyuan Feng,"Siyuan Feng, Piotr \.Zelasko, Laureano Moro-Vel\'azquez, Ali
  Abavisani, Mark Hasegawa-Johnson, Odette Scharenborg, Najim Dehak",How Phonotactics Affect Multilingual and Zero-shot ASR Performance,"Submitted to ICASSP 2021. The first 2 authors contributed equally to
  this work",,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The idea of combining multiple languages' recordings to train a single
automatic speech recognition (ASR) model brings the promise of the emergence of
universal speech representation. Recently, a Transformer encoder-decoder model
has been shown to leverage multilingual data well in IPA transcriptions of
languages presented during training. However, the representations it learned
were not successful in zero-shot transfer to unseen languages. Because that
model lacks an explicit factorization of the acoustic model (AM) and language
model (LM), it is unclear to what degree the performance suffered from
differences in pronunciation or the mismatch in phonotactics. To gain more
insight into the factors limiting zero-shot ASR transfer, we replace the
encoder-decoder with a hybrid ASR system consisting of a separate AM and LM.
Then, we perform an extensive evaluation of monolingual, multilingual, and
crosslingual (zero-shot) acoustic and language models on a set of 13
phonetically diverse languages. We show that the gain from modeling
crosslingual phonotactics is limited, and imposing a too strong model can hurt
the zero-shot transfer. Furthermore, we find that a multilingual LM hurts a
multilingual ASR system's performance, and retaining only the target language's
phonotactic data in LM training is preferable.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 23:07:24 GMT'}]",2020-10-26,"[['Feng', 'Siyuan', ''], ['Żelasko', 'Piotr', ''], ['Moro-Velázquez', 'Laureano', ''], ['Abavisani', 'Ali', ''], ['Hasegawa-Johnson', 'Mark', ''], ['Scharenborg', 'Odette', ''], ['Dehak', 'Najim', '']]"
1368426,2010.12096,Thibault Doutre,"Thibault Doutre, Wei Han, Min Ma, Zhiyun Lu, Chung-Cheng Chiu, Ruoming
  Pang, Arun Narayanan, Ananya Misra, Yu Zhang, Liangliang Cao","Improving Streaming Automatic Speech Recognition With Non-Streaming
  Model Distillation On Unsupervised Data",,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Streaming end-to-end automatic speech recognition (ASR) models are widely
used on smart speakers and on-device applications. Since these models are
expected to transcribe speech with minimal latency, they are constrained to be
causal with no future context, compared to their non-streaming counterparts.
Consequently, streaming models usually perform worse than non-streaming models.
We propose a novel and effective learning method by leveraging a non-streaming
ASR model as a teacher to generate transcripts on an arbitrarily large data
set, which is then used to distill knowledge into streaming ASR models. This
way, we scale the training of streaming models to up to 3 million hours of
YouTube audio. Experiments show that our approach can significantly reduce the
word error rate (WER) of RNNT models not only on LibriSpeech but also on
YouTube data in four languages. For example, in French, we are able to reduce
the WER by 16.4% relatively to a baseline streaming model by leveraging a
non-streaming teacher model trained on the same amount of labeled data as the
baseline.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 22:41:33 GMT'}]",2020-10-26,"[['Doutre', 'Thibault', ''], ['Han', 'Wei', ''], ['Ma', 'Min', ''], ['Lu', 'Zhiyun', ''], ['Chiu', 'Chung-Cheng', ''], ['Pang', 'Ruoming', ''], ['Narayanan', 'Arun', ''], ['Misra', 'Ananya', ''], ['Zhang', 'Yu', ''], ['Cao', 'Liangliang', '']]"
1368413,2010.12083,Simon Stepputtis,"Simon Stepputtis, Joseph Campbell, Mariano Phielipp, Stefan Lee,
  Chitta Baral, Heni Ben Amor",Language-Conditioned Imitation Learning for Robot Manipulation Tasks,"Accepted to the 34th Conference on Neural Information Processing
  Systems (NeurIPS 2020), Vancouver, Canada as spotlight presentation",,,,cs.RO cs.CL cs.CV cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Imitation learning is a popular approach for teaching motor skills to robots.
However, most approaches focus on extracting policy parameters from execution
traces alone (i.e., motion trajectories and perceptual data). No adequate
communication channel exists between the human expert and the robot to describe
critical aspects of the task, such as the properties of the target object or
the intended shape of the motion. Motivated by insights into the human teaching
process, we introduce a method for incorporating unstructured natural language
into imitation learning. At training time, the expert can provide
demonstrations along with verbal descriptions in order to describe the
underlying intent (e.g., ""go to the large green bowl""). The training process
then interrelates these two modalities to encode the correlations between
language, perception, and motion. The resulting language-conditioned visuomotor
policies can be conditioned at runtime on new human commands and instructions,
which allows for more fine-grained control over the trained policies while also
reducing situational ambiguity. We demonstrate in a set of simulation
experiments how our approach can learn language-conditioned manipulation
policies for a seven-degree-of-freedom robot arm and compare the results to a
variety of alternative methods.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 21:49:08 GMT'}]",2020-10-26,"[['Stepputtis', 'Simon', ''], ['Campbell', 'Joseph', ''], ['Phielipp', 'Mariano', ''], ['Lee', 'Stefan', ''], ['Baral', 'Chitta', ''], ['Amor', 'Heni Ben', '']]"
1368407,2010.12077,Daiki Shirafuji,"Daiki Shirafuji, Hiromichi Kameya, Rafal Rzepka and Kenji Araki","Summarizing Utterances from Japanese Assembly Minutes using Political
  Sentence-BERT-based Method for QA Lab-PoliInfo-2 Task of NTCIR-15","8 pages, 1 figure, 8 tables, NTCIR-15 conference",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  There are many discussions held during political meetings, and a large number
of utterances for various topics is included in their transcripts. We need to
read all of them if we want to follow speakers\' intentions or opinions about a
given topic. To avoid such a costly and time-consuming process to grasp often
longish discussions, NLP researchers work on generating concise summaries of
utterances. Summarization subtask in QA Lab-PoliInfo-2 task of the NTCIR-15
addresses this problem for Japanese utterances in assembly minutes, and our
team (SKRA) participated in this subtask. As a first step for summarizing
utterances, we created a new pre-trained sentence embedding model, i.e. the
Japanese Political Sentence-BERT. With this model, we summarize utterances
without labelled data. This paper describes our approach to solving the task
and discusses its results.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 21:37:28 GMT'}]",2020-10-26,"[['Shirafuji', 'Daiki', ''], ['Kameya', 'Hiromichi', ''], ['Rzepka', 'Rafal', ''], ['Araki', 'Kenji', '']]"
1368639,2010.12309,Lukas Lange,"Michael A. Hedderich, Lukas Lange, Heike Adel, Jannik Str\""otgen,
  Dietrich Klakow","A Survey on Recent Approaches for Natural Language Processing in
  Low-Resource Scenarios",,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Current developments in natural language processing offer challenges and
opportunities for low-resource languages and domains. Deep neural networks are
known for requiring large amounts of training data which might not be available
in resource-lean scenarios. However, there is also a growing body of works to
improve the performance in low-resource settings. Motivated by fundamental
changes towards neural models and the currently popular pre-train and fine-tune
paradigm, we give an overview of promising approaches for low-resource natural
language processing. After a discussion about the definition of low-resource
scenarios and the different dimensions of data availability, we then examine
methods that enable learning when training data is sparse. This includes
mechanisms to create additional labeled data like data augmentation and distant
supervision as well as transfer learning settings that reduce the need for
target supervision. The survey closes with a brief look into methods suggested
in non-NLP machine learning communities, which might be beneficial for NLP in
low-resource scenarios
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 11:22:01 GMT'}]",2020-10-26,"[['Hedderich', 'Michael A.', ''], ['Lange', 'Lukas', ''], ['Adel', 'Heike', ''], ['Strötgen', 'Jannik', ''], ['Klakow', 'Dietrich', '']]"
1368338,2010.12008,Siamak Shakeri,"Siamak Shakeri, Noah Constant, Mihir Sanjay Kale, Linting Xue","Multilingual Synthetic Question and Answer Generation for Cross-Lingual
  Reading Comprehension",,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a simple method to generate large amounts of multilingual question
and answer pairs by a single generative model. These synthetic samples are then
applied to augment the available gold multilingual ones to improve the
performance of multilingual QA models on target languages. Our approach only
requires existence of automatically translated samples from English to the
target domain, thus removing the need for human annotations in the target
languages. Experimental results show our proposed approach achieves significant
gains in a number of multilingual datasets.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 19:59:37 GMT'}]",2020-10-26,"[['Shakeri', 'Siamak', ''], ['Constant', 'Noah', ''], ['Kale', 'Mihir Sanjay', ''], ['Xue', 'Linting', '']]"
1368651,2010.12321,Antoine Tixier,"Moussa Kamal Eddine, Antoine J.-P. Tixier, Michalis Vazirgiannis",BARThez: a Skilled Pretrained French Sequence-to-Sequence Model,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Inductive transfer learning, enabled by self-supervised learning, have taken
the entire Natural Language Processing (NLP) field by storm, with models such
as BERT and BART setting new state of the art on countless natural language
understanding tasks. While there are some notable exceptions, most of the
available models and research have been conducted for the English language. In
this work, we introduce BARThez, the first BART model for the French language
(to the best of our knowledge). BARThez was pretrained on a very large
monolingual French corpus from past research that we adapted to suit BART's
perturbation schemes. Unlike already existing BERT-based French language models
such as CamemBERT and FlauBERT, BARThez is particularly well-suited for
generative tasks, since not only its encoder but also its decoder is
pretrained. In addition to discriminative tasks from the FLUE benchmark, we
evaluate BARThez on a novel summarization dataset, OrangeSum, that we release
with this paper. We also continue the pretraining of an already pretrained
multilingual BART on BARThez's corpus, and we show that the resulting model,
which we call mBARTHez, provides a significant boost over vanilla BARThez, and
is on par with or outperforms CamemBERT and FlauBERT.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 11:57:33 GMT'}]",2020-10-26,"[['Eddine', 'Moussa Kamal', ''], ['Tixier', 'Antoine J. -P.', ''], ['Vazirgiannis', 'Michalis', '']]"
1368735,2010.12405,Xin Li,"Xin Li, Lidong Bing, Wenxuan Zhang, Zheng Li, Wai Lam",Unsupervised Cross-lingual Adaptation for Sequence Tagging and Beyond,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Cross-lingual adaptation with multilingual pre-trained language models
(mPTLMs) mainly consists of two lines of works: zero-shot approach and
translation-based approach, which have been studied extensively on the
sequence-level tasks. We further verify the efficacy of these cross-lingual
adaptation approaches by evaluating their performances on more fine-grained
sequence tagging tasks. After re-examining their strengths and drawbacks, we
propose a novel framework to consolidate the zero-shot approach and the
translation-based approach for better adaptation performance. Instead of simply
augmenting the source data with the machine-translated data, we tailor-make a
warm-up mechanism to quickly update the mPTLMs with the gradients estimated on
a few translated data. Then, the adaptation approach is applied to the refined
parameters and the cross-lingual transfer is performed in a warm-start way. The
experimental results on nine target languages demonstrate that our method is
beneficial to the cross-lingual adaptation of various sequence tagging tasks.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 13:47:01 GMT'}]",2020-10-26,"[['Li', 'Xin', ''], ['Bing', 'Lidong', ''], ['Zhang', 'Wenxuan', ''], ['Li', 'Zheng', ''], ['Lam', 'Wai', '']]"
1368896,2010.12566,Aditi Chaudhary,"Aditi Chaudhary, Karthik Raman, Krishna Srinivasan, Jiecao Chen","DICT-MLM: Improved Multilingual Pre-Training using Bilingual
  Dictionaries",13 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pre-trained multilingual language models such as mBERT have shown immense
gains for several natural language processing (NLP) tasks, especially in the
zero-shot cross-lingual setting. Most, if not all, of these pre-trained models
rely on the masked-language modeling (MLM) objective as the key language
learning objective. The principle behind these approaches is that predicting
the masked words with the help of the surrounding text helps learn potent
contextualized representations. Despite the strong representation learning
capability enabled by MLM, we demonstrate an inherent limitation of MLM for
multilingual representation learning. In particular, by requiring the model to
predict the language-specific token, the MLM objective disincentivizes learning
a language-agnostic representation -- which is a key goal of multilingual
pre-training. Therefore to encourage better cross-lingual representation
learning we propose the DICT-MLM method. DICT-MLM works by incentivizing the
model to be able to predict not just the original masked word, but potentially
any of its cross-lingual synonyms as well. Our empirical analysis on multiple
downstream tasks spanning 30+ languages, demonstrates the efficacy of the
proposed approach and its ability to learn better multilingual representations.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 17:53:11 GMT'}]",2020-10-26,"[['Chaudhary', 'Aditi', ''], ['Raman', 'Karthik', ''], ['Srinivasan', 'Krishna', ''], ['Chen', 'Jiecao', '']]"
1368893,2010.12563,Eric Wallace,"Eric Wallace, Tony Z. Zhao, Shi Feng, Sameer Singh",Customizing Triggers with Concealed Data Poisoning,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Adversarial attacks alter NLP model predictions by perturbing test-time
inputs. However, it is much less understood whether, and how, predictions can
be manipulated with small, concealed changes to the training data. In this
work, we develop a new data poisoning attack that allows an adversary to
control model predictions whenever a desired trigger phrase is present in the
input. For instance, we insert 50 poison examples into a sentiment model's
training set that causes the model to frequently predict Positive whenever the
input contains ""James Bond"". Crucially, we craft these poison examples using a
gradient-based procedure so that they do not mention the trigger phrase. We
also apply our poison attack to language modeling (""Apple iPhone"" triggers
negative generations) and machine translation (""iced coffee"" mistranslated as
""hot coffee""). We conclude by proposing three defenses that can mitigate our
attack at some cost in prediction accuracy or extra human annotation.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 17:47:06 GMT'}]",2020-10-26,"[['Wallace', 'Eric', ''], ['Zhao', 'Tony Z.', ''], ['Feng', 'Shi', ''], ['Singh', 'Sameer', '']]"
1368892,2010.12562,Xiaotao Gu,"Xiaotao Gu, Liyuan Liu, Hongkun Yu, Jing Li, Chen Chen, Jiawei Han",On the Transformer Growth for Progressive BERT Training,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As the excessive pre-training cost arouses the need to improve efficiency,
considerable efforts have been made to train BERT progressively--start from an
inferior but low-cost model and gradually increase the computational
complexity. Our objective is to help advance the understanding of such
Transformer growth and discover principles that guide progressive training.
First, we find that similar to network architecture selection, Transformer
growth also favors compound scaling. Specifically, while existing methods only
conduct network growth in a single dimension, we observe that it is beneficial
to use compound growth operators and balance multiple dimensions (e.g., depth,
width, and input length of the model). Moreover, we explore alternative growth
operators in each dimension via controlled comparison to give practical
guidance for operator selection. In light of our analyses, the proposed method
CompoundGrow speeds up BERT pre-training by 73.6% and 82.2% for the base and
large models respectively while achieving comparable performances. Code will be
released for reproduction and future studies.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 17:44:59 GMT'}]",2020-10-26,"[['Gu', 'Xiaotao', ''], ['Liu', 'Liyuan', ''], ['Yu', 'Hongkun', ''], ['Li', 'Jing', ''], ['Chen', 'Chen', ''], ['Han', 'Jiawei', '']]"
1368877,2010.12547,Lin Pan,"Lin Pan, Chung-Wei Hang, Haode Qi, Abhishek Shah, Mo Yu, Saloni Potdar",Multilingual BERT Post-Pretraining Alignment,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a simple method to align multilingual contextual embeddings as a
post-pretraining step for improved zero-shot cross-lingual transferability of
the pretrained models. Using parallel data, our method aligns embeddings on the
word level through the recently proposed Translation Language Modeling
objective as well as on the sentence level via contrastive learning and random
input shuffling. We also perform code-switching with English when finetuning on
downstream tasks. On XNLI, our best model (initialized from mBERT) improves
over mBERT by 4.7% in the zero-shot setting and achieves comparable result to
XLM for translate-train while using less than 18% of the same parallel data and
31% less model parameters. On MLQA, our model outperforms XLM-R_Base that has
57% more parameters than ours.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 17:14:41 GMT'}]",2020-10-26,"[['Pan', 'Lin', ''], ['Hang', 'Chung-Wei', ''], ['Qi', 'Haode', ''], ['Shah', 'Abhishek', ''], ['Yu', 'Mo', ''], ['Potdar', 'Saloni', '']]"
1368862,2010.12532,Nicole Peinelt,"Nicole Peinelt, Marek Rei and Maria Liakata","GiBERT: Introducing Linguistic Knowledge into BERT through a Lightweight
  Gated Injection Method",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large pre-trained language models such as BERT have been the driving force
behind recent improvements across many NLP tasks. However, BERT is only trained
to predict missing words - either behind masks or in the next sentence - and
has no knowledge of lexical, syntactic or semantic information beyond what it
picks up through unsupervised pre-training. We propose a novel method to
explicitly inject linguistic knowledge in the form of word embeddings into any
layer of a pre-trained BERT. Our performance improvements on multiple semantic
similarity datasets when injecting dependency-based and counter-fitted
embeddings indicate that such information is beneficial and currently missing
from the original model. Our qualitative analysis shows that counter-fitted
embedding injection particularly helps with cases involving synonym pairs.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 17:00:26 GMT'}]",2020-10-26,"[['Peinelt', 'Nicole', ''], ['Rei', 'Marek', ''], ['Liakata', 'Maria', '']]"
1368853,2010.12523,Yinfei Yang,"Jing Lu, Gustavo Hernandez Abrego, Ji Ma, Jianmo Ni, Yinfei Yang",Neural Passage Retrieval with Improved Negative Contrast,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper we explore the effects of negative sampling in dual encoder
models used to retrieve passages for automatic question answering. We explore
four negative sampling strategies that complement the straightforward random
sampling of negatives, typically used to train dual encoder models. Out of the
four strategies, three are based on retrieval and one on heuristics. Our
retrieval-based strategies are based on the semantic similarity and the lexical
overlap between questions and passages. We train the dual encoder models in two
stages: pre-training with synthetic data and fine tuning with domain-specific
data. We apply negative sampling to both stages. The approach is evaluated in
two passage retrieval tasks. Even though it is not evident that there is one
single sampling strategy that works best in all the tasks, it is clear that our
strategies contribute to improving the contrast between the response and all
the other passages. Furthermore, mixing the negatives from different strategies
achieve performance on par with the best performing strategy in all tasks. Our
results establish a new state-of-the-art level of performance on two of the
open-domain question answering datasets that we evaluated.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 16:45:06 GMT'}]",2020-10-26,"[['Lu', 'Jing', ''], ['Abrego', 'Gustavo Hernandez', ''], ['Ma', 'Ji', ''], ['Ni', 'Jianmo', ''], ['Yang', 'Yinfei', '']]"
1368842,2010.12512,Linyi Yang,"Linyi Yang, Eoin M. Kenny, Tin Lok James Ng, Yi Yang, Barry Smyth, and
  Ruihai Dong","Generating Plausible Counterfactual Explanations for Deep Transformers
  in Financial Text Classification",Accepted by COLING-20 (Oral),,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Corporate mergers and acquisitions (M&A) account for billions of dollars of
investment globally every year, and offer an interesting and challenging domain
for artificial intelligence. However, in these highly sensitive domains, it is
crucial to not only have a highly robust and accurate model, but be able to
generate useful explanations to garner a user's trust in the automated system.
Regrettably, the recent research regarding eXplainable AI (XAI) in financial
text classification has received little to no attention, and many current
methods for generating textual-based explanations result in highly implausible
explanations, which damage a user's trust in the system. To address these
issues, this paper proposes a novel methodology for producing plausible
counterfactual explanations, whilst exploring the regularization benefits of
adversarial training on language models in the domain of FinTech. Exhaustive
quantitative experiments demonstrate that not only does this approach improve
the model accuracy when compared to the current state-of-the-art and human
performance, but it also generates counterfactual explanations which are
significantly more plausible based on human trials.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 16:29:26 GMT'}]",2020-10-26,"[['Yang', 'Linyi', ''], ['Kenny', 'Eoin M.', ''], ['Ng', 'Tin Lok James', ''], ['Yang', 'Yi', ''], ['Smyth', 'Barry', ''], ['Dong', 'Ruihai', '']]"
1368840,2010.12510,Nafise Sadat Moosavi,"Nafise Sadat Moosavi, Marcel de Boer, Prasetya Ajie Utama, Iryna
  Gurevych","Improving Robustness by Augmenting Training Sentences with
  Predicate-Argument Structures",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Existing NLP datasets contain various biases, and models tend to quickly
learn those biases, which in turn limits their robustness. Existing approaches
to improve robustness against dataset biases mostly focus on changing the
training objective so that models learn less from biased examples. Besides,
they mostly focus on addressing a specific bias, and while they improve the
performance on adversarial evaluation sets of the targeted bias, they may bias
the model in other ways, and therefore, hurt the overall robustness. In this
paper, we propose to augment the input sentences in the training data with
their corresponding predicate-argument structures, which provide a higher-level
abstraction over different realizations of the same meaning and help the model
to recognize important parts of sentences. We show that without targeting a
specific bias, our sentence augmentation improves the robustness of transformer
models against multiple biases. In addition, we show that models can still be
vulnerable to the lexical overlap bias, even when the training data does not
contain this bias, and that the sentence augmentation also improves the
robustness in this scenario. We will release our adversarial datasets to
evaluate bias in such a scenario as well as our augmentation scripts at
https://github.com/UKPLab/data-augmentation-for-robustness.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 16:22:05 GMT'}]",2020-10-26,"[['Moosavi', 'Nafise Sadat', ''], ['de Boer', 'Marcel', ''], ['Utama', 'Prasetya Ajie', ''], ['Gurevych', 'Iryna', '']]"
1368835,2010.12505,Tim Draws,"Tim Draws, Jody Liu, Nava Tintarev","Helping users discover perspectives: Enhancing opinion mining with joint
  topic models","Accepted at the SENTIRE workshop at ICDM 2020:
  https://sentic.net/sentire/#2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Support or opposition concerning a debated claim such as abortion should be
legal can have different underlying reasons, which we call perspectives. This
paper explores how opinion mining can be enhanced with joint topic modeling, to
identify distinct perspectives within the topic, providing an informative
overview from unstructured text. We evaluate four joint topic models (TAM, JST,
VODUM, and LAM) in a user study assessing human understandability of the
extracted perspectives. Based on the results, we conclude that joint topic
models such as TAM can discover perspectives that align with human judgments.
Moreover, our results suggest that users are not influenced by their
pre-existing stance on the topic of abortion when interpreting the output of
topic models.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 16:13:06 GMT'}]",2020-10-26,"[['Draws', 'Tim', ''], ['Liu', 'Jody', ''], ['Tintarev', 'Nava', '']]"
1368827,2010.12497,Omid Ghahabi,"Omid Ghahabi, Volker Fischer",EML System Description for VoxCeleb Speaker Diarization Challenge 2020,,,,,cs.SD cs.CL eess.AS,http://creativecommons.org/licenses/by/4.0/,"  This technical report describes the EML submission to the first VoxCeleb
speaker diarization challenge. Although the aim of the challenge has been the
offline processing of the signals, the submitted system is basically the EML
online algorithm which decides about the speaker labels in runtime
approximately every 1.2 sec. For the first phase of the challenge, only
VoxCeleb2 dev dataset was used for training. The results on the provided
VoxConverse dev set show much better accuracy in terms of both DER and JER
compared to the offline baseline provided in the challenge. The real-time
factor of the whole diarization process is about 0.01 using a single CPU
machine.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 16:01:28 GMT'}]",2020-10-26,"[['Ghahabi', 'Omid', ''], ['Fischer', 'Volker', '']]"
1368825,2010.12495,Daniel Deutsch,"Daniel Deutsch, Dan Roth","Understanding the Extent to which Summarization Evaluation Metrics
  Measure the Information Quality of Summaries",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Reference-based metrics such as ROUGE or BERTScore evaluate the content
quality of a summary by comparing the summary to a reference. Ideally, this
comparison should measure the summary's information quality by calculating how
much information the summaries have in common. In this work, we analyze the
token alignments used by ROUGE and BERTScore to compare summaries and argue
that their scores largely cannot be interpreted as measuring information
overlap, but rather the extent to which they discuss the same topics. Further,
we provide evidence that this result holds true for many other summarization
evaluation metrics. The consequence of this result is that it means the
summarization community has not yet found a reliable automatic metric that
aligns with its research goal, to generate summaries with high-quality
information. Then, we propose a simple and interpretable method of evaluating
summaries which does directly measure information overlap and demonstrate how
it can be used to gain insights into model behavior that could not be provided
by other methods alone.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 15:55:15 GMT'}]",2020-10-26,"[['Deutsch', 'Daniel', ''], ['Roth', 'Dan', '']]"
1368817,2010.12487,Damien Garreau,Dina Mardaoui and Damien Garreau,An Analysis of LIME for Text Data,"29 pages, 17 figures",,,,stat.ML cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Text data are increasingly handled in an automated fashion by machine
learning algorithms. But the models handling these data are not always
well-understood due to their complexity and are more and more often referred to
as ""black-boxes."" Interpretability methods aim to explain how these models
operate. Among them, LIME has become one of the most popular in recent years.
However, it comes without theoretical guarantees: even for simple models, we
are not sure that LIME behaves accurately. In this paper, we provide a first
theoretical analysis of LIME for text data. As a consequence of our theoretical
findings, we show that LIME indeed provides meaningful explanations for simple
models, namely decision trees and linear models.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 15:40:13 GMT'}]",2020-10-26,"[['Mardaoui', 'Dina', ''], ['Garreau', 'Damien', '']]"
1368803,2010.12473,Henning Wachsmuth,Henning Wachsmuth and Till Werner,Intrinsic Quality Assessment of Arguments,Accepted at COLING 2020,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Several quality dimensions of natural language arguments have been
investigated. Some are likely to be reflected in linguistic features (e.g., an
argument's arrangement), whereas others depend on context (e.g., relevance) or
topic knowledge (e.g., acceptability). In this paper, we study the intrinsic
computational assessment of 15 dimensions, i.e., only learning from an
argument's text. In systematic experiments with eight feature types on an
existing corpus, we observe moderate but significant learning success for most
dimensions. Rhetorical quality seems hardest to assess, and subjectivity
features turn out strong, although length bias in the corpus impedes full
validity. We also find that human assessors differ more clearly to each other
than to our approach.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 15:16:10 GMT'}]",2020-10-26,"[['Wachsmuth', 'Henning', ''], ['Werner', 'Till', '']]"
1368802,2010.12472,Tommaso Caselli,"Tommaso Caselli, Valerio Basile, Jelena Mitrovi\'c, Michael Granitzer",HateBERT: Retraining BERT for Abusive Language Detection in English,,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  In this paper, we introduce HateBERT, a re-trained BERT model for abusive
language detection in English. The model was trained on RAL-E, a large-scale
dataset of Reddit comments in English from communities banned for being
offensive, abusive, or hateful that we have collected and made available to the
public. We present the results of a detailed comparison between a general
pre-trained language model and the abuse-inclined version obtained by
retraining with posts from the banned communities on three English datasets for
offensive, abusive language and hate speech detection tasks. In all datasets,
HateBERT outperforms the corresponding general BERT model. We also discuss a
battery of experiments comparing the portability of the general pre-trained
language model and its corresponding abusive language-inclined counterpart
across the datasets, indicating that portability is affected by compatibility
of the annotated phenomena.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 15:14:14 GMT'}]",2020-10-26,"[['Caselli', 'Tommaso', ''], ['Basile', 'Valerio', ''], ['Mitrović', 'Jelena', ''], ['Granitzer', 'Michael', '']]"
1368763,2010.12433,Gaurish Thakkar Mr,"Diego Alves, Gaurish Thakkar, Marko Tadi\'c","Natural Language Processing Chains Inside a Cross-lingual Event-Centric
  Knowledge Pipeline for European Union Under-resourced Languages",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This article presents the strategy for developing a platform containing
Language Processing Chains for European Union languages, consisting of
Tokenization to Parsing, also including Named Entity recognition andwith
addition ofSentiment Analysis. These chains are part of the first step of an
event-centric knowledge processing pipeline whose aim is to process
multilingual media information about major events that can cause an impactin
Europe and the rest of the world. Due to the differences in terms of
availability of language resources for each language, we have built this
strategy in three steps, starting with processing chains for the well-resourced
languages and finishing with the development of new modules for the
under-resourced ones. In order to classify all European Union official
languages in terms of resources, we have analysed the size of annotated corpora
as well as the existence of pre-trained models in mainstream Language
Processing tools, and we have combined this information with the proposed
classification published at META-NETwhitepaper series.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 14:26:30 GMT'}]",2020-10-26,"[['Alves', 'Diego', ''], ['Thakkar', 'Gaurish', ''], ['Tadić', 'Marko', '']]"
1368758,2010.12428,Gaurish Thakkar Mr,"Diego Alves, Gaurish Thakkar, Marko Tadi\'c","Evaluating Language Tools for Fifteen EU-official Under-resourced
  Languages",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This article presents the results of the evaluation campaign of language
tools available for fifteen EU-official under-resourced languages. The
evaluation was conducted within the MSC ITN CLEOPATRA action that aims at
building the cross-lingual event-centric knowledge processing on top of the
application of linguistic processing chains (LPCs) for at least 24 EU-official
languages. In this campaign, we concentrated on three existing NLP platforms
(Stanford CoreNLP, NLP Cube, UDPipe) that all provide models for
under-resourced languages and in this first run we covered 15 under-resourced
languages for which the models were available. We present the design of the
evaluation campaign and present the results as well as discuss them. We
considered the difference between reported and our tested results within a
single percentage point as being within the limits of acceptable tolerance and
thus consider this result as reproducible. However, for a number of languages,
the results are below what was reported in the literature, and in some cases,
our testing results are even better than the ones reported previously.
Particularly problematic was the evaluation of NERC systems. One of the reasons
is the absence of universally or cross-lingually applicable named entities
classification scheme that would serve the NERC task in different languages
analogous to the Universal Dependency scheme in parsing task. To build such a
scheme has become one of our the future research directions.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 14:21:03 GMT'}]",2020-10-26,"[['Alves', 'Diego', ''], ['Thakkar', 'Gaurish', ''], ['Tadić', 'Marko', '']]"
1368748,2010.12418,Ahmed Al-Ali,"Ahmed Ghanim Al-Ali, Robert Phaal, Donald Sull","Deep Learning Framework for Measuring the Digital Strategy of Companies
  from Earnings Calls","Accepted for The 28th International Conference on Computational
  Linguistics, 9 pages, 1 figure",,,,cs.CL cs.CY cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Companies today are racing to leverage the latest digital technologies, such
as artificial intelligence, blockchain, and cloud computing. However, many
companies report that their strategies did not achieve the anticipated business
results. This study is the first to apply state of the art NLP models on
unstructured data to understand the different clusters of digital strategy
patterns that companies are Adopting. We achieve this by analyzing earnings
calls from Fortune Global 500 companies between 2015 and 2019. We use
Transformer based architecture for text classification which show a better
understanding of the conversation context. We then investigate digital strategy
patterns by applying clustering analysis. Our findings suggest that Fortune 500
companies use four distinct strategies which are product led, customer
experience led, service led, and efficiency led. This work provides an
empirical baseline for companies and researchers to enhance our understanding
of the field.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 14:07:12 GMT'}]",2020-10-26,"[['Al-Ali', 'Ahmed Ghanim', ''], ['Phaal', 'Robert', ''], ['Sull', 'Donald', '']]"
1368742,2010.12412,Ohad Rubin,Ohad Rubin and Jonathan Berant,SmBoP: Semi-autoregressive Bottom-up Semantic Parsing,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The de-facto standard decoding method for semantic parsing in recent years
has been to autoregressively decode the abstract syntax tree of the target
program using a top-down depth-first traversal. In this work, we propose an
alternative approach: a Semi-autoregressive Bottom-up Parser (SmBoP) that
constructs at decoding step $t$ the top-$K$ sub-trees of height $\leq t$. Our
parser enjoys several benefits compared to top-down autoregressive parsing.
First, since sub-trees in each decoding step are generated in parallel, the
theoretical runtime is logarithmic rather than linear. Second, our bottom-up
approach learns representations with meaningful semantic sub-programs at each
step, rather than semantically vague partial trees. Last, SmBoP includes
Transformer-based layers that contextualize sub-trees with one another,
allowing us, unlike traditional beam-search, to score trees conditioned on
other trees that have been previously explored. We apply SmBoP on Spider, a
challenging zero-shot semantic parsing benchmark, and show that SmBoP is
competitive with top-down autoregressive parsing. On the test set, SmBoP
obtains an EM score of $60.5\%$, similar to the best published score for a
model that does not use database content, which is at $60.6\%$.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 14:02:32 GMT'}]",2020-10-26,"[['Rubin', 'Ohad', ''], ['Berant', 'Jonathan', '']]"
1368736,2010.12406,Gaurish Thakkar Mr,"Diego Alves, Tin Kuculo, Gabriel Amaral, Gaurish Thakkar, and Marko
  Tadic",UNER: Universal Named-Entity RecognitionFramework,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We introduce the Universal Named-Entity Recognition (UNER)framework, a
4-level classification hierarchy, and the methodology that isbeing adopted to
create the first multilingual UNER corpus: the SETimesparallel corpus annotated
for named-entities. First, the English SETimescorpus will be annotated using
existing tools and knowledge bases. Afterevaluating the resulting annotations
through crowdsourcing campaigns,they will be propagated automatically to other
languages within the SE-Times corpora. Finally, as an extrinsic evaluation, the
UNER multilin-gual dataset will be used to train and test available NER tools.
As part offuture research directions, we aim to increase the number of
languages inthe UNER corpus and to investigate possible ways of integrating
UNERwith available knowledge graphs to improve named-entity recognition.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 13:53:31 GMT'}]",2020-10-26,"[['Alves', 'Diego', ''], ['Kuculo', 'Tin', ''], ['Amaral', 'Gabriel', ''], ['Thakkar', 'Gaurish', ''], ['Tadic', 'Marko', '']]"
1368652,2010.12322,Lukas Lange,"Lukas Lange, Xiang Dai, Heike Adel, Jannik Str\""otgen","NLNDE at CANTEMIST: Neural Sequence Labeling and Parsing Approaches for
  Clinical Concept Extraction",IberLEF 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The recognition and normalization of clinical information, such as tumor
morphology mentions, is an important, but complex process consisting of
multiple subtasks. In this paper, we describe our system for the CANTEMIST
shared task, which is able to extract, normalize and rank ICD codes from
Spanish electronic health records using neural sequence labeling and parsing
approaches with context-aware embeddings. Our best system achieves 85.3 F1,
76.7 F1, and 77.0 MAP for the three tasks, respectively.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 11:59:28 GMT'}]",2020-10-26,"[['Lange', 'Lukas', ''], ['Dai', 'Xiang', ''], ['Adel', 'Heike', ''], ['Strötgen', 'Jannik', '']]"
1368327,2010.11997,Zhanwen Chen,"Zhanwen Chen, Shiyao Li, Roxanne Rashedi, Xiaoman Zi, Morgan
  Elrod-Erickson, Bryan Hollis, Angela Maliakal, Xinyu Shen, Simeng Zhao,
  Maithilee Kunda","Characterizing Datasets for Social Visual Question Answering, and the
  New TinySocial Dataset","To appear in the Joint IEEE International Conference on Development
  and Learning and on Epigenetic Robotics (ICDL), 2020",,,,cs.HC cs.CL cs.CV cs.SI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Modern social intelligence includes the ability to watch videos and answer
questions about social and theory-of-mind-related content, e.g., for a scene in
Harry Potter, ""Is the father really upset about the boys flying the car?""
Social visual question answering (social VQA) is emerging as a valuable
methodology for studying social reasoning in both humans (e.g., children with
autism) and AI agents. However, this problem space spans enormous variations in
both videos and questions. We discuss methods for creating and characterizing
social VQA datasets, including 1) crowdsourcing versus in-house authoring,
including sample comparisons of two new datasets that we created
(TinySocial-Crowd and TinySocial-InHouse) and the previously existing Social-IQ
dataset; 2) a new rubric for characterizing the difficulty and content of a
given video; and 3) a new rubric for characterizing question types. We close by
describing how having well-characterized social VQA datasets will enhance the
explainability of AI agents and can also inform assessments and educational
interventions for people.
","[{'version': 'v1', 'created': 'Thu, 8 Oct 2020 03:20:23 GMT'}]",2020-10-26,"[['Chen', 'Zhanwen', ''], ['Li', 'Shiyao', ''], ['Rashedi', 'Roxanne', ''], ['Zi', 'Xiaoman', ''], ['Elrod-Erickson', 'Morgan', ''], ['Hollis', 'Bryan', ''], ['Maliakal', 'Angela', ''], ['Shen', 'Xinyu', ''], ['Zhao', 'Simeng', ''], ['Kunda', 'Maithilee', '']]"
1368553,2010.12223,Richard Moot,"Richard Moot (TEXTE, LIRMM, CNRS)",Proof-theoretic aspects of NL$\lambda$,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present a proof-theoretic analysis of the logic NL$\lambda$ (Barker \&
Shan 2014, Barker 2019). We notably introduce a novel calculus of proof nets
and prove it is sound and complete with respect to the sequent calculus for the
logic. We study decidability and complexity of the logic using this new
calculus, proving a new upper bound for complexity of the logic (showing it is
in NP) and a new lower bound for the class of formal language generated by the
formalism (mildly context-sensitive languages extended with a permutation
closure operation). Finally, thanks to this new calculus, we present a novel
comparison between NL$\lambda$ and the hybrid type-logical grammars of Kubota
\& Levine (2020). We show there is an unexpected convergence of the natural
language analyses proposed in the two formalism. In addition to studying the
proof-theoretic properties of NL$\lambda$, we greatly extends its linguistic
coverage.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 08:13:39 GMT'}]",2020-10-26,"[['Moot', 'Richard', '', 'TEXTE, LIRMM, CNRS']]"
1368315,2010.11985,Jianing Yang,"Jianing Yang, Yongxin Wang, Ruitao Yi, Yuying Zhu, Azaan Rehman, Amir
  Zadeh, Soujanya Poria, Louis-Philippe Morency","MTGAT: Multimodal Temporal Graph Attention Networks for Unaligned Human
  Multimodal Language Sequences",,,,,cs.CL cs.CV cs.LG cs.MM,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Human communication is multimodal in nature; it is through multiple
modalities, i.e., language, voice, and facial expressions, that opinions and
emotions are expressed. Data in this domain exhibits complex multi-relational
and temporal interactions. Learning from this data is a fundamentally
challenging research problem. In this paper, we propose Multimodal Temporal
Graph Attention Networks (MTGAT). MTGAT is an interpretable graph-based neural
model that provides a suitable framework for analyzing this type of multimodal
sequential data. We first introduce a procedure to convert unaligned multimodal
sequence data into a graph with heterogeneous nodes and edges that captures the
rich interactions between different modalities through time. Then, a novel
graph operation, called Multimodal Temporal Graph Attention, along with a
dynamic pruning and read-out technique is designed to efficiently process this
multimodal temporal graph. By learning to focus only on the important
interactions within the graph, our MTGAT is able to achieve state-of-the-art
performance on multimodal sentiment analysis and emotion recognition benchmarks
including IEMOCAP and CMU-MOSI, while utilizing significantly fewer
computations.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 18:58:50 GMT'}]",2020-10-26,"[['Yang', 'Jianing', ''], ['Wang', 'Yongxin', ''], ['Yi', 'Ruitao', ''], ['Zhu', 'Yuying', ''], ['Rehman', 'Azaan', ''], ['Zadeh', 'Amir', ''], ['Poria', 'Soujanya', ''], ['Morency', 'Louis-Philippe', '']]"
1352535,2009.11032,Arie Cattan,"Arie Cattan, Alon Eirew, Gabriel Stanovsky, Mandar Joshi, and Ido
  Dagan","Streamlining Cross-Document Coreference Resolution: Evaluation and
  Modeling",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent evaluation protocols for Cross-document (CD) coreference resolution
have often been inconsistent or lenient, leading to incomparable results across
works and overestimation of performance. To facilitate proper future research
on this task, our primary contribution is proposing a pragmatic evaluation
methodology which assumes access to only raw text -- rather than assuming gold
mentions, disregards singleton prediction, and addresses typical targeted
settings in CD coreference resolution. Aiming to set baseline results for
future research that would follow our evaluation methodology, we build the
first end-to-end model for this task. Our model adapts and extends recent
neural models for within-document coreference resolution to address the CD
coreference setting, which outperforms state-of-the-art results by a
significant margin.
","[{'version': 'v1', 'created': 'Wed, 23 Sep 2020 10:02:10 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 12:18:01 GMT'}, {'version': 'v3', 'created': 'Fri, 23 Oct 2020 13:40:30 GMT'}]",2020-10-26,"[['Cattan', 'Arie', ''], ['Eirew', 'Alon', ''], ['Stanovsky', 'Gabriel', ''], ['Joshi', 'Mandar', ''], ['Dagan', 'Ido', '']]"
1355321,2009.13818,Dinghan Shen,"Dinghan Shen, Mingzhi Zheng, Yelong Shen, Yanru Qu, Weizhu Chen","A Simple but Tough-to-Beat Data Augmentation Approach for Natural
  Language Understanding and Generation",Source code is available at: https://github.com/dinghanshen/cutoff,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Adversarial training has been shown effective at endowing the learned
representations with stronger generalization ability. However, it typically
requires expensive computation to determine the direction of the injected
perturbations. In this paper, we introduce a set of simple yet effective data
augmentation strategies dubbed cutoff, where part of the information within an
input sentence is erased to yield its restricted views (during the fine-tuning
stage). Notably, this process relies merely on stochastic sampling and thus
adds little computational overhead. A Jensen-Shannon Divergence consistency
loss is further utilized to incorporate these augmented samples into the
training objective in a principled manner. To verify the effectiveness of the
proposed strategies, we apply cutoff to both natural language understanding and
generation problems. On the GLUE benchmark, it is demonstrated that cutoff, in
spite of its simplicity, performs on par or better than several competitive
adversarial-based approaches. We further extend cutoff to machine translation
and observe significant gains in BLEU scores (based upon the Transformer Base
model). Moreover, cutoff consistently outperforms adversarial training and
achieves state-of-the-art results on the IWSLT2014 German-English dataset.
","[{'version': 'v1', 'created': 'Tue, 29 Sep 2020 07:08:35 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 03:19:58 GMT'}]",2020-10-26,"[['Shen', 'Dinghan', ''], ['Zheng', 'Mingzhi', ''], ['Shen', 'Yelong', ''], ['Qu', 'Yanru', ''], ['Chen', 'Weizhu', '']]"
1368318,2010.11988,Bailin Wang,"Bailin Wang, Mirella Lapata and Ivan Titov",Meta-Learning for Domain Generalization in Semantic Parsing,V1.0,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The importance of building semantic parsers which can be applied to new
domains and generate programs unseen at training has long been acknowledged,
and datasets testing out-of-domain performance are becoming increasingly
available. However, little or no attention has been devoted to studying
learning algorithms or objectives which promote domain generalization, with
virtually all existing approaches relying on standard supervised learning. In
this work, we use a meta-learning framework which targets specifically
zero-shot domain generalization for semantic parsing. We apply a model-agnostic
training algorithm that simulates zero-shot parsing by constructing virtual
train and test sets from disjoint domains. The learning objective capitalizes
on the intuition that gradient steps that improve source-domain performance
should also improve target-domain performance, thus encouraging a parser to
generalize well to unseen target domains. Experimental results on the (English)
Spider and Chinese Spider datasets show that the meta-learning objective
significantly boosts the performance of a baseline parser.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 19:00:36 GMT'}]",2020-10-26,"[['Wang', 'Bailin', ''], ['Lapata', 'Mirella', ''], ['Titov', 'Ivan', '']]"
1287478,2005.07683,Victor Sanh,"Victor Sanh, Thomas Wolf, Alexander M. Rush",Movement Pruning: Adaptive Sparsity by Fine-Tuning,"14 pages, 6 figures, 3 tables. Published at NeurIPS2020. Code:
  \url{huggingface.co/mvp}",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Magnitude pruning is a widely used strategy for reducing model size in pure
supervised learning; however, it is less effective in the transfer learning
regime that has become standard for state-of-the-art natural language
processing applications. We propose the use of movement pruning, a simple,
deterministic first-order weight pruning method that is more adaptive to
pretrained model fine-tuning. We give mathematical foundations to the method
and compare it to existing zeroth- and first-order pruning methods. Experiments
show that when pruning large pretrained language models, movement pruning shows
significant improvements in high-sparsity regimes. When combined with
distillation, the approach achieves minimal accuracy loss with down to only 3%
of the model parameters.
","[{'version': 'v1', 'created': 'Fri, 15 May 2020 17:54:15 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 16:14:58 GMT'}]",2020-10-26,"[['Sanh', 'Victor', ''], ['Wolf', 'Thomas', ''], ['Rush', 'Alexander M.', '']]"
1359487,2010.03157,Sheng Bi,"Sheng Bi and Xiya Cheng and Yuan-Fang Li and Yongzhen Wang and Guilin
  Qi","Knowledge-enriched, Type-constrained and Grammar-guided Question
  Generation over Knowledge Bases",Accepted by COLING 2020,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Question generation over knowledge bases (KBQG) aims at generating
natural-language questions about a subgraph, i.e. a set of (connected) triples.
Two main challenges still face the current crop of encoder-decoder-based
methods, especially on small subgraphs: (1) low diversity and poor fluency due
to the limited information contained in the subgraphs, and (2) semantic drift
due to the decoder's oblivion of the semantics of the answer entity. We propose
an innovative knowledge-enriched, type-constrained and grammar-guided KBQG
model, named KTG, to addresses the above challenges. In our model, the encoder
is equipped with auxiliary information from the KB, and the decoder is
constrained with word types during QG. Specifically, entity domain and
description, as well as relation hierarchy information are considered to
construct question contexts, while a conditional copy mechanism is incorporated
to modulate question semantics according to current word types. Besides, a
novel reward function featuring grammatical similarity is designed to improve
both generative richness and syntactic correctness via reinforcement learning.
Extensive experiments show that our proposed model outperforms existing methods
by a significant margin on two widely-used benchmark datasets SimpleQuestion
and PathQuestion.
","[{'version': 'v1', 'created': 'Wed, 7 Oct 2020 04:49:48 GMT'}, {'version': 'v2', 'created': 'Thu, 8 Oct 2020 05:39:58 GMT'}, {'version': 'v3', 'created': 'Fri, 23 Oct 2020 03:32:38 GMT'}]",2020-10-26,"[['Bi', 'Sheng', ''], ['Cheng', 'Xiya', ''], ['Li', 'Yuan-Fang', ''], ['Wang', 'Yongzhen', ''], ['Qi', 'Guilin', '']]"
1362970,2010.06640,Gathika Ratnayaka,"Gathika Ratnayaka, Thushari Atapattu, Mahen Herath, Georgia Zhang,
  Katrina Falkner",Enhancing the Identification of Cyberbullying through Participant Roles,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Cyberbullying is a prevalent social problem that inflicts detrimental
consequences to the health and safety of victims such as psychological
distress, anti-social behaviour, and suicide. The automation of cyberbullying
detection is a recent but widely researched problem, with current research
having a strong focus on a binary classification of bullying versus
non-bullying. This paper proposes a novel approach to enhancing cyberbullying
detection through role modeling. We utilise a dataset from ASKfm to perform
multi-class classification to detect participant roles (e.g. victim, harasser).
Our preliminary results demonstrate promising performance including 0.83 and
0.76 of F1-score for cyberbullying and role classification respectively,
outperforming baselines.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 19:13:07 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 01:15:20 GMT'}]",2020-10-26,"[['Ratnayaka', 'Gathika', ''], ['Atapattu', 'Thushari', ''], ['Herath', 'Mahen', ''], ['Zhang', 'Georgia', ''], ['Falkner', 'Katrina', '']]"
1279095,2004.14325,Daniel Loureiro,Daniel Loureiro and Jose Camacho-Collados,"Don't Neglect the Obvious: On the Role of Unambiguous Words in Word
  Sense Disambiguation",Accepted to EMNLP 2020. Website: http://danlou.github.io/uwa,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  State-of-the-art methods for Word Sense Disambiguation (WSD) combine two
different features: the power of pre-trained language models and a propagation
method to extend the coverage of such models. This propagation is needed as
current sense-annotated corpora lack coverage of many instances in the
underlying sense inventory (usually WordNet). At the same time, unambiguous
words make for a large portion of all words in WordNet, while being poorly
covered in existing sense-annotated corpora. In this paper, we propose a simple
method to provide annotations for most unambiguous words in a large corpus. We
introduce the UWA (Unambiguous Word Annotations) dataset and show how a
state-of-the-art propagation-based model can use it to extend the coverage and
quality of its word sense embeddings by a significant margin, improving on its
original results on WSD.
","[{'version': 'v1', 'created': 'Wed, 29 Apr 2020 16:51:21 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Oct 2020 08:57:53 GMT'}, {'version': 'v3', 'created': 'Fri, 23 Oct 2020 09:20:11 GMT'}]",2020-10-26,"[['Loureiro', 'Daniel', ''], ['Camacho-Collados', 'Jose', '']]"
1365865,2010.09535,Michelle Yuan,"Michelle Yuan, Hsuan-Tien Lin, Jordan Boyd-Graber",Cold-start Active Learning through Self-supervised Language Modeling,Published in EMNLP 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Active learning strives to reduce annotation costs by choosing the most
critical examples to label. Typically, the active learning strategy is
contingent on the classification model. For instance, uncertainty sampling
depends on poorly calibrated model confidence scores. In the cold-start
setting, active learning is impractical because of model instability and data
scarcity. Fortunately, modern NLP provides an additional source of information:
pre-trained language models. The pre-training loss can find examples that
surprise the model and should be labeled for efficient fine-tuning. Therefore,
we treat the language modeling loss as a proxy for classification uncertainty.
With BERT, we develop a simple strategy based on the masked language modeling
loss that minimizes labeling costs for text classification. Compared to other
baselines, our approach reaches higher accuracy within less sampling iterations
and computation time.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 14:09:17 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 18:51:04 GMT'}]",2020-10-26,"[['Yuan', 'Michelle', ''], ['Lin', 'Hsuan-Tien', ''], ['Boyd-Graber', 'Jordan', '']]"
1300709,2006.06195,Zhe Gan,"Zhe Gan, Yen-Chun Chen, Linjie Li, Chen Zhu, Yu Cheng, Jingjing Liu","Large-Scale Adversarial Training for Vision-and-Language Representation
  Learning",NeurIPS 2020 Spotlight paper,,,,cs.CV cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present VILLA, the first known effort on large-scale adversarial training
for vision-and-language (V+L) representation learning. VILLA consists of two
training stages: (i) task-agnostic adversarial pre-training; followed by (ii)
task-specific adversarial finetuning. Instead of adding adversarial
perturbations on image pixels and textual tokens, we propose to perform
adversarial training in the embedding space of each modality. To enable
large-scale training, we adopt the ""free"" adversarial training strategy, and
combine it with KL-divergence-based regularization to promote higher invariance
in the embedding space. We apply VILLA to current best-performing V+L models,
and achieve new state of the art on a wide range of tasks, including Visual
Question Answering, Visual Commonsense Reasoning, Image-Text Retrieval,
Referring Expression Comprehension, Visual Entailment, and NLVR2.
","[{'version': 'v1', 'created': 'Thu, 11 Jun 2020 05:14:35 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 18:12:53 GMT'}]",2020-10-26,"[['Gan', 'Zhe', ''], ['Chen', 'Yen-Chun', ''], ['Li', 'Linjie', ''], ['Zhu', 'Chen', ''], ['Cheng', 'Yu', ''], ['Liu', 'Jingjing', '']]"
1301414,2006.06900,Yue Wu,"Yue Wu, Pan Zhou, Andrew Gordon Wilson, Eric P. Xing, Zhiting Hu","Improving GAN Training with Probability Ratio Clipping and Sample
  Reweighting",NeurIPS 2020 camera ready version,,,,cs.LG cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite success on a wide range of problems related to vision, generative
adversarial networks (GANs) often suffer from inferior performance due to
unstable training, especially for text generation. To solve this issue, we
propose a new variational GAN training framework which enjoys superior training
stability. Our approach is inspired by a connection of GANs and reinforcement
learning under a variational perspective. The connection leads to (1)
probability ratio clipping that regularizes generator training to prevent
excessively large updates, and (2) a sample re-weighting mechanism that
improves discriminator training by downplaying bad-quality fake samples.
Moreover, our variational GAN framework can provably overcome the training
issue in many GANs that an optimal discriminator cannot provide any informative
gradient to training generator. By plugging the training approach in diverse
state-of-the-art GAN architectures, we obtain significantly improved
performance over a range of tasks, including text generation, text style
transfer, and image generation.
","[{'version': 'v1', 'created': 'Fri, 12 Jun 2020 01:39:48 GMT'}, {'version': 'v2', 'created': 'Tue, 30 Jun 2020 15:02:27 GMT'}, {'version': 'v3', 'created': 'Fri, 23 Oct 2020 03:24:01 GMT'}]",2020-10-26,"[['Wu', 'Yue', ''], ['Zhou', 'Pan', ''], ['Wilson', 'Andrew Gordon', ''], ['Xing', 'Eric P.', ''], ['Hu', 'Zhiting', '']]"
1366371,2010.10041,Chi-Liang Liu,"Chi-Liang Liu and Tsung-Yuan Hsu and Yung-Sung Chuang and Chung-Yi Li
  and Hung-yi Lee","Language Representation in Multilingual BERT and its applications to
  improve Cross-lingual Generalization",preprint,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A token embedding in multilingual BERT (m-BERT) contains both language and
semantic information. We find that representation of a language can be obtained
by simply averaging the embeddings of the tokens of the language. With the
language representation, we can control the output languages of multilingual
BERT by manipulating the token embeddings and achieve unsupervised token
translation. We further propose a computationally cheap but effective approach
to improve the cross-lingual ability of m-BERT based on the observation.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 05:41:35 GMT'}, {'version': 'v2', 'created': 'Wed, 21 Oct 2020 07:26:02 GMT'}, {'version': 'v3', 'created': 'Fri, 23 Oct 2020 05:47:46 GMT'}]",2020-10-26,"[['Liu', 'Chi-Liang', ''], ['Hsu', 'Tsung-Yuan', ''], ['Chuang', 'Yung-Sung', ''], ['Li', 'Chung-Yi', ''], ['Lee', 'Hung-yi', '']]"
1302851,2006.08337,Jinfeng Xiao,"Jinfeng Xiao, Lidan Wang, Franck Dernoncourt, Trung Bui, Tong Sun,
  Jiawei Han",Open-Domain Question Answering with Pre-Constructed Question Spaces,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Open-domain question answering aims at solving the task of locating the
answers to user-generated questions in massive collections of documents. There
are two families of solutions available: retriever-readers, and
knowledge-graph-based approaches. A retriever-reader usually first uses
information retrieval methods like TF-IDF to locate some documents or
paragraphs that are likely to be relevant to the question, and then feeds the
retrieved text to a neural network reader to extract the answer. Alternatively,
knowledge graphs can be constructed from the corpus and be queried against to
answer user questions. We propose a novel algorithm with a reader-retriever
structure that differs from both families. Our reader-retriever first uses an
offline reader to read the corpus and generate collections of all answerable
questions associated with their answers, and then uses an online retriever to
respond to user queries by searching the pre-constructed question spaces for
answers that are most likely to be asked in the given way. We further combine
retriever-reader and reader-retriever results into one single answer by
examining the consistency between the two components. We claim that our
algorithm solves some bottlenecks in existing work, and demonstrate that it
achieves superior accuracy on real-world datasets.
","[{'version': 'v1', 'created': 'Tue, 2 Jun 2020 04:31:09 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 02:10:07 GMT'}]",2020-10-26,"[['Xiao', 'Jinfeng', ''], ['Wang', 'Lidan', ''], ['Dernoncourt', 'Franck', ''], ['Bui', 'Trung', ''], ['Sun', 'Tong', ''], ['Han', 'Jiawei', '']]"
1366693,2010.10363,Laurel Orr,"Laurel Orr, Megan Leszczynski, Simran Arora, Sen Wu, Neel Guha, Xiao
  Ling, Christopher Re","Bootleg: Chasing the Tail with Self-Supervised Named Entity
  Disambiguation",,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A challenge for named entity disambiguation (NED), the task of mapping
textual mentions to entities in a knowledge base, is how to disambiguate
entities that appear rarely in the training data, termed tail entities. Humans
use subtle reasoning patterns based on knowledge of entity facts, relations,
and types to disambiguate unfamiliar entities. Inspired by these patterns, we
introduce Bootleg, a self-supervised NED system that is explicitly grounded in
reasoning patterns for disambiguation. We define core reasoning patterns for
disambiguation, create a learning procedure to encourage the self-supervised
model to learn the patterns, and show how to use weak supervision to enhance
the signals in the training data. Encoding the reasoning patterns in a simple
Transformer architecture, Bootleg meets or exceeds state-of-the-art on three
NED benchmarks. We further show that the learned representations from Bootleg
successfully transfer to other non-disambiguation tasks that require
entity-based knowledge: we set a new state-of-the-art in the popular TACRED
relation extraction task by 1.0 F1 points and demonstrate up to 8% performance
lift in highly optimized production search and assistant tasks at a major
technology company
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 15:17:49 GMT'}, {'version': 'v2', 'created': 'Wed, 21 Oct 2020 02:19:08 GMT'}, {'version': 'v3', 'created': 'Fri, 23 Oct 2020 16:21:13 GMT'}]",2020-10-26,"[['Orr', 'Laurel', ''], ['Leszczynski', 'Megan', ''], ['Arora', 'Simran', ''], ['Wu', 'Sen', ''], ['Guha', 'Neel', ''], ['Ling', 'Xiao', ''], ['Re', 'Christopher', '']]"
1367073,2010.10743,Jianhao Yan,"Jianhao Yan, Fandong Meng, Jie Zhou",Multi-Unit Transformers for Neural Machine Translation,Accepted as a main conference paper in EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Transformer models achieve remarkable success in Neural Machine Translation.
Many efforts have been devoted to deepening the Transformer by stacking several
units (i.e., a combination of Multihead Attentions and FFN) in a cascade, while
the investigation over multiple parallel units draws little attention. In this
paper, we propose the Multi-Unit Transformers (MUTE), which aim to promote the
expressiveness of the Transformer by introducing diverse and complementary
units. Specifically, we use several parallel units and show that modeling with
multiple units improves model performance and introduces diversity. Further, to
better leverage the advantage of the multi-unit setting, we design biased
module and sequential dependency that guide and encourage complementariness
among different units. Experimental results on three machine translation tasks,
the NIST Chinese-to-English, WMT'14 English-to-German and WMT'18
Chinese-to-English, show that the MUTE models significantly outperform the
Transformer-Base, by up to +1.52, +1.90 and +1.10 BLEU points, with only a mild
drop in inference speed (about 3.1%). In addition, our methods also surpass the
Transformer-Big model, with only 54\% of its parameters. These results
demonstrate the effectiveness of the MUTE, as well as its efficiency in both
the inference process and parameter usage.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 03:41:49 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 11:33:45 GMT'}]",2020-10-26,"[['Yan', 'Jianhao', ''], ['Meng', 'Fandong', ''], ['Zhou', 'Jie', '']]"
1366215,2010.09885,Seyone Chithrananda,"Seyone Chithrananda, Gabriel Grand and Bharath Ramsundar","ChemBERTa: Large-Scale Self-Supervised Pretraining for Molecular
  Property Prediction",Submitted to NeurIPS 2020 ML for Molecules Workshop,,,,cs.LG cs.CL physics.chem-ph q-bio.BM,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  GNNs and chemical fingerprints are the predominant approaches to representing
molecules for property prediction. However, in NLP, transformers have become
the de-facto standard for representation learning thanks to their strong
downstream task transfer. In parallel, the software ecosystem around
transformers is maturing rapidly, with libraries like HuggingFace and BertViz
enabling streamlined training and introspection. In this work, we make one of
the first attempts to systematically evaluate transformers on molecular
property prediction tasks via our ChemBERTa model. ChemBERTa scales well with
pretraining dataset size, offering competitive downstream performance on
MoleculeNet and useful attention-based visualization modalities. Our results
suggest that transformers offer a promising avenue of future work for molecular
representation learning and property prediction. To facilitate these efforts,
we release a curated dataset of 77M SMILES from PubChem suitable for
large-scale self-supervised pretraining.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 21:41:41 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 04:22:37 GMT'}]",2020-10-26,"[['Chithrananda', 'Seyone', ''], ['Grand', 'Gabriel', ''], ['Ramsundar', 'Bharath', '']]"
1368312,2010.11982,Avia Efrat,Avia Efrat and Omer Levy,The Turking Test: Can Language Models Understand Instructions?,,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Supervised machine learning provides the learner with a set of input-output
examples of the target task. Humans, however, can also learn to perform new
tasks from instructions in natural language. Can machines learn to understand
instructions as well? We present the Turking Test, which examines a model's
ability to follow natural language instructions of varying complexity. These
range from simple tasks, like retrieving the nth word of a sentence, to ones
that require creativity, such as generating examples for SNLI and SQuAD in
place of human intelligence workers (""turkers""). Despite our lenient evaluation
methodology, we observe that a large pretrained language model performs poorly
across all tasks. Analyzing the model's error patterns reveals that the model
tends to ignore explicit instructions and often generates outputs that cannot
be construed as an attempt to solve the task. While it is not yet clear whether
instruction understanding can be captured by traditional language models, the
sheer expressivity of instruction understanding makes it an appealing
alternative to the rising few-shot inference paradigm.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 18:44:16 GMT'}]",2020-10-26,"[['Efrat', 'Avia', ''], ['Levy', 'Omer', '']]"
1368296,2010.11966,David Lowell,"David Lowell, Brian E. Howard, Zachary C. Lipton, Byron C. Wallace","Unsupervised Data Augmentation with Naive Augmentation and without
  Unlabeled Data",,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Unsupervised Data Augmentation (UDA) is a semi-supervised technique that
applies a consistency loss to penalize differences between a model's
predictions on (a) observed (unlabeled) examples; and (b) corresponding
'noised' examples produced via data augmentation. While UDA has gained
popularity for text classification, open questions linger over which design
decisions are necessary and over how to extend the method to sequence labeling
tasks. This method has recently gained traction for text classification. In
this paper, we re-examine UDA and demonstrate its efficacy on several
sequential tasks. Our main contribution is an empirical study of UDA to
establish which components of the algorithm confer benefits in NLP. Notably,
although prior work has emphasized the use of clever augmentation techniques
including back-translation, we find that enforcing consistency between
predictions assigned to observed and randomly substituted words often yields
comparable (or greater) benefits compared to these complex perturbation models.
Furthermore, we find that applying its consistency loss affords meaningful
gains without any unlabeled data at all, i.e., in a standard supervised
setting. In short: UDA need not be unsupervised, and does not require complex
data augmentation to be effective.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 18:01:51 GMT'}]",2020-10-26,"[['Lowell', 'David', ''], ['Howard', 'Brian E.', ''], ['Lipton', 'Zachary C.', ''], ['Wallace', 'Byron C.', '']]"
1368303,2010.11973,Badr M. Abdullah,"Badr M. Abdullah, Jacek Kudera, Tania Avgustinova, Bernd M\""obius,
  Dietrich Klakow","Rediscovering the Slavic Continuum in Representations Emerging from
  Neural Models of Spoken Language Identification",Accepted in VarDial 2020 Workshop,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Deep neural networks have been employed for various spoken language
recognition tasks, including tasks that are multilingual by definition such as
spoken language identification. In this paper, we present a neural model for
Slavic language identification in speech signals and analyze its emergent
representations to investigate whether they reflect objective measures of
language relatedness and/or non-linguists' perception of language similarity.
While our analysis shows that the language representation space indeed captures
language relatedness to a great extent, we find perceptual confusability
between languages in our study to be the best predictor of the language
representation similarity.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 18:18:19 GMT'}]",2020-10-26,"[['Abdullah', 'Badr M.', ''], ['Kudera', 'Jacek', ''], ['Avgustinova', 'Tania', ''], ['Möbius', 'Bernd', ''], ['Klakow', 'Dietrich', '']]"
1368310,2010.11980,Tuan Manh Lai,"Tuan Manh Lai, Trung Bui, Doo Soon Kim, Quan Hung Tran","A Joint Learning Approach based on Self-Distillation for Keyphrase
  Extraction from Scientific Documents",Accepted to COLING 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Keyphrase extraction is the task of extracting a small set of phrases that
best describe a document. Most existing benchmark datasets for the task
typically have limited numbers of annotated documents, making it challenging to
train increasingly complex neural networks. In contrast, digital libraries
store millions of scientific articles online, covering a wide range of topics.
While a significant portion of these articles contain keyphrases provided by
their authors, most other articles lack such kind of annotations. Therefore, to
effectively utilize these large amounts of unlabeled articles, we propose a
simple and efficient joint learning approach based on the idea of
self-distillation. Experimental results show that our approach consistently
improves the performance of baseline models for keyphrase extraction.
Furthermore, our best models outperform previous methods for the task,
achieving new state-of-the-art results on two public benchmarks: Inspec and
SemEval-2017.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 18:36:31 GMT'}]",2020-10-26,"[['Lai', 'Tuan Manh', ''], ['Bui', 'Trung', ''], ['Kim', 'Doo Soon', ''], ['Tran', 'Quan Hung', '']]"
1368277,2010.11947,Zekun Xu,"Zekun Xu, Abhinav Aggarwal, Oluwaseyi Feyisetan, Nathanael Teissier","A Differentially Private Text Perturbation Method Using a Regularized
  Mahalanobis Metric","11 pages, 7 figures",,,,cs.CL cs.CR cs.LG stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Balancing the privacy-utility tradeoff is a crucial requirement of many
practical machine learning systems that deal with sensitive customer data. A
popular approach for privacy-preserving text analysis is noise injection, in
which text data is first mapped into a continuous embedding space, perturbed by
sampling a spherical noise from an appropriate distribution, and then projected
back to the discrete vocabulary space. While this allows the perturbation to
admit the required metric differential privacy, often the utility of downstream
tasks modeled on this perturbed data is low because the spherical noise does
not account for the variability in the density around different words in the
embedding space. In particular, words in a sparse region are likely unchanged
even when the noise scale is large. %Using the global sensitivity of the
mechanism can potentially add too much noise to the words in the dense regions
of the embedding space, causing a high utility loss, whereas using local
sensitivity can leak information through the scale of the noise added.
  In this paper, we propose a text perturbation mechanism based on a carefully
designed regularized variant of the Mahalanobis metric to overcome this
problem. For any given noise scale, this metric adds an elliptical noise to
account for the covariance structure in the embedding space. This heterogeneity
in the noise scale along different directions helps ensure that the words in
the sparse region have sufficient likelihood of replacement without sacrificing
the overall utility. We provide a text-perturbation algorithm based on this
metric and formally prove its privacy guarantees. Additionally, we empirically
show that our mechanism improves the privacy statistics to achieve the same
level of utility as compared to the state-of-the-art Laplace mechanism.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 23:06:44 GMT'}]",2020-10-26,"[['Xu', 'Zekun', ''], ['Aggarwal', 'Abhinav', ''], ['Feyisetan', 'Oluwaseyi', ''], ['Teissier', 'Nathanael', '']]"
1368297,2010.11967,Chenguang Wang,"Chenguang Wang, Xiao Liu, Dawn Song",Language Models are Open Knowledge Graphs,"30 pages, 32 figures, 3 tables",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper shows how to construct knowledge graphs (KGs) from pre-trained
language models (e.g., BERT, GPT-2/3), without human supervision. Popular KGs
(e.g, Wikidata, NELL) are built in either a supervised or semi-supervised
manner, requiring humans to create knowledge. Recent deep language models
automatically acquire knowledge from large-scale corpora via pre-training. The
stored knowledge has enabled the language models to improve downstream NLP
tasks, e.g., answering questions, and writing code and articles. In this paper,
we propose an unsupervised method to cast the knowledge contained within
language models into KGs. We show that KGs are constructed with a single
forward pass of the pre-trained language models (without fine-tuning) over the
corpora. We demonstrate the quality of the constructed KGs by comparing to two
KGs (Wikidata, TAC KBP) created by humans. Our KGs also provide open factual
knowledge that is new in the existing KGs. Our code and KGs will be made
publicly available.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 18:01:56 GMT'}]",2020-10-26,"[['Wang', 'Chenguang', ''], ['Liu', 'Xiao', ''], ['Song', 'Dawn', '']]"
1131884,1905.13448,Xuenan Xu,"Xuenan Xu, Heinrich Dinkel, Mengyue Wu, Kai Yu",Audio Caption in a Car Setting with a Sentence-Level Loss,,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Captioning has attracted much attention in image and video understanding
while a small amount of work examines audio captioning. This paper contributes
a Mandarin-annotated dataset for audio captioning within a car scene. A
sentence-level loss is proposed to be used in tandem with a GRU encoder-decoder
model to generate captions with higher semantic similarity to human
annotations. We evaluate the model on the newly-proposed Car dataset, a
previously published Mandarin Hospital dataset and the Joint dataset,
indicating its generalization capability across different scenes. An
improvement in all metrics can be observed, including classical natural
language generation (NLG) metrics, sentence richness and human evaluation
ratings. However, though detailed audio captions can now be automatically
generated, human annotations still outperform model captions on many aspects.
","[{'version': 'v1', 'created': 'Fri, 31 May 2019 07:30:15 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 06:58:36 GMT'}]",2020-10-26,"[['Xu', 'Xuenan', ''], ['Dinkel', 'Heinrich', ''], ['Wu', 'Mengyue', ''], ['Yu', 'Kai', '']]"
1367987,2010.11657,Renyu Wang,"Renyu Wang, Ruilin Tong, Yu Ting Yeung, Xiao Chen","The HUAWEI Speaker Diarisation System for the VoxCeleb Speaker
  Diarisation Challenge","5 pages, 2 figures, A report about our diarisation system for
  VoxCeleb Challenge, Interspeech conference workshop",,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper describes system setup of our submission to speaker diarisation
track (Track 4) of VoxCeleb Speaker Recognition Challenge 2020. Our diarisation
system consists of a well-trained neural network based speech enhancement model
as pre-processing front-end of input speech signals. We replace conventional
energy-based voice activity detection (VAD) with a neural network based VAD.
The neural network based VAD provides more accurate annotation of speech
segments containing only background music, noise, and other interference, which
is crucial to diarisation performance. We apply agglomerative hierarchical
clustering (AHC) of x-vectors and variational Bayesian hidden Markov model
(VB-HMM) based iterative clustering for speaker clustering. Experimental
results demonstrate that our proposed system achieves substantial improvements
over the baseline system, yielding diarisation error rate (DER) of 10.45%, and
Jacard error rate (JER) of 22.46% on the evaluation set.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 12:42:07 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 07:45:47 GMT'}]",2020-10-26,"[['Wang', 'Renyu', ''], ['Tong', 'Ruilin', ''], ['Yeung', 'Yu Ting', ''], ['Chen', 'Xiao', '']]"
1367808,2010.11478,Minho Ryu,Minho Ryu and Kichun Lee,Knowledge Distillation for BERT Unsupervised Domain Adaptation,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A pre-trained language model, BERT, has brought significant performance
improvements across a range of natural language processing tasks. Since the
model is trained on a large corpus of diverse topics, it shows robust
performance for domain shift problems in which data distributions at training
(source data) and testing (target data) differ while sharing similarities.
Despite its great improvements compared to previous models, it still suffers
from performance degradation due to domain shifts. To mitigate such problems,
we propose a simple but effective unsupervised domain adaptation method,
adversarial adaptation with distillation (AAD), which combines the adversarial
discriminative domain adaptation (ADDA) framework with knowledge distillation.
We evaluate our approach in the task of cross-domain sentiment classification
on 30 domain pairs, advancing the state-of-the-art performance for unsupervised
domain adaptation in text sentiment classification.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 06:51:24 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 02:12:06 GMT'}]",2020-10-26,"[['Ryu', 'Minho', ''], ['Lee', 'Kichun', '']]"
1367725,2010.11395,Xie Chen,"Xie Chen, Yu Wu, Zhenghao Wang, Shujie Liu, Jinyu Li","Developing Real-time Streaming Transformer Transducer for Speech
  Recognition on Large-scale Dataset",5 pages,,,,cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, Transformer based end-to-end models have achieved great success in
many areas including speech recognition. However, compared to LSTM models, the
heavy computational cost of the Transformer during inference is a key issue to
prevent their applications. In this work, we explored the potential of
Transformer Transducer (T-T) models for the fist pass decoding with low latency
and fast speed on a large-scale dataset. We combine the idea of Transformer-XL
and chunk-wise streaming processing to design a streamable Transformer
Transducer model. We demonstrate that T-T outperforms the hybrid model, RNN
Transducer (RNN-T), and streamable Transformer attention-based encoder-decoder
model in the streaming scenario. Furthermore, the runtime cost and latency can
be optimized with a relatively small look-ahead.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 03:01:21 GMT'}]",2020-10-26,"[['Chen', 'Xie', ''], ['Wu', 'Yu', ''], ['Wang', 'Zhenghao', ''], ['Liu', 'Shujie', ''], ['Li', 'Jinyu', '']]"
1369125,2010.12795,Navita Goyal,"Navita Goyal, Roodram Paneri, Ayush Agarwal, Udit Kalani, Abhilasha
  Sancheti, Niyati Chhaya",CaM-Gen:Causally-aware Metric-guided Text Generation,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Content is created for a well-defined purpose, often described by a metric or
a signal represented in the form of structured information. The relationship
between the metrics or the goal of a target content and the content itself are
non-trivial. While large scale language models show promising text generation
capabilities, guiding and informing the generated text with external metrics is
challenging. These metrics and the content tend to have inherent relationships
and not all of them may directly impact the content. We introduce a CaM-Gen:
Causally-aware Generative Networks guided by user-defined input metrics
incorporating the causal relationships between the metric and the content
features. We leverage causal inference techniques to identify the causally
significant aspects of text that leads to the target metric and then explicitly
guide the generative model towards these by a feedback mechanism. We propose
this mechanism for variational autoencoder-based and transformer-based
generative models. The proposed models beat baselines in terms of the target
metric accuracy while maintaining the fluency and the language quality of the
generated text. To the best of our knowledge, this is one of the early attempts
at incorporating a metric-guide using causal inference towards controlled
generation.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 06:17:35 GMT'}]",2020-10-27,"[['Goyal', 'Navita', ''], ['Paneri', 'Roodram', ''], ['Agarwal', 'Ayush', ''], ['Kalani', 'Udit', ''], ['Sancheti', 'Abhilasha', ''], ['Chhaya', 'Niyati', '']]"
1369124,2010.12794,Zihan Wang,Zihan Wang and Dheeraj Mekala and Jingbo Shang,X-Class: Text Classification with Extremely Weak Supervision,,,,,cs.CL cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we explore to conduct text classification with extremely weak
supervision, i.e., only relying on the surface text of class names. This is a
more challenging setting than the seed-driven weak supervision, which allows a
few seed words per class. We opt to attack this problem from a representation
learning perspective -- ideal document representations should lead to very
close results between clustering and the desired classification. In particular,
one can classify the same corpus differently (e.g., based on topics and
locations), so document representations must be adaptive to the given class
names. We propose a novel framework X-Class to realize it. Specifically, we
first estimate comprehensive class representations by incrementally adding the
most similar word to each class until inconsistency appears. Following a
tailored mixture of class attention mechanisms, we obtain the document
representation via a weighted average of contextualized token representations.
We then cluster and align the documents to classes with the prior of each
document assigned to its nearest class. Finally, we pick the most confident
documents from each cluster to train a text classifier. Extensive experiments
demonstrate that X-Class can rival and even outperform seed-driven weakly
supervised methods on 7 benchmark datasets.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 06:09:51 GMT'}]",2020-10-27,"[['Wang', 'Zihan', ''], ['Mekala', 'Dheeraj', ''], ['Shang', 'Jingbo', '']]"
1369119,2010.12789,Limin Zhang,Limin Zhang,"Exploration of NLU: disassemble the information represented by Natural
  Language, based on the understanding of the internal structure of
  information, modeling the storage and processing system of information","13 pages, 8 figures, 11 tables",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Natural language is one of the ways information is encoded and it has highly
abstracted and conceptualized the information. This paper disassembles the
information represented by natural language, analyzes the classification coding
system of attribute information and the abstraction relation between attribute
information and entities in the real world, constructs the storage model of
information, and simulate the attribute information precessing process in one
of the attribute spaces, interprets how the relations which represented by
""Be"", ""Of"", ""Have"", and so on are embodied in the information storage data
structures and the corresponding data reading modes, reclassifies the sentences
types from the perspective of task types and data reading modes. Then,
simulated the understanding process (the information processing process) on a
dialogue example. Finally, the author summarizes the basic conditions of
understanding and gives out the definition of understanding from a personal
point of view. The study in this paper provides a practical, theoretical basis
and research methods for NLU. It also can be applied in large-scale, multi-type
information processing in the artificial intelligence (AI) area.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 05:40:47 GMT'}]",2020-10-27,"[['Zhang', 'Limin', '']]"
1369117,2010.12787,Kung-Hsiang Huang,"Kung-Hsiang Huang, Nanyun Peng","Efficient End-to-end Learning of Cross-event Dependencies for
  Document-level Event Extraction","10 pages, 3 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Document-level event extraction is important for indexing the most important
information in a document to facilitate downstream tasks such as information
retrieval or question answering. However, it is a challenging task because it
requires the understanding of event and entity coreference, and capturing
arguments that span across different sentences. Existing works on event
extraction generally confine on extracting events from single sentences, which
fail to capture the relationships between the event mentions at the scale of a
document, as well as the event arguments that appear in a different sentence
than the event trigger. In this paper, we propose an end-to-end model
leveraging Deep Value Networks (DVN), a structured prediction algorithm, to
efficiently capture cross-event dependencies for document-level event
extraction. Experimental results show that our approach achieves comparable
performance to CRF-based model on ACE05, while enjoys significantly higher
efficiency.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 05:28:16 GMT'}]",2020-10-27,"[['Huang', 'Kung-Hsiang', ''], ['Peng', 'Nanyun', '']]"
1369116,2010.12786,Huda Khayrallah,"Huda Khayrallah, Jo\~ao Sedoc","Measuring the `I don't know' Problem through the Lens of Gricean
  Quantity",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We consider the intrinsic evaluation of neural generative dialog models
through the lens of Grices Maxims of Conversation (1975). Based on the maxim of
Quantity (be informative), we propose Relative Utterance Quantity (RUQ) to
diagnose the `I don't know' problem. The RUQ diagnostic compares the model
score of a generic response to that of the reference response. We find that for
reasonable baseline models, `I don't know' is preferred over the reference more
than half the time, but this can be mitigated with hyperparameter tuning.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 05:16:36 GMT'}]",2020-10-27,"[['Khayrallah', 'Huda', ''], ['Sedoc', 'João', '']]"
1369138,2010.12808,Xiaodong Yu,"Xiaodong Yu, Wenpeng Yin, Dan Roth",Paired Representation Learning for Event and Entity Coreference,"9 pages, 2 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Co-reference of Events and of Entities are commonly formulated as binary
classification problems, given a pair of events or entities as input. Earlier
work addressed the main challenge in these problems -- the representation of
each element in the input pair by: (i) modelling the representation of one
element (event or entity) without considering the other element in the pair;
(ii) encoding all attributes of one element (e.g., arguments of an event) into
a single non-interpretable vector, thus losing the ability to compare
cross-element attributes. In this work we propose paired representation
learning (PairedRL) for coreference resolution. Given a pair of elements
(Events or Entities) our model treats the pair's sentences as a single sequence
so that each element in the pair learns its representation by encoding its own
context as well the other element's context. In addition, when representing
events, PairedRL is structured in that it represents the event's arguments to
facilitate their individual contribution to the final prediction. As we show,
in both (within-document & cross-document) event and entity coreference
benchmarks, our unified approach, PairedRL, outperforms prior state of the art
systems with a large margin.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 06:55:52 GMT'}]",2020-10-27,"[['Yu', 'Xiaodong', ''], ['Yin', 'Wenpeng', ''], ['Roth', 'Dan', '']]"
1369114,2010.12784,Vikram Gupta,"Vikram Gupta, Haoyue Shi, Kevin Gimpel, Mrinmaya Sachan","Clustering Contextualized Representations of Text for Unsupervised
  Syntax Induction",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We explore clustering of contextualized text representations for two
unsupervised syntax induction tasks: part of speech induction (POSI) and
constituency labelling (CoLab). We propose a deep embedded clustering approach
which jointly transforms these representations into a lower dimension cluster
friendly space and clusters them. We further enhance these representations by
augmenting them with task-specific representations. We also explore the
effectiveness of multilingual representations for different tasks and
languages. With this work, we establish the first strong baselines for
unsupervised syntax induction using contextualized text representations. We
report competitive performance on 45-tag POSI, state-of-the-art performance on
12-tag POSI across 10 languages, and competitive results on CoLab.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 05:06:29 GMT'}]",2020-10-27,"[['Gupta', 'Vikram', ''], ['Shi', 'Haoyue', ''], ['Gimpel', 'Kevin', ''], ['Sachan', 'Mrinmaya', '']]"
1369142,2010.12812,Zexuan Zhong,Zexuan Zhong and Danqi Chen,A Frustratingly Easy Approach for Joint Entity and Relation Extraction,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  End-to-end relation extraction aims to identify named entities and extract
relations between them simultaneously. Most recent work models these two
subtasks jointly, either by unifying them in one structured prediction
framework, or multi-task learning through shared representations. In this work,
we describe a very simple approach for joint entity and relation extraction,
and establish the new state-of-the-art on standard benchmarks (ACE04, ACE05,
and SciERC). Our approach essentially builds on two independent pre-trained
encoders and merely uses the entity model to provide input features for the
relation model. Through a series of careful examinations, we validate the
importance of learning distinct contextual representations for entities and
relations, fusing entity information at the input layer of the relation model,
and incorporating global context. Finally, we also present an efficient
approximation to our approach which requires only one pass of both encoders at
inference time, obtaining a 8-16$\times$ speedup with a small accuracy drop.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 07:14:01 GMT'}]",2020-10-27,"[['Zhong', 'Zexuan', ''], ['Chen', 'Danqi', '']]"
1369130,2010.12800,Xinliang (Frederick) Zhang,"Xinliang Frederick Zhang, Heming Sun, Xiang Yue, Emmett Jesrani, Simon
  Lin, Huan Sun",COUGH: A Challenge Dataset and Models for COVID-19 FAQ Retrieval,,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present a large challenging dataset, COUGH, for COVID-19 FAQ retrieval.
Specifically, similar to a standard FAQ dataset, COUGH consists of three parts:
FAQ Bank, User Query Bank and Annotated Relevance Set. FAQ Bank contains ~16K
FAQ items scraped from 55 credible websites (e.g., CDC and WHO). For
evaluation, we introduce User Query Bank and Annotated Relevance Set, where the
former contains 1201 human-paraphrased queries while the latter contains ~32
human-annotated FAQ items for each query. We analyze COUGH by testing different
FAQ retrieval models built on top of BM25 and BERT, among which the best model
achieves 0.29 under P@5, indicating that the dataset presents a great challenge
for future research. Our dataset is freely available at
https://github.com/sunlab-osu/covid-faq.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 06:30:59 GMT'}]",2020-10-27,"[['Zhang', 'Xinliang Frederick', ''], ['Sun', 'Heming', ''], ['Yue', 'Xiang', ''], ['Jesrani', 'Emmett', ''], ['Lin', 'Simon', ''], ['Sun', 'Huan', '']]"
1369100,2010.12770,Jianpeng Cheng J,"Jianpeng Cheng, Devang Agrawal, Hector Martinez Alonso, Shruti
  Bhargava, Joris Driesen, Federico Flego, Dain Kaplan, Dimitri Kartsaklis, Lin
  Li, Dhivya Piraviperumal, Jason D Williams, Hong Yu, Diarmuid O Seaghdha,
  Anders Johannsen",Conversational Semantic Parsing for Dialog State Tracking,Publish as a conference paper at EMNLP 2020,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  We consider a new perspective on dialog state tracking (DST), the task of
estimating a user's goal through the course of a dialog. By formulating DST as
a semantic parsing task over hierarchical representations, we can incorporate
semantic compositionality, cross-domain knowledge sharing and co-reference. We
present TreeDST, a dataset of 27k conversations annotated with tree-structured
dialog states and system acts. We describe an encoder-decoder framework for DST
with hierarchical representations, which leads to 20% improvement over
state-of-the-art DST approaches that operate on a flat meaning space of
slot-value pairs.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 04:10:32 GMT'}]",2020-10-27,"[['Cheng', 'Jianpeng', ''], ['Agrawal', 'Devang', ''], ['Alonso', 'Hector Martinez', ''], ['Bhargava', 'Shruti', ''], ['Driesen', 'Joris', ''], ['Flego', 'Federico', ''], ['Kaplan', 'Dain', ''], ['Kartsaklis', 'Dimitri', ''], ['Li', 'Lin', ''], ['Piraviperumal', 'Dhivya', ''], ['Williams', 'Jason D', ''], ['Yu', 'Hong', ''], ['Seaghdha', 'Diarmuid O', ''], ['Johannsen', 'Anders', '']]"
1369110,2010.12780,Yan Zeng,Yan Zeng and Jian-Yun Nie,Open-Domain Dialogue Generation Based on Pre-trained Language Models,"[v0], 10 pages, 4 figures",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pre-trained language models have been successfully used in response
generation for open-domain dialogue. Four main frameworks have been proposed:
(1) Transformer-ED using Transformer encoder and decoder separately for source
and target sentences; (2) Transformer-Dec using Transformer decoder for both
source and target sentences; (3) Transformer-MLM using Transformer decoder that
applies bi-directional attention on the source side and left-to-right attention
on the target side with masked language model objective; and (4) Transformer-AR
that uses auto-regressive objective instead. In this study, we compare these
frameworks on 3 datasets, and our comparison reveals that the best framework
uses bidirectional attention on the source side and does not separate encoder
and decoder. We also examine model discrepancy, and our experiments confirm
that the performance of a model is directly impacted by the underlying
discrepancies. We then propose two correction methods to reduce the
discrepancies, and both improve the model performance. These results show that
discrepancies is an important factor to consider when we use a pre-trained
model, and a reduction in discrepancies can lead to improved performance.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 04:52:28 GMT'}]",2020-10-27,"[['Zeng', 'Yan', ''], ['Nie', 'Jian-Yun', '']]"
1369109,2010.12779,Aida Mostafazadeh Davani,"Aida Mostafazadeh Davani, Ali Omrani, Brendan Kennedy, Mohammad Atari,
  Xiang Ren, Morteza Dehghani","Fair Hate Speech Detection through Evaluation of Social Group
  Counterfactuals",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Approaches for mitigating bias in supervised models are designed to reduce
models' dependence on specific sensitive features of the input data, e.g.,
mentioned social groups. However, in the case of hate speech detection, it is
not always desirable to equalize the effects of social groups because of their
essential role in distinguishing outgroup-derogatory hate, such that particular
types of hateful rhetoric carry the intended meaning only when contextualized
around certain social group tokens. Counterfactual token fairness for a
mentioned social group evaluates the model's predictions as to whether they are
the same for (a) the actual sentence and (b) a counterfactual instance, which
is generated by changing the mentioned social group in the sentence. Our
approach assures robust model predictions for counterfactuals that imply
similar meaning as the actual sentence. To quantify the similarity of a
sentence and its counterfactual, we compare their likelihood score calculated
by generative language models. By equalizing model behaviors on each sentence
and its counterfactuals, we mitigate bias in the proposed model while
preserving the overall classification performance.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 04:51:47 GMT'}]",2020-10-27,"[['Davani', 'Aida Mostafazadeh', ''], ['Omrani', 'Ali', ''], ['Kennedy', 'Brendan', ''], ['Atari', 'Mohammad', ''], ['Ren', 'Xiang', ''], ['Dehghani', 'Morteza', '']]"
1369107,2010.12777,Hyung Won Chung,"Hyung Won Chung, Dan Garrette, Kiat Chuan Tan, Jason Riesa",Improving Multilingual Models with Language-Clustered Vocabularies,Published in the main conference of EMNLP 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  State-of-the-art multilingual models depend on vocabularies that cover all of
the languages the model will expect to see at inference time, but the standard
methods for generating those vocabularies are not ideal for massively
multilingual applications. In this work, we introduce a novel procedure for
multilingual vocabulary generation that combines the separately trained
vocabularies of several automatically derived language clusters, thus balancing
the trade-off between cross-lingual subword sharing and language-specific
vocabularies. Our experiments show improvements across languages on key
multilingual benchmark tasks TyDi QA (+2.9 F1), XNLI (+2.1\%), and WikiAnn NER
(+2.8 F1) and factor of 8 reduction in out-of-vocabulary rate, all without
increasing the size of the model or data.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 04:49:15 GMT'}]",2020-10-27,"[['Chung', 'Hyung Won', ''], ['Garrette', 'Dan', ''], ['Tan', 'Kiat Chuan', ''], ['Riesa', 'Jason', '']]"
1369106,2010.12776,Yanda Chen,"Yanda Chen (1), Md Arafat Sultan (2), Vittorio Castelli (2) ((1)
  Department of Computer Science, Columbia University, (2) IBM Research AI,
  T.J. Watson Research Center, New York, USA)",Improved Synthetic Training for Reading Comprehension,"11 pages, 2 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automatically generated synthetic training examples have been shown to
improve performance in machine reading comprehension (MRC). Compared to human
annotated gold standard data, synthetic training data has unique properties,
such as high availability at the possible expense of quality. In view of such
differences, in this paper, we explore novel applications of synthetic examples
to MRC. Our proposed pre-training and knowledge distillation strategies show
significant improvements over existing methods. In a particularly surprising
discovery, we observe that synthetic distillation often yields students that
can outperform the teacher model.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 04:41:30 GMT'}]",2020-10-27,"[['Chen', 'Yanda', ''], ['Sultan', 'Md Arafat', ''], ['Castelli', 'Vittorio', '']]"
1253799,2003.03444,Yuval Pinter,Yuval Pinter and Cassandra L. Jacobs and Max Bittker,NYTWIT: A Dataset of Novel Words in the New York Times,COLING 2020,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We present the New York Times Word Innovation Types dataset, or NYTWIT, a
collection of over 2,500 novel English words published in the New York Times
between November 2017 and March 2019, manually annotated for their class of
novelty (such as lexical derivation, dialectal variation, blending, or
compounding). We present baseline results for both uncontextual and contextual
prediction of novelty class, showing that there is room for improvement even
for state-of-the-art NLP systems. We hope this resource will prove useful for
linguists and NLP practitioners by providing a real-world environment of novel
word appearance.
","[{'version': 'v1', 'created': 'Fri, 6 Mar 2020 21:19:44 GMT'}, {'version': 'v2', 'created': 'Tue, 26 May 2020 03:54:35 GMT'}, {'version': 'v3', 'created': 'Fri, 23 Oct 2020 18:54:48 GMT'}]",2020-10-27,"[['Pinter', 'Yuval', ''], ['Jacobs', 'Cassandra L.', ''], ['Bittker', 'Max', '']]"
1369103,2010.12773,Xiang Deng,"Xiang Deng, Ahmed Hassan Awadallah, Christopher Meek, Oleksandr
  Polozov, Huan Sun, Matthew Richardson",Structure-Grounded Pretraining for Text-to-SQL,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Learning to capture text-table alignment is essential for table related tasks
like text-to-SQL. The model needs to correctly recognize natural language
references to columns and values and to ground them in the given database
schema. In this paper, we present a novel weakly supervised Structure-Grounded
pretraining framework (StruG) for text-to-SQL that can effectively learn to
capture text-table alignment based on a parallel text-table corpus. We identify
a set of novel prediction tasks: column grounding, value grounding and
column-value mapping, and train them using weak supervision without requiring
complex SQL annotation. Additionally, to evaluate the model under a more
realistic setting, we create a new evaluation set Spider-Realistic based on
Spider with explicit mentions of column names removed, and adopt two existing
single-database text-to-SQL datasets. StruG significantly outperforms
BERT-LARGE on Spider and the realistic evaluation sets, while bringing
consistent improvement on the large-scale WikiSQL benchmark.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 04:35:35 GMT'}]",2020-10-27,"[['Deng', 'Xiang', ''], ['Awadallah', 'Ahmed Hassan', ''], ['Meek', 'Christopher', ''], ['Polozov', 'Oleksandr', ''], ['Sun', 'Huan', ''], ['Richardson', 'Matthew', '']]"
1369085,2010.12755,Xinyu Zhao,"Xinyu Zhao, Shih-ting Lin, Greg Durrett",Effective Distant Supervision for Temporal Relation Extraction,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A principal barrier to training temporal relation extraction models in new
domains is the lack of varied, high quality examples and the challenge of
collecting more. We present a method of automatically collecting
distantly-supervised examples of temporal relations. We scrape and
automatically label event pairs where the temporal relations are made explicit
in text, then mask out those explicit cues, forcing a model trained on this
data to learn other signals. We demonstrate that a pre-trained Transformer
model is able to transfer from the weakly labeled examples to human-annotated
benchmarks in both zero-shot and few-shot settings, and that the masking scheme
is important in improving generalization.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 03:17:31 GMT'}]",2020-10-27,"[['Zhao', 'Xinyu', ''], ['Lin', 'Shih-ting', ''], ['Durrett', 'Greg', '']]"
1369143,2010.12813,Kevin Lin,"Catherine Chen, Kevin Lin, Dan Klein",Inducing Taxonomic Knowledge from Pretrained Transformers,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present a method for inducing taxonomic trees from pretrained
transformers. Given a set of input terms, we assign a score for the likelihood
that each pair of terms forms a parent-child relation. To produce a tree from
pairwise parent-child edge scores, we treat this as a graph optimization
problem and output the maximum spanning tree. We train the model by finetuning
it on parent-child relations from subtrees of WordNet and test on
non-overlapping subtrees. In addition, we incorporate semi-structured
definitions from the web to further improve performance. On the task of
inducing subtrees of WordNet, the model achieves 66.0 ancestor F_1, a 10.4
point absolute increase over the previous best published result on this task.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 07:16:21 GMT'}]",2020-10-27,"[['Chen', 'Catherine', ''], ['Lin', 'Kevin', ''], ['Klein', 'Dan', '']]"
1369101,2010.12771,Yixin Liu,"Yixin Liu, Graham Neubig, John Wieting",On Learning Text Style Transfer with Direct Rewards,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In most cases, the lack of parallel corpora makes it impossible to directly
train supervised models for text style transfer task. In this paper, we explore
training algorithms that instead optimize reward functions that explicitly
consider different aspects of the style-transferred outputs. In particular, we
leverage semantic similarity metrics originally used for fine-tuning neural
machine translation models to explicitly assess the preservation of content
between system outputs and input texts. We also investigate the potential
weaknesses of the existing automatic metrics and propose efficient strategies
of using these metrics for training. The experimental results show that our
model provides significant gains in both automatic and human evaluation over
strong baselines, indicating the effectiveness of our proposed methods and
training strategies.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 04:30:02 GMT'}]",2020-10-27,"[['Liu', 'Yixin', ''], ['Neubig', 'Graham', ''], ['Wieting', 'John', '']]"
1369087,2010.12757,Kai Sun,"Kai Sun, Seungwhan Moon, Paul Crook, Stephen Roller, Becka Silvert,
  Bing Liu, Zhiguang Wang, Honglei Liu, Eunjoon Cho, Claire Cardie",Adding Chit-Chats to Enhance Task-Oriented Dialogues,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The existing dialogue corpora and models are typically designed under two
disjoint motives: while task-oriented systems focus on achieving functional
goals (e.g., booking hotels), open-domain chatbots aim at making socially
engaging conversations. In this work, we propose to integrate both types of
systems by Adding Chit-Chats to ENhance Task-ORiented dialogues (ACCENTOR),
with the goal of making virtual assistant conversations more engaging and
interactive. Specifically, we propose a flexible approach for generating
diverse chit-chat responses to augment task-oriented dialogues with minimal
annotation effort. We then present our new chit-chat annotations to 23.8K
dialogues from the popular task-oriented datasets (Schema-Guided Dialogue and
MultiWOZ 2.1) and demonstrate their advantage over the originals via human
evaluation. Lastly, we propose three new models for ACCENTOR explicitly trained
to predict user goals and to generate contextually relevant chit-chat
responses. Automatic and human evaluations show that, compared with the
state-of-the-art task-oriented baseline, our models can code-switch between
task and chit-chat to be more engaging, interesting, knowledgeable, and
humanlike, while maintaining competitive task performance.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 03:22:43 GMT'}]",2020-10-27,"[['Sun', 'Kai', ''], ['Moon', 'Seungwhan', ''], ['Crook', 'Paul', ''], ['Roller', 'Stephen', ''], ['Silvert', 'Becka', ''], ['Liu', 'Bing', ''], ['Wang', 'Zhiguang', ''], ['Liu', 'Honglei', ''], ['Cho', 'Eunjoon', ''], ['Cardie', 'Claire', '']]"
1369088,2010.12758,Zhiyu Chen,"Zhiyu Chen, Honglei Liu, Hu Xu, Seungwhan Moon, Hao Zhou, Bing Liu","NUANCED: Natural Utterance Annotation for Nuanced Conversation with
  Estimated Distributions",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Existing conversational systems are mostly agent-centric, which assumes the
user utterances would closely follow the system ontology (for NLU or dialogue
state tracking). However, in real-world scenarios, it is highly desirable that
the users can speak freely in their own way. It is extremely hard, if not
impossible, for the users to adapt to the unknown system ontology. In this
work, we attempt to build a user-centric dialogue system. As there is no clean
mapping for a user's free form utterance to an ontology, we first model the
user preferences as estimated distributions over the system ontology and map
the users' utterances to such distributions. Learning such a mapping poses new
challenges on reasoning over existing knowledge, ranging from factoid
knowledge, commonsense knowledge to the users' own situations. To this end, we
build a new dataset named NUANCED that focuses on such realistic settings for
conversational recommendation. Collected via dialogue simulation and
paraphrasing, NUANCED contains 5.1k dialogues, 26k turns of high-quality user
responses. We conduct experiments, showing both the usefulness and challenges
of our problem setting. We believe NUANCED can serve as a valuable resource to
push existing research from the agent-centric system to the user-centric
system. The code and data will be made publicly available.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 03:23:14 GMT'}]",2020-10-27,"[['Chen', 'Zhiyu', ''], ['Liu', 'Honglei', ''], ['Xu', 'Hu', ''], ['Moon', 'Seungwhan', ''], ['Zhou', 'Hao', ''], ['Liu', 'Bing', '']]"
1369092,2010.12762,Sarah Wiegreffe,"Sarah Wiegreffe, Ana Marasovic, Noah A. Smith",Measuring Association Between Labels and Free-Text Rationales,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Interpretable NLP has taking increasing interest in ensuring that
explanations are faithful to the model's decision-making process. This property
is crucial for machine learning researchers and practitioners using
explanations to better understand models. While prior work focuses primarily on
extractive rationales (a subset of the input elements), we investigate their
less-studied counterpart: free-text natural language rationales. We demonstrate
that existing models for faithful interpretability do not extend cleanly to
tasks where free-text rationales are needed. We turn to models that jointly
predict and rationalize, a common class of models for free-text rationalization
whose faithfulness is not yet established. We propose measurements of
label-rationale association, a necessary property of faithful rationales, for
these models. Using our measurements, we show that a state-of-the-art joint
model based on T5 has strengths and weaknesses for producing faithful
rationales.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 03:40:56 GMT'}]",2020-10-27,"[['Wiegreffe', 'Sarah', ''], ['Marasovic', 'Ana', ''], ['Smith', 'Noah A.', '']]"
1369094,2010.12764,Rodolfo Corona,"Rodolfo Corona, Daniel Fried, Coline Devin, Dan Klein, Trevor Darrell",Modularity Improves Out-of-Domain Instruction Following,,,,,cs.CL cs.AI cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a modular architecture for following natural language instructions
that describe sequences of diverse subgoals, such as navigating to landmarks or
picking up objects. Standard, non-modular, architectures used in instruction
following do not exploit subgoal compositionality and often struggle on
out-of-distribution tasks and environments. In our approach, subgoal modules
each carry out natural language instructions for a specific subgoal type. A
sequence of modules to execute is chosen by learning to segment the
instructions and predicting a subgoal type for each segment. When compared to
standard sequence-to-sequence approaches on ALFRED, a challenging instruction
following benchmark, we find that modularization improves generalization to
environments unseen in training and to novel tasks.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 03:48:45 GMT'}]",2020-10-27,"[['Corona', 'Rodolfo', ''], ['Fried', 'Daniel', ''], ['Devin', 'Coline', ''], ['Klein', 'Dan', ''], ['Darrell', 'Trevor', '']]"
1369150,2010.12820,Emily Sheng,"Emily Sheng, Kai-Wei Chang, Premkumar Natarajan, Nanyun Peng","""Nice Try, Kiddo"": Ad Hominems in Dialogue Systems",14 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Ad hominem attacks are those that attack some feature of a person's character
instead of the position the person is maintaining. As a form of toxic and
abusive language, ad hominems contain harmful language that could further
amplify the skew of power inequality for marginalized populations. Since
dialogue systems are designed to respond directly to user input, it is
important to study ad hominems in these system responses. In this work, we
propose categories of ad hominems that allow us to analyze human and dialogue
system responses to Twitter posts. We specifically compare responses to Twitter
posts about marginalized communities (#BlackLivesMatter, #MeToo) and other
topics (#Vegan, #WFH). Furthermore, we propose a constrained decoding technique
that uses salient $n$-gram similarity to apply soft constraints to top-$k$
sampling and can decrease the amount of ad hominems generated by dialogue
systems. Our results indicate that 1) responses composed by both humans and
DialoGPT contain more ad hominems for discussions around marginalized
communities versus other topics, 2) different amounts of ad hominems in the
training data can influence the likelihood of the model generating ad hominems,
and 3) we can thus carefully choose training data and use constrained decoding
techniques to decrease the amount of ad hominems generated by dialogue systems.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 07:37:49 GMT'}]",2020-10-27,"[['Sheng', 'Emily', ''], ['Chang', 'Kai-Wei', ''], ['Natarajan', 'Premkumar', ''], ['Peng', 'Nanyun', '']]"
1369211,2010.12881,Arturo Oncevay,Arturo Oncevay and Kervy Rivas Rojas,Revisiting Neural Language Modelling with Syllables,"5 pages (main paper), 4 pages of Appendix",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language modelling is regularly analysed at word, subword or character units,
but syllables are seldom used. Syllables provide shorter sequences than
characters, they can be extracted with rules, and their segmentation typically
requires less specialised effort than identifying morphemes. We reconsider
syllables for an open-vocabulary generation task in 20 languages. We use
rule-based syllabification methods for five languages and address the rest with
a hyphenation tool, which behaviour as syllable proxy is validated. With a
comparable perplexity, we show that syllables outperform characters, annotated
morphemes and unsupervised subwords. Finally, we also study the overlapping of
syllables concerning other subword pieces and discuss some limitations and
opportunities.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 11:44:41 GMT'}]",2020-10-27,"[['Oncevay', 'Arturo', ''], ['Rojas', 'Kervy Rivas', '']]"
1369155,2010.12825,Rochelle Choenni,"Rochelle Choenni, Ekaterina Shutova","Cross-neutralising: Probing for joint encoding of linguistic information
  in multilingual models",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Multilingual sentence encoders are widely used to transfer NLP models across
languages. The success of this transfer is, however, dependent on the model's
ability to encode the patterns of cross-lingual similarity and variation. Yet,
little is known as to how these models are able to do this. We propose a simple
method to study how relationships between languages are encoded in two
state-of-the-art multilingual models (i.e. M-BERT and XLM-R). The results
provide insight into their information sharing mechanisms and suggest that
linguistic properties are encoded jointly across typologically-similar
languages in these models.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 07:55:32 GMT'}]",2020-10-27,"[['Choenni', 'Rochelle', ''], ['Shutova', 'Ekaterina', '']]"
1369161,2010.12831,Liunian Harold Li,"Liunian Harold Li, Haoxuan You, Zhecan Wang, Alireza Zareian, Shih-Fu
  Chang, Kai-Wei Chang","Weakly-supervised VisualBERT: Pre-training without Parallel Images and
  Captions",,,,,cs.CL cs.CV cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pre-trained contextual vision-and-language (V&L) models have brought
impressive performance improvement on various benchmarks. However, the paired
text-image data required for pre-training are hard to collect and scale up. We
investigate if a strong V&L representation model can be learned without
text-image pairs. We propose Weakly-supervised VisualBERT with the key idea of
conducting ""mask-and-predict"" pre-training on language-only and image-only
corpora. Additionally, we introduce the object tags detected by an object
recognition model as anchor points to bridge two modalities. Evaluation on four
V&L benchmarks shows that Weakly-supervised VisualBERT achieves similar
performance with a model pre-trained with paired data. Besides, pre-training on
more image-only data further improves a model that already has access to
aligned data, suggesting the possibility of utilizing billions of raw images
available to enhance V&L models.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 08:17:54 GMT'}]",2020-10-27,"[['Li', 'Liunian Harold', ''], ['You', 'Haoxuan', ''], ['Wang', 'Zhecan', ''], ['Zareian', 'Alireza', ''], ['Chang', 'Shih-Fu', ''], ['Chang', 'Kai-Wei', '']]"
1369164,2010.12834,Saadia Gabriel,"Saadia Gabriel, Asli Celikyilmaz, Rahul Jha, Yejin Choi, Jianfeng Gao",Go Figure! A Meta Evaluation of Factuality in Summarization,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Text generation models can generate factually inconsistent text containing
distorted or fabricated facts about the source text. Recent work has focused on
building evaluation models to verify the factual correctness of semantically
constrained text generation tasks such as document summarization. While the
field of factuality evaluation is growing fast, we don't have well-defined
criteria for measuring the effectiveness, generalizability, reliability, or
sensitivity of the factuality metrics. Focusing on these aspects, in this
paper, we introduce a meta-evaluation framework for evaluating factual
consistency metrics. We introduce five necessary, common-sense conditions for
effective factuality metrics and experiment with nine recent factuality metrics
using synthetic and human-labeled factuality data from short news, long news
and dialogue summarization domains. Our framework enables assessing the
efficiency of any new factual consistency metric on a variety of dimensions
over multiple summarization domains and can be easily extended with new
meta-evaluation criteria. We also present our conclusions towards standardizing
the factuality evaluation metrics.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 08:30:20 GMT'}]",2020-10-27,"[['Gabriel', 'Saadia', ''], ['Celikyilmaz', 'Asli', ''], ['Jha', 'Rahul', ''], ['Choi', 'Yejin', ''], ['Gao', 'Jianfeng', '']]"
1369166,2010.12836,Alexander Fabbri,"Alexander R. Fabbri, Simeng Han, Haoyuan Li, Haoran Li, Marjan
  Ghazvininejad, Shafiq Joty, Dragomir Radev, Yashar Mehdad","Improving Zero and Few-Shot Abstractive Summarization with Intermediate
  Fine-tuning and Data Augmentation",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Models pretrained with self-supervised objectives on large text corpora
achieve state-of-the-art performance on text summarization tasks. However,
these models are typically fine-tuned on hundreds of thousands of data points,
an infeasible requirement when applying summarization to new, niche domains. In
this work, we introduce a general method, called WikiTransfer, for fine-tuning
pretrained models for summarization in an unsupervised, dataset-specific manner
which makes use of characteristics of the target dataset such as the length and
abstractiveness of the desired summaries. We achieve state-of-the-art,
zero-shot abstractive summarization performance on the CNN-DailyMail dataset
and demonstrate the effectiveness of our approach on three additional, diverse
datasets. The models fine-tuned in this unsupervised manner are more robust to
noisy data and also achieve better few-shot performance using 10 and 100
training examples. We perform ablation studies on the effect of the components
of our unsupervised fine-tuning data and analyze the performance of these
models in few-shot scenarios along with data augmentation techniques using both
automatic and human evaluation.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 08:36:49 GMT'}]",2020-10-27,"[['Fabbri', 'Alexander R.', ''], ['Han', 'Simeng', ''], ['Li', 'Haoyuan', ''], ['Li', 'Haoran', ''], ['Ghazvininejad', 'Marjan', ''], ['Joty', 'Shafiq', ''], ['Radev', 'Dragomir', ''], ['Mehdad', 'Yashar', '']]"
1369083,2010.12753,Ben Zhou,"Ben Zhou and Kyle Richardson and Qiang Ning and Tushar Khot and Ashish
  Sabharwal and Dan Roth",Temporal Reasoning on Implicit Events from Distant Supervision,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Existing works on temporal reasoning among events described in text focus on
modeling relationships between explicitly mentioned events and do not handle
event end time effectively. However, human readers can infer from natural
language text many implicit events that help them better understand the
situation and, consequently, better reason about time. This work proposes a new
crowd-sourced dataset, TRACIE, which evaluates systems' understanding of
implicit events - events that are not mentioned explicitly in the text but can
be inferred from it. This is done via textual entailment instances querying
both start and end times of events. We show that TRACIE is challenging for
state-of-the-art language models. Our proposed model, SymTime, exploits distant
supervision signals from the text itself and reasons over events' start time
and duration to infer events' end time points. We show that our approach
improves over baseline language models, gaining 5% on the i.i.d. split and 9%
on an out-of-distribution test split. Our approach is also general to other
annotation schemes, gaining 2%-8% on MATRES, an extrinsic temporal relation
benchmark.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 03:12:27 GMT'}]",2020-10-27,"[['Zhou', 'Ben', ''], ['Richardson', 'Kyle', ''], ['Ning', 'Qiang', ''], ['Khot', 'Tushar', ''], ['Sabharwal', 'Ashish', ''], ['Roth', 'Dan', '']]"
1369174,2010.12844,Sahisnu Mazumder,"Sahisnu Mazumder, Oriana Riva",FLIN: A Flexible Natural Language Interface for Web Navigation,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  AI assistants have started carrying out tasks on a user's behalf by
interacting directly with the web. However, training an interface that maps
natural language (NL) commands to web actions is challenging for existing
semantic parsing approaches due to the variable and unknown set of actions that
characterize websites. We propose FLIN, a natural language interface for web
navigation that maps NL commands to concept-level actions rather than low-level
UI interactions, thus being able to flexibly adapt to different websites and
handle their transient nature. We frame this as a ranking problem where, given
a user command and a webpage, FLIN learns to score the most appropriate
navigation instruction (involving action and parameter values). To train and
evaluate FLIN, we collect a dataset using nine popular websites from three
different domains. Quantitative results show that FLIN is capable of adapting
to new websites in a given domain.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 09:11:26 GMT'}]",2020-10-27,"[['Mazumder', 'Sahisnu', ''], ['Riva', 'Oriana', '']]"
1369180,2010.12850,Semih Yavuz,"Shiyang Li, Semih Yavuz, Kazuma Hashimoto, Jia Li, Tong Niu, Nazneen
  Rajani, Xifeng Yan, Yingbo Zhou and Caiming Xiong","CoCo: Controllable Counterfactuals for Evaluating Dialogue State
  Trackers",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Dialogue state trackers have made significant progress on benchmark datasets,
but their generalization capability to novel and realistic scenarios beyond the
held-out conversations is less understood. We propose controllable
counterfactuals (CoCo) to bridge this gap and evaluate dialogue state tracking
(DST) models on novel scenarios, i.e., would the system successfully tackle the
request if the user responded differently but still consistently with the
dialogue flow? CoCo leverages turn-level belief states as counterfactual
conditionals to produce novel conversation scenarios in two steps: (i)
counterfactual goal generation at turn-level by dropping and adding slots
followed by replacing slot values, (ii) counterfactual conversation generation
that is conditioned on (i) and consistent with the dialogue flow. Evaluating
state-of-the-art DST models on MultiWOZ dataset with CoCo-generated
counterfactuals results in a significant performance drop of up to 30.8% (from
49.4% to 18.6%) in absolute joint goal accuracy. In comparison, widely used
techniques like paraphrasing only affect the accuracy by at most 2%. Human
evaluations show that CoCo-generated conversations perfectly reflect the
underlying user goal with more than 95% accuracy and are as human-like as the
original conversations, further strengthening its reliability and promise to be
adopted as part of the robustness evaluation of DST models.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 09:39:35 GMT'}]",2020-10-27,"[['Li', 'Shiyang', ''], ['Yavuz', 'Semih', ''], ['Hashimoto', 'Kazuma', ''], ['Li', 'Jia', ''], ['Niu', 'Tong', ''], ['Rajani', 'Nazneen', ''], ['Yan', 'Xifeng', ''], ['Zhou', 'Yingbo', ''], ['Xiong', 'Caiming', '']]"
1369184,2010.12854,Tushar Khot,Shih-Ting Lin and Ashish Sabharwal and Tushar Khot,ReadOnce Transformers: Reusable Representations of Text for Transformers,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While large-scale language models are extremely effective when directly
fine-tuned on many end-tasks, such models learn to extract information and
solve the task simultaneously from end-task supervision. This is wasteful, as
the general problem of gathering information from a document is mostly
task-independent and need not be re-learned from scratch each time. Moreover,
once the information has been captured in a computable representation, it can
now be re-used across examples, leading to faster training and evaluation of
models. We present a transformer-based approach, ReadOnce Transformers, that is
trained to build such information-capturing representations of text. Our model
compresses the document into a variable-length task-independent representation
that can now be re-used in different examples and tasks, thereby requiring a
document to only be read once. Additionally, we extend standard text-to-text
models to consume our ReadOnce Representations along with text to solve
multiple downstream tasks. We show our task-independent representations can be
used for multi-hop QA, abstractive QA, and summarization. We observe 2x-5x
speedups compared to standard text-to-text models, while also being able to
handle long documents that would normally exceed the length limit of current
models.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 09:53:16 GMT'}]",2020-10-27,"[['Lin', 'Shih-Ting', ''], ['Sabharwal', 'Ashish', ''], ['Khot', 'Tushar', '']]"
1369188,2010.12858,Benjamin Muller,"Benjamin Muller and Antonis Anastasopoulos and Beno\^it Sagot and
  Djam\'e Seddah","When Being Unseen from mBERT is just the Beginning: Handling New
  Languages With Multilingual Language Models",,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Transfer learning based on pretraining language models on a large amount of
raw data has become a new norm to reach state-of-the-art performance in NLP.
Still, it remains unclear how this approach should be applied for unseen
languages that are not covered by any available large-scale multilingual
language model and for which only a small amount of raw data is generally
available. In this work, by comparing multilingual and monolingual models, we
show that such models behave in multiple ways on unseen languages. Some
languages greatly benefit from transfer learning and behave similarly to
closely related high resource languages whereas others apparently do not.
Focusing on the latter, we show that this failure to transfer is largely
related to the impact of the script used to write such languages.
Transliterating those languages improves very significantly the ability of
large-scale multilingual language models on downstream tasks.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 10:15:03 GMT'}]",2020-10-27,"[['Muller', 'Benjamin', ''], ['Anastasopoulos', 'Antonis', ''], ['Sagot', 'Benoît', ''], ['Seddah', 'Djamé', '']]"
1369159,2010.12829,Juan Pino,"Chau Tran, Changhan Wang, Yuqing Tang, Yun Tang, Juan Pino, Xian Li","Cross-Modal Transfer Learning for Multilingual Speech-to-Text
  Translation",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose an effective approach to utilize pretrained speech and text models
to perform speech-to-text translation (ST). Our recipe to achieve cross-modal
and cross-lingual transfer learning (XMTL) is simple and generalizable: using
an adaptor module to bridge the modules pretrained in different modalities, and
an efficient finetuning step which leverages the knowledge from pretrained
modules yet making it work on a drastically different downstream task. With
this approach, we built a multilingual speech-to-text translation model with
pretrained audio encoder (wav2vec) and multilingual text decoder (mBART), which
achieves new state-of-the-art on CoVoST 2 ST benchmark [1] for English into 15
languages as well as 6 Romance languages into English with on average +2.8 BLEU
and +3.9 BLEU, respectively. On low-resource languages (with less than 10 hours
training data), our approach significantly improves the quality of
speech-to-text translation with +9.0 BLEU on Portuguese-English and +5.2 BLEU
on Dutch-English.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 08:15:08 GMT'}]",2020-10-27,"[['Tran', 'Chau', ''], ['Wang', 'Changhan', ''], ['Tang', 'Yuqing', ''], ['Tang', 'Yun', ''], ['Pino', 'Juan', ''], ['Li', 'Xian', '']]"
1369158,2010.12828,Haoyu Zhang,"Haoyu Zhang, Dingkun Long, Guangwei Xu, Pengjun Xie, Fei Huang, Ji
  Wang","Keyphrase Extraction with Dynamic Graph Convolutional Networks and
  Diversified Inference",11 pages,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Keyphrase extraction (KE) aims to summarize a set of phrases that accurately
express a concept or a topic covered in a given document. Recently,
Sequence-to-Sequence (Seq2Seq) based generative framework is widely used in KE
task, and it has obtained competitive performance on various benchmarks. The
main challenges of Seq2Seq methods lie in acquiring informative latent document
representation and better modeling the compositionality of the target
keyphrases set, which will directly affect the quality of generated keyphrases.
In this paper, we propose to adopt the Dynamic Graph Convolutional Networks
(DGCN) to solve the above two problems simultaneously. Concretely, we explore
to integrate dependency trees with GCN for latent representation learning.
Moreover, the graph structure in our model is dynamically modified during the
learning process according to the generated keyphrases. To this end, our
approach is able to explicitly learn the relations within the keyphrases
collection and guarantee the information interchange between encoder and
decoder in both directions. Extensive experiments on various KE benchmark
datasets demonstrate the effectiveness of our approach.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 08:11:23 GMT'}]",2020-10-27,"[['Zhang', 'Haoyu', ''], ['Long', 'Dingkun', ''], ['Xu', 'Guangwei', ''], ['Xie', 'Pengjun', ''], ['Huang', 'Fei', ''], ['Wang', 'Ji', '']]"
1369151,2010.12821,Hyung Won Chung,"Hyung Won Chung, Thibault F\'evry, Henry Tsai, Melvin Johnson,
  Sebastian Ruder",Rethinking embedding coupling in pre-trained language models,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We re-evaluate the standard practice of sharing weights between input and
output embeddings in state-of-the-art pre-trained language models. We show that
decoupled embeddings provide increased modeling flexibility, allowing us to
significantly improve the efficiency of parameter allocation in the input
embedding of multilingual models. By reallocating the input embedding
parameters in the Transformer layers, we achieve dramatically better
performance on standard natural language understanding tasks with the same
number of parameters during fine-tuning. We also show that allocating
additional capacity to the output embedding provides benefits to the model that
persist through the fine-tuning stage even though the output embedding is
discarded after pre-training. Our analysis shows that larger output embeddings
prevent the model's last layers from overspecializing to the pre-training task
and encourage Transformer representations to be more general and more
transferable to other tasks and languages. Harnessing these findings, we are
able to train models that achieve strong performance on the XTREME benchmark
without increasing the number of parameters at the fine-tuning stage.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 07:43:00 GMT'}]",2020-10-27,"[['Chung', 'Hyung Won', ''], ['Févry', 'Thibault', ''], ['Tsai', 'Henry', ''], ['Johnson', 'Melvin', ''], ['Ruder', 'Sebastian', '']]"
1369198,2010.12868,Yongchang Hao,"Yongchang Hao, Shilin He, Wenxiang Jiao, Zhaopeng Tu, Michael Lyu and
  Xing Wang","Multi-Task Learning with Shared Encoder for Non-Autoregressive Machine
  Translation",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Non-Autoregressive machine Translation (NAT) models have demonstrated
significant inference speedup but suffer from inferior translation accuracy.
The common practice to tackle the problem is transferring the Autoregressive
machine Translation (AT) knowledge to NAT models, e.g., with knowledge
distillation. In this work, we hypothesize and empirically verify that AT and
NAT encoders capture different linguistic properties and representations of
source sentences. Therefore, we propose to adopt the multi-task learning to
transfer the AT knowledge to NAT models through the encoder sharing.
Specifically, we take the AT model as an auxiliary task to enhance NAT model
performance. Experimental results on WMT14 English->German and WMT16
English->Romanian datasets show that the proposed multi-task NAT achieves
significant improvements over the baseline NAT models. In addition,
experimental results demonstrate that our multi-task NAT is complementary to
the standard knowledge transfer method, knowledge distillation. Code is
publicly available at https://github.com/yongchanghao/multi-task-nat
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 11:00:58 GMT'}]",2020-10-27,"[['Hao', 'Yongchang', ''], ['He', 'Shilin', ''], ['Jiao', 'Wenxiang', ''], ['Tu', 'Zhaopeng', ''], ['Lyu', 'Michael', ''], ['Wang', 'Xing', '']]"
1369202,2010.12872,Aaron Chan,"Mrigank Raman, Siddhant Agarwal, Peifeng Wang, Aaron Chan, Hansen
  Wang, Sungchul Kim, Ryan Rossi, Handong Zhao, Nedim Lipka, Xiang Ren","Learning to Deceive Knowledge Graph Augmented Models via Targeted
  Perturbation","13 pages, 9 figures",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Symbolic knowledge (e.g., entities, relations, and facts in a knowledge
graph) has become an increasingly popular component of neural-symbolic models
applied to machine learning tasks, such as question answering and recommender
systems. Besides improving downstream performance, these symbolic structures
(and their associated attention weights) are often used to help explain the
model's predictions and provide ""insights"" to practitioners. In this paper, we
question the faithfulness of such symbolic explanations. We demonstrate that,
through a learned strategy (or even simple heuristics), one can produce
deceptively perturbed symbolic structures which maintain the downstream
performance of the original structure while significantly deviating from the
original semantics. In particular, we train a reinforcement learning policy to
manipulate relation types or edge connections in a knowledge graph, such that
the resulting downstream performance is maximally preserved. Across multiple
models and tasks, our approach drastically alters knowledge graphs with little
to no drop in performance. These results raise doubts about the faithfulness of
explanations provided by learned symbolic structures and the reliability of
current neural-symbolic models in leveraging symbolic knowledge.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 11:04:45 GMT'}]",2020-10-27,"[['Raman', 'Mrigank', ''], ['Agarwal', 'Siddhant', ''], ['Wang', 'Peifeng', ''], ['Chan', 'Aaron', ''], ['Wang', 'Hansen', ''], ['Kim', 'Sungchul', ''], ['Rossi', 'Ryan', ''], ['Zhao', 'Handong', ''], ['Lipka', 'Nedim', ''], ['Ren', 'Xiang', '']]"
1369203,2010.12873,Jun Yan,"Jun Yan, Mrigank Raman, Tianyu Zhang, Ryan Rossi, Handong Zhao,
  Sungchul Kim, Nedim Lipka, Xiang Ren",Learning Contextualized Knowledge Structures for Commonsense Reasoning,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, neural-symbolic architectures have achieved success on commonsense
reasoning through effectively encoding relational structures retrieved from
external knowledge graphs (KGs) and obtained state-of-the-art results in tasks
such as (commonsense) question answering and natural language inference.
However, these methods rely on quality and contextualized knowledge structures
(i.e., fact triples) that are retrieved at the pre-processing stage but
overlook challenges caused by incompleteness of a KG, limited expressiveness of
its relations, and retrieved facts irrelevant to the reasoning context. In this
paper, we present a novel neural-symbolic model, named Hybrid Graph Network
(HGN), which jointly generates feature representations for new triples (as a
complement to existing edges in the KG), determines the relevance of the
triples to the reasoning context, and learns graph module parameters for
encoding the relational information. Our model learns a compact graph structure
(comprising both extracted and generated edges) through filtering edges that
are unhelpful to the reasoning process. We show marked improvement on three
commonsense reasoning benchmarks and demonstrate the superiority of the learned
graph structures with user studies.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 11:09:16 GMT'}]",2020-10-27,"[['Yan', 'Jun', ''], ['Raman', 'Mrigank', ''], ['Zhang', 'Tianyu', ''], ['Rossi', 'Ryan', ''], ['Zhao', 'Handong', ''], ['Kim', 'Sungchul', ''], ['Lipka', 'Nedim', ''], ['Ren', 'Xiang', '']]"
1369212,2010.12882,Mingyang Chen,"Mingyang Chen, Wen Zhang, Zonggang Yuan, Yantao Jia, Huajun Chen",FedE: Embedding Knowledge Graphs in Federated Setting,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Knowledge graphs (KGs) consisting of triples are always incomplete, so it's
important to do Knowledge Graph Completion (KGC) by predicting missing triples.
Multi-Source KG is a common situation in real KG applications which can be
viewed as a set of related individual KGs where different KGs contains
relations of different aspects of entities. It's intuitive that, for each
individual KG, its completion could be greatly contributed by the triples
defined and labeled in other ones. However, because of the data privacy and
sensitivity, a set of relevant knowledge graphs cannot complement each other's
KGC by just collecting data from different knowledge graphs together.
Therefore, in this paper, we introduce federated setting to keep their privacy
without triple transferring between KGs and apply it in embedding knowledge
graph, a typical method which have proven effective for KGC in the past decade.
We propose a Federated Knowledge Graph Embedding framework FedE, focusing on
learning knowledge graph embeddings by aggregating locally-computed updates.
Finally, we conduct extensive experiments on datasets derived from KGE
benchmark datasets and results show the effectiveness of our proposed FedE.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 11:52:05 GMT'}]",2020-10-27,"[['Chen', 'Mingyang', ''], ['Zhang', 'Wen', ''], ['Yuan', 'Zonggang', ''], ['Jia', 'Yantao', ''], ['Chen', 'Huajun', '']]"
1369214,2010.12884,Ximing Lu,"Ximing Lu, Peter West, Rowan Zellers, Ronan Le Bras, Chandra
  Bhagavatula, Yejin Choi","NeuroLogic Decoding: (Un)supervised Neural Text Generation with
  Predicate Logic Constraints",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Conditional text generation often requires lexical constraints, i.e., which
words should or shouldn't be included in the output text. While the dominant
recipe for conditional text generation has been large-scale pretrained language
models that are finetuned on the task-specific training data, such models do
not learn to follow the underlying constraints reliably, even when supervised
with large amounts of task-specific examples.
  We propose NeuroLogic Decoding, a simple yet effective algorithm that enables
neural language models -- supervised or not -- to generate fluent text while
satisfying complex lexical constraints. Our approach is powerful yet efficient.
It handles any set of lexical constraints that is expressible under predicate
logic, while its asymptotic runtime is equivalent to conventional beam search.
  Empirical results on four benchmarks show that NeuroLogic Decoding
outperforms previous approaches, including algorithms that handle a subset of
our constraints. Moreover, we find that unsupervised models with NeuroLogic
Decoding often outperform supervised models with conventional decoding, even
when the latter is based on considerably larger networks. Our results suggest
the limit of large-scale neural networks for fine-grained controllable
generation and the promise of inference-time algorithms.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 11:55:22 GMT'}]",2020-10-27,"[['Lu', 'Ximing', ''], ['West', 'Peter', ''], ['Zellers', 'Rowan', ''], ['Bras', 'Ronan Le', ''], ['Bhagavatula', 'Chandra', ''], ['Choi', 'Yejin', '']]"
1369157,2010.12827,Amane Sugiyama,Amane Sugiyama and Naoki Yoshinaga,"Context-aware Decoder for Neural Machine Translation using a Target-side
  Document-Level Language Model",Under Review,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Although many context-aware neural machine translation models have been
proposed to incorporate contexts in translation, most of those models are
trained end-to-end on parallel documents aligned in sentence-level. Because
only a few domains (and language pairs) have such document-level parallel data,
we cannot perform accurate context-aware translation in most domains. We
therefore present a simple method to turn a sentence-level translation model
into a context-aware model by incorporating a document-level language model
into the decoder. Our context-aware decoder is built upon only a sentence-level
parallel corpora and monolingual corpora; thus no document-level parallel data
is needed. In a theoretical viewpoint, the core part of this work is the novel
representation of contextual information using point-wise mutual information
between context and the current sentence. We show the effectiveness of our
approach in three language pairs, English to French, English to Russian, and
Japanese to English, by evaluation in \textsc{bleu} and contrastive tests for
context-aware translation.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 08:06:18 GMT'}]",2020-10-27,"[['Sugiyama', 'Amane', ''], ['Yoshinaga', 'Naoki', '']]"
1369215,2010.12885,Tong Niu,"Tong Niu, Semih Yavuz, Yingbo Zhou, Huan Wang, Nitish Shirish Keskar,
  Caiming Xiong",Unsupervised Paraphrase Generation via Dynamic Blocking,10 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose Dynamic Blocking, a decoding algorithm which enables large-scale
pretrained autoregressive models (such as BART, T5, GPT-2 and XLNet) to
generate high-quality paraphrases in an unsupervised setting. In order to
obtain an alternative surface form, whenever the language model emits a token
that is present in the source sequence, we prevent the model from generating
the subsequent source token for the next time step. We show that our approach
achieves state-of-the-art results on benchmark datasets when compared to
previous unsupervised approaches, and is even comparable with strong
supervised, in-domain models. We also propose a new automatic metric based on
self-BLEU and BERTscore which not only discourages the model from copying the
input through, but also evaluates text similarity based on distributed
representations, hence avoiding reliance on exact keyword matching. In
addition, we demonstrate that our model generalizes across languages without
any additional training.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 11:55:28 GMT'}]",2020-10-27,"[['Niu', 'Tong', ''], ['Yavuz', 'Semih', ''], ['Zhou', 'Yingbo', ''], ['Wang', 'Huan', ''], ['Keskar', 'Nitish Shirish', ''], ['Xiong', 'Caiming', '']]"
1369242,2010.12912,Camilo Thorne,Camilo Thorne and Saber Akhondi,Word Embeddings for Chemical Patent Natural Language Processing,"Extended version of an extended abstract presented (and reviewed) at
  the Latinx Workshop at ICML 2020",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  We evaluate chemical patent word embeddings against known biomedical
embeddings and show that they outperform the latter extrinsically and
intrinsically. We also show that using contextualized embeddings can induce
predictive models of reasonable performance for this domain over a relatively
small gold standard.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 15:03:20 GMT'}]",2020-10-27,"[['Thorne', 'Camilo', ''], ['Akhondi', 'Saber', '']]"
1369249,2010.12919,Reid Pryzant,"Reid Pryzant, Dallas Card, Dan Jurafsky, Victor Veitch, Dhanya Sridhar",Causal Effects of Linguistic Properties,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We consider the problem of estimating the causal effects of linguistic
properties on downstream outcomes. For example, does writing a complaint
politely lead to a faster response time? How much will a positive product
review increase sales? This paper focuses on two challenges related to the
problem. First, we formalize the causal quantity of interest as the effect of a
writer's intent, and establish the assumptions necessary to identify this from
observational data. Second, in practice we only have access to noisy proxies
for these linguistic properties---e.g., predictions from classifiers and
lexicons. We propose an estimator for this setting and prove that its bias is
bounded when we perform an adjustment for the text. The method leverages (1) a
pre-trained language model (BERT) to adjust for the text, and (2) distant
supervision to improve the quality of noisy proxies. We show that our algorithm
produces better causal estimates than related methods on two datasets:
predicting the effect of music review sentiment on sales, and complaint
politeness on response time.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 15:43:37 GMT'}]",2020-10-27,"[['Pryzant', 'Reid', ''], ['Card', 'Dallas', ''], ['Jurafsky', 'Dan', ''], ['Veitch', 'Victor', ''], ['Sridhar', 'Dhanya', '']]"
1369255,2010.12925,Camilo Thorne,Dhruba Pujary and Camilo Thorne and Wilker Aziz,Disease Normalization with Graph Embeddings,"This is a pre-print of a paper to appear in the proceedings of the
  IntelliSys 2020 conference",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  The detection and normalization of diseases in biomedical texts are key
biomedical natural language processing tasks. Disease names need not only be
identified, but also normalized or linked to clinical taxonomies describing
diseases such as MeSH. In this paper we describe deep learning methods that
tackle both tasks. We train and test our methods on the known NCBI disease
benchmark corpus. We propose to represent disease names by leveraging MeSH's
graphical structure together with the lexical information available in the
taxonomy using graph embeddings. We also show that combining neural named
entity recognition models with our graph-based entity linking methods via
multitask learning leads to improved disease recognition in the NCBI corpus.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 16:25:05 GMT'}]",2020-10-27,"[['Pujary', 'Dhruba', ''], ['Thorne', 'Camilo', ''], ['Aziz', 'Wilker', '']]"
1369156,2010.12826,Felix Faltings,"Felix Faltings and Michel Galley and Gerold Hintz and Chris Brockett
  and Chris Quirk and Jianfeng Gao and Bill Dolan",Text Editing by Command,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A prevailing paradigm in neural text generation is one-shot generation, where
text is produced in a single step. The one-shot setting is inadequate, however,
when the constraints the user wishes to impose on the generated text are
dynamic, especially when authoring longer documents. We address this limitation
with an interactive text generation setting in which the user interacts with
the system by issuing commands to edit existing text. To this end, we propose a
novel text editing task, and introduce WikiDocEdits, a dataset of
single-sentence edits crawled from Wikipedia. We show that our Interactive
Editor, a transformer-based model trained on this dataset, outperforms
baselines and obtains positive results in both automatic and human evaluations.
We present empirical and qualitative analyses of this model's performance.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 08:00:30 GMT'}]",2020-10-27,"[['Faltings', 'Felix', ''], ['Galley', 'Michel', ''], ['Hintz', 'Gerold', ''], ['Brockett', 'Chris', ''], ['Quirk', 'Chris', ''], ['Gao', 'Jianfeng', ''], ['Dolan', 'Bill', '']]"
1369201,2010.12871,Zein Shaheen,"Zein Shaheen, Gerhard Wohlgenannt, Erwin Filtz",Large Scale Legal Text Classification Using Transformer Models,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large multi-label text classification is a challenging Natural Language
Processing (NLP) problem that is concerned with text classification for
datasets with thousands of labels. We tackle this problem in the legal domain,
where datasets, such as JRC-Acquis and EURLEX57K labeled with the EuroVoc
vocabulary were created within the legal information systems of the European
Union. The EuroVoc taxonomy includes around 7000 concepts. In this work, we
study the performance of various recent transformer-based models in combination
with strategies such as generative pretraining, gradual unfreezing and
discriminative learning rates in order to reach competitive classification
performance, and present new state-of-the-art results of 0.661 (F1) for
JRC-Acquis and 0.754 for EURLEX57K. Furthermore, we quantify the impact of
individual steps, such as language model fine-tuning or gradual unfreezing in
an ablation study, and provide reference dataset splits created with an
iterative stratification algorithm.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 11:03:01 GMT'}]",2020-10-27,"[['Shaheen', 'Zein', ''], ['Wohlgenannt', 'Gerhard', ''], ['Filtz', 'Erwin', '']]"
1369072,2010.12742,Zhiqiang Hu,"Zhiqiang Hu, Roy Ka-Wei Lee, Charu C. Aggarwal",Text Style Transfer: A Review and Experiment Evaluation,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The stylistic properties of text have intrigued computational linguistics
researchers in recent years. Specifically, researchers have investigated the
Text Style Transfer (TST) task, which aims to change the stylistic properties
of the text while retaining its style independent content. Over the last few
years, many novel TST algorithms have been developed, while the industry has
leveraged these algorithms to enable exciting TST applications. The field of
TST research has burgeoned because of this symbiosis. This article aims to
provide a comprehensive review of recent research efforts on text style
transfer. More concretely, we create a taxonomy to organize the TST models and
provide a comprehensive summary of the state of the art. We review the existing
evaluation methodologies for TST tasks and conduct a large-scale
reproducibility study where we experimentally benchmark 19 state-of-the-art TST
algorithms on two publicly available datasets. Finally, we expand on current
trends and provide new perspectives on the new and exciting developments in the
TST field.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 02:02:58 GMT'}]",2020-10-27,"[['Hu', 'Zhiqiang', ''], ['Lee', 'Roy Ka-Wei', ''], ['Aggarwal', 'Charu C.', '']]"
1369194,2010.12864,Xisen Jin,"Xisen Jin, Francesco Barbieri, Aida Mostafazadeh Davani, Brendan
  Kennedy, Leonardo Neves, Xiang Ren",Efficiently Mitigating Classification Bias via Transfer Learning,10 pages,,,,cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Prediction bias in machine learning models refers to unintended model
behaviors that discriminate against inputs mentioning or produced by certain
groups; for example, hate speech classifiers predict more false positives for
neutral text mentioning specific social groups. Mitigating bias for each task
or domain is inefficient, as it requires repetitive model training, data
annotation (e.g., demographic information), and evaluation. In pursuit of a
more accessible solution, we propose the Upstream Bias Mitigation for
Downstream Fine-Tuning (UBM) framework, which mitigate one or multiple bias
factors in downstream classifiers by transfer learning from an upstream model.
In the upstream bias mitigation stage, explanation regularization and
adversarial training are applied to mitigate multiple bias factors. In the
downstream fine-tuning stage, the classifier layer of the model is
re-initialized, and the entire model is fine-tuned to downstream tasks in
potentially novel domains without any further bias mitigation. We expect
downstream classifiers to be less biased by transfer learning from de-biased
upstream models. We conduct extensive experiments varying the similarity
between the source and target data, as well as varying the number of dimensions
of bias (e.g., discrimination against specific social groups or dialects). Our
results indicate the proposed UBM framework can effectively reduce bias in
downstream classifiers.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 10:36:11 GMT'}]",2020-10-27,"[['Jin', 'Xisen', ''], ['Barbieri', 'Francesco', ''], ['Davani', 'Aida Mostafazadeh', ''], ['Kennedy', 'Brendan', ''], ['Neves', 'Leonardo', ''], ['Ren', 'Xiang', '']]"
1369060,2010.12730,Gustavo Aguilar,"Gustavo Aguilar, Bryan McCann, Tong Niu, Nazneen Rajani, Nitish
  Keskar, Thamar Solorio","Char2Subword: Extending the Subword Embedding Space from Pre-trained
  Models Using Robust Character Compositionality",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Byte-pair encoding (BPE) is a ubiquitous algorithm in the subword
tokenization process of language models. BPE provides multiple benefits, such
as handling the out-of-vocabulary problem and reducing vocabulary sparsity.
However, this process is defined from the pre-training data statistics, making
the tokenization on different domains susceptible to infrequent spelling
sequences (e.g., misspellings as in social media or character-level adversarial
attacks). On the other hand, pure character-level models, though robust to
misspellings, often lead to unreasonably large sequence lengths and make it
harder for the model to learn meaningful contiguous characters. To alleviate
these challenges, we propose a character-based subword transformer module
(char2subword) that learns the subword embedding table in pre-trained models
like BERT. Our char2subword module builds representations from characters out
of the subword vocabulary, and it can be used as a drop-in replacement of the
subword embedding table. The module is robust to character-level alterations
such as misspellings, word inflection, casing, and punctuation. We integrate it
further with BERT through pre-training while keeping BERT transformer
parameters fixed. We show our method's effectiveness by outperforming a vanilla
multilingual BERT on the linguistic code-switching evaluation (LinCE)
benchmark.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 01:08:28 GMT'}]",2020-10-27,"[['Aguilar', 'Gustavo', ''], ['McCann', 'Bryan', ''], ['Niu', 'Tong', ''], ['Rajani', 'Nazneen', ''], ['Keskar', 'Nitish', ''], ['Solorio', 'Thamar', '']]"
1368943,2010.12613,Julia Siekiera,"Julia Siekiera, Marius K\""oppel, Edwin Simpson, Kevin Stowe, Iryna
  Gurevych, Stefan Kramer",Ranking Creative Language Characteristics in Small Data Scenarios,"10 pages, 3 figures",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The ability to rank creative natural language provides an important general
tool for downstream language understanding and generation. However, current
deep ranking models require substantial amounts of labeled data that are
difficult and expensive to obtain for different domains, languages and creative
characteristics. A recent neural approach, the DirectRanker, promises to reduce
the amount of training data needed but its application to text isn't fully
explored. We therefore adapt the DirectRanker to provide a new deep model for
ranking creative language with small data. We compare DirectRanker with a
Bayesian approach, Gaussian process preference learning (GPPL), which has
previously been shown to work well with sparse data. Our experiments with
sparse training data show that while the performance of standard neural ranking
approaches collapses with small training datasets, DirectRanker remains
effective. We find that combining DirectRanker with GPPL increases performance
across different settings by leveraging the complementary benefits of both
models. Our combined approach outperforms the previous state-of-the-art on
humor and metaphor novelty tasks, increasing Spearman's $\rho$ by 14% and 16%
on average.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 18:57:47 GMT'}]",2020-10-27,"[['Siekiera', 'Julia', ''], ['Köppel', 'Marius', ''], ['Simpson', 'Edwin', ''], ['Stowe', 'Kevin', ''], ['Gurevych', 'Iryna', ''], ['Kramer', 'Stefan', '']]"
1369267,2010.12937,Arun Kumar Singh,"Arun Kumar Singh, Sushant Dave, Dr. Prathosh A. P., Prof. Brejesh Lall
  and Shresth Mehta","A Benchmark Corpus and Neural Approach for Sanskrit Derivative Nouns
  Analysis","6 pages, 2 figures, EACL 2021 Submission",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents first benchmark corpus of Sanskrit Pratyaya (suffix) and
inflectional words (padas) formed due to suffixes along with neural network
based approaches to process the formation and splitting of inflectional words.
Inflectional words spans the primary and secondary derivative nouns as the
scope of current work. Pratyayas are an important dimension of morphological
analysis of Sanskrit texts. There have been Sanskrit Computational Linguistics
tools for processing and analyzing Sanskrit texts. Unfortunately there has not
been any work to standardize & validate these tools specifically for derivative
nouns analysis. In this work, we prepared a Sanskrit suffix benchmark corpus
called Pratyaya-Kosh to evaluate the performance of tools. We also present our
own neural approach for derivative nouns analysis while evaluating the same on
most prominent Sanskrit Morphological Analysis tools. This benchmark will be
freely dedicated and available to researchers worldwide and we hope it will
motivate all to improve morphological analysis in Sanskrit Language.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 17:22:44 GMT'}]",2020-10-27,"[['Singh', 'Arun Kumar', ''], ['Dave', 'Sushant', ''], ['P.', 'Dr. Prathosh A.', ''], ['Lall', 'Prof. Brejesh', ''], ['Mehta', 'Shresth', '']]"
1237621,2002.00198,Kun Zhou,"Kun Zhou, Berrak Sisman, Haizhou Li","Transforming Spectrum and Prosody for Emotional Voice Conversion with
  Non-Parallel Training Data","accepted by Speaker Odyssey 2020 in Tokyo, Japan",,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Emotional voice conversion aims to convert the spectrum and prosody to change
the emotional patterns of speech, while preserving the speaker identity and
linguistic content. Many studies require parallel speech data between different
emotional patterns, which is not practical in real life. Moreover, they often
model the conversion of fundamental frequency (F0) with a simple linear
transform. As F0 is a key aspect of intonation that is hierarchical in nature,
we believe that it is more adequate to model F0 in different temporal scales by
using wavelet transform. We propose a CycleGAN network to find an optimal
pseudo pair from non-parallel training data by learning forward and inverse
mappings simultaneously using adversarial and cycle-consistency losses. We also
study the use of continuous wavelet transform (CWT) to decompose F0 into ten
temporal scales, that describes speech prosody at different time resolution,
for effective F0 conversion. Experimental results show that our proposed
framework outperforms the baselines both in objective and subjective
evaluations.
","[{'version': 'v1', 'created': 'Sat, 1 Feb 2020 12:36:55 GMT'}, {'version': 'v2', 'created': 'Mon, 6 Apr 2020 12:43:26 GMT'}, {'version': 'v3', 'created': 'Tue, 7 Apr 2020 07:25:24 GMT'}, {'version': 'v4', 'created': 'Wed, 13 May 2020 05:21:37 GMT'}, {'version': 'v5', 'created': 'Sat, 24 Oct 2020 06:37:42 GMT'}]",2020-10-27,"[['Zhou', 'Kun', ''], ['Sisman', 'Berrak', ''], ['Li', 'Haizhou', '']]"
1368751,2010.12421,Jose Camacho-Collados,"Francesco Barbieri and Jose Camacho-Collados and Leonardo Neves and
  Luis Espinosa-Anke","TweetEval: Unified Benchmark and Comparative Evaluation for Tweet
  Classification","Findings of EMNLP 2020. TweetEval benchmark available at
  https://github.com/cardiffnlp/tweeteval",,,,cs.CL cs.SI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The experimental landscape in natural language processing for social media is
too fragmented. Each year, new shared tasks and datasets are proposed, ranging
from classics like sentiment analysis to irony detection or emoji prediction.
Therefore, it is unclear what the current state of the art is, as there is no
standardized evaluation protocol, neither a strong set of baselines trained on
such domain-specific data. In this paper, we propose a new evaluation framework
(TweetEval) consisting of seven heterogeneous Twitter-specific classification
tasks. We also provide a strong set of baselines as starting point, and compare
different language modeling pre-training strategies. Our initial experiments
show the effectiveness of starting off with existing pre-trained generic
language models, and continue training them on Twitter corpora.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 14:11:04 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 09:14:54 GMT'}]",2020-10-27,"[['Barbieri', 'Francesco', ''], ['Camacho-Collados', 'Jose', ''], ['Neves', 'Leonardo', ''], ['Espinosa-Anke', 'Luis', '']]"
1368264,2010.11934,Colin Raffel,"Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou,
  Aditya Siddhant, Aditya Barua, Colin Raffel",mT5: A massively multilingual pre-trained text-to-text transformer,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The recent ""Text-to-Text Transfer Transformer"" (T5) leveraged a unified
text-to-text format and scale to attain state-of-the-art results on a wide
variety of English-language NLP tasks. In this paper, we introduce mT5, a
multilingual variant of T5 that was pre-trained on a new Common Crawl-based
dataset covering 101 languages. We describe the design and modified training of
mT5 and demonstrate its state-of-the-art performance on many multilingual
benchmarks. All of the code and model checkpoints used in this work are
publicly available.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 17:58:14 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 21:25:28 GMT'}]",2020-10-27,"[['Xue', 'Linting', ''], ['Constant', 'Noah', ''], ['Roberts', 'Adam', ''], ['Kale', 'Mihir', ''], ['Al-Rfou', 'Rami', ''], ['Siddhant', 'Aditya', ''], ['Barua', 'Aditya', ''], ['Raffel', 'Colin', '']]"
1368186,2010.11856,Akari Asai,"Akari Asai, Jungo Kasai, Jonathan H. Clark, Kenton Lee, Eunsol Choi
  and Hannaneh Hajishirzi",XOR QA: Cross-lingual Open-Retrieval Question Answering,"Our data and code are available at
  https://nlp.cs.washington.edu/xorqa",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Multilingual question answering tasks typically assume answers exist in the
same language as the question. Yet in practice, many languages face both
information scarcity---where languages have few reference articles---and
information asymmetry---where questions reference concepts from other cultures.
This work extends open-retrieval question answering to a cross-lingual setting
enabling questions from one language to be answered via answer content from
another language. We construct a large-scale dataset built on questions from
TyDi QA lacking same-language answers. Our task formulation, called
Cross-lingual Open Retrieval Question Answering (XOR QA), includes 40k
information-seeking questions from across 7 diverse non-English languages.
Based on this dataset, we introduce three new tasks that involve cross-lingual
document retrieval using multi-lingual and English resources. We establish
baselines with state-of-the-art machine translation systems and cross-lingual
pretrained models. Experimental results suggest that XOR QA is a challenging
task that will facilitate the development of novel techniques for multilingual
question answering. Our data and code are available at
https://nlp.cs.washington.edu/xorqa.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 16:47:17 GMT'}, {'version': 'v2', 'created': 'Sat, 24 Oct 2020 10:00:22 GMT'}]",2020-10-27,"[['Asai', 'Akari', ''], ['Kasai', 'Jungo', ''], ['Clark', 'Jonathan H.', ''], ['Lee', 'Kenton', ''], ['Choi', 'Eunsol', ''], ['Hajishirzi', 'Hannaneh', '']]"
1367758,2010.11428,Qiujia Li,"Qiujia Li, David Qiu, Yu Zhang, Bo Li, Yanzhang He, Philip C.
  Woodland, Liangliang Cao, Trevor Strohman","Confidence Estimation for Attention-based Sequence-to-sequence Models
  for Speech Recognition",Submitted to ICASSP 2021,,,,eess.AS cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  For various speech-related tasks, confidence scores from a speech recogniser
are a useful measure to assess the quality of transcriptions. In traditional
hidden Markov model-based automatic speech recognition (ASR) systems,
confidence scores can be reliably obtained from word posteriors in decoding
lattices. However, for an ASR system with an auto-regressive decoder, such as
an attention-based sequence-to-sequence model, computing word posteriors is
difficult. An obvious alternative is to use the decoder softmax probability as
the model confidence. In this paper, we first examine how some commonly used
regularisation methods influence the softmax-based confidence scores and study
the overconfident behaviour of end-to-end models. Then we propose a lightweight
and effective approach named confidence estimation module (CEM) on top of an
existing end-to-end ASR model. Experiments on LibriSpeech show that CEM can
mitigate the overconfidence problem and can produce more reliable confidence
scores with and without shallow fusion of a language model. Further analysis
shows that CEM generalises well to speech from a moderately mismatched domain
and can potentially improve downstream tasks such as semi-supervised learning.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 04:02:27 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 18:49:07 GMT'}]",2020-10-27,"[['Li', 'Qiujia', ''], ['Qiu', 'David', ''], ['Zhang', 'Yu', ''], ['Li', 'Bo', ''], ['He', 'Yanzhang', ''], ['Woodland', 'Philip C.', ''], ['Cao', 'Liangliang', ''], ['Strohman', 'Trevor', '']]"
1367634,2010.11304,Wenxuan Zhou,"Wenxuan Zhou, Kevin Huang, Tengyu Ma, Jing Huang","Document-Level Relation Extraction with Adaptive Thresholding and
  Localized Context Pooling",Code available at https://github.com/wzhouad/ATLOP,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Document-level relation extraction (RE) poses new challenges compared to its
sentence-level RE counterpart. One document commonly contains multiple entity
pairs, and one entity pair occurs multiple times in the document associated
with multiple possible relations. In this paper, we propose two novel
techniques, adaptive thresholding and localized context pooling, to solve the
multilabel and multi-entity problems. The adaptive thresholding replaces the
global threshold for multi-label classification in the prior work by a
learnable entities-dependent threshold. The localized context pooling directly
transfers attention from pre-trained language models to locate relevant context
that is useful to decide the relation. We experiment on three document-level RE
benchmark datasets: DocRED, a recently released large-scale RE dataset, and two
datasets CDR and GDA in the biomedical domain. Our ATLOP (Adaptive Thresholding
and Localized cOntext Pooling) model achieves an F1 score of 63.4; and also
significantly outperforms existing models on both CDR and GDA.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 20:41:23 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 21:18:24 GMT'}]",2020-10-27,"[['Zhou', 'Wenxuan', ''], ['Huang', 'Kevin', ''], ['Ma', 'Tengyu', ''], ['Huang', 'Jing', '']]"
1367328,2010.10998,Aditya Kalyanpur,"Aditya Kalyanpur, Or Biran, Tom Breloff, Jennifer Chu-Carroll, Ariel
  Diertani, Owen Rambow, Mark Sammons",Open-Domain Frame Semantic Parsing Using Transformers,11 pages,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Frame semantic parsing is a complex problem which includes multiple
underlying subtasks. Recent approaches have employed joint learning of subtasks
(such as predicate and argument detection), and multi-task learning of related
tasks (such as syntactic and semantic parsing). In this paper, we explore
multi-task learning of all subtasks with transformer-based models. We show that
a purely generative encoder-decoder architecture handily beats the previous
state of the art in FrameNet 1.7 parsing, and that a mixed decoding multi-task
approach achieves even better performance. Finally, we show that the multi-task
model also outperforms recent state of the art systems for PropBank SRL parsing
on the CoNLL 2012 benchmark.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 13:38:04 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 23:37:12 GMT'}]",2020-10-27,"[['Kalyanpur', 'Aditya', ''], ['Biran', 'Or', ''], ['Breloff', 'Tom', ''], ['Chu-Carroll', 'Jennifer', ''], ['Diertani', 'Ariel', ''], ['Rambow', 'Owen', ''], ['Sammons', 'Mark', '']]"
1366264,2010.09934,Chengzhi Zhang,Yingyi Zhang and Chengzhi Zhang,Enhancing Keyphrase Extraction from Microblogs using Human Reading Time,,"Journal of the Association for Information Science and
  Technology,2021",10.1002/ASI.24430,,cs.CL cs.HC cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The premise of manual keyphrase annotation is to read the corresponding
content of an annotated object. Intuitively, when we read, more important words
will occupy a longer reading time. Hence, by leveraging human reading time, we
can find the salient words in the corresponding content. However, previous
studies on keyphrase extraction ignore human reading features. In this article,
we aim to leverage human reading time to extract keyphrases from microblog
posts. There are two main tasks in this study. One is to determine how to
measure the time spent by a human on reading a word. We use eye fixation
durations extracted from an open source eye-tracking corpus (OSEC). Moreover,
we propose strategies to make eye fixation duration more effective on keyphrase
extraction. The other task is to determine how to integrate human reading time
into keyphrase extraction models. We propose two novel neural network models.
The first is a model in which the human reading time is used as the ground
truth of the attention mechanism. In the second model, we use human reading
time as the external feature. Quantitative and qualitative experiments show
that our proposed models yield better performance than the baseline models on
two microblog datasets.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 00:18:44 GMT'}, {'version': 'v2', 'created': 'Sun, 25 Oct 2020 11:24:18 GMT'}]",2020-10-27,"[['Zhang', 'Yingyi', ''], ['Zhang', 'Chengzhi', '']]"
1365563,2010.09233,Dang Pham Nhu Hai,"Dang Pham, Tuan M.V.Le",Auto-Encoding Variational Bayes for Inferring Topics and Visualization,"Accepted at the 28th International Conference on Computational
  Linguistics (COLING 2020)",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Visualization and topic modeling are widely used approaches for text
analysis. Traditional visualization methods find low-dimensional
representations of documents in the visualization space (typically 2D or 3D)
that can be displayed using a scatterplot. In contrast, topic modeling aims to
discover topics from text, but for visualization, one needs to perform a
post-hoc embedding using dimensionality reduction methods. Recent approaches
propose using a generative model to jointly find topics and visualization,
allowing the semantics to be infused in the visualization space for a
meaningful interpretation. A major challenge that prevents these methods from
being used practically is the scalability of their inference algorithms. We
present, to the best of our knowledge, the first fast Auto-Encoding Variational
Bayes based inference method for jointly inferring topics and visualization.
Since our method is black box, it can handle model changes efficiently with
little mathematical rederivation effort. We demonstrate the efficiency and
effectiveness of our method on real-world large datasets and compare it with
existing baselines.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 05:57:11 GMT'}, {'version': 'v2', 'created': 'Sun, 25 Oct 2020 19:37:56 GMT'}]",2020-10-27,"[['Pham', 'Dang', ''], ['Le', 'Tuan M. V.', '']]"
1365524,2010.09194,Pan Xie,"Pan Xie, Zhi Cui, Xiuyin Chen, Xiaohui Hu, Jianwei Cui, Bin Wang","Infusing Sequential Information into Conditional Masked Translation
  Model with Self-Review Mechanism",accepted to coling 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Non-autoregressive models generate target words in a parallel way, which
achieve a faster decoding speed but at the sacrifice of translation accuracy.
To remedy a flawed translation by non-autoregressive models, a promising
approach is to train a conditional masked translation model (CMTM), and refine
the generated results within several iterations. Unfortunately, such approach
hardly considers the \textit{sequential dependency} among target words, which
inevitably results in a translation degradation. Hence, instead of solely
training a Transformer-based CMTM, we propose a Self-Review Mechanism to infuse
sequential information into it. Concretely, we insert a left-to-right mask to
the same decoder of CMTM, and then induce it to autoregressively review whether
each generated word from CMTM is supposed to be replaced or kept. The
experimental results (WMT14 En$\leftrightarrow$De and WMT16
En$\leftrightarrow$Ro) demonstrate that our model uses dramatically less
training computations than the typical CMTM, as well as outperforms several
state-of-the-art non-autoregressive models by over 1 BLEU. Through knowledge
distillation, our model even surpasses a typical left-to-right Transformer
model, while significantly speeding up decoding.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 03:38:56 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 13:22:06 GMT'}]",2020-10-27,"[['Xie', 'Pan', ''], ['Cui', 'Zhi', ''], ['Chen', 'Xiuyin', ''], ['Hu', 'Xiaohui', ''], ['Cui', 'Jianwei', ''], ['Wang', 'Bin', '']]"
1364910,2010.08580,Zeyu Liu,"Chuanrong Li, Lin Shengshuo, Leo Z. Liu, Xinyi Wu, Xuhui Zhou, Shane
  Steinert-Threlkeld","Linguistically-Informed Transformations (LIT): A Method forAutomatically
  Generating Contrast Sets",Appears at EMNLP BlackboxNLP Workshop 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Although large-scale pretrained language models, such as BERT and RoBERTa,
have achieved superhuman performance on in-distribution test sets, their
performance suffers on out-of-distribution test sets (e.g., on contrast sets).
Building contrast sets often re-quires human-expert annotation, which is
expensive and hard to create on a large scale. In this work, we propose a
Linguistically-Informed Transformation (LIT) method to automatically generate
contrast sets, which enables practitioners to explore linguistic phenomena of
interests as well as compose different phenomena. Experimenting with our method
on SNLI and MNLI shows that current pretrained language models, although being
claimed to contain sufficient linguistic knowledge, struggle on our
automatically generated contrast sets. Furthermore, we improve models'
performance on the contrast sets by apply-ing LIT to augment the training data,
without affecting performance on the original data.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 18:23:05 GMT'}, {'version': 'v2', 'created': 'Sun, 25 Oct 2020 01:39:23 GMT'}]",2020-10-27,"[['Li', 'Chuanrong', ''], ['Shengshuo', 'Lin', ''], ['Liu', 'Leo Z.', ''], ['Wu', 'Xinyi', ''], ['Zhou', 'Xuhui', ''], ['Steinert-Threlkeld', 'Shane', '']]"
1364763,2010.08433,Andrey Kormilitzin,"Andrey Kormilitzin, Nemanja Vaci, Qiang Liu, Hao Ni, Goran Nenadic,
  Alejo Nevado-Holgado",An efficient representation of chronological events in medical texts,"4 pages, 2 figures, 7 tables",,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this work we addressed the problem of capturing sequential information
contained in longitudinal electronic health records (EHRs). Clinical notes,
which is a particular type of EHR data, are a rich source of information and
practitioners often develop clever solutions how to maximise the sequential
information contained in free-texts. We proposed a systematic methodology for
learning from chronological events available in clinical notes. The proposed
methodological {\it path signature} framework creates a non-parametric
hierarchical representation of sequential events of any type and can be used as
features for downstream statistical learning tasks. The methodology was
developed and externally validated using the largest in the UK secondary care
mental health EHR data on a specific task of predicting survival risk of
patients diagnosed with Alzheimer's disease. The signature-based model was
compared to a common survival random forest model. Our results showed a
15.4$\%$ increase of risk prediction AUC at the time point of 20 months after
the first admission to a specialist memory clinic and the signature method
outperformed the baseline mixed-effects model by 13.2 $\%$.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 14:54:29 GMT'}, {'version': 'v2', 'created': 'Sat, 24 Oct 2020 21:52:03 GMT'}]",2020-10-27,"[['Kormilitzin', 'Andrey', ''], ['Vaci', 'Nemanja', ''], ['Liu', 'Qiang', ''], ['Ni', 'Hao', ''], ['Nenadic', 'Goran', ''], ['Nevado-Holgado', 'Alejo', '']]"
1364576,2010.08246,Johannes Bjerva,"Johannes Bjerva and Elizabeth Salesky and Sabrina J. Mielke and Aditi
  Chaudhary and Giuseppe G. A. Celano and Edoardo M. Ponti and Ekaterina
  Vylomova and Ryan Cotterell and Isabelle Augenstein",SIGTYP 2020 Shared Task: Prediction of Typological Features,SigTyp 2020 Shared Task Description Paper @ EMNLP 2020,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Typological knowledge bases (KBs) such as WALS (Dryer and Haspelmath, 2013)
contain information about linguistic properties of the world's languages. They
have been shown to be useful for downstream applications, including
cross-lingual transfer learning and linguistic probing. A major drawback
hampering broader adoption of typological KBs is that they are sparsely
populated, in the sense that most languages only have annotations for some
features, and skewed, in that few features have wide coverage. As typological
features often correlate with one another, it is possible to predict them and
thus automatically populate typological KBs, which is also the focus of this
shared task. Overall, the task attracted 8 submissions from 5 teams, out of
which the most successful methods make use of such feature correlations.
However, our error analysis reveals that even the strongest submitted systems
struggle with predicting feature values for languages where few features are
known.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 08:47:24 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 07:29:45 GMT'}]",2020-10-27,"[['Bjerva', 'Johannes', ''], ['Salesky', 'Elizabeth', ''], ['Mielke', 'Sabrina J.', ''], ['Chaudhary', 'Aditi', ''], ['Celano', 'Giuseppe G. A.', ''], ['Ponti', 'Edoardo M.', ''], ['Vylomova', 'Ekaterina', ''], ['Cotterell', 'Ryan', ''], ['Augenstein', 'Isabelle', '']]"
1359306,2010.02976,Albert Webson,"Albert Webson, Zhizhong Chen, Carsten Eickhoff, Ellie Pavlick","Are ""Undocumented Workers"" the Same as ""Illegal Aliens""? Disentangling
  Denotation and Connotation in Vector Spaces","Published at EMNLP 2020. Recorded talk available at
  https://youtu.be/V2pdS6Y_8n0 . Code and data available at
  https://github.com/awebson/congressional_adversary",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In politics, neologisms are frequently invented for partisan objectives. For
example, ""undocumented workers"" and ""illegal aliens"" refer to the same group of
people (i.e., they have the same denotation), but they carry clearly different
connotations. Examples like these have traditionally posed a challenge to
reference-based semantic theories and led to increasing acceptance of
alternative theories (e.g., Two-Factor Semantics) among philosophers and
cognitive scientists. In NLP, however, popular pretrained models encode both
denotation and connotation as one entangled representation. In this study, we
propose an adversarial neural network that decomposes a pretrained
representation as independent denotation and connotation representations. For
intrinsic interpretability, we show that words with the same denotation but
different connotations (e.g., ""immigrants"" vs. ""aliens"", ""estate tax"" vs.
""death tax"") move closer to each other in denotation space while moving further
apart in connotation space. For extrinsic application, we train an information
retrieval system with our disentangled representations and show that the
denotation vectors improve the viewpoint diversity of document rankings.
","[{'version': 'v1', 'created': 'Tue, 6 Oct 2020 19:09:03 GMT'}, {'version': 'v2', 'created': 'Sun, 25 Oct 2020 15:43:44 GMT'}]",2020-10-27,"[['Webson', 'Albert', ''], ['Chen', 'Zhizhong', ''], ['Eickhoff', 'Carsten', ''], ['Pavlick', 'Ellie', '']]"
1357359,2010.01029,Chengjin Xu,"Chengjin Xu, Mojtaba Nayyeri, Fouad Alkhoury, Hamed Shariat Yazdi,
  Jens Lehmann",TeRo: A Time-aware Knowledge Graph Embedding via Temporal Rotation,This paper is accepted by COLING2020,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In the last few years, there has been a surge of interest in learning
representations of entitiesand relations in knowledge graph (KG). However, the
recent availability of temporal knowledgegraphs (TKGs) that contain time
information for each fact created the need for reasoning overtime in such TKGs.
In this regard, we present a new approach of TKG embedding, TeRo, which defines
the temporal evolution of entity embedding as a rotation from the initial time
to the currenttime in the complex vector space. Specially, for facts involving
time intervals, each relation isrepresented as a pair of dual complex
embeddings to handle the beginning and the end of therelation, respectively. We
show our proposed model overcomes the limitations of the existing KG embedding
models and TKG embedding models and has the ability of learning and
inferringvarious relation patterns over time. Experimental results on four
different TKGs show that TeRo significantly outperforms existing
state-of-the-art models for link prediction. In addition, we analyze the effect
of time granularity on link prediction over TKGs, which as far as we know
hasnot been investigated in previous literature.
","[{'version': 'v1', 'created': 'Fri, 2 Oct 2020 14:35:27 GMT'}, {'version': 'v2', 'created': 'Sat, 24 Oct 2020 22:42:26 GMT'}]",2020-10-27,"[['Xu', 'Chengjin', ''], ['Nayyeri', 'Mojtaba', ''], ['Alkhoury', 'Fouad', ''], ['Yazdi', 'Hamed Shariat', ''], ['Lehmann', 'Jens', '']]"
1354770,2009.13267,Pedram Rooshenas,"Subhajit Naskar, Amirmohammad Rooshenas, Simeng Sun, Mohit Iyyer,
  Andrew McCallum","Energy-Based Reranking: Improving Neural Machine Translation Using
  Energy-Based Models",,,,,cs.CL cs.LG stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The discrepancy between maximum likelihood estimation (MLE) and task measures
such as BLEU score has been studied before for autoregressive neural machine
translation (NMT) and resulted in alternative training algorithms (Ranzato et
al., 2016; Norouzi et al., 2016; Shen et al., 2016; Wu et al., 2018). However,
MLE training remains the de facto approach for autoregressive NMT because of
its computational efficiency and stability. Despite this mismatch between the
training objective and task measure, we notice that the samples drawn from an
MLE-based trained NMT support the desired distribution -- there are samples
with much higher BLEU score comparing to the beam decoding output. To benefit
from this observation, we train an energy-based model to mimic the behavior of
the task measure (i.e., the energy-based model assigns lower energy to samples
with higher BLEU score), which is resulted in a re-ranking algorithm based on
the samples drawn from NMT: energy-based re-ranking (EBR). Our EBR consistently
improves the performance of the Transformer-based NMT: +3 BLEU points on
Sinhala-English, +2.0 BLEU points on IWSLT'17 French-English, and +1.7 BLEU
points on WMT'19 German-English tasks.
","[{'version': 'v1', 'created': 'Sun, 20 Sep 2020 02:50:52 GMT'}, {'version': 'v2', 'created': 'Sat, 24 Oct 2020 04:57:59 GMT'}]",2020-10-27,"[['Naskar', 'Subhajit', ''], ['Rooshenas', 'Amirmohammad', ''], ['Sun', 'Simeng', ''], ['Iyyer', 'Mohit', ''], ['McCallum', 'Andrew', '']]"
1353847,2009.12344,"Tommi Gr\""ondahl","Mika Juuti, Tommi Gr\""ondahl, Adrian Flanagan and N. Asokan","A little goes a long way: Improving toxic language classification
  despite data scarcity",To appear in Findings of ACL: EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Detection of some types of toxic language is hampered by extreme scarcity of
labeled training data. Data augmentation - generating new synthetic data from a
labeled seed dataset - can help. The efficacy of data augmentation on toxic
language classification has not been fully explored. We present the first
systematic study on how data augmentation techniques impact performance across
toxic language classifiers, ranging from shallow logistic regression
architectures to BERT - a state-of-the-art pre-trained Transformer network. We
compare the performance of eight techniques on very scarce seed datasets. We
show that while BERT performed the best, shallow classifiers performed
comparably when trained on data augmented with a combination of three
techniques, including GPT-2-generated sentences. We discuss the interplay of
performance and computational overhead, which can inform the choice of
techniques under different constraints.
","[{'version': 'v1', 'created': 'Fri, 25 Sep 2020 17:04:17 GMT'}, {'version': 'v2', 'created': 'Sat, 24 Oct 2020 19:31:34 GMT'}]",2020-10-27,"[['Juuti', 'Mika', ''], ['Gröndahl', 'Tommi', ''], ['Flanagan', 'Adrian', ''], ['Asokan', 'N.', '']]"
1352187,2009.10684,Bruno Taill\'e,"Bruno Taill\'e, Vincent Guigue, Geoffrey Scoutheeten and Patrick
  Gallinari",Let's Stop Incorrect Comparisons in End-to-end Relation Extraction!,Accepted at EMNLP 2020,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite efforts to distinguish three different evaluation setups (Bekoulis et
al., 2018), numerous end-to-end Relation Extraction (RE) articles present
unreliable performance comparison to previous work. In this paper, we first
identify several patterns of invalid comparisons in published papers and
describe them to avoid their propagation. We then propose a small empirical
study to quantify the impact of the most common mistake and evaluate it leads
to overestimating the final RE performance by around 5% on ACE05. We also seize
this opportunity to study the unexplored ablations of two recent developments:
the use of language model pretraining (specifically BERT) and span-level NER.
This meta-analysis emphasizes the need for rigor in the report of both the
evaluation setting and the datasets statistics and we call for unifying the
evaluation setting in end-to-end RE.
","[{'version': 'v1', 'created': 'Tue, 22 Sep 2020 16:59:15 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 16:43:35 GMT'}]",2020-10-27,"[['Taillé', 'Bruno', ''], ['Guigue', 'Vincent', ''], ['Scoutheeten', 'Geoffrey', ''], ['Gallinari', 'Patrick', '']]"
1350056,2009.08553,Yuning Mao,"Yuning Mao, Pengcheng He, Xiaodong Liu, Yelong Shen, Jianfeng Gao,
  Jiawei Han, Weizhu Chen",Generation-Augmented Retrieval for Open-domain Question Answering,"Added experiments with a generative reader. Current performance:
  EM=41.8 (43.8 +DPR) on NQ and 62.7 on Trivia with BERT-base (extractive);
  EM=38.1 (45.3 +DPR) on NQ and 61.8 on Trivia with BART-large (generative)",,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Conventional sparse retrieval methods such as TF-IDF and BM25 are simple and
efficient, but solely rely on lexical overlap without semantic matching. Recent
dense retrieval methods learn latent representations to tackle the lexical
mismatch problem, while being more computationally expensive and insufficient
for exact matching as they embed the text sequence into a single vector with
limited capacity. In this paper, we present Generation-Augmented Retrieval
(GAR), a query expansion method that augments a query with relevant contexts
through text generation. We demonstrate on open-domain question answering that
the generated contexts significantly enrich the semantics of the queries and
thus GAR with sparse representations (BM25) achieves comparable or better
performance than the state-of-the-art dense methods such as DPR
\cite{karpukhin2020dense}. We show that generating various contexts of a query
is beneficial as fusing their results consistently yields better retrieval
accuracy. Moreover, as sparse and dense representations are often
complementary, GAR can be easily combined with DPR to achieve even better
performance. Furthermore, GAR achieves the state-of-the-art performance on the
Natural Questions and TriviaQA datasets under the extractive setting when
equipped with an extractive reader, and consistently outperforms other
retrieval methods when the same generative reader is used.
","[{'version': 'v1', 'created': 'Thu, 17 Sep 2020 23:08:01 GMT'}, {'version': 'v2', 'created': 'Sat, 24 Oct 2020 03:23:27 GMT'}]",2020-10-27,"[['Mao', 'Yuning', ''], ['He', 'Pengcheng', ''], ['Liu', 'Xiaodong', ''], ['Shen', 'Yelong', ''], ['Gao', 'Jianfeng', ''], ['Han', 'Jiawei', ''], ['Chen', 'Weizhu', '']]"
1347990,2009.06487,Chengyu Wang,"Chengyu Wang, Mengli Cheng, Xu Hu, Jun Huang","EasyASR: A Distributed Machine Learning Platform for End-to-end
  Automatic Speech Recognition",aaai 2021 demo paper,,,,cs.CL cs.AI cs.DC cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present EasyASR, a distributed machine learning platform for training and
serving large-scale Automatic Speech Recognition (ASR) models, as well as
collecting and processing audio data at scale. Our platform is built upon the
Machine Learning Platform for AI of Alibaba Cloud. Its main functionality is to
support efficient learning and inference for end-to-end ASR models on
distributed GPU clusters. It allows users to learn ASR models with either
pre-defined or user-customized network architectures via simple user interface.
On EasyASR, we have produced state-of-the-art results over several public
datasets for Mandarin speech recognition.
","[{'version': 'v1', 'created': 'Mon, 14 Sep 2020 14:47:02 GMT'}, {'version': 'v2', 'created': 'Sat, 24 Oct 2020 09:44:27 GMT'}]",2020-10-27,"[['Wang', 'Chengyu', ''], ['Cheng', 'Mengli', ''], ['Hu', 'Xu', ''], ['Huang', 'Jun', '']]"
1347389,2009.05886,Dylan Slack,Gavin Kerrigan and Dylan Slack and Jens Tuyls,Differentially Private Language Models Benefit from Public Pre-training,,,,,cs.LG cs.CL cs.CR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language modeling is a keystone task in natural language processing. When
training a language model on sensitive information, differential privacy (DP)
allows us to quantify the degree to which our private data is protected.
However, training algorithms which enforce differential privacy often lead to
degradation in model quality. We study the feasibility of learning a language
model which is simultaneously high-quality and privacy preserving by tuning a
public base model on a private corpus. We find that DP fine-tuning boosts the
performance of language models in the private domain, making the training of
such models possible.
","[{'version': 'v1', 'created': 'Sun, 13 Sep 2020 00:50:44 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 16:04:43 GMT'}]",2020-10-27,"[['Kerrigan', 'Gavin', ''], ['Slack', 'Dylan', ''], ['Tuyls', 'Jens', '']]"
1368953,2010.12623,Wenhu Chen,"Liangming Pan, Wenhu Chen, Wenhan Xiong, Min-Yen Kan, William Yang
  Wang",Unsupervised Multi-hop Question Answering by Question Generation,Technical Report,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Obtaining training data for Multi-hop Question Answering (QA) is extremely
time-consuming and resource-intensive. To address this, we propose the problem
of \textit{unsupervised} multi-hop QA, assuming that no human-labeled multi-hop
question-answer pairs are available. We propose MQA-QG, an unsupervised
question answering framework that can generate human-like multi-hop training
pairs from both homogeneous and heterogeneous data sources. Our model generates
questions by first selecting or generating relevant information from each data
source and then integrating the multiple information to form a multi-hop
question. We find that we can train a competent multi-hop QA model with only
generated data. The F1 gap between the unsupervised and fully-supervised models
is less than 20 in both the HotpotQA and the HybridQA dataset. Further
experiments reveal that an unsupervised pretraining with the QA data generated
by our model would greatly reduce the demand for human-annotated training data
for multi-hop QA.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 19:13:47 GMT'}]",2020-10-27,"[['Pan', 'Liangming', ''], ['Chen', 'Wenhu', ''], ['Xiong', 'Wenhan', ''], ['Kan', 'Min-Yen', ''], ['Wang', 'William Yang', '']]"
1369071,2010.12741,Jo\~ao Sedoc,"Seolhwa Lee, Heuiseok Lim, Jo\~ao Sedoc",An Evaluation Protocol for Generative Conversational Systems,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  There is a multitude of novel generative models for open-domain
conversational systems; however, there is no systematic evaluation of different
systems. Systematic comparisons require consistency in experimental design,
evaluation sets, conversational systems and their outputs, and statistical
analysis. We lay out a protocol for the evaluation of conversational models
using head-to-head pairwise comparison. We analyze ten recent models that claim
state-of-the-art performance using a paired head-to-head performance
(win-loss-tie) on five evaluation datasets. Our findings show that DialoGPT and
Blender are superior systems using Bradley-Terry model and TrueSkill ranking
methods. These findings demonstrate the feasibility of our protocol to evaluate
conversational agents and evaluation sets. Finally, we make all code and
evaluations publicly available for researchers to compare their model to other
state-of-the-art dialog models.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 01:59:49 GMT'}]",2020-10-27,"[['Lee', 'Seolhwa', ''], ['Lim', 'Heuiseok', ''], ['Sedoc', 'João', '']]"
1368956,2010.12626,Laure Thompson,"Laure Thompson, David Mimno",Topic Modeling with Contextualized Word Representation Clusters,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Clustering token-level contextualized word representations produces output
that shares many similarities with topic models for English text collections.
Unlike clusterings of vocabulary-level word embeddings, the resulting models
more naturally capture polysemy and can be used as a way of organizing
documents. We evaluate token clusterings trained from several different output
layers of popular contextualized language models. We find that BERT and GPT-2
produce high quality clusterings, but RoBERTa does not. These cluster models
are simple, reliable, and can perform as well as, if not better than, LDA topic
models, maintaining high topic quality even when the number of topics is large
relative to the size of the local collection.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 19:16:59 GMT'}]",2020-10-27,"[['Thompson', 'Laure', ''], ['Mimno', 'David', '']]"
1368964,2010.12634,Yusen Zhang,"Yusen Zhang, Xiangyu Dong, Shuaichen Chang, Tao Yu, Peng Shi and Rui
  Zhang","Did You Ask a Good Question? A Cross-Domain Question Intention
  Classification Benchmark for Text-to-SQL","8 pages, 2 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Neural models have achieved significant results on the text-to-SQL task, in
which most current work assumes all the input questions are legal and generates
a SQL query for any input. However, in the real scenario, users can input any
text that may not be able to be answered by a SQL query. In this work, we
propose TriageSQL, the first cross-domain text-to-SQL question intention
classification benchmark that requires models to distinguish four types of
unanswerable questions from answerable questions. The baseline RoBERTa model
achieves a 60% F1 score on the test set, demonstrating the need for further
improvement on this task. Our dataset is available at
https://github.com/chatc/TriageSQL.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 19:36:57 GMT'}]",2020-10-27,"[['Zhang', 'Yusen', ''], ['Dong', 'Xiangyu', ''], ['Chang', 'Shuaichen', ''], ['Yu', 'Tao', ''], ['Shi', 'Peng', ''], ['Zhang', 'Rui', '']]"
1369059,2010.12729,Adina Williams,"Adina Williams, Tristan Thrush, Douwe Kiela",ANLIzing the Adversarial Natural Language Inference Dataset,"33 pages, 1 figure, 24 tables",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We perform an in-depth error analysis of Adversarial NLI (ANLI), a recently
introduced large-scale human-and-model-in-the-loop natural language inference
dataset collected over multiple rounds. We propose a fine-grained annotation
scheme of the different aspects of inference that are responsible for the gold
classification labels, and use it to hand-code all three of the ANLI
development sets. We use these annotations to answer a variety of interesting
questions: which inference types are most common, which models have the highest
performance on each reasoning type, and which types are the most challenging
for state of-the-art models? We hope that our annotations will enable more
fine-grained evaluation of models trained on ANLI, provide us with a deeper
understanding of where models fail and succeed, and help us determine how to
train better models in future.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 01:03:51 GMT'}]",2020-10-27,"[['Williams', 'Adina', ''], ['Thrush', 'Tristan', ''], ['Kiela', 'Douwe', '']]"
1369055,2010.12725,Peter Shaw,"Peter Shaw, Ming-Wei Chang, Panupong Pasupat, Kristina Toutanova","Compositional Generalization and Natural Language Variation: Can a
  Semantic Parsing Approach Handle Both?",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Sequence-to-sequence models excel at handling natural language variation, but
have been shown to struggle with out-of-distribution compositional
generalization. This has motivated new specialized architectures with stronger
compositional biases, but most of these approaches have only been evaluated on
synthetically-generated datasets, which are not representative of natural
language variation. In this work we ask: can we develop a semantic parsing
approach that handles both natural language variation and compositional
generalization? To better assess this capability, we propose new train and test
splits of non-synthetic datasets. We demonstrate that strong existing semantic
parsing approaches do not yet perform well across a broad set of evaluations.
We also propose NQG-T5, a hybrid model that combines a high-precision
grammar-based approach with a pre-trained sequence-to-sequence model. It
outperforms existing approaches across several compositional generalization
challenges, while also being competitive with the state-of-the-art on standard
evaluations. While still far from solving this problem, our study highlights
the importance of diverse evaluations and the open challenge of handling both
compositional generalization and natural language variation in semantic
parsing.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 00:38:27 GMT'}]",2020-10-27,"[['Shaw', 'Peter', ''], ['Chang', 'Ming-Wei', ''], ['Pasupat', 'Panupong', ''], ['Toutanova', 'Kristina', '']]"
1369053,2010.12723,Yuning Mao,"Yuning Mao, Xiang Ren, Heng Ji, Jiawei Han","Constrained Abstractive Summarization: Preserving Factual Consistency
  with Constrained Generation",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Summaries generated by abstractive summarization are supposed to only contain
statements entailed by the source documents. However, state-of-the-art
abstractive methods are still prone to hallucinate content inconsistent with
the source documents. In this paper, we propose constrained abstractive
summarization (CAS), a general setup that preserves the factual consistency of
abstractive summarization by specifying tokens as constraints that must be
present in the summary. We explore the feasibility of using lexically
constrained decoding, a technique applicable to any abstractive method with
beam search decoding, to fulfill CAS and conduct experiments in two scenarios:
(1) Standard summarization without human involvement, where keyphrase
extraction is used to extract constraints from source documents; (2)
Interactive summarization with human feedback, which is simulated by taking
missing tokens in the reference summaries as constraints. Automatic and human
evaluations on two benchmark datasets demonstrate that CAS improves the quality
of abstractive summaries, especially on factual consistency. In particular, we
observe up to 11.2 ROUGE-2 gains when several ground-truth tokens are used as
constraints in the interactive summarization scenario.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 00:27:44 GMT'}]",2020-10-27,"[['Mao', 'Yuning', ''], ['Ren', 'Xiang', ''], ['Ji', 'Heng', ''], ['Han', 'Jiawei', '']]"
1369049,2010.12719,Falcon Dai,Falcon Z. Dai,Word2vec Conjecture and A Limitative Result,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Being inspired by the success of \texttt{word2vec}
\citep{mikolov2013distributed} in capturing analogies, we study the conjecture
that analogical relations can be represented by vector spaces. Unlike many
previous works that focus on the distributional semantic aspect of
\texttt{word2vec}, we study the purely \emph{representational} question: can
\emph{all} semantic word-word relations be represented by differences (or
directions) of vectors? We call this the word2vec conjecture and point out some
of its desirable implications. However, we will exhibit a class of relations
that cannot be represented in this way, thus falsifying the conjecture and
establishing a limitative result for the representability of semantic relations
by vector spaces over fields of characteristic 0, e.g., real or complex
numbers.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 00:14:04 GMT'}]",2020-10-27,"[['Dai', 'Falcon Z.', '']]"
1369042,2010.12712,Shuguang Chen,"Shuguang Chen, Gustavo Aguilar, Leonardo Neves, Thamar Solorio","A Caption Is Worth A Thousand Images: Investigating Image Captions for
  Multimodal Named Entity Recognition","8 pages, 2 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Multimodal named entity recognition (MNER) requires to bridge the gap between
language understanding and visual context. Due to advances in natural language
processing (NLP) and computer vision (CV), many neural techniques have been
proposed to incorporate images into the NER task. In this work, we conduct a
detailed analysis of current state-of-the-art fusion techniques for MNER and
describe scenarios where adding information from the image does not always
result in boosts in performance. We also study the use of captions as a way to
enrich the context for MNER. We provide extensive empirical analysis and an
ablation study on three datasets from popular social platforms to expose the
situations where the approach is beneficial.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 23:41:51 GMT'}]",2020-10-27,"[['Chen', 'Shuguang', ''], ['Aguilar', 'Gustavo', ''], ['Neves', 'Leonardo', ''], ['Solorio', 'Thamar', '']]"
1369040,2010.12710,Maria Phillips,"Debajyoti Datta, Maria Phillips, Jennifer Chiu, Ginger S. Watson,
  James P. Bywater, Laura Barnes, and Donald Brown","Improving Classification through Weak Supervision in Context-specific
  Conversational Agent Development for Teacher Education",Preprint: Under Review,,,,cs.CL cs.CY cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Machine learning techniques applied to the Natural Language Processing (NLP)
component of conversational agent development show promising results for
improved accuracy and quality of feedback that a conversational agent can
provide. The effort required to develop an educational scenario specific
conversational agent is time consuming as it requires domain experts to label
and annotate noisy data sources such as classroom videos. Previous approaches
to modeling annotations have relied on labeling thousands of examples and
calculating inter-annotator agreement and majority votes in order to model the
necessary scenarios. This method, while proven successful, ignores individual
annotator strengths in labeling a data point and under-utilizes examples that
do not have a majority vote for labeling. We propose using a multi-task weak
supervision method combined with active learning to address these concerns.
This approach requires less labeling than traditional methods and shows
significant improvements in precision, efficiency, and time-requirements than
the majority vote method (Ratner 2019). We demonstrate the validity of this
method on the Google Jigsaw data set and then propose a scenario to apply this
method using the Instructional Quality Assessment(IQA) to define the categories
for labeling. We propose using probabilistic modeling of annotator labeling to
generate active learning examples to further label the data. Active learning is
able to iteratively improve the training performance and accuracy of the
original classification model. This approach combines state-of-the art labeling
techniques of weak supervision and active learning to optimize results in the
educational domain and could be further used to lessen the data requirements
for expanded scenarios within the education domain through transfer learning.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 23:39:40 GMT'}]",2020-10-27,"[['Datta', 'Debajyoti', ''], ['Phillips', 'Maria', ''], ['Chiu', 'Jennifer', ''], ['Watson', 'Ginger S.', ''], ['Bywater', 'James P.', ''], ['Barnes', 'Laura', ''], ['Brown', 'Donald', '']]"
1369037,2010.12707,Dorottya Demszky,"Dorottya Demszky, Devyani Sharma, Jonathan H. Clark, Vinodkumar
  Prabhakaran, Jacob Eisenstein",Learning to Recognize Dialect Features,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Linguists characterize dialects by the presence, absence, and frequency of
dozens of interpretable features. Detecting these features in text has
applications to social science and dialectology, and can be used to assess the
robustness of natural language processing systems to dialect differences. For
most dialects, large-scale annotated corpora for these features are
unavailable, making it difficult to train recognizers. Linguists typically
define dialect features by providing a small number of minimal pairs, which are
paired examples distinguished only by whether the feature is present, while
holding everything else constant. In this paper, we present two multitask
learning architectures for recognizing dialect features, both based on
pretrained transformers. We evaluate these models on two test sets of Indian
English, annotated for a total of 22 dialect features. We find these models
learn to recognize many features with high accuracy; crucially, a few minimal
pairs can be nearly as effective for training as thousands of labeled examples.
We also demonstrate the downstream applicability of our dialect feature
detection model as a dialect density measure and as a dialect classifier.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 23:25:00 GMT'}]",2020-10-27,"[['Demszky', 'Dorottya', ''], ['Sharma', 'Devyani', ''], ['Clark', 'Jonathan H.', ''], ['Prabhakaran', 'Vinodkumar', ''], ['Eisenstein', 'Jacob', '']]"
1369029,2010.12699,"Stefan Gr\""unewald","Stefan Gr\""unewald, Annemarie Friedrich, Jonas Kuhn","Graph-Based Universal Dependency Parsing in the Age of the Transformer:
  What Works, and What Doesn't",14 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Current state-of-the-art graph-based dependency parsers differ on various
dimensions. Among others, these include (a) the choice of pre-trained word
embeddings or language models used for representing token, (b) training setups
performing only parsing or additional tasks such as part-of-speech-tagging, and
(c) their mechanism of constructing trees or graphs from edge scores. Because
of this, it is difficult to estimate the impact of these architectural
decisions when comparing parsers.
  In this paper, we perform a series of experiments on STEPS, a new modular
graph-based parser for basic and enhanced Universal Dependencies, analyzing the
effects of architectural configurations. We find that pre-trained embeddings
have by far the greatest and most clear-cut impact on parser performance. The
choice of factorized vs. unfactorized architectures and a multi-task training
setup affect parsing accuracy in more subtle ways, depending on target language
and output representation (trees vs. graphs). Our parser achieves new
state-of-the-art results for a wide range of languages on both basic as well as
enhanced Universal Dependencies, using a unified and comparatively simple
architecture for both parsing tasks.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 22:58:26 GMT'}]",2020-10-27,"[['Grünewald', 'Stefan', ''], ['Friedrich', 'Annemarie', ''], ['Kuhn', 'Jonas', '']]"
1369024,2010.12694,Sayali Kulkarni,"Sayali Kulkarni, Sheide Chammas, Wan Zhu, Fei Sha, Eugene Ie","AQuaMuSe: Automatically Generating Datasets for Query-Based
  Multi-Document Summarization",,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Summarization is the task of compressing source document(s) into coherent and
succinct passages. This is a valuable tool to present users with concise and
accurate sketch of the top ranked documents related to their queries.
Query-based multi-document summarization (qMDS) addresses this pervasive need,
but the research is severely limited due to lack of training and evaluation
datasets as existing single-document and multi-document summarization datasets
are inadequate in form and scale. We propose a scalable approach called
AQuaMuSe to automatically mine qMDS examples from question answering datasets
and large document corpora. Our approach is unique in the sense that it can
general a dual dataset -- for extractive and abstractive summaries both. We
publicly release a specific instance of an AQuaMuSe dataset with 5,519
query-based summaries, each associated with an average of 6 input documents
selected from an index of 355M documents from Common Crawl. Extensive
evaluation of the dataset along with baseline summarization model experiments
are provided.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 22:38:18 GMT'}]",2020-10-27,"[['Kulkarni', 'Sayali', ''], ['Chammas', 'Sheide', ''], ['Zhu', 'Wan', ''], ['Sha', 'Fei', ''], ['Ie', 'Eugene', '']]"
1369023,2010.12693,Nadezhda Chirkova,Nadezhda Chirkova,Neural Code Completion with Anonymized Variable Names,,,,,cs.SE cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Source code processing heavily relies on the methods widely used in natural
language processing (NLP), but involves specifics that need to be taken into
account to achieve higher quality. An example of this specificity is that
renaming variables does not change the semantics of what the code does. In this
work, we develop a recurrent architecture that processes code with all variable
names anonymized, i. e. replaced with unique placeholders. The proposed
architecture outperforms standard NLP baselines on code completion task by a
large margin in the anonymized setting, and improves the base model in the
non-anonymized setting, being ensembled with it.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 22:32:11 GMT'}]",2020-10-27,"[['Chirkova', 'Nadezhda', '']]"
1369018,2010.12688,Oshin Agarwal,"Oshin Agarwal, Heming Ge, Siamak Shakeri, Rami Al-Rfou","Large Scale Knowledge Graph Based Synthetic Corpus Generation for
  Knowledge-Enhanced Language Model Pre-training",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Generating natural sentences from Knowledge Graph (KG) triples, known as
Data-To-Text Generation, is a task with many datasets for which numerous
complex systems have been developed. However, no prior work has attempted to
perform this generation at scale by converting an entire KG into natural text.
In this paper, we verbalize the entire Wikidata KG, and create a KG-Text
aligned corpus in the training process. We discuss the challenges in
verbalizing an entire KG versus verbalizing smaller datasets. We further show
that verbalizing an entire KG can be used to integrate structured and natural
language data. In contrast to the many architectures that have been developed
to integrate the structural differences between these two sources, our approach
converts the KG into the same format as natural text allowing it to be
seamlessly plugged into existing natural language systems. We evaluate this
approach by augmenting the retrieval corpus in REALM and showing improvements,
both on the LAMA knowledge probe and open domain QA.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 22:14:50 GMT'}]",2020-10-27,"[['Agarwal', 'Oshin', ''], ['Ge', 'Heming', ''], ['Shakeri', 'Siamak', ''], ['Al-Rfou', 'Rami', '']]"
1369014,2010.12684,Valentin Hofmann,"Valentin Hofmann, Janet B. Pierrehumbert, Hinrich Sch\""utze",Dynamic Contextualized Word Embeddings,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Static word embeddings that represent words by a single vector cannot capture
the variability of word meaning in different linguistic and extralinguistic
contexts. Building on prior work on contextualized and dynamic word embeddings,
we introduce dynamic contextualized word embeddings that represent words as a
function of both linguistic and extralinguistic context. Based on a pretrained
language model (PLM), dynamic contextualized word embeddings model time and
social space jointly, which makes them attractive for various tasks in the
computational social sciences. We highlight potential applications by means of
qualitative and quantitative analyses.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 22:02:40 GMT'}]",2020-10-27,"[['Hofmann', 'Valentin', ''], ['Pierrehumbert', 'Janet B.', ''], ['Schütze', 'Hinrich', '']]"
1369013,2010.12683,Jyun-Yu Jiang,"Jyun-Yu Jiang, Chenyan Xiong, Chia-Jung Lee and Wei Wang",Long Document Ranking with Query-Directed Sparse Transformer,"Accepted by EMNLP 2020, 12 pages, 5 figures",,,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The computing cost of transformer self-attention often necessitates breaking
long documents to fit in pretrained models in document ranking tasks. In this
paper, we design Query-Directed Sparse attention that induces IR-axiomatic
structures in transformer self-attention. Our model, QDS-Transformer, enforces
the principle properties desired in ranking: local contextualization,
hierarchical representation, and query-oriented proximity matching, while it
also enjoys efficiency from sparsity. Experiments on one fully supervised and
three few-shot TREC document ranking benchmarks demonstrate the consistent and
robust advantage of QDS-Transformer over previous approaches, as they either
retrofit long documents into BERT or use sparse attention without emphasizing
IR principles. We further quantify the computing complexity and demonstrates
that our sparse attention with TVM implementation is twice more efficient than
the fully-connected self-attention. All source codes, trained model, and
predictions of this work are available at
https://github.com/hallogameboy/QDS-Transformer.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 21:57:56 GMT'}]",2020-10-27,"[['Jiang', 'Jyun-Yu', ''], ['Xiong', 'Chenyan', ''], ['Lee', 'Chia-Jung', ''], ['Wang', 'Wei', '']]"
1369011,2010.12681,Armineh Nourbakhsh,"Natraj Raman, Armineh Nourbakhsh, Sameena Shah, Manuela Veloso",Robust Document Representations using Latent Topics and Metadata,"9 pages, 7 figures",,,,cs.CL cs.AI cs.LG cs.NE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Task specific fine-tuning of a pre-trained neural language model using a
custom softmax output layer is the de facto approach of late when dealing with
document classification problems. This technique is not adequate when labeled
examples are not available at training time and when the metadata artifacts in
a document must be exploited. We address these challenges by generating
document representations that capture both text and metadata artifacts in a
task agnostic manner. Instead of traditional auto-regressive or auto-encoding
based training, our novel self-supervised approach learns a soft-partition of
the input space when generating text embeddings. Specifically, we employ a
pre-learned topic model distribution as surrogate labels and construct a loss
function based on KL divergence. Our solution also incorporates metadata
explicitly rather than just augmenting them with text. The generated document
embeddings exhibit compositional characteristics and are directly used by
downstream classification tasks to create decision boundaries from a small
number of labeled examples, thereby eschewing complicated recognition methods.
We demonstrate through extensive evaluation that our proposed cross-model
fusion solution outperforms several competitive baselines on multiple datasets.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 21:52:38 GMT'}]",2020-10-27,"[['Raman', 'Natraj', ''], ['Nourbakhsh', 'Armineh', ''], ['Shah', 'Sameena', ''], ['Veloso', 'Manuela', '']]"
1369006,2010.12676,Chunchuan Lyu Mr.,"Chunchuan Lyu, Shay B. Cohen, Ivan Titov","A Differentiable Relaxation of Graph Segmentation and Alignment for AMR
  Parsing",,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Abstract Meaning Representations (AMR) are a broad-coverage semantic
formalism which represents sentence meaning as a directed acyclic graph. To
train most AMR parsers, one needs to segment the graph into subgraphs and align
each such subgraph to a word in a sentence; this is normally done at
preprocessing, relying on hand-crafted rules. In contrast, we treat both
alignment and segmentation as latent variables in our model and induce them as
part of end-to-end training.
  As marginalizing over the structured latent variables is infeasible, we use
the variational autoencoding framework.
  To ensure end-to-end differentiable optimization, we introduce a continuous
differentiable relaxation of the segmentation and alignment problems. We
observe that inducing segmentation yields substantial gains over using a
`greedy' segmentation heuristic. The performance of our method also approaches
that of a model that relies on \citet{Lyu2018AMRPA}'s segmentation rules, which
were hand-crafted to handle individual AMR constructions.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 21:22:50 GMT'}]",2020-10-27,"[['Lyu', 'Chunchuan', ''], ['Cohen', 'Shay B.', ''], ['Titov', 'Ivan', '']]"
1369005,2010.12675,David Gaddy,"David Gaddy, Alex Kouzemtchenko, Pavan Kumar Reddy, Prateek Kolhar,
  and Rushin Shah",Overcoming Conflicting Data for Model Updates,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we explore how to use a small amount of new data to update a
model when the desired output for some examples has changed. When making
updates in this way, one potential problem that arises is the presence of
conflicting data, or out-of-date labels in the original training set. To
evaluate the impact of this problem, we propose an experimental setup for
simulating changes to a neural semantic parser. We show that the presence of
conflicting data greatly hinders learning of an update, then explore several
methods to mitigate its effect. Our methods lead to large improvements in model
accuracy compared to a naive mixing strategy, and our best method closes 86% of
the accuracy gap between this baseline and an oracle upper bound.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 21:19:03 GMT'}]",2020-10-27,"[['Gaddy', 'David', ''], ['Kouzemtchenko', 'Alex', ''], ['Reddy', 'Pavan Kumar', ''], ['Kolhar', 'Prateek', ''], ['Shah', 'Rushin', '']]"
1369003,2010.12673,Liang Lu,"Liang Lu, Zhong Meng, Naoyuki Kanda, Jinyu Li, and Yifan Gong","On Minimum Word Error Rate Training of the Hybrid Autoregressive
  Transducer","5 pages, submitted to ICASSP 2021",,,,cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Hybrid Autoregressive Transducer (HAT) is a recently proposed end-to-end
acoustic model that extends the standard Recurrent Neural Network Transducer
(RNN-T) for the purpose of the external language model (LM) fusion. In HAT, the
blank probability and the label probability are estimated using two separate
probability distributions, which provides a more accurate solution for internal
LM score estimation, and thus works better when combining with an external LM.
Previous work mainly focuses on HAT model training with the negative
log-likelihood loss, while in this paper, we study the minimum word error rate
(MWER) training of HAT -- a criterion that is closer to the evaluation metric
for speech recognition, and has been successfully applied to other types of
end-to-end models such as sequence-to-sequence (S2S) and RNN-T models. From
experiments with around 30,000 hours of training data, we show that MWER
training can improve the accuracy of HAT models, while at the same time,
improving the robustness of the model against the decoding hyper-parameters
such as length normalization and decoding beam during inference.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 21:16:30 GMT'}]",2020-10-27,"[['Lu', 'Liang', ''], ['Meng', 'Zhong', ''], ['Kanda', 'Naoyuki', ''], ['Li', 'Jinyu', ''], ['Gong', 'Yifan', '']]"
1368988,2010.12658,Cheng Zhang,"Cheng Zhang, Yicheng Sun, Hejia Chen, Jie Wang",Generating Adequate Distractors for Multiple-Choice Questions,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents a novel approach to automatic generation of adequate
distractors for a given question-answer pair (QAP) generated from a given
article to form an adequate multiple-choice question (MCQ). Our method is a
combination of part-of-speech tagging, named-entity tagging, semantic-role
labeling, regular expressions, domain knowledge bases, word embeddings, word
edit distance, WordNet, and other algorithms. We use the US SAT (Scholastic
Assessment Test) practice reading tests as a dataset to produce QAPs and
generate three distractors for each QAP to form an MCQ. We show that, via
experiments and evaluations by human judges, each MCQ has at least one adequate
distractor and 84\% of MCQs have three adequate distractors.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 20:47:58 GMT'}]",2020-10-27,"[['Zhang', 'Cheng', ''], ['Sun', 'Yicheng', ''], ['Chen', 'Hejia', ''], ['Wang', 'Jie', '']]"
1368982,2010.12652,Orhan Firat,"Mahdis Mahdieh, Mia Xu Chen, Yuan Cao, Orhan Firat",Rapid Domain Adaptation for Machine Translation with Monolingual Data,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  One challenge of machine translation is how to quickly adapt to unseen
domains in face of surging events like COVID-19, in which case timely and
accurate translation of in-domain information into multiple languages is
critical but little parallel data is available yet. In this paper, we propose
an approach that enables rapid domain adaptation from the perspective of
unsupervised translation. Our proposed approach only requires in-domain
monolingual data and can be quickly applied to a preexisting translation system
trained on general domain, reaching significant gains on in-domain translation
quality with little or no drop on general-domain. We also propose an effective
procedure of simultaneous adaptation for multiple domains and languages. To the
best of our knowledge, this is the first attempt that aims to address
unsupervised multilingual domain adaptation.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 20:31:37 GMT'}]",2020-10-27,"[['Mahdieh', 'Mahdis', ''], ['Chen', 'Mia Xu', ''], ['Cao', 'Yuan', ''], ['Firat', 'Orhan', '']]"
1368973,2010.12643,Jacopo Staiano,"Arij Riabi, Thomas Scialom, Rachel Keraron, Beno\^it Sagot, Djam\'e
  Seddah, Jacopo Staiano","Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question
  Answering",7 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Coupled with the availability of large scale datasets, deep learning
architectures have enabled rapid progress on the Question Answering task.
However, most of those datasets are in English, and the performances of
state-of-the-art multilingual models are significantly lower when evaluated on
non-English data. Due to high data collection costs, it is not realistic to
obtain annotated data for each language one desires to support.
  We propose a method to improve the Cross-lingual Question Answering
performance without requiring additional annotated data, leveraging Question
Generation models to produce synthetic samples in a cross-lingual fashion. We
show that the proposed method allows to significantly outperform the baselines
trained on English data only. We report a new state-of-the-art on four
multilingual datasets: MLQA, XQuAD, SQuAD-it and PIAF (fr).
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 20:09:01 GMT'}]",2020-10-27,"[['Riabi', 'Arij', ''], ['Scialom', 'Thomas', ''], ['Keraron', 'Rachel', ''], ['Sagot', 'Benoît', ''], ['Seddah', 'Djamé', ''], ['Staiano', 'Jacopo', '']]"
1368969,2010.12639,Jesse Thomason,"Shurjo Banerjee, Jesse Thomason, Jason J. Corso","The RobotSlang Benchmark: Dialog-guided Robot Localization and
  Navigation",Conference on Robot Learning 2020,,,,cs.RO cs.AI cs.CL cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Autonomous robot systems for applications from search and rescue to assistive
guidance should be able to engage in natural language dialog with people. To
study such cooperative communication, we introduce Robot Simultaneous
Localization and Mapping with Natural Language (RobotSlang), a benchmark of 169
natural language dialogs between a human Driver controlling a robot and a human
Commander providing guidance towards navigation goals. In each trial, the pair
first cooperates to localize the robot on a global map visible to the
Commander, then the Driver follows Commander instructions to move the robot to
a sequence of target objects. We introduce a Localization from Dialog History
(LDH) and a Navigation from Dialog History (NDH) task where a learned agent is
given dialog and visual observations from the robot platform as input and must
localize in the global map or navigate towards the next target object,
respectively. RobotSlang is comprised of nearly 5k utterances and over 1k
minutes of robot camera and control streams. We present an initial model for
the NDH task, and show that an agent trained in simulation can follow the
RobotSlang dialog-based navigation instructions for controlling a physical
robot platform. Code and data are available at https://umrobotslang.github.io/.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 19:58:17 GMT'}]",2020-10-27,"[['Banerjee', 'Shurjo', ''], ['Thomason', 'Jesse', ''], ['Corso', 'Jason J.', '']]"
1368968,2010.12638,Hao Cheng,"Hao Cheng, Xiaodong Liu, Lis Pereira, Yaoliang Yu, Jianfeng Gao","Posterior Differential Regularization with f-divergence for Improving
  Model Robustness",,,,,cs.CL cs.LG stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We address the problem of enhancing model robustness through regularization.
Specifically, we focus on methods that regularize the model posterior
difference between clean and noisy inputs. Theoretically, we provide a
connection of two recent methods, Jacobian Regularization and Virtual
Adversarial Training, under this framework. Additionally, we generalize the
posterior differential regularization to the family of $f$-divergences and
characterize the overall regularization framework in terms of Jacobian matrix.
Empirically, we systematically compare those regularizations and standard BERT
training on a diverse set of tasks to provide a comprehensive profile of their
effect on model in-domain and out-of-domain generalization. For both fully
supervised and semi-supervised settings, our experiments show that regularizing
the posterior differential with $f$-divergence can result in well-improved
model robustness. In particular, with a proper $f$-divergence, a BERT-base
model can achieve comparable generalization as its BERT-large counterpart for
in-domain, adversarial and domain shift scenarios, indicating the great
potential of the proposed framework for boosting model generalization for NLP
models.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 19:58:01 GMT'}]",2020-10-27,"[['Cheng', 'Hao', ''], ['Liu', 'Xiaodong', ''], ['Pereira', 'Lis', ''], ['Yu', 'Yaoliang', ''], ['Gao', 'Jianfeng', '']]"
1368967,2010.12637,Dhivya Chandrasekaran,Dhivya Chandrasekaran and Vijay Mago,Domain Specific Complex Sentence (DCSC) Semantic Similarity Dataset,"12 pages, 4 figures, submitted to ""IEEE Transactions on Knowledge and
  Data Engineering",,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Semantic textual similarity is one of the open research challenges in the
field of Natural Language Processing. Extensive research has been carried out
in this field and near-perfect results are achieved by recent transformed based
models in existing benchmark datasets like STS dataset and SICK dataset. In
this paper, we study the sentences in these datasets and analyze the
sensitivity of various word embeddings with respect to the complexity of the
sentences. We propose a new benchmark dataset -- the Domain Specific Complex
Sentences (DSCS) dataset comprising of 50 sentence pairs with associated
semantic similarity values provided by 15 human annotators. Readability
analysis is performed to highlight the increase in complexity of the sentences
in the existing benchmark datasets and those in the proposed dataset. Further,
we perform a comparative analysis of the performance of various word embeddings
and the results justify the hypothesis that the performance of the word
embeddings decrease with an increase in complexity of the sentences.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 19:55:11 GMT'}]",2020-10-27,"[['Chandrasekaran', 'Dhivya', ''], ['Mago', 'Vijay', '']]"
1368957,2010.12627,Tobias Eder,"Tobias Eder, Viktor Hangya, Alexander Fraser",Anchor-based Bilingual Word Embeddings for Low-Resource Languages,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Bilingual word embeddings (BWEs) are useful for many cross-lingual
applications, such as bilingual lexicon induction (BLI) and cross-lingual
transfer learning. While recent methods have led to good quality BWEs for
different language pairs using only weak bilingual signals, they still rely on
an abundance of monolingual training data in both languages for their
performance. This becomes a problem especially in the case of low resource
languages where neither parallel bilingual corpora nor large monolingual
training data are available. This paper proposes a new approach for building
BWEs in which the vector space of the high resource source language is used as
a starting point for training an embedding space for the low resource target
language. By using the source vectors as anchors the vector spaces are
automatically aligned. We evaluate the resulting BWEs on BLI and show the
proposed method outperforms previous approaches in the low-resource setting by
a large margin. We show strong results on the standard English-German test pair
(using German to simulate low resource). We also show we can build useful BWEs
for English-Hiligaynon, a true low-resource language, where previous approaches
failed.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 19:17:00 GMT'}]",2020-10-27,"[['Eder', 'Tobias', ''], ['Hangya', 'Viktor', ''], ['Fraser', 'Alexander', '']]"
1369270,2010.12940,Arun Kumar Singh,"Sushant Dave, Arun Kumar Singh, Dr. Prathosh A. P. and Prof. Brejesh
  Lall","Neural Compound-Word (Sandhi) Generation and Splitting in Sanskrit
  Language","6 pages, 3 figures, CODS-COMAD 2021, IIIT Bangalore, India",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper describes neural network based approaches to the process of the
formation and splitting of word-compounding, respectively known as the Sandhi
and Vichchhed, in Sanskrit language. Sandhi is an important idea essential to
morphological analysis of Sanskrit texts. Sandhi leads to word transformations
at word boundaries. The rules of Sandhi formation are well defined but complex,
sometimes optional and in some cases, require knowledge about the nature of the
words being compounded. Sandhi split or Vichchhed is an even more difficult
task given its non uniqueness and context dependence. In this work, we propose
the route of formulating the problem as a sequence to sequence prediction task,
using modern deep learning techniques. Being the first fully data driven
technique, we demonstrate that our model has an accuracy better than the
existing methods on multiple standard datasets, despite not using any
additional lexical or morphological resources. The code is being made available
at https://github.com/IITD-DataScience/Sandhi_Prakarana
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 18:02:40 GMT'}]",2020-10-27,"[['Dave', 'Sushant', ''], ['Singh', 'Arun Kumar', ''], ['P.', 'Dr. Prathosh A.', ''], ['Lall', 'Prof. Brejesh', '']]"
1279698,2004.14928,Christos Baziotis,"Christos Baziotis, Barry Haddow, Alexandra Birch",Language Model Prior for Low-Resource Neural Machine Translation,Accepted at EMNLP 2020. Camera-ready version,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The scarcity of large parallel corpora is an important obstacle for neural
machine translation. A common solution is to exploit the knowledge of language
models (LM) trained on abundant monolingual data. In this work, we propose a
novel approach to incorporate a LM as prior in a neural translation model (TM).
Specifically, we add a regularization term, which pushes the output
distributions of the TM to be probable under the LM prior, while avoiding wrong
predictions when the TM ""disagrees"" with the LM. This objective relates to
knowledge distillation, where the LM can be viewed as teaching the TM about the
target language. The proposed approach does not compromise decoding speed,
because the LM is used only at training time, unlike previous work that
requires it during inference. We present an analysis of the effects that
different methods have on the distributions of the TM. Results on two
low-resource machine translation datasets show clear improvements even with
limited monolingual data.
","[{'version': 'v1', 'created': 'Thu, 30 Apr 2020 16:29:56 GMT'}, {'version': 'v2', 'created': 'Wed, 21 Oct 2020 21:39:55 GMT'}, {'version': 'v3', 'created': 'Mon, 26 Oct 2020 08:56:46 GMT'}]",2020-10-27,"[['Baziotis', 'Christos', ''], ['Haddow', 'Barry', ''], ['Birch', 'Alexandra', '']]"
1369971,2010.13641,Timo Schick,"Timo Schick, Helmut Schmid, Hinrich Sch\""utze","Automatically Identifying Words That Can Serve as Labels for Few-Shot
  Text Classification",To appear at COLING 2020,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A recent approach for few-shot text classification is to convert textual
inputs to cloze questions that contain some form of task description, process
them with a pretrained language model and map the predicted words to labels.
Manually defining this mapping between words and labels requires both domain
expertise and an understanding of the language model's abilities. To mitigate
this issue, we devise an approach that automatically finds such a mapping given
small amounts of training data. For a number of tasks, the mapping found by our
approach performs almost as well as hand-crafted label-to-word mappings.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 14:56:22 GMT'}]",2020-10-27,"[['Schick', 'Timo', ''], ['Schmid', 'Helmut', ''], ['Schütze', 'Hinrich', '']]"
1369734,2010.13404,Rifat Rahman,Rifat Rahman,"Robust and Consistent Estimation of Word Embedding for Bangla Language
  by fine-tuning Word2Vec Model","6 pages, 8 figures, submitted to 23rd International Conference of
  Computer and Information Technology (ICCIT). IEEE, 2020",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Word embedding or vector representation of word holds syntactical and
semantic characteristics of word which can be an informative feature for any
machine learning based models of natural language processing. There are several
deep learning based models for the vectorization of words like word2vec,
fasttext, gensim, glove etc. In this study, we analysis word2vec model for
learning word vectors by tuning different hyper-parameters and present the most
effective word embedding for Bangla language. For testing the performances of
different word embeddings induced by fine-tuning of word2vec model, we perform
both intrinsic and extrinsic evaluations. We cluster the word vectors to
examine the relational similarity of words and also use different word
embeddings as the feature of news article classifier for extrinsic evaluation.
From our experiment, we discover that the word vectors with 300 dimension,
generated from 'skip-gram' method of word2vec model using the sliding window
size of 4, are giving the most robust vector representations for Bangla
language.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 08:00:48 GMT'}]",2020-10-27,"[['Rahman', 'Rifat', '']]"
1369745,2010.13415,Yucheng Wang,"Yucheng Wang, Bowen Yu, Yueyang Zhang, Tingwen Liu, Hongsong Zhu and
  Limin Sun","TPLinker: Single-stage Joint Extraction of Entities and Relations
  Through Token Pair Linking",COLING 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Extracting entities and relations from unstructured text has attracted
increasing attention in recent years but remains challenging, due to the
intrinsic difficulty in identifying overlapping relations with shared entities.
Prior works show that joint learning can result in a noticeable performance
gain. However, they usually involve sequential interrelated steps and suffer
from the problem of exposure bias. At training time, they predict with the
ground truth conditions while at inference it has to make extraction from
scratch. This discrepancy leads to error accumulation. To mitigate the issue,
we propose in this paper a one-stage joint extraction model, namely, TPLinker,
which is capable of discovering overlapping relations sharing one or both
entities while immune from the exposure bias. TPLinker formulates joint
extraction as a token pair linking problem and introduces a novel handshaking
tagging scheme that aligns the boundary tokens of entity pairs under each
relation type. Experiment results show that TPLinker performs significantly
better on overlapping and multiple relation extraction, and achieves
state-of-the-art performance on two public datasets.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 08:35:06 GMT'}]",2020-10-27,"[['Wang', 'Yucheng', ''], ['Yu', 'Bowen', ''], ['Zhang', 'Yueyang', ''], ['Liu', 'Tingwen', ''], ['Zhu', 'Hongsong', ''], ['Sun', 'Limin', '']]"
1281590,2005.01795,Kundan Krishna,"Kundan Krishna, Sopan Khosla, Jeffrey P. Bigham, Zachary C. Lipton",Generating SOAP Notes from Doctor-Patient Conversations,,,,,cs.CL cs.AI cs.LG stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Following each patient visit, physicians must draft a detailed clinical
summary called a SOAP note. Moreover, with electronic health records, these
notes must be digitized. Despite the benefits of this documentation, their
creation remains an onerous process, contributing to increasing physician
burnout. In this paper, we present the first study to evaluate complete
pipelines to train summarization models to generate these notes from
conversations between physicians and patients. We benefit from a dataset that,
along with transcripts and paired SOAP notes, consists of annotations marking
noteworthy utterances that support each summary sentence. We decompose the
problem into extractive and abstractive subtasks, exploring a spectrum of
approaches according to how much they demand from each component. We observe
that the performance improves constantly as the extractive subtask is made more
complex - an observation that we also replicate on the well-known AMI meeting
summarization dataset. Our best performing method first (i) extracts noteworthy
utterances via multi-label classification, assigning each to summary
section(s); (ii) clusters noteworthy utterances on a per-section basis; and
(iii) generates the summary sentences by conditioning on the corresponding
cluster and the subsection of the SOAP sentence to be generated. Compared to an
end-to-end approach that generates the full SOAP note from the full
conversation, our approach improves by around 8 ROUGE-1 points.
","[{'version': 'v1', 'created': 'Mon, 4 May 2020 19:10:26 GMT'}, {'version': 'v2', 'created': 'Sat, 24 Oct 2020 04:09:10 GMT'}]",2020-10-27,"[['Krishna', 'Kundan', ''], ['Khosla', 'Sopan', ''], ['Bigham', 'Jeffrey P.', ''], ['Lipton', 'Zachary C.', '']]"
1369845,2010.13515,Andrea Asperti,Andrea Asperti and Stefano Dal Bianco,Syllabification of the Divine Comedy,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We provide a syllabification algorithm for the Divine Comedy using techniques
from probabilistic and constraint programming. We particularly focus on the
synalephe, addressed in terms of the ""propensity"" of a word to take part in a
synalephe with adjacent words. We jointly provide an online vocabulary
containing, for each word, information about its syllabification, the location
of the tonic accent, and the aforementioned synalephe propensity, on the left
and right sides. The algorithm is intrinsically nondeterministic, producing
different possible syllabifications for each verse, with different likelihoods;
metric constraints relative to accents on the 10th, 4th and 6th syllables are
used to further reduce the solution space. The most likely syllabification is
hence returned as output. We believe that this work could be a major milestone
for a lot of different investigations. From the point of view of digital
humanities it opens new perspectives on computer assisted analysis of digital
sources, comprising automated detection of anomalous and problematic cases,
metric clustering of verses and their categorization, or more foundational
investigations addressing e.g. the phonetic roles of consonants and vowels.
From the point of view of text processing and deep learning, information about
syllabification and the location of accents opens a wide range of exciting
perspectives, from the possibility of automatic learning syllabification of
words and verses, to the improvement of generative models, aware of metric
issues, and more respectful of the expected musicality.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 12:14:14 GMT'}]",2020-10-27,"[['Asperti', 'Andrea', ''], ['Bianco', 'Stefano Dal', '']]"
1369874,2010.13544,Zhenzhen Li,"Zhenzhen Li, Jian-Yun Nie, Benyou Wang, Pan Du, Yuhan Zhang, Lixin
  Zou, and Dongsheng Li","Meta-Learning for Neural Relation Classification with Distant
  Supervision","10 pages, 7 figures; corrected one encoding error in CIKM pdf","In Proceedings of CIKM, pp. 815-824. 2020",10.1145/3340531.3412039,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Distant supervision provides a means to create a large number of weakly
labeled data at low cost for relation classification. However, the resulting
labeled instances are very noisy, containing data with wrong labels. Many
approaches have been proposed to select a subset of reliable instances for
neural model training, but they still suffer from noisy labeling problem or
underutilization of the weakly-labeled data. To better select more reliable
training instances, we introduce a small amount of manually labeled data as
reference to guide the selection process. In this paper, we propose a
meta-learning based approach, which learns to reweight noisy training data
under the guidance of reference data. As the clean reference data is usually
very small, we propose to augment it by dynamically distilling the most
reliable elite instances from the noisy data. Experiments on several datasets
demonstrate that the reference data can effectively guide the selection of
training data, and our augmented approach consistently improves the performance
of relation classification comparing to the existing state-of-the-art methods.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 12:52:28 GMT'}]",2020-10-27,"[['Li', 'Zhenzhen', ''], ['Nie', 'Jian-Yun', ''], ['Wang', 'Benyou', ''], ['Du', 'Pan', ''], ['Zhang', 'Yuhan', ''], ['Zou', 'Lixin', ''], ['Li', 'Dongsheng', '']]"
1369886,2010.13556,Yu Zhang,"Yu Zhang, Xiusi Chen, Yu Meng, Jiawei Han","Hierarchical Metadata-Aware Document Categorization under Weak
  Supervision",9 pages; Accepted to WSDM 2021,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Categorizing documents into a given label hierarchy is intuitively appealing
due to the ubiquity of hierarchical topic structures in massive text corpora.
Although related studies have achieved satisfying performance in fully
supervised hierarchical document classification, they usually require massive
human-annotated training data and only utilize text information. However, in
many domains, (1) annotations are quite expensive where very few training
samples can be acquired; (2) documents are accompanied by metadata information.
Hence, this paper studies how to integrate the label hierarchy, metadata, and
text signals for document categorization under weak supervision. We develop
HiMeCat, an embedding-based generative framework for our task. Specifically, we
propose a novel joint representation learning module that allows simultaneous
modeling of category dependencies, metadata information and textual semantics,
and we introduce a data augmentation module that hierarchically synthesizes
training documents to complement the original, small-scale training set. Our
experiments demonstrate a consistent improvement of HiMeCat over competitive
baselines and validate the contribution of our representation learning and data
augmentation modules.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 13:07:56 GMT'}]",2020-10-27,"[['Zhang', 'Yu', ''], ['Chen', 'Xiusi', ''], ['Meng', 'Yu', ''], ['Han', 'Jiawei', '']]"
1369915,2010.13585,Reza Marzban,"Reza Marzban, Christopher John Crick",Interpreting convolutional networks trained on textual data,"9 pages, 6 figures, 5 tables",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  There have been many advances in the artificial intelligence field due to the
emergence of deep learning. In almost all sub-fields, artificial neural
networks have reached or exceeded human-level performance. However, most of the
models are not interpretable. As a result, it is hard to trust their decisions,
especially in life and death scenarios. In recent years, there has been a
movement toward creating explainable artificial intelligence, but most work to
date has concentrated on image processing models, as it is easier for humans to
perceive visual patterns. There has been little work in other fields like
natural language processing. In this paper, we train a convolutional model on
textual data and analyze the global logic of the model by studying its filter
values. In the end, we find the most important words in our corpus to our
models logic and remove the rest (95%). New models trained on just the 5% most
important words can achieve the same performance as the original model while
reducing training time by more than half. Approaches such as this will help us
to understand NLP models, explain their decisions according to their word
choices, and improve them by finding blind spots and biases.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 20:12:05 GMT'}]",2020-10-27,"[['Marzban', 'Reza', ''], ['Crick', 'Christopher John', '']]"
1369918,2010.13588,Ozan Caglayan,"Ozan Caglayan, Pranava Madhyastha, Lucia Specia","Curious Case of Language Generation Evaluation Metrics: A Cautionary
  Tale","7 pages, accepted to COLING 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automatic evaluation of language generation systems is a well-studied problem
in Natural Language Processing. While novel metrics are proposed every year, a
few popular metrics remain as the de facto metrics to evaluate tasks such as
image captioning and machine translation, despite their known limitations. This
is partly due to ease of use, and partly because researchers expect to see them
and know how to interpret them. In this paper, we urge the community for more
careful consideration of how they automatically evaluate their models by
demonstrating important failure cases on multiple datasets, language pairs and
tasks. Our experiments show that metrics (i) usually prefer system outputs to
human-authored texts, (ii) can be insensitive to correct translations of rare
words, (iii) can yield surprisingly high scores when given a single sentence as
system output for the entire test set.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 13:57:20 GMT'}]",2020-10-27,"[['Caglayan', 'Ozan', ''], ['Madhyastha', 'Pranava', ''], ['Specia', 'Lucia', '']]"
1305141,2006.10627,Qian Liu,"Qian Liu, Shengnan An, Jian-Guang Lou, Bei Chen, Zeqi Lin, Yan Gao,
  Bin Zhou, Nanning Zheng, Dongmei Zhang",Compositional Generalization by Learning Analytical Expressions,To appear in NeurIPS 2020 (Spotlight),,,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Compositional generalization is a basic and essential intellective capability
of human beings, which allows us to recombine known parts readily. However,
existing neural network based models have been proven to be extremely deficient
in such a capability. Inspired by work in cognition which argues
compositionality can be captured by variable slots with symbolic functions, we
present a refreshing view that connects a memory-augmented neural model with
analytical expressions, to achieve compositional generalization. Our model
consists of two cooperative neural modules, Composer and Solver, fitting well
with the cognitive argument while being able to be trained in an end-to-end
manner via a hierarchical reinforcement learning algorithm. Experiments on the
well-known benchmark SCAN demonstrate that our model seizes a great ability of
compositional generalization, solving all challenges addressed by previous
works with 100% accuracies.
","[{'version': 'v1', 'created': 'Thu, 18 Jun 2020 15:50:57 GMT'}, {'version': 'v2', 'created': 'Sat, 24 Oct 2020 03:47:49 GMT'}]",2020-10-27,"[['Liu', 'Qian', ''], ['An', 'Shengnan', ''], ['Lou', 'Jian-Guang', ''], ['Chen', 'Bei', ''], ['Lin', 'Zeqi', ''], ['Gao', 'Yan', ''], ['Zhou', 'Bin', ''], ['Zheng', 'Nanning', ''], ['Zhang', 'Dongmei', '']]"
1306638,2006.12124,Anne Wu,"Anne Wu, Changhan Wang, Juan Pino, Jiatao Gu",Self-Supervised Representations Improve End-to-End Speech Translation,Accepted to INTERSPEECH 2020,,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  End-to-end speech-to-text translation can provide a simpler and smaller
system but is facing the challenge of data scarcity. Pre-training methods can
leverage unlabeled data and have been shown to be effective on data-scarce
settings. In this work, we explore whether self-supervised pre-trained speech
representations can benefit the speech translation task in both high- and
low-resource settings, whether they can transfer well to other languages, and
whether they can be effectively combined with other common methods that help
improve low-resource end-to-end speech translation such as using a pre-trained
high-resource speech recognition system. We demonstrate that self-supervised
pre-trained features can consistently improve the translation performance, and
cross-lingual transfer allows to extend to a variety of languages without or
with little tuning.
","[{'version': 'v1', 'created': 'Mon, 22 Jun 2020 10:28:38 GMT'}, {'version': 'v2', 'created': 'Sun, 25 Oct 2020 03:31:15 GMT'}]",2020-10-27,"[['Wu', 'Anne', ''], ['Wang', 'Changhan', ''], ['Pino', 'Juan', ''], ['Gu', 'Jiatao', '']]"
1369967,2010.13637,Peng Gao,"Peng Gao, Fei Shao, Xiaoyuan Liu, Xusheng Xiao, Zheng Qin, Fengyuan
  Xu, Prateek Mittal, Sanjeev R. Kulkarni, Dawn Song",Enabling Efficient Cyber Threat Hunting With Cyber Threat Intelligence,,,,,cs.CR cs.CL cs.DB,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Log-based cyber threat hunting has emerged as an important solution to
counter sophisticated cyber attacks. However, existing approaches require
non-trivial efforts of manual query construction and have overlooked the rich
external knowledge about threat behaviors provided by open-source Cyber Threat
Intelligence (OSCTI). To bridge the gap, we propose EffHunter, a system that
facilitates cyber threat hunting in computer systems using OSCTI. Built upon
mature system auditing frameworks, EffHunter provides (1) an unsupervised,
light-weight, and accurate NLP pipeline that extracts structured threat
behaviors from unstructured OSCTI text, (2) a concise and expressive
domain-specific query language, TBQL, to hunt for malicious system activities,
(3) a query synthesis mechanism that automatically synthesizes a TBQL query for
threat hunting from the extracted threat behaviors, and (4) an efficient query
execution engine to search the big audit logging data. Evaluations on a broad
set of attack cases demonstrate the accuracy and efficiency of EffHunter in
enabling practical threat hunting.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 14:54:01 GMT'}]",2020-10-27,"[['Gao', 'Peng', ''], ['Shao', 'Fei', ''], ['Liu', 'Xiaoyuan', ''], ['Xiao', 'Xusheng', ''], ['Qin', 'Zheng', ''], ['Xu', 'Fengyuan', ''], ['Mittal', 'Prateek', ''], ['Kulkarni', 'Sanjeev R.', ''], ['Song', 'Dawn', '']]"
1369988,2010.13658,Baosong Yang,"Tianchi Bi and Liang Yao and Baosong Yang and Haibo Zhang and Weihua
  Luo and Boxing Chen","Constraint Translation Candidates: A Bridge between Neural Query
  Translation and Cross-lingual Information Retrieval",SIGIR eCom 2020,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Query translation (QT) is a key component in cross-lingual information
retrieval system (CLIR). With the help of deep learning, neural machine
translation (NMT) has shown promising results on various tasks. However, NMT is
generally trained with large-scale out-of-domain data rather than in-domain
query translation pairs. Besides, the translation model lacks a mechanism at
the inference time to guarantee the generated words to match the search index.
The two shortages of QT result in readable texts for human but inadequate
candidates for the downstream retrieval task. In this paper, we propose a novel
approach to alleviate these problems by limiting the open target vocabulary
search space of QT to a set of important words mined from search index
database. The constraint translation candidates are employed at both of
training and inference time, thus guiding the translation model to learn and
generate well performing target queries. The proposed methods are exploited and
examined in a real-word CLIR system--Aliexpress e-Commerce search engine.
Experimental results demonstrate that our approach yields better performance on
both translation quality and retrieval accuracy than the strong NMT baseline.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 15:27:51 GMT'}]",2020-10-27,"[['Bi', 'Tianchi', ''], ['Yao', 'Liang', ''], ['Yang', 'Baosong', ''], ['Zhang', 'Haibo', ''], ['Luo', 'Weihua', ''], ['Chen', 'Boxing', '']]"
1369989,2010.13659,Baosong Yang,"Liang Yao and Baosong Yang and Haibo Zhang and Weihua Luo and Boxing
  Chen","Exploiting Neural Query Translation into Cross Lingual Information
  Retrieval",SIGIR eCom 2020,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As a crucial role in cross-language information retrieval (CLIR), query
translation has three main challenges: 1) the adequacy of translation; 2) the
lack of in-domain parallel training data; and 3) the requisite of low latency.
To this end, existing CLIR systems mainly exploit statistical-based machine
translation (SMT) rather than the advanced neural machine translation (NMT),
limiting the further improvements on both translation and retrieval quality. In
this paper, we investigate how to exploit neural query translation model into
CLIR system. Specifically, we propose a novel data augmentation method that
extracts query translation pairs according to user clickthrough data, thus to
alleviate the problem of domain-adaptation in NMT. Then, we introduce an
asynchronous strategy which is able to leverage the advantages of the real-time
in SMT and the veracity in NMT. Experimental results reveal that the proposed
approach yields better retrieval quality than strong baselines and can be well
applied into a real-world CLIR system, i.e. Aliexpress e-Commerce search
engine. Readers can examine and test their cases on our website:
https://aliexpress.com .
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 15:28:19 GMT'}]",2020-10-27,"[['Yao', 'Liang', ''], ['Yang', 'Baosong', ''], ['Zhang', 'Haibo', ''], ['Luo', 'Weihua', ''], ['Chen', 'Boxing', '']]"
1370004,2010.13674,Christina Niklaus,"Thiemo Wambsganss, Christina Niklaus, Matthias S\""ollner, Siegfried
  Handschuh, Jan Marco Leimeister",A Corpus for Argumentative Writing Support in German,"to be published in The 28th International Conference on Computational
  Linguistics (COLING 2020)",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we present a novel annotation approach to capture claims and
premises of arguments and their relations in student-written persuasive peer
reviews on business models in German language. We propose an annotation scheme
based on annotation guidelines that allows to model claims and premises as well
as support and attack relations for capturing the structure of argumentative
discourse in student-written peer reviews. We conduct an annotation study with
three annotators on 50 persuasive essays to evaluate our annotation scheme. The
obtained inter-rater agreement of $\alpha=0.57$ for argument components and
$\alpha=0.49$ for argumentative relations indicates that the proposed
annotation scheme successfully guides annotators to moderate agreement.
Finally, we present our freely available corpus of 1,000 persuasive
student-written peer reviews on business models and our annotation guidelines
to encourage future research on the design and development of argumentative
writing support systems for students.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 15:52:12 GMT'}]",2020-10-27,"[['Wambsganss', 'Thiemo', ''], ['Niklaus', 'Christina', ''], ['Söllner', 'Matthias', ''], ['Handschuh', 'Siegfried', ''], ['Leimeister', 'Jan Marco', '']]"
1370018,2010.13688,Alexander Kalinowski,"Alexander Kalinowski, Yuan An","A Survey of Embedding Space Alignment Methods for Language and Knowledge
  Graphs","27 pages, 2 figures",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Neural embedding approaches have become a staple in the fields of computer
vision, natural language processing, and more recently, graph analytics. Given
the pervasive nature of these algorithms, the natural question becomes how to
exploit the embedding spaces to map, or align, embeddings of different data
sources. To this end, we survey the current research landscape on word,
sentence and knowledge graph embedding algorithms. We provide a classification
of the relevant alignment techniques and discuss benchmark datasets used in
this field of research. By gathering these diverse approaches into a singular
survey, we hope to further motivate research into alignment of embedding spaces
of varied data types and sources.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 16:08:13 GMT'}]",2020-10-27,"[['Kalinowski', 'Alexander', ''], ['An', 'Yuan', '']]"
1279583,2004.14813,Liying Cheng,"Liying Cheng, Dekun Wu, Lidong Bing, Yan Zhang, Zhanming Jie, Wei Lu,
  Luo Si",ENT-DESC: Entity Description Generation by Exploring Knowledge Graph,"11 pages, 6 figures, accepted by EMNLP 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Previous works on knowledge-to-text generation take as input a few RDF
triples or key-value pairs conveying the knowledge of some entities to generate
a natural language description. Existing datasets, such as WIKIBIO, WebNLG, and
E2E, basically have a good alignment between an input triple/pair set and its
output text. However, in practice, the input knowledge could be more than
enough, since the output description may only cover the most significant
knowledge. In this paper, we introduce a large-scale and challenging dataset to
facilitate the study of such a practical scenario in KG-to-text. Our dataset
involves retrieving abundant knowledge of various types of main entities from a
large knowledge graph (KG), which makes the current graph-to-sequence models
severely suffer from the problems of information loss and parameter explosion
while generating the descriptions. We address these challenges by proposing a
multi-graph structure that is able to represent the original graph information
more comprehensively. Furthermore, we also incorporate aggregation methods that
learn to extract the rich graph information. Extensive experiments demonstrate
the effectiveness of our model architecture.
","[{'version': 'v1', 'created': 'Thu, 30 Apr 2020 14:16:19 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 07:33:32 GMT'}]",2020-10-27,"[['Cheng', 'Liying', ''], ['Wu', 'Dekun', ''], ['Bing', 'Lidong', ''], ['Zhang', 'Yan', ''], ['Jie', 'Zhanming', ''], ['Lu', 'Wei', ''], ['Si', 'Luo', '']]"
1295328,2006.00814,Maha Elbayad,"Maha Elbayad, Michael Ustaszewski, Emmanuelle Esperan\c{c}a-Rodier,
  Francis Brunet Manquat, Laurent Besacier","Online Versus Offline NMT Quality: An In-depth Analysis on
  English-German and German-English",Accepted at COLING 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We conduct in this work an evaluation study comparing offline and online
neural machine translation architectures. Two sequence-to-sequence models:
convolutional Pervasive Attention (Elbayad et al. 2018) and attention-based
Transformer (Vaswani et al. 2017) are considered. We investigate, for both
architectures, the impact of online decoding constraints on the translation
quality through a carefully designed human evaluation on English-German and
German-English language pairs, the latter being particularly sensitive to
latency constraints. The evaluation results allow us to identify the strengths
and shortcomings of each model when we shift to the online setup.
","[{'version': 'v1', 'created': 'Mon, 1 Jun 2020 09:43:54 GMT'}, {'version': 'v2', 'created': 'Sat, 24 Oct 2020 13:36:00 GMT'}]",2020-10-27,"[['Elbayad', 'Maha', ''], ['Ustaszewski', 'Michael', ''], ['Esperança-Rodier', 'Emmanuelle', ''], ['Manquat', 'Francis Brunet', ''], ['Besacier', 'Laurent', '']]"
1369303,2010.12973,Andros Tjandra,"Andros Tjandra, Ruoming Pang, Yu Zhang, Shigeki Karita","Unsupervised Learning of Disentangled Speech Content and Style
  Representation",Submitted to ICASSP 2021,,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present an approach for unsupervised learning of speech representation
disentangling contents and styles. Our model consists of: (1) a local encoder
that captures per-frame information; (2) a global encoder that captures
per-utterance information; and (3) a conditional decoder that reconstructs
speech given local and global latent variables. Our experiments show that (1)
the local latent variables encode speech contents, as reconstructed speech can
be recognized by ASR with low word error rates (WER), even with a different
global encoding; (2) the global latent variables encode speaker style, as
reconstructed speech shares speaker identity with the source utterance of the
global encoding. Additionally, we demonstrate an useful application from our
pre-trained model, where we can train a speaker recognition model from the
global latent variables and achieve high accuracy by fine-tuning with as few
data as one label per speaker.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 20:16:03 GMT'}]",2020-10-27,"[['Tjandra', 'Andros', ''], ['Pang', 'Ruoming', ''], ['Zhang', 'Yu', ''], ['Karita', 'Shigeki', '']]"
1279693,2004.14923,Arturo Oncevay,"Arturo Oncevay, Barry Haddow, Alexandra Birch","Bridging Linguistic Typology and Multilingual Machine Translation with
  Multi-View Language Representations",Accepted at EMNLP 2020. Camera-ready version,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Sparse language vectors from linguistic typology databases and learned
embeddings from tasks like multilingual machine translation have been
investigated in isolation, without analysing how they could benefit from each
other's language characterisation. We propose to fuse both views using singular
vector canonical correlation analysis and study what kind of information is
induced from each source. By inferring typological features and language
phylogenies, we observe that our representations embed typology and strengthen
correlations with language relationships. We then take advantage of our
multi-view language vector space for multilingual machine translation, where we
achieve competitive overall translation accuracy in tasks that require
information about language similarities, such as language clustering and
ranking candidates for multilingual transfer. With our method, which is also
released as a tool, we can easily project and assess new languages without
expensive retraining of massive multilingual or ranking models, which are major
disadvantages of related approaches.
","[{'version': 'v1', 'created': 'Thu, 30 Apr 2020 16:25:39 GMT'}, {'version': 'v2', 'created': 'Sun, 25 Oct 2020 20:51:46 GMT'}]",2020-10-27,"[['Oncevay', 'Arturo', ''], ['Haddow', 'Barry', ''], ['Birch', 'Alexandra', '']]"
1286997,2005.07202,Shoya Wada,"Shoya Wada, Toshihiro Takeda, Shiro Manabe, Shozo Konishi, Jun
  Kamohara, and Yasushi Matsumura","A pre-training technique to localize medical BERT and to enhance
  biomedical BERT","We made the pre-trained weights of ouBioBERT and the source code for
  fine-tuning freely available at
  https://github.com/sy-wada/blue_benchmark_with_transformers",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Bidirectional Encoder Representations from Transformers (BERT) models for
medical specialties, such as BioBERT and clinicalBERT, have significantly
improved in performing biomedical text mining tasks and have enabled extracting
valuable information from biomedical literature; however, only English speakers
benefit due to the significant scarcity of high-quality medical documents, such
as PubMed, in each language. Therefore, we propose a method to train a
high-performance BERT model using a small corpus. We introduce the method to
train a BERT model on a small medical corpus both in English and in Japanese,
and we present the evaluation of each model in terms of the biomedical language
understanding evaluation (BLUE) benchmark and the medical document
classification task in Japanese, respectively. After confirming their
satisfactory performances, we applied our method to develop a model comparable
to the publicly available models. OuBioBERT, short for Bidirectional Encoder
Representations from Transformers for Biomedical Text Mining by Osaka
University, achieved the best score in terms of the BLUE benchmark. The total
score is 1.1 points above that of BioBERT and 0.3 points above that of the
ablated model trained without our proposed method. This proposed technique is
an effective approach to develop localized medical BERT models and to enhance
domain-specific models in the biomedical domain.
","[{'version': 'v1', 'created': 'Thu, 14 May 2020 18:00:01 GMT'}, {'version': 'v2', 'created': 'Sun, 25 Oct 2020 04:22:24 GMT'}]",2020-10-27,"[['Wada', 'Shoya', ''], ['Takeda', 'Toshihiro', ''], ['Manabe', 'Shiro', ''], ['Konishi', 'Shozo', ''], ['Kamohara', 'Jun', ''], ['Matsumura', 'Yasushi', '']]"
1369982,2010.13652,Thomas Winters,"Thomas Winters, Pieter Delobelle",Dutch Humor Detection by Generating Negative Examples,"Accepted at the Proceedings of the 32st Benelux Conference on
  Artificial Intelligence (BNAIC 2020) and the 29th Belgian Dutch Conference on
  Machine Learning (Benelearn 2020)",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Detecting if a text is humorous is a hard task to do computationally, as it
usually requires linguistic and common sense insights. In machine learning,
humor detection is usually modeled as a binary classification task, trained to
predict if the given text is a joke or another type of text. Rather than using
completely different non-humorous texts, we propose using text generation
algorithms for imitating the original joke dataset to increase the difficulty
for the learning algorithm. We constructed several different joke and non-joke
datasets to test the humor detection abilities of different language
technologies. In particular, we compare the humor detection capabilities of
classic neural network approaches with the state-of-the-art Dutch language
model RobBERT. In doing so, we create and compare the first Dutch humor
detection systems. We found that while other language models perform well when
the non-jokes came from completely different domains, RobBERT was the only one
that was able to distinguish jokes from generated negative examples. This
performance illustrates the usefulness of using text generation to create
negative datasets for humor recognition, and also shows that transformer models
are a large step forward in humor detection.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 15:15:10 GMT'}]",2020-10-27,"[['Winters', 'Thomas', ''], ['Delobelle', 'Pieter', '']]"
1369721,2010.13391,Amir Pouran Ben Veyseh,"Amir Pouran Ben Veyseh, Tuan Ngo Nguyen, Thien Huu Nguyen","Graph Transformer Networks with Syntactic and Semantic Structures for
  Event Argument Extraction",accepted at EMNLP 2020 findings,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The goal of Event Argument Extraction (EAE) is to find the role of each
entity mention for a given event trigger word. It has been shown in the
previous works that the syntactic structures of the sentences are helpful for
the deep learning models for EAE. However, a major problem in such prior works
is that they fail to exploit the semantic structures of the sentences to induce
effective representations for EAE. Consequently, in this work, we propose a
novel model for EAE that exploits both syntactic and semantic structures of the
sentences with the Graph Transformer Networks (GTNs) to learn more effective
sentence structures for EAE. In addition, we introduce a novel inductive bias
based on information bottleneck to improve generalization of the EAE models.
Extensive experiments are performed to demonstrate the benefits of the proposed
model, leading to state-of-the-art performance for EAE on standard datasets.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 07:41:40 GMT'}]",2020-10-27,"[['Veyseh', 'Amir Pouran Ben', ''], ['Nguyen', 'Tuan Ngo', ''], ['Nguyen', 'Thien Huu', '']]"
1369787,2010.13457,Henry Turner,"Henry Turner, Giulio Lovisotto and Ivan Martinovic","Speaker Anonymization with Distribution-Preserving X-Vector Generation
  for the VoicePrivacy Challenge 2020",,,,,cs.SD cs.CL cs.CR eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we present a Distribution-Preserving Voice Anonymization
technique, as our submission to the VoicePrivacy Challenge 2020. We notice that
the challenge baseline system generates fake X-vectors which are very similar
to each other, significantly more so than those extracted from organic
speakers. This difference arises from averaging many X-vectors from a pool of
speakers in the anonymization processs, causing a loss of information. We
propose a new method to generate fake X-vectors which overcomes these
limitations by preserving the distributional properties of X-vectors and their
intra-similarity. We use population data to learn the properties of the
X-vector space, before fitting a generative model which we use to sample fake
X-vectors. We show how this approach generates X-vectors that more closely
follow the expected intra-similarity distribution of organic speaker X-vectors.
Our method can be easily integrated with others as the anonymization component
of the system and removes the need to distribute a pool of speakers to use
during the anonymization. Our approach leads to an increase in EER of up to
16.8\% in males and 8.4\% in females in scenarios where enrollment and trial
utterances are anonymized versus the baseline solution, demonstrating the
diversity of our generated voices.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 09:53:56 GMT'}]",2020-10-27,"[['Turner', 'Henry', ''], ['Lovisotto', 'Giulio', ''], ['Martinovic', 'Ivan', '']]"
1369712,2010.13382,Young Jin Kim,Young Jin Kim and Hany Hassan Awadalla,"FastFormers: Highly Efficient Transformer Models for Natural Language
  Understanding",Accepted to SustaiNLP 2020 at EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Transformer-based models are the state-of-the-art for Natural Language
Understanding (NLU) applications. Models are getting bigger and better on
various tasks. However, Transformer models remain computationally challenging
since they are not efficient at inference-time compared to traditional
approaches. In this paper, we present FastFormers, a set of recipes to achieve
efficient inference-time performance for Transformer-based models on various
NLU tasks. We show how carefully utilizing knowledge distillation, structured
pruning and numerical optimization can lead to drastic improvements on
inference efficiency. We provide effective recipes that can guide practitioners
to choose the best settings for various NLU tasks and pretrained models.
Applying the proposed recipes to the SuperGLUE benchmark, we achieve from 9.8x
up to 233.9x speed-up compared to out-of-the-box models on CPU. On GPU, we also
achieve up to 12.4x speed-up with the presented methods. We show that
FastFormers can drastically reduce cost of serving 100 million requests from
4,223 USD to just 18 USD on an Azure F16s_v2 instance. This translates to a
sustainable runtime by reducing energy consumption 6.9x - 125.8x according to
the metrics used in the SustaiNLP 2020 shared task.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 07:25:15 GMT'}]",2020-10-27,"[['Kim', 'Young Jin', ''], ['Awadalla', 'Hany Hassan', '']]"
1369339,2010.13009,Jianguo Zhang,"Jian-Guo Zhang, Kazuma Hashimoto, Wenhao Liu, Chien-Sheng Wu, Yao Wan,
  Philip S. Yu, Richard Socher, Caiming Xiong","Discriminative Nearest Neighbor Few-Shot Intent Detection by
  Transferring Natural Language Inference","19 pages, accepted by EMNLP 2020 main conference as a long paper.
  Code will be available at https://github.com/salesforce/DNNC-few-shot-intent",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Intent detection is one of the core components of goal-oriented dialog
systems, and detecting out-of-scope (OOS) intents is also a practically
important skill. Few-shot learning is attracting much attention to mitigate
data scarcity, but OOS detection becomes even more challenging. In this paper,
we present a simple yet effective approach, discriminative nearest neighbor
classification with deep self-attention. Unlike softmax classifiers, we
leverage BERT-style pairwise encoding to train a binary classifier that
estimates the best matched training example for a user input. We propose to
boost the discriminative ability by transferring a natural language inference
(NLI) model. Our extensive experiments on a large-scale multi-domain intent
detection task show that our method achieves more stable and accurate in-domain
and OOS detection accuracy than RoBERTa-based classifiers and embedding-based
nearest neighbor approaches. More notably, the NLI transfer enables our 10-shot
model to perform competitively with 50-shot or even full-shot classifiers,
while we can keep the inference time constant by leveraging a faster embedding
retrieval model.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 00:39:32 GMT'}]",2020-10-27,"[['Zhang', 'Jian-Guo', ''], ['Hashimoto', 'Kazuma', ''], ['Liu', 'Wenhao', ''], ['Wu', 'Chien-Sheng', ''], ['Wan', 'Yao', ''], ['Yu', 'Philip S.', ''], ['Socher', 'Richard', ''], ['Xiong', 'Caiming', '']]"
1369358,2010.13028,Sayyed Zahiri,Sayyed M. Zahiri and Ali Ahmadvand,"CRAB: Class Representation Attentive BERT for Hate Speech Identification
  in Social Media",,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In recent years, social media platforms have hosted an explosion of hate
speech and objectionable content. The urgent need for effective automatic hate
speech detection models have drawn remarkable investment from companies and
researchers. Social media posts are generally short and their semantics could
drastically be altered by even a single token. Thus, it is crucial for this
task to learn context-aware input representations, and consider relevancy
scores between input embeddings and class representations as an additional
signal. To accommodate these needs, this paper introduces CRAB (Class
Representation Attentive BERT), a neural model for detecting hate speech in
social media. The model benefits from two semantic representations: (i)
trainable token-wise and sentence-wise class representations, and (ii)
contextualized input embeddings from state-of-the-art BERT encoder. To
investigate effectiveness of CRAB, we train our model on Twitter data and
compare it against strong baselines. Our results show that CRAB achieves 1.89%
relative improved Macro-averaged F1 over state-of-the-art baseline. The results
of this research open an opportunity for the future research on automated
abusive behavior detection in social media
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 04:11:30 GMT'}]",2020-10-27,"[['Zahiri', 'Sayyed M.', ''], ['Ahmadvand', 'Ali', '']]"
1328086,2008.00364,Qian Li,"Qian Li, Hao Peng, Jianxin Li, Congying Xia, Renyu Yang, Lichao Sun,
  Philip S. Yu, Lifang He",A Survey on Text Classification: From Shallow to Deep Learning,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Text classification is the most fundamental and essential task in natural
language processing. The last decade has seen a surge of research in this area
due to the unprecedented success of deep learning. Numerous methods, datasets,
and evaluation metrics have been proposed in the literature, raising the need
for a comprehensive and updated survey. This paper fills the gap by reviewing
the state of the art approaches from 1961 to 2020, focusing on models from
shallow to deep learning. We create a taxonomy for text classification
according to the text involved and the models used for feature extraction and
classification. We then discuss each of these categories in detail, dealing
with both the technical developments and benchmark datasets that support tests
of predictions. A comprehensive comparison between different techniques, as
well as identifying the pros and cons of various evaluation metrics are also
provided in this survey. Finally, we conclude by summarizing key implications,
future research directions, and the challenges facing the research area.
","[{'version': 'v1', 'created': 'Sun, 2 Aug 2020 00:09:03 GMT'}, {'version': 'v2', 'created': 'Tue, 4 Aug 2020 06:13:59 GMT'}, {'version': 'v3', 'created': 'Sun, 11 Oct 2020 04:15:57 GMT'}, {'version': 'v4', 'created': 'Tue, 13 Oct 2020 07:05:36 GMT'}, {'version': 'v5', 'created': 'Mon, 26 Oct 2020 02:46:42 GMT'}]",2020-10-27,"[['Li', 'Qian', ''], ['Peng', 'Hao', ''], ['Li', 'Jianxin', ''], ['Xia', 'Congying', ''], ['Yang', 'Renyu', ''], ['Sun', 'Lichao', ''], ['Yu', 'Philip S.', ''], ['He', 'Lifang', '']]"
1369361,2010.13031,Jian Du,"Xiaoying Li, Suyuan Peng, Jian Du","Towards Medical Knowmetrics: Representing and Computing Medical
  Knowledge using Semantic Predications as the Knowledge Unit and the
  Uncertainty as the Knowledge Context",,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  In China, Prof. Hongzhou Zhao and Zeyuan Liu are the pioneers of the concept
""knowledge unit"" and ""knowmetrics"" for measuring knowledge. However, the
definition of ""computable knowledge object"" remains controversial so far in
different fields. For example, it is defined as 1) quantitative scientific
concept in natural science and engineering, 2) knowledge point in the field of
education research, and 3) semantic predications, i.e.,
Subject-Predicate-Object (SPO) triples in biomedical fields. The Semantic
MEDLINE Database (SemMedDB), a high-quality public repository of SPO triples
extracted from medical literature, provides a basic data infrastructure for
measuring medical knowledge. In general, the study of extracting SPO triples as
computable knowledge unit from unstructured scientific text has been
overwhelmingly focusing on scientific knowledge per se. Since the SPO triples
would be possibly extracted from hypothetical, speculative statements or even
conflicting and contradictory assertions, the knowledge status (i.e., the
uncertainty), which serves as an integral and critical part of scientific
knowledge has been largely overlooked. This article aims to put forward a
framework for Medical Knowmetrics using the SPO triples as the knowledge unit
and the uncertainty as the knowledge context. The lung cancer publications
dataset is used to validate the proposed framework. The uncertainty of medical
knowledge and how its status evolves over time indirectly reflect the strength
of competing knowledge claims, and the probability of certainty for a given SPO
triple. We try to discuss the new insights using the uncertainty-centric
approaches to detect research fronts, and identify knowledge claims with high
certainty level, in order to improve the efficacy of knowledge-driven decision
support.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 04:27:43 GMT'}]",2020-10-27,"[['Li', 'Xiaoying', ''], ['Peng', 'Suyuan', ''], ['Du', 'Jian', '']]"
1369370,2010.13040,Zhaoning Li,Zhaoning Li and Jiangtao Ren,Fine-tuning ERNIE for chest abnormal imaging signs extraction,"30 pages, 5 figures, 8 tables",J. Biomed. Inform. 108 (2020),10.1016/j.jbi.2020.103492,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Chest imaging reports describe the results of chest radiography procedures.
Automatic extraction of abnormal imaging signs from chest imaging reports has a
pivotal role in clinical research and a wide range of downstream medical tasks.
However, there are few studies on information extraction from Chinese chest
imaging reports. In this paper, we formulate chest abnormal imaging sign
extraction as a sequence tagging and matching problem. On this basis, we
propose a transferred abnormal imaging signs extractor with pretrained ERNIE as
the backbone, named EASON (fine-tuning ERNIE with CRF for Abnormal Signs
ExtractiON), which can address the problem of data insufficiency. In addition,
to assign the attributes (the body part and degree) to corresponding abnormal
imaging signs from the results of the sequence tagging model, we design a
simple but effective tag2relation algorithm based on the nature of chest
imaging report text. We evaluate our method on the corpus provided by a medical
big data company, and the experimental results demonstrate that our method
achieves significant and consistent improvement compared to other baselines.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 05:18:14 GMT'}]",2020-10-27,"[['Li', 'Zhaoning', ''], ['Ren', 'Jiangtao', '']]"
1369377,2010.13047,Hirofumi Inaguma,"Hirofumi Inaguma, Yosuke Higuchi, Kevin Duh, Tatsuya Kawahara, Shinji
  Watanabe","Orthros: Non-autoregressive End-to-end Speech Translation with
  Dual-decoder",,,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Fast inference speed is an important goal towards real-world deployment of
speech translation (ST) systems. End-to-end (E2E) models based on the
encoder-decoder architecture are more suitable for this goal than traditional
cascaded systems, but their effectiveness regarding decoding speed has not been
explored so far. Inspired by recent progress in non-autoregressive (NAR)
methods in text-based translation, which generates target tokens in parallel by
eliminating conditional dependencies, we study the problem of NAR decoding for
E2E-ST. We propose a novel NAR E2E-ST framework, Orthoros, in which both NAR
and autoregressive (AR) decoders are jointly trained on the shared speech
encoder. The latter is used for selecting better translation among various
length candidates generated from the former, which dramatically improves the
effectiveness of a large length beam with negligible overhead. We further
investigate effective length prediction methods from speech inputs and the
impact of vocabulary sizes. Experiments on four benchmarks show the
effectiveness of the proposed method in improving inference speed while
maintaining competitive translation quality compared to state-of-the-art AR
E2E-ST systems.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 06:35:30 GMT'}]",2020-10-27,"[['Inaguma', 'Hirofumi', ''], ['Higuchi', 'Yosuke', ''], ['Duh', 'Kevin', ''], ['Kawahara', 'Tatsuya', ''], ['Watanabe', 'Shinji', '']]"
1369719,2010.13389,Amir Pouran Ben Veyseh,"Amir Pouran Ben Veyseh, Nasim Nour, Franck Dernoncourt, Quan Hung
  Tran, Dejing Dou, Thien Huu Nguyen","Improving Aspect-based Sentiment Analysis with Gated Graph Convolutional
  Networks and Syntax-based Regulation",accepted at EMNLP 2020 findings,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Aspect-based Sentiment Analysis (ABSA) seeks to predict the sentiment
polarity of a sentence toward a specific aspect. Recently, it has been shown
that dependency trees can be integrated into deep learning models to produce
the state-of-the-art performance for ABSA. However, these models tend to
compute the hidden/representation vectors without considering the aspect terms
and fail to benefit from the overall contextual importance scores of the words
that can be obtained from the dependency tree for ABSA. In this work, we
propose a novel graph-based deep learning model to overcome these two issues of
the prior work on ABSA. In our model, gate vectors are generated from the
representation vectors of the aspect terms to customize the hidden vectors of
the graph-based models toward the aspect terms. In addition, we propose a
mechanism to obtain the importance scores for each word in the sentences based
on the dependency trees that are then injected into the model to improve the
representation vectors for ABSA. The proposed model achieves the
state-of-the-art performance on three benchmark datasets.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 07:36:24 GMT'}]",2020-10-27,"[['Veyseh', 'Amir Pouran Ben', ''], ['Nour', 'Nasim', ''], ['Dernoncourt', 'Franck', ''], ['Tran', 'Quan Hung', ''], ['Dou', 'Dejing', ''], ['Nguyen', 'Thien Huu', '']]"
1369387,2010.13057,Sathvik Nair,"Sathvik Nair, Mahesh Srinivasan, Stephan Meylan","Contextualized Word Embeddings Encode Aspects of Human-Like Word Sense
  Knowledge","To appear in proceedings of the Cognitive Aspects of the Lexicon
  Workshop at the 28th International Conference on Computational Linguistics
  (COLING)",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Understanding context-dependent variation in word meanings is a key aspect of
human language comprehension supported by the lexicon. Lexicographic resources
(e.g., WordNet) capture only some of this context-dependent variation; for
example, they often do not encode how closely senses, or discretized word
meanings, are related to one another. Our work investigates whether recent
advances in NLP, specifically contextualized word embeddings, capture
human-like distinctions between English word senses, such as polysemy and
homonymy. We collect data from a behavioral, web-based experiment, in which
participants provide judgments of the relatedness of multiple WordNet senses of
a word in a two-dimensional spatial arrangement task. We find that
participants' judgments of the relatedness between senses are correlated with
distances between senses in the BERT embedding space. Homonymous senses (e.g.,
bat as mammal vs. bat as sports equipment) are reliably more distant from one
another in the embedding space than polysemous ones (e.g., chicken as animal
vs. chicken as meat). Our findings point towards the potential utility of
continuous-space representations of sense meanings.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 07:56:52 GMT'}]",2020-10-27,"[['Nair', 'Sathvik', ''], ['Srinivasan', 'Mahesh', ''], ['Meylan', 'Stephan', '']]"
1369392,2010.13062,Zhixiang Li,"Mengzhe Li, Yudan Wang, Ying Zhao and Zhixiang Li","Transgender Community Sentiment Analysis from Social Media Data: A
  Natural Language Processing Approach","5 pages, 1 figures",,,,cs.CL,http://creativecommons.org/publicdomain/zero/1.0/,"  Transgender community is experiencing a huge disparity in mental health
conditions compared with the general population. Interpreting the social medial
data posted by transgender people may help us understand the sentiments of
these sexual minority groups better and apply early interventions. In this
study, we manually categorize 300 social media comments posted by transgender
people to the sentiment of negative, positive, and neutral. 5 machine learning
algorithms and 2 deep neural networks are adopted to build sentiment analysis
classifiers based on the annotated data. Results show that our annotations are
reliable with a high Cohen's Kappa score over 0.8 across all three classes.
LSTM model yields an optimal performance of accuracy over 0.85 and AUC of
0.876. Our next step will focus on using advanced natural language processing
algorithms on a larger annotated dataset.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 08:13:34 GMT'}]",2020-10-27,"[['Li', 'Mengzhe', ''], ['Wang', 'Yudan', ''], ['Zhao', 'Ying', ''], ['Li', 'Zhixiang', '']]"
1369379,2010.13049,Gongqi Lin,"Gongqi Lin, Yuan Miao, Xiaoyong Yang, Wenwu Ou, Lizhen Cui, Wei Guo,
  Chunyan Miao",Commonsense knowledge adversarial dataset that challenges ELECTRA,To appear in ICARCV2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Commonsense knowledge is critical in human reading comprehension. While
machine comprehension has made significant progress in recent years, the
ability in handling commonsense knowledge remains limited. Synonyms are one of
the most widely used commonsense knowledge. Constructing adversarial dataset is
an important approach to find weak points of machine comprehension models and
support the design of solutions. To investigate machine comprehension models'
ability in handling the commonsense knowledge, we created a Question and Answer
Dataset with common knowledge of Synonyms (QADS). QADS are questions generated
based on SQuAD 2.0 by applying commonsense knowledge of synonyms. The synonyms
are extracted from WordNet. Words often have multiple meanings and synonyms. We
used an enhanced Lesk algorithm to perform word sense disambiguation to
identify synonyms for the context. ELECTRA achieves the state-of-art result on
the SQuAD 2.0 dataset in 2019. With scale, ELECTRA can achieve similar
performance as BERT does. However, QADS shows that ELECTRA has little ability
to handle commonsense knowledge of synonyms. In our experiment, ELECTRA-small
can achieve 70% accuracy on SQuAD 2.0, but only 20% on QADS. ELECTRA-large did
not perform much better. Its accuracy on SQuAD 2.0 is 88% but dropped
significantly to 26% on QADS. In our earlier experiments, BERT, although also
failed badly on QADS, was not as bad as ELECTRA. The result shows that even
top-performing NLP models have little ability to handle commonsense knowledge
which is essential in reading comprehension.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 07:17:45 GMT'}]",2020-10-27,"[['Lin', 'Gongqi', ''], ['Miao', 'Yuan', ''], ['Yang', 'Xiaoyong', ''], ['Ou', 'Wenwu', ''], ['Cui', 'Lizhen', ''], ['Guo', 'Wei', ''], ['Miao', 'Chunyan', '']]"
1369600,2010.13270,Yosuke Higuchi,"Yosuke Higuchi, Hirofumi Inaguma, Shinji Watanabe, Tetsuji Ogawa,
  Tetsunori Kobayashi",Improved Mask-CTC for Non-Autoregressive End-to-End ASR,Submitted to ICASSP2021,,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  For real-world deployment of automatic speech recognition (ASR), the system
is desired to be capable of fast inference while relieving the requirement of
computational resources. The recently proposed end-to-end ASR system based on
mask-predict with connectionist temporal classification (CTC), Mask-CTC,
fulfills this demand by generating tokens in a non-autoregressive fashion.
While Mask-CTC achieves remarkably fast inference speed, its recognition
performance falls behind that of conventional autoregressive (AR) systems. To
boost the performance of Mask-CTC, we first propose to enhance the encoder
network architecture by employing a recently proposed architecture called
Conformer. Next, we propose new training and decoding methods by introducing
auxiliary objective to predict the length of a partial target sequence, which
allows the model to delete or insert tokens during inference. Experimental
results on different ASR tasks show that the proposed approaches improve
Mask-CTC significantly, outperforming a standard CTC model (15.5% $\rightarrow$
9.1% WER on WSJ). Moreover, Mask-CTC now achieves competitive results to AR
models with no degradation of inference speed ($<$ 0.1 RTF using CPU). We also
show a potential application of Mask-CTC to end-to-end speech translation.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 01:22:35 GMT'}]",2020-10-27,"[['Higuchi', 'Yosuke', ''], ['Inaguma', 'Hirofumi', ''], ['Watanabe', 'Shinji', ''], ['Ogawa', 'Tetsuji', ''], ['Kobayashi', 'Tetsunori', '']]"
1321824,2007.10310,Changhan Wang,"Changhan Wang, Anne Wu, Juan Pino",CoVoST 2 and Massively Multilingual Speech-to-Text Translation,,,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Speech translation has recently become an increasingly popular topic of
research, partly due to the development of benchmark datasets. Nevertheless,
current datasets cover a limited number of languages. With the aim to foster
research in massive multilingual speech translation and speech translation for
low resource language pairs, we release CoVoST 2, a large-scale multilingual
speech translation corpus covering translations from 21 languages into English
and from English into 15 languages. This represents the largest open dataset
available to date from total volume and language coverage perspective. Data
sanity checks provide evidence about the quality of the data, which is released
under CC0 license. We also provide extensive speech recognition, bilingual and
multilingual machine translation and speech translation baselines with
open-source implementation.
","[{'version': 'v1', 'created': 'Mon, 20 Jul 2020 17:53:35 GMT'}, {'version': 'v2', 'created': 'Thu, 20 Aug 2020 17:53:10 GMT'}, {'version': 'v3', 'created': 'Sat, 24 Oct 2020 06:07:01 GMT'}]",2020-10-27,"[['Wang', 'Changhan', ''], ['Wu', 'Anne', ''], ['Pino', 'Juan', '']]"
1369708,2010.13378,Amir Pouran Ben Veyseh,"Amir Pouran Ben Veyseh, Nasim Nouri, Franck Dernoncourt, Dejing Dou,
  Thien Huu Nguyen","Introducing Syntactic Structures into Target Opinion Word Extraction
  with Deep Learning",accepted at EMNLP 2020 main conference,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Targeted opinion word extraction (TOWE) is a sub-task of aspect based
sentiment analysis (ABSA) which aims to find the opinion words for a given
aspect-term in a sentence. Despite their success for TOWE, the current deep
learning models fail to exploit the syntactic information of the sentences that
have been proved to be useful for TOWE in the prior research. In this work, we
propose to incorporate the syntactic structures of the sentences into the deep
learning models for TOWE, leveraging the syntax-based opinion possibility
scores and the syntactic connections between the words. We also introduce a
novel regularization technique to improve the performance of the deep learning
models based on the representation distinctions between the words in TOWE. The
proposed model is extensively analyzed and achieves the state-of-the-art
performance on four benchmark datasets.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 07:13:17 GMT'}]",2020-10-27,"[['Veyseh', 'Amir Pouran Ben', ''], ['Nouri', 'Nasim', ''], ['Dernoncourt', 'Franck', ''], ['Dou', 'Dejing', ''], ['Nguyen', 'Thien Huu', '']]"
1274534,2004.09764,Fang Xianghong,"Xianghong Fang and Haoli Bai and Zenglin Xu and Michael Lyu and Irwin
  King",Discrete Auto-regressive Variational Attention Models for Text Modeling,"10 pages, 4 figures",,,,cs.LG cs.CL stat.ML,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Variational autoencoders (VAEs) have been widely applied for text modeling.
In practice, however, they are troubled by two challenges: information
underrepresentation and posterior collapse. The former arises as only the last
hidden state of LSTM encoder is transformed into the latent space, which is
generally insufficient to summarize the data. The latter is a long-standing
problem during the training of VAEs as the optimization is trapped to a
disastrous local optimum. In this paper, we propose Discrete Auto-regressive
Variational Attention Model (DAVAM) to address the challenges. Specifically, we
introduce an auto-regressive variational attention approach to enrich the
latent space by effectively capturing the semantic dependency from the input.
We further design discrete latent space for the variational attention and
mathematically show that our model is free from posterior collapse. Extensive
experiments on language modeling tasks demonstrate the superiority of DAVAM
against several VAE counterparts.
","[{'version': 'v1', 'created': 'Tue, 21 Apr 2020 05:49:04 GMT'}, {'version': 'v2', 'created': 'Sun, 25 Oct 2020 08:02:24 GMT'}]",2020-10-27,"[['Fang', 'Xianghong', ''], ['Bai', 'Haoli', ''], ['Xu', 'Zenglin', ''], ['Lyu', 'Michael', ''], ['King', 'Irwin', '']]"
1326856,2007.15342,Ramon Ferrer i Cancho,"Ramon Ferrer-i-Cancho, Carlos G\'omez-Rodr\'iguez, Juan Luis Esteban
  and Llu\'is Alemany-Puig",The optimality of syntactic dependency distances,"results on the zeta score have been corrected; format of the article
  has changed; some figures/tables have been resized; typos corrected",,,,cs.CL cs.DM physics.soc-ph,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  It is often stated that human languages, as other biological systems, are
shaped by cost-cutting pressures but, to what extent? Attempts to quantify the
degree of optimality of languages by means of an optimality score have been
scarce and focused mostly on English. Here we recast the problem of the
optimality of the word order of a sentence as an optimization problem on a
spatial network where the vertices are words, arcs indicate syntactic
dependencies and the space is defined by the linear order of the words in the
sentence. We introduce a new score to quantify the cognitive pressure to reduce
the distance between linked words in a sentence. The analysis of sentences from
93 languages representing 19 linguistic families reveals that half of languages
are optimized to a 70% or more. The score indicates that distances are not
significantly reduced in a few languages and confirms two theoretical
predictions, i.e. that longer sentences are more optimized and that distances
are more likely to be longer than expected by chance in short sentences. We
present a new hierarchical ranking of languages by their degree of
optimization. The statistical advantages of the new score call for a
reevaluation of the evolution of dependency distance over time in languages as
well as the relationship between dependency distance and linguistic competence.
Finally, the principles behind the design of the score can be extended to
develop more powerful normalizations of topological distances or physical
distances in more dimensions.
","[{'version': 'v1', 'created': 'Thu, 30 Jul 2020 09:40:41 GMT'}, {'version': 'v2', 'created': 'Sun, 25 Oct 2020 22:15:22 GMT'}]",2020-10-27,"[['Ferrer-i-Cancho', 'Ramon', ''], ['Gómez-Rodríguez', 'Carlos', ''], ['Esteban', 'Juan Luis', ''], ['Alemany-Puig', 'Lluís', '']]"
1369522,2010.13192,Alexandra Chronopoulou,"Alexandra Chronopoulou, Dario Stojanovski, Viktor Hangya, Alexander
  Fraser","The LMU Munich System for the WMT 2020 Unsupervised Machine Translation
  Shared Task",WMT Unsupervised Shared Task 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper describes the submission of LMU Munich to the WMT 2020
unsupervised shared task, in two language directions, German<->Upper Sorbian.
Our core unsupervised neural machine translation (UNMT) system follows the
strategy of Chronopoulou et al. (2020), using a monolingual pretrained language
generation model (on German) and fine-tuning it on both German and Upper
Sorbian, before initializing a UNMT model, which is trained with online
backtranslation. Pseudo-parallel data obtained from an unsupervised statistical
machine translation (USMT) system is used to fine-tune the UNMT model. We also
apply BPE-Dropout to the low resource (Upper Sorbian) data to obtain a more
robust system. We additionally experiment with residual adapters and find them
useful in the Upper Sorbian->German direction. We explore sampling during
backtranslation and curriculum learning to use SMT translations in a more
principled way. Finally, we ensemble our best-performing systems and reach a
BLEU score of 32.4 on German->Upper Sorbian and 35.2 on Upper Sorbian->German.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 19:04:03 GMT'}]",2020-10-27,"[['Chronopoulou', 'Alexandra', ''], ['Stojanovski', 'Dario', ''], ['Hangya', 'Viktor', ''], ['Fraser', 'Alexander', '']]"
1280356,2005.00561,Anna Rogers,"Sai Prasanna, Anna Rogers, Anna Rumshisky","When BERT Plays the Lottery, All Tickets Are Winning",EMNLP 2020 camera-ready,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Transformer-based models were shown to be reducible to a smaller number
of self-attention heads and layers. We consider this phenomenon from the
perspective of the lottery ticket hypothesis, using both structured and
magnitude pruning. For fine-tuned BERT, we show that (a) it is possible to find
subnetworks achieving performance that is comparable with that of the full
model, and (b) similarly-sized subnetworks sampled from the rest of the model
perform worse. Strikingly, with structured pruning even the worst possible
subnetworks remain highly trainable, indicating that most pre-trained BERT
weights are potentially useful. We also study the ""good"" subnetworks to see if
their success can be attributed to superior linguistic knowledge, but find them
unstable, and not explained by meaningful self-attention patterns.
","[{'version': 'v1', 'created': 'Fri, 1 May 2020 18:24:42 GMT'}, {'version': 'v2', 'created': 'Sat, 24 Oct 2020 10:15:27 GMT'}]",2020-10-27,"[['Prasanna', 'Sai', ''], ['Rogers', 'Anna', ''], ['Rumshisky', 'Anna', '']]"
1369498,2010.13168,Tenzin Singhay Bhotia,"Vaibhav Kumar, Tenzin Singhay Bhotia, Vaibhav Kumar","Fair Embedding Engine: A Library for Analyzing and Mitigating Gender
  Bias in Word Embeddings","6 pages, 3 figures",,,,cs.CL cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Non-contextual word embedding models have been shown to inherit human-like
stereotypical biases of gender, race and religion from the training corpora. To
counter this issue, a large body of research has emerged which aims to mitigate
these biases while keeping the syntactic and semantic utility of embeddings
intact. This paper describes Fair Embedding Engine (FEE), a library for
analysing and mitigating gender bias in word embeddings. FEE combines various
state of the art techniques for quantifying, visualising and mitigating gender
bias in word embeddings under a standard abstraction. FEE will aid
practitioners in fast track analysis of existing debiasing methods on their
embedding models. Further, it will allow rapid prototyping of new methods by
evaluating their performance on a suite of standard metrics.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 17:31:12 GMT'}]",2020-10-27,"[['Kumar', 'Vaibhav', ''], ['Bhotia', 'Tenzin Singhay', ''], ['Kumar', 'Vaibhav', '']]"
1369458,2010.13128,Mokanarangan Thayaparan,"Mokanarangan Thayaparan, Marco Valentino, Andr\'e Freitas","ExplanationLP: Abductive Reasoning for Explainable Science Question
  Answering",,,,,cs.AI cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a novel approach for answering and explaining multiple-choice
science questions by reasoning on grounding and abstract inference chains. This
paper frames question answering as an abductive reasoning problem, constructing
plausible explanations for each choice and then selecting the candidate with
the best explanation as the final answer. Our system, ExplanationLP, elicits
explanations by constructing a weighted graph of relevant facts for each
candidate answer and extracting the facts that satisfy certain structural and
semantic constraints. To extract the explanations, we employ a linear
programming formalism designed to select the optimal subgraph. The graphs'
weighting function is composed of a set of parameters, which we fine-tune to
optimize answer selection performance. We carry out our experiments on the
WorldTree and ARC-Challenge corpus to empirically demonstrate the following
conclusions: (1) Grounding-Abstract inference chains provides the semantic
control to perform explainable abductive reasoning (2) Efficiency and
robustness in learning with a fewer number of parameters by outperforming
contemporary explainable and transformer-based approaches in a similar setting
(3) Generalisability by outperforming SOTA explainable approaches on general
science question sets.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 14:49:24 GMT'}]",2020-10-27,"[['Thayaparan', 'Mokanarangan', ''], ['Valentino', 'Marco', ''], ['Freitas', 'André', '']]"
1369435,2010.13105,Gyuwan Kim,"Seongbin Kim, Gyuwan Kim, Seongjin Shin, Sangmin Lee","Two-stage Textual Knowledge Distillation to Speech Encoder for Spoken
  Language Understanding","Preprint; 5 pages, 1 figure",,,,cs.CL cs.LG cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  End-to-end approaches open a new way for more accurate and efficient spoken
language understanding (SLU) systems by alleviating the drawbacks of
traditional pipeline systems. Previous works exploit textual information for an
SLU model via pre-training with automatic speech recognition or fine-tuning
with knowledge distillation. To utilize textual information more effectively,
this work proposes a two-stage textual knowledge distillation method that
matches utterance-level representations and predicted logits of two modalities
during pre-training and fine-tuning, sequentially. We use vq-wav2vec BERT as a
speech encoder because it captures general and rich features. Furthermore, we
improve the performance, especially in a low-resource scenario, with data
augmentation methods by randomly masking spans of discrete audio tokens and
contextualized hidden representations. Consequently, we push the
state-of-the-art on the Fluent Speech Commands, achieving 99.7% test accuracy
in the full dataset setting and 99.5% in the 10% subset setting. Throughout the
ablation studies, we empirically verify that all used methods are crucial to
the final performance, providing the best practice for spoken language
understanding. Code to reproduce our results will be available upon
publication.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 12:36:05 GMT'}]",2020-10-27,"[['Kim', 'Seongbin', ''], ['Kim', 'Gyuwan', ''], ['Shin', 'Seongjin', ''], ['Lee', 'Sangmin', '']]"
1267434,2004.02664,Qingyu Zhou,"Qingyu Zhou, Furu Wei, Ming Zhou","At Which Level Should We Extract? An Empirical Analysis on Extractive
  Document Summarization",To appear at COLING 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Extractive methods have been proven effective in automatic document
summarization. Previous works perform this task by identifying informative
contents at sentence level. However, it is unclear whether performing
extraction at sentence level is the best solution. In this work, we show that
unnecessity and redundancy issues exist when extracting full sentences, and
extracting sub-sentential units is a promising alternative. Specifically, we
propose extracting sub-sentential units based on the constituency parsing tree.
A neural extractive model which leverages the sub-sentential information and
extracts them is presented. Extensive experiments and analyses show that
extracting sub-sentential units performs competitively comparing to full
sentence extraction under the evaluation of both automatic and human
evaluations. Hopefully, our work could provide some inspiration of the basic
extraction units in extractive summarization for future research.
","[{'version': 'v1', 'created': 'Mon, 6 Apr 2020 13:35:10 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 08:35:19 GMT'}]",2020-10-27,"[['Zhou', 'Qingyu', ''], ['Wei', 'Furu', ''], ['Zhou', 'Ming', '']]"
1370795,2010.14465,Marta R. Costa-juss\`a,Marta R. Costa-juss\`a and Christine Basta and Gerard I. G\'allego,Evaluating Gender Bias in Speech Translation,"Preprint, Submitted to ICASSP 2021",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The scientific community is more and more aware of the necessity to embrace
pluralism and consistently represent major and minor social groups. In this
direction, there is an urgent need to provide evaluation sets and protocols to
measure existing biases in our automatic systems. This paper introduces WinoST,
a new freely available challenge set for evaluating gender bias in speech
translation. WinoST is the speech version of WinoMT which is an MT challenge
set and both follow an evaluation protocol to measure gender accuracy. Using a
state-of-the-art end-to-end speech translation system, we report the gender
bias evaluation on 4 language pairs, and we show that gender accuracy in speech
translation is more than 23% lower than in MT.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 17:24:27 GMT'}]",2020-10-28,"[['Costa-jussà', 'Marta R.', ''], ['Basta', 'Christine', ''], ['Gállego', 'Gerard I.', '']]"
1370809,2010.14479,Sugat Chaturvedi,"Rochana Chaturvedi, Sugat Chaturvedi",It's All in the Name: A Character Based Approach To Infer Religion,,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Demographic inference from text has received a surge of attention in the
field of natural language processing in the last decade. In this paper, we use
personal names to infer religion in South Asia - where religion is a salient
social division, and yet, disaggregated data on it remains scarce. Existing
work predicts religion using dictionary based method, and therefore, can not
classify unseen names. We use character based models which learn character
patterns and, therefore, can classify unseen names as well with high accuracy.
These models are also much faster and can easily be scaled to large data sets.
We improve our classifier by combining the name of an individual with that of
their parent/spouse and achieve remarkably high accuracy. Finally, we trace the
classification decisions of a convolutional neural network model using
layer-wise relevance propagation which can explain the predictions of complex
non-linear classifiers and circumvent their purported black box nature. We show
how character patterns learned by the classifier are rooted in the linguistic
origins of names.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 17:38:11 GMT'}]",2020-10-28,"[['Chaturvedi', 'Rochana', ''], ['Chaturvedi', 'Sugat', '']]"
960680,1803.10547,Nurendra Choudhary,"Nurendra Choudhary, Rajat Singh, Ishita Bindlish and Manish
  Shrivastava",Neural Network Architecture for Credibility Assessment of Textual Claims,"Best Paper Award at 19th International Conference on Computational
  Linguistics and Intelligent Text Processing, March 2018, Hanoi, Vietnam",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Text articles with false claims, especially news, have recently become
aggravating for the Internet users. These articles are in wide circulation and
readers face difficulty discerning fact from fiction. Previous work on
credibility assessment has focused on factual analysis and linguistic features.
The task's main challenge is the distinction between the features of true and
false articles. In this paper, we propose a novel approach called Credibility
Outcome (CREDO) which aims at scoring the credibility of an article in an open
domain setting.
  CREDO consists of different modules for capturing various features
responsible for the credibility of an article. These features includes
credibility of the article's source and author, semantic similarity between the
article and related credible articles retrieved from a knowledge base, and
sentiments conveyed by the article. A neural network architecture learns the
contribution of each of these modules to the overall credibility of an article.
Experiments on Snopes dataset reveals that CREDO outperforms the
state-of-the-art approaches based on linguistic features.
","[{'version': 'v1', 'created': 'Wed, 28 Mar 2018 11:50:32 GMT'}, {'version': 'v2', 'created': 'Fri, 30 Mar 2018 10:42:04 GMT'}, {'version': 'v3', 'created': 'Mon, 26 Oct 2020 21:30:25 GMT'}]",2020-10-28,"[['Choudhary', 'Nurendra', ''], ['Singh', 'Rajat', ''], ['Bindlish', 'Ishita', ''], ['Shrivastava', 'Manish', '']]"
1370811,2010.14481,Biao Zhang,"Biao Zhang, Ivan Titov, Rico Sennrich",Fast Interleaved Bidirectional Sequence Generation,"WMT2020, source code is at
  https://github.com/bzhangGo/zero/tree/master/docs/interleaved_bidirectional_transformer",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Independence assumptions during sequence generation can speed up inference,
but parallel generation of highly inter-dependent tokens comes at a cost in
quality. Instead of assuming independence between neighbouring tokens
(semi-autoregressive decoding, SA), we take inspiration from bidirectional
sequence generation and introduce a decoder that generates target words from
the left-to-right and right-to-left directions simultaneously. We show that we
can easily convert a standard architecture for unidirectional decoding into a
bidirectional decoder by simply interleaving the two directions and adapting
the word positions and self-attention masks. Our interleaved bidirectional
decoder (IBDecoder) retains the model simplicity and training efficiency of the
standard Transformer, and on five machine translation tasks and two document
summarization tasks, achieves a decoding speedup of ~2X compared to
autoregressive decoding with comparable quality. Notably, it outperforms
left-to-right SA because the independence assumptions in IBDecoder are more
felicitous. To achieve even higher speedups, we explore hybrid models where we
either simultaneously predict multiple neighbouring tokens per direction, or
perform multi-directional decoding by partitioning the target sequence. These
methods achieve speedups to 4X-11X across different tasks at the cost of <1
BLEU or <0.5 ROUGE (on average). Source code is released at
https://github.com/bzhangGo/zero.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 17:38:51 GMT'}]",2020-10-28,"[['Zhang', 'Biao', ''], ['Titov', 'Ivan', ''], ['Sennrich', 'Rico', '']]"
1246301,2002.08878,Clement Moulin-Frier,Cl\'ement Moulin-Frier and Pierre-Yves Oudeyer,"Multi-Agent Reinforcement Learning as a Computational Tool for Language
  Evolution Research: Historical Context and Future Challenges",,"Challenges and Opportunities for Multi-Agent Reinforcement
  Learning (COMARL AAAI 2020-2021), AAAI Spring Symposium Series, Stanford
  University, Palo Alto, California, USA",,,cs.MA cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Computational models of emergent communication in agent populations are
currently gaining interest in the machine learning community due to recent
advances in Multi-Agent Reinforcement Learning (MARL). Current contributions
are however still relatively disconnected from the earlier theoretical and
computational literature aiming at understanding how language might have
emerged from a prelinguistic substance. The goal of this paper is to position
recent MARL contributions within the historical context of language evolution
research, as well as to extract from this theoretical and computational
background a few challenges for future research.
","[{'version': 'v1', 'created': 'Thu, 20 Feb 2020 17:26:46 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 13:54:46 GMT'}]",2020-10-28,"[['Moulin-Frier', 'Clément', ''], ['Oudeyer', 'Pierre-Yves', '']]"
1352508,2009.11005,Khang Nguyen,Khang Phuoc-Quy Nguyen and Kiet Van Nguyen,"Exploiting Vietnamese Social Media Characteristics for Textual Emotion
  Recognition in Vietnamese","6 pages, 9 tables, 2 figures of table, conference",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Textual emotion recognition has been a promising research topic in recent
years. Many researchers aim to build more accurate and robust emotion detection
systems. In this paper, we conduct several experiments to indicate how data
pre-processing affects a machine learning method on textual emotion
recognition. These experiments are performed on the Vietnamese Social Media
Emotion Corpus (UIT-VSMEC) as the benchmark dataset. We explore Vietnamese
social media characteristics to propose different pre-processing techniques,
and key-clause extraction with emotional context to improve the machine
performance on UIT-VSMEC. Our experimental evaluation shows that with
appropriate pre-processing techniques based on Vietnamese social media
characteristics, Multinomial Logistic Regression (MLR) achieves the best
F1-score of 64.40%, a significant improvement of 4.66% over the CNN model built
by the authors of UIT-VSMEC (59.74%).
","[{'version': 'v1', 'created': 'Wed, 23 Sep 2020 08:49:39 GMT'}, {'version': 'v2', 'created': 'Fri, 25 Sep 2020 15:46:49 GMT'}, {'version': 'v3', 'created': 'Tue, 27 Oct 2020 14:39:40 GMT'}]",2020-10-28,"[['Nguyen', 'Khang Phuoc-Quy', ''], ['Van Nguyen', 'Kiet', '']]"
1280128,2005.00333,Edoardo Maria Ponti,"Edoardo Maria Ponti, Goran Glava\v{s}, Olga Majewska, Qianchu Liu,
  Ivan Vuli\'c and Anna Korhonen",XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In order to simulate human language capacity, natural language processing
systems must be able to reason about the dynamics of everyday situations,
including their possible causes and effects. Moreover, they should be able to
generalise the acquired world knowledge to new languages, modulo cultural
differences. Advances in machine reasoning and cross-lingual transfer depend on
the availability of challenging evaluation benchmarks. Motivated by both
demands, we introduce Cross-lingual Choice of Plausible Alternatives (XCOPA), a
typologically diverse multilingual dataset for causal commonsense reasoning in
11 languages, which includes resource-poor languages like Eastern Apur\'imac
Quechua and Haitian Creole. We evaluate a range of state-of-the-art models on
this novel dataset, revealing that the performance of current methods based on
multilingual pretraining and zero-shot fine-tuning falls short compared to
translation-based transfer. Finally, we propose strategies to adapt
multilingual models to out-of-sample resource-lean languages where only a small
corpus or a bilingual dictionary is available, and report substantial
improvements over the random baseline. The XCOPA dataset is freely available at
github.com/cambridgeltl/xcopa.
","[{'version': 'v1', 'created': 'Fri, 1 May 2020 12:22:33 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 23:23:58 GMT'}]",2020-10-28,"[['Ponti', 'Edoardo Maria', ''], ['Glavaš', 'Goran', ''], ['Majewska', 'Olga', ''], ['Liu', 'Qianchu', ''], ['Vulić', 'Ivan', ''], ['Korhonen', 'Anna', '']]"
1353816,2009.12313,Iacer Calixto,Victor Milewski and Marie-Francine Moens and Iacer Calixto,Are scene graphs good enough to improve Image Captioning?,"Published at AACL-IJCNLP 2020. 12 pages, 5 figures",,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Many top-performing image captioning models rely solely on object features
computed with an object detection model to generate image descriptions.
However, recent studies propose to directly use scene graphs to introduce
information about object relations into captioning, hoping to better describe
interactions between objects. In this work, we thoroughly investigate the use
of scene graphs in image captioning. We empirically study whether using
additional scene graph encoders can lead to better image descriptions and
propose a conditional graph attention network (C-GAT), where the image
captioning decoder state is used to condition the graph updates. Finally, we
determine to what extent noise in the predicted scene graphs influence caption
quality. Overall, we find no significant difference between models that use
scene graph features and models that only use object detection features across
different captioning metrics, which suggests that existing scene graph
generation models are still too noisy to be useful in image captioning.
Moreover, although the quality of predicted scene graphs is very low in
general, when using high quality scene graphs we obtain gains of up to 3.3
CIDEr compared to a strong Bottom-Up Top-Down baseline. We open source code to
reproduce all our experiments in
https://github.com/iacercalixto/butd-image-captioning.
","[{'version': 'v1', 'created': 'Fri, 25 Sep 2020 16:09:08 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 17:55:55 GMT'}]",2020-10-28,"[['Milewski', 'Victor', ''], ['Moens', 'Marie-Francine', ''], ['Calixto', 'Iacer', '']]"
1370778,2010.14448,Xavier Ferrer Aran,"Xavier Ferrer-Aran, Tom van Nuenen, Natalia Criado, Jose M. Such",Discovering and Interpreting Conceptual Biases in Online Communities,,,,,cs.CL cs.AI cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language carries implicit human biases, functioning both as a reflection and
a perpetuation of stereotypes that people carry with them. Recently, ML-based
NLP methods such as word embeddings have been shown to learn such language
biases with striking accuracy. This capability of word embeddings has been
successfully exploited as a tool to quantify and study human biases. However,
previous studies only consider a predefined set of conceptual biases to attest
(e.g., whether gender is more or less associated with particular jobs), or just
discover biased words without helping to understand their meaning at the
conceptual level. As such, these approaches are either unable to find
conceptual biases that have not been defined in advance, or the biases they
find are difficult to interpret and study. This makes existing approaches
unsuitable to discover and interpret biases in online communities, as such
communities may carry different biases than those in mainstream culture. This
paper proposes a general, data-driven approach to automatically discover and
help interpret conceptual biases encoded in word embeddings. We apply this
approach to study the conceptual biases present in the language used in online
communities and experimentally show the validity and stability of our method.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 17:07:12 GMT'}]",2020-10-28,"[['Ferrer-Aran', 'Xavier', ''], ['van Nuenen', 'Tom', ''], ['Criado', 'Natalia', ''], ['Such', 'Jose M.', '']]"
1370794,2010.14464,Lukasz Borchmann,"{\L}ukasz Borchmann, Dawid Jurkiewicz, Filip Grali\'nski, Tomasz
  G\'orecki","Dynamic Boundary Time Warping for Sub-sequence Matching with Few
  Examples",,,,,cs.DS cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The paper presents a novel method of finding a fragment in a long temporal
sequence similar to the set of shorter sequences. We are the first to propose
an algorithm for such a search that does not rely on computing the average
sequence from query examples. Instead, we use query examples as is, utilizing
all of them simultaneously. The introduced method based on the Dynamic Time
Warping (DTW) technique is suited explicitly for few-shot query-by-example
retrieval tasks. We evaluate it on two different few-shot problems from the
field of Natural Language Processing. The results show it either outperforms
baselines and previous approaches or achieves comparable results when a low
number of examples is available.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 17:23:18 GMT'}]",2020-10-28,"[['Borchmann', 'Łukasz', ''], ['Jurkiewicz', 'Dawid', ''], ['Graliński', 'Filip', ''], ['Górecki', 'Tomasz', '']]"
998122,1807.00914,Edoardo Maria Ponti,"Edoardo Maria Ponti, Helen O'Horan, Yevgeni Berzak, Ivan Vuli\'c, Roi
  Reichart, Thierry Poibeau, Ekaterina Shutova, Anna Korhonen","Modeling Language Variation and Universals: A Survey on Typological
  Linguistics for Natural Language Processing",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Linguistic typology aims to capture structural and semantic variation across
the world's languages. A large-scale typology could provide excellent guidance
for multilingual Natural Language Processing (NLP), particularly for languages
that suffer from the lack of human labeled resources. We present an extensive
literature survey on the use of typological information in the development of
NLP techniques. Our survey demonstrates that to date, the use of information in
existing typological databases has resulted in consistent but modest
improvements in system performance. We show that this is due to both intrinsic
limitations of databases (in terms of coverage and feature granularity) and
under-employment of the typological features included in them. We advocate for
a new approach that adapts the broad and discrete nature of typological
categories to the contextual and continuous nature of machine learning
algorithms used in contemporary NLP. In particular, we suggest that such
approach could be facilitated by recent developments in data-driven induction
of typological knowledge.
","[{'version': 'v1', 'created': 'Mon, 2 Jul 2018 22:09:59 GMT'}, {'version': 'v2', 'created': 'Wed, 27 Feb 2019 19:55:28 GMT'}, {'version': 'v3', 'created': 'Mon, 26 Oct 2020 23:23:45 GMT'}]",2020-10-28,"[['Ponti', 'Edoardo Maria', ''], [""O'Horan"", 'Helen', ''], ['Berzak', 'Yevgeni', ''], ['Vulić', 'Ivan', ''], ['Reichart', 'Roi', ''], ['Poibeau', 'Thierry', ''], ['Shutova', 'Ekaterina', ''], ['Korhonen', 'Anna', '']]"
1355762,2009.14259,Peter Jansen,Peter A. Jansen,"Visually-Grounded Planning without Vision: Language Models Infer
  Detailed Plans from High-level Instructions","Accepted to Findings of EMNLP. V2: corrected typo Table 1; margins
  Table 3",,,,cs.CL cs.CV,http://creativecommons.org/licenses/by/4.0/,"  The recently proposed ALFRED challenge task aims for a virtual robotic agent
to complete complex multi-step everyday tasks in a virtual home environment
from high-level natural language directives, such as ""put a hot piece of bread
on a plate"". Currently, the best-performing models are able to complete less
than 5% of these tasks successfully. In this work we focus on modeling the
translation problem of converting natural language directives into detailed
multi-step sequences of actions that accomplish those goals in the virtual
environment. We empirically demonstrate that it is possible to generate gold
multi-step plans from language directives alone without any visual input in 26%
of unseen cases. When a small amount of visual information is incorporated,
namely the starting location in the virtual environment, our best-performing
GPT-2 model successfully generates gold command sequences in 58% of cases. Our
results suggest that contextualized language models may provide strong visual
semantic planning modules for grounded virtual agents.
","[{'version': 'v1', 'created': 'Tue, 29 Sep 2020 18:52:39 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 19:16:00 GMT'}]",2020-10-28,"[['Jansen', 'Peter A.', '']]"
776112,1610.00765,Edoardo Maria Ponti,"Edoardo Maria Ponti, Elisabetta Jezek, Bernardo Magnini","Distributed Representations of Lexical Sets and Prototypes in Causal
  Alternation Verbs","5 pages, 4 figures, accepted at: Third Italian Conference on
  Computational Linguistics (CLIC-it). 5-6 December 2016, Napoli (Italy)",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Lexical sets contain the words filling an argument slot of a verb, and are in
part determined by selectional preferences. The purpose of this paper is to
unravel the properties of lexical sets through distributional semantics. We
investigate 1) whether lexical set behave as prototypical categories with a
centre and a periphery; 2) whether they are polymorphic, i.e. composed by
subcategories; 3) whether the distance between lexical sets of different
arguments is explanatory of verb properties. In particular, our case study are
lexical sets of causative-inchoative verbs in Italian. Having studied several
vector models, we find that 1) based on spatial distance from the centroid,
object fillers are scattered uniformly across the category, whereas
intransitive subject fillers lie on its edge; 2) a correlation exists between
the amount of verb senses and that of clusters discovered automatically,
especially for intransitive subjects; 3) the distance between the centroids of
object and intransitive subject is correlated with other properties of verbs,
such as their cross-lingual tendency to appear in the intransitive pattern
rather than transitive one. This paper is noncommittal with respect to the
hypothesis that this connection is underpinned by a semantic reason, namely the
spontaneity of the event denoted by the verb.
","[{'version': 'v1', 'created': 'Mon, 3 Oct 2016 21:50:27 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 23:48:14 GMT'}]",2020-10-28,"[['Ponti', 'Edoardo Maria', ''], ['Jezek', 'Elisabetta', ''], ['Magnini', 'Bernardo', '']]"
1362519,2010.06189,Zhengbao Jiang,"Zhengbao Jiang, Antonios Anastasopoulos, Jun Araki, Haibo Ding, Graham
  Neubig","X-FACTR: Multilingual Factual Knowledge Retrieval from Pretrained
  Language Models",EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language models (LMs) have proven surprisingly successful at capturing
factual knowledge by completing cloze-style fill-in-the-blank questions such as
""Punta Cana is located in _."" However, while knowledge is both written and
queried in many languages, studies on LMs' factual representation ability have
almost invariably been performed on English. To assess factual knowledge
retrieval in LMs in different languages, we create a multilingual benchmark of
cloze-style probes for 23 typologically diverse languages. To properly handle
language variations, we expand probing methods from single- to multi-word
entities, and develop several decoding algorithms to generate multi-token
predictions. Extensive experimental results provide insights about how well (or
poorly) current state-of-the-art LMs perform at this task in languages with
more or fewer available resources. We further propose a code-switching-based
method to improve the ability of multilingual LMs to access knowledge, and
verify its effectiveness on several benchmark languages. Benchmark data and
code have been released at https://x-factr.github.io.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 05:29:56 GMT'}, {'version': 'v2', 'created': 'Wed, 14 Oct 2020 22:23:17 GMT'}, {'version': 'v3', 'created': 'Tue, 27 Oct 2020 15:30:03 GMT'}]",2020-10-28,"[['Jiang', 'Zhengbao', ''], ['Anastasopoulos', 'Antonios', ''], ['Araki', 'Jun', ''], ['Ding', 'Haibo', ''], ['Neubig', 'Graham', '']]"
1362726,2010.06396,Ekta Sood,"Ekta Sood, Simon Tannert, Diego Frassinelli, Andreas Bulling and Ngoc
  Thang Vu","Interpreting Attention Models with Human Visual Attention in Machine
  Reading Comprehension",CoNLL 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While neural networks with attention mechanisms have achieved superior
performance on many natural language processing tasks, it remains unclear to
which extent learned attention resembles human visual attention. In this paper,
we propose a new method that leverages eye-tracking data to investigate the
relationship between human visual attention and neural attention in machine
reading comprehension. To this end, we introduce a novel 23 participant eye
tracking dataset - MQA-RC, in which participants read movie plots and answered
pre-defined questions. We compare state of the art networks based on long
short-term memory (LSTM), convolutional neural models (CNN) and XLNet
Transformer architectures. We find that higher similarity to human attention
and performance significantly correlates to the LSTM and CNN models. However,
we show this relationship does not hold true for the XLNet models -- despite
the fact that the XLNet performs best on this challenging task. Our results
suggest that different architectures seem to learn rather different neural
attention strategies and similarity of neural to human attention does not
guarantee best performance.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 13:51:57 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 14:47:51 GMT'}]",2020-10-28,"[['Sood', 'Ekta', ''], ['Tannert', 'Simon', ''], ['Frassinelli', 'Diego', ''], ['Bulling', 'Andreas', ''], ['Vu', 'Ngoc Thang', '']]"
1364221,2010.07891,Ekta Sood,"Ekta Sood, Simon Tannert, Philipp Mueller, Andreas Bulling","Improving Natural Language Processing Tasks with Human Gaze-Guided
  Neural Attention",NeurIPS 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A lack of corpora has so far limited advances in integrating human gaze data
as a supervisory signal in neural attention mechanisms for natural language
processing(NLP). We propose a novel hybrid text saliency model(TSM) that, for
the first time, combines a cognitive model of reading with explicit human gaze
supervision in a single machine learning framework. On four different corpora
we demonstrate that our hybrid TSM duration predictions are highly correlated
with human gaze ground truth. We further propose a novel joint modeling
approach to integrate TSM predictions into the attention layer of a network
designed for a specific upstream NLP task without the need for any
task-specific human gaze data. We demonstrate that our joint model outperforms
the state of the art in paraphrase generation on the Quora Question Pairs
corpus by more than 10% in BLEU-4 and achieves state of the art performance for
sentence compression on the challenging Google Sentence Compression corpus. As
such, our work introduces a practical approach for bridging between data-driven
and cognitive models and demonstrates a new way to integrate human gaze-guided
neural attention into NLP tasks.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 17:14:09 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 16:16:18 GMT'}]",2020-10-28,"[['Sood', 'Ekta', ''], ['Tannert', 'Simon', ''], ['Mueller', 'Philipp', ''], ['Bulling', 'Andreas', '']]"
1177919,1909.07881,Palakorn Achananuparp,"Helena Lee, Palakorn Achananuparp, Yue Liu, Ee-Peng Lim, Lav R.
  Varshney","Estimating Glycemic Impact of Cooking Recipes via Online Crowdsourcing
  and Machine Learning","To appear in the Proceedings of Digital Public Health 2019 as short
  paper",,10.1145/3357729.3357748,,cs.CY cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Consumption of diets with low glycemic impact is highly recommended for
diabetics and pre-diabetics as it helps maintain their blood glucose levels.
However, laboratory analysis of dietary glycemic potency is time-consuming and
expensive. In this paper, we explore a data-driven approach utilizing online
crowdsourcing and machine learning to estimate the glycemic impact of cooking
recipes. We show that a commonly used healthiness metric may not always be
effective in determining recipes suitable for diabetics, thus emphasizing the
importance of the glycemic-impact estimation task. Our best classification
model, trained on nutritional and crowdsourced data obtained from Amazon
Mechanical Turk (AMT), can accurately identify recipes which are unhealthful
for diabetics.
","[{'version': 'v1', 'created': 'Tue, 17 Sep 2019 15:14:51 GMT'}]",2020-10-28,"[['Lee', 'Helena', ''], ['Achananuparp', 'Palakorn', ''], ['Liu', 'Yue', ''], ['Lim', 'Ee-Peng', ''], ['Varshney', 'Lav R.', '']]"
1299720,2006.05206,Jayden Macklin-Cordes,"Jayden L. Macklin-Cordes, Erich R. Round",Re-evaluating phoneme frequencies,"29pp (3 figures, 3 tables). This article has been provisionally
  accepted for publication (Frontiers in Psychology, Language Sciences).
  Supplementary information, data and code available at
  http://doi.org/10.5281/zenodo.3886212",,10.3389/fpsyg.2020.570895,,cs.CL physics.soc-ph stat.AP,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Causal processes can give rise to distinctive distributions in the linguistic
variables that they affect. Consequently, a secure understanding of a
variable's distribution can hold a key to understanding the forces that have
causally shaped it. A storied distribution in linguistics has been Zipf's law,
a kind of power law. In the wake of a major debate in the sciences around
power-law hypotheses and the unreliability of earlier methods of evaluating
them, here we re-evaluate the distributions claimed to characterize phoneme
frequencies. We infer the fit of power laws and three alternative distributions
to 166 Australian languages, using a maximum likelihood framework. We find
evidence supporting earlier results, but also nuancing them and increasing our
understanding of them. Most notably, phonemic inventories appear to have a
Zipfian-like frequency structure among their most-frequent members (though
perhaps also a lognormal structure) but a geometric (or exponential) structure
among the least-frequent. We compare these new insights the kinds of causal
processes that affect the evolution of phonemic inventories over time, and
identify a potential account for why, despite there being an important role for
phonetic substance in phonemic change, we could still expect inventories with
highly diverse phonetic content to share similar distributions of phoneme
frequencies. We conclude with priorities for future work in this promising
program of research.
","[{'version': 'v1', 'created': 'Tue, 9 Jun 2020 12:05:10 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 03:56:14 GMT'}]",2020-10-28,"[['Macklin-Cordes', 'Jayden L.', ''], ['Round', 'Erich R.', '']]"
1367182,2010.10852,Huy To Quoc,"Huy Quoc To, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen, Anh Gia-Tuan
  Nguyen","Gender Prediction Based on Vietnamese Names with Machine Learning
  Techniques","6 pages, 6 figures",,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  As biological gender is one of the aspects of presenting individual human,
much work has been done on gender classification based on people names. The
proposals for English and Chinese languages are tremendous; still, there have
been few works done for Vietnamese so far. We propose a new dataset for gender
prediction based on Vietnamese names. This dataset comprises over 26,000 full
names annotated with genders. This dataset is available on our website for
research purposes. In addition, this paper describes six machine learning
algorithms (Support Vector Machine, Multinomial Naive Bayes, Bernoulli Naive
Bayes, Decision Tree, Random Forrest and Logistic Regression) and a deep
learning model (LSTM) with fastText word embedding for gender prediction on
Vietnamese names. We create a dataset and investigate the impact of each name
component on detecting gender. As a result, the best F1-score that we have
achieved is up to 96\% on LSTM model and we generate a web API based on our
trained model.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 09:25:48 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 02:21:32 GMT'}, {'version': 'v3', 'created': 'Tue, 27 Oct 2020 01:29:35 GMT'}]",2020-10-28,"[['To', 'Huy Quoc', ''], ['Van Nguyen', 'Kiet', ''], ['Nguyen', 'Ngan Luu-Thuy', ''], ['Nguyen', 'Anh Gia-Tuan', '']]"
1236866,2001.11453,Edoardo Maria Ponti,"Edoardo M. Ponti, Ivan Vuli\'c, Ryan Cotterell, Marinela Parovic, Roi
  Reichart and Anna Korhonen","Parameter Space Factorization for Zero-Shot Learning across Tasks and
  Languages",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Most combinations of NLP tasks and language varieties lack in-domain examples
for supervised training because of the paucity of annotated data. How can
neural models make sample-efficient generalizations from task--language
combinations with available data to low-resource ones? In this work, we propose
a Bayesian generative model for the space of neural parameters. We assume that
this space can be factorized into latent variables for each language and each
task. We infer the posteriors over such latent variables based on data from
seen task--language combinations through variational inference. This enables
zero-shot classification on unseen combinations at prediction time. For
instance, given training data for named entity recognition (NER) in Vietnamese
and for part-of-speech (POS) tagging in Wolof, our model can perform accurate
predictions for NER in Wolof. In particular, we experiment with a typologically
diverse sample of 33 languages from 4 continents and 11 families, and show that
our model yields comparable or better results than state-of-the-art, zero-shot
cross-lingual transfer methods. Moreover, we demonstrate that approximate
Bayesian model averaging results in smoother predictive distributions, whose
entropy strongly correlates with accuracy. Hence, the proposed framework also
offers robust estimates of uncertainty.
","[{'version': 'v1', 'created': 'Thu, 30 Jan 2020 16:58:56 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 23:30:01 GMT'}]",2020-10-28,"[['Ponti', 'Edoardo M.', ''], ['Vulić', 'Ivan', ''], ['Cotterell', 'Ryan', ''], ['Parovic', 'Marinela', ''], ['Reichart', 'Roi', ''], ['Korhonen', 'Anna', '']]"
1304040,2006.09526,Chau Tran,"Chau Tran, Yuqing Tang, Xian Li, Jiatao Gu",Cross-lingual Retrieval for Iterative Self-Supervised Training,,NeurIPS 2020,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent studies have demonstrated the cross-lingual alignment ability of
multilingual pretrained language models. In this work, we found that the
cross-lingual alignment can be further improved by training seq2seq models on
sentence pairs mined using their own encoder outputs. We utilized these
findings to develop a new approach -- cross-lingual retrieval for iterative
self-supervised training (CRISS), where mining and training processes are
applied iteratively, improving cross-lingual alignment and translation ability
at the same time. Using this method, we achieved state-of-the-art unsupervised
machine translation results on 9 language directions with an average
improvement of 2.4 BLEU, and on the Tatoeba sentence retrieval task in the
XTREME benchmark on 16 languages with an average improvement of 21.5% in
absolute accuracy. Furthermore, CRISS also brings an additional 1.8 BLEU
improvement on average compared to mBART, when finetuned on supervised machine
translation downstream tasks.
","[{'version': 'v1', 'created': 'Tue, 16 Jun 2020 21:30:51 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 23:25:31 GMT'}]",2020-10-28,"[['Tran', 'Chau', ''], ['Tang', 'Yuqing', ''], ['Li', 'Xian', ''], ['Gu', 'Jiatao', '']]"
1367362,2010.11032,Leshem Choshen,"Leshem Choshen, Dmitry Nikolaev, Yevgeni Berzak, Omri Abend",Classifying Syntactic Errors in Learner Language,CoNLL 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present a method for classifying syntactic errors in learner language,
namely errors whose correction alters the morphosyntactic structure of a
sentence.
  The methodology builds on the established Universal Dependencies syntactic
representation scheme, and provides complementary information to other
error-classification systems.
  Unlike existing error classification methods, our method is applicable across
languages, which we showcase by producing a detailed picture of syntactic
errors in learner English and learner Russian. We further demonstrate the
utility of the methodology for analyzing the outputs of leading Grammatical
Error Correction (GEC) systems.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 14:28:22 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 14:58:14 GMT'}]",2020-10-28,"[['Choshen', 'Leshem', ''], ['Nikolaev', 'Dmitry', ''], ['Berzak', 'Yevgeni', ''], ['Abend', 'Omri', '']]"
1370769,2010.14439,Bill Yuchen Lin,"Bill Yuchen Lin, Haitian Sun, Bhuwan Dhingra, Manzil Zaheer, Xiang
  Ren, William W. Cohen",Differentiable Open-Ended Commonsense Reasoning,Work in progress. Project page: https://yuchenlin.xyz/opencsr/,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Current commonsense reasoning research mainly focuses on developing models
that use commonsense knowledge to answer multiple-choice questions. However,
systems designed to answer multiple-choice questions may not be useful in
applications that do not provide a small list of possible candidate answers to
choose from. As a step towards making commonsense reasoning research more
realistic, we propose to study open-ended commonsense reasoning (OpenCSR) --
the task of answering a commonsense question without any pre-defined choices,
using as a resource only a corpus of commonsense facts written in natural
language. The task is challenging due to a much larger decision space, and
because many commonsense questions require multi-hop reasoning. We propose an
efficient differentiable model for multi-hop reasoning over knowledge facts,
named DrFact. We evaluate our approach on a collection of re-formatted,
open-ended versions of popular tests targeting commonsense reasoning, and show
that our approach outperforms strong baseline methods by a large margin.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 10:07:00 GMT'}]",2020-10-28,"[['Lin', 'Bill Yuchen', ''], ['Sun', 'Haitian', ''], ['Dhingra', 'Bhuwan', ''], ['Zaheer', 'Manzil', ''], ['Ren', 'Xiang', ''], ['Cohen', 'William W.', '']]"
1329286,2008.01564,Bruce Lee,"Bruce W. Lee, Jason Hyung-Jong Lee","LXPER Index: a curriculum-specific text readability assessment model for
  EFL students in Korea","8 pages, 2 figures, 7 tables",,10.14569/IJACSA.2020.0110801,,cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Automatic readability assessment is one of the most important applications of
Natural Language Processing (NLP) in education. Since automatic readability
assessment allows the fast selection of appropriate reading material for
readers at all levels of proficiency, it can be particularly useful for the
English education of English as Foreign Language (EFL) students around the
world. Most readability assessment models are developed for the native readers
of English and have low accuracy for texts in the non-native English Language
Training (ELT) curriculum. We introduce LXPER Index, which is a readability
assessment model for non-native EFL readers in the ELT curriculum of Korea. Our
experiments show that our new model, trained with CoKEC-text (Text Corpus of
the Korean ELT Curriculum), significantly improves the accuracy of automatic
readability assessment for texts in the Korean ELT curriculum.
","[{'version': 'v1', 'created': 'Sat, 1 Aug 2020 11:55:03 GMT'}]",2020-10-28,"[['Lee', 'Bruce W.', ''], ['Lee', 'Jason Hyung-Jong', '']]"
1280414,2005.00619,Gabriel Ilharco,"Gabriel Ilharco, Rowan Zellers, Ali Farhadi, Hannaneh Hajishirzi","Probing Contextual Language Models for Common Ground with Visual
  Representations",,,,,cs.CL cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While large-scale contextual language models have enjoyed great success
recently, much remains to be understood about what is encoded in their
representations. In this work, we characterize how contextual representations
of concrete nouns extracted by trained language models relate to the physical
properties of the objects they refer to. Our approach uses a probing model that
examines how effective these language representations are in discerning between
different visual representations. We show that many recent language models
yield representations that are useful in retrieving semantically aligned image
patches, and explore the role of context in this process. Much weaker results
are found in control experiments, attesting the selectivity of the probe. All
examined models greatly under-perform humans in retrieval, highlighting
substantial room for future progress. Altogether, our findings shed new
empirical insights on language grounding and its materialization in contextual
language models.
","[{'version': 'v1', 'created': 'Fri, 1 May 2020 21:28:28 GMT'}, {'version': 'v2', 'created': 'Tue, 6 Oct 2020 17:19:20 GMT'}, {'version': 'v3', 'created': 'Fri, 23 Oct 2020 22:12:40 GMT'}, {'version': 'v4', 'created': 'Tue, 27 Oct 2020 16:40:01 GMT'}]",2020-10-28,"[['Ilharco', 'Gabriel', ''], ['Zellers', 'Rowan', ''], ['Farhadi', 'Ali', ''], ['Hajishirzi', 'Hannaneh', '']]"
1370672,2010.14342,Guanyi Chen,"Guanyi Chen, Yinhe Zheng, Yupei Du",Listener's Social Identity Matters in Personalised Response Generation,Long paper accepted at INLG 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Personalised response generation enables generating human-like responses by
means of assigning the generator a social identity. However, pragmatics theory
suggests that human beings adjust the way of speaking based on not only who
they are but also whom they are talking to. In other words, when modelling
personalised dialogues, it might be favourable if we also take the listener's
social identity into consideration. To validate this idea, we use gender as a
typical example of a social variable to investigate how the listener's identity
influences the language used in Chinese dialogues on social media. Also, we
build personalised generators. The experiment results demonstrate that the
listener's identity indeed matters in the language use of responses and that
the response generator can capture such differences in language use. More
interestingly, by additionally modelling the listener's identity, the
personalised response generator performs better in its own identity.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 14:57:21 GMT'}]",2020-10-28,"[['Chen', 'Guanyi', ''], ['Zheng', 'Yinhe', ''], ['Du', 'Yupei', '']]"
1370434,2010.14104,"Bj\""orn Bebensee","Bj\""orn Bebensee, Byoung-Tak Zhang",Co-attentional Transformers for Story-Based Video Understanding,"10 pages, 2 figures, submitted to ICASSP 2021",,,,cs.CV cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Inspired by recent trends in vision and language learning, we explore
applications of attention mechanisms for visio-lingual fusion within an
application to story-based video understanding. Like other video-based QA
tasks, video story understanding requires agents to grasp complex temporal
dependencies. However, as it focuses on the narrative aspect of video it also
requires understanding of the interactions between different characters, as
well as their actions and their motivations. We propose a novel co-attentional
transformer model to better capture long-term dependencies seen in visual
stories such as dramas and measure its performance on the video question
answering task. We evaluate our approach on the recently introduced DramaQA
dataset which features character-centered video story understanding questions.
Our model outperforms the baseline model by 8 percentage points overall, at
least 4.95 and up to 12.8 percentage points on all difficulty levels and
manages to beat the winner of the DramaQA challenge.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 07:17:09 GMT'}]",2020-10-28,"[['Bebensee', 'Björn', ''], ['Zhang', 'Byoung-Tak', '']]"
1370601,2010.14271,Ming Gong,"Junhao Liu, Linjun Shou, Jian Pei, Ming Gong, Min Yang, Daxin Jiang","Cross-lingual Machine Reading Comprehension with Language Branch
  Knowledge Distillation",Accepted as long paper in COLING 2020,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Cross-lingual Machine Reading Comprehension (CLMRC) remains a challenging
problem due to the lack of large-scale annotated datasets in low-source
languages, such as Arabic, Hindi, and Vietnamese. Many previous approaches use
translation data by translating from a rich-source language, such as English,
to low-source languages as auxiliary supervision. However, how to effectively
leverage translation data and reduce the impact of noise introduced by
translation remains onerous. In this paper, we tackle this challenge and
enhance the cross-lingual transferring performance by a novel augmentation
approach named Language Branch Machine Reading Comprehension (LBMRC). A
language branch is a group of passages in one single language paired with
questions in all target languages. We train multiple machine reading
comprehension (MRC) models proficient in individual language based on LBMRC.
Then, we devise a multilingual distillation approach to amalgamate knowledge
from multiple language branch models to a single model for all target
languages. Combining the LBMRC and multilingual distillation can be more robust
to the data noises, therefore, improving the model's cross-lingual ability.
Meanwhile, the produced single multilingual model is applicable to all target
languages, which saves the cost of training, inference, and maintenance for
multiple models. Extensive experiments on two CLMRC benchmarks clearly show the
effectiveness of our proposed method.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 13:12:17 GMT'}]",2020-10-28,"[['Liu', 'Junhao', ''], ['Shou', 'Linjun', ''], ['Pei', 'Jian', ''], ['Gong', 'Ming', ''], ['Yang', 'Min', ''], ['Jiang', 'Daxin', '']]"
1370144,2010.13814,Constantin Orasan,"Hadeel Saadany, Constantin Orasan","Is it Great or Terrible? Preserving Sentiment in Neural Machine
  Translation of Arabic Reviews",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Since the advent of Neural Machine Translation (NMT) approaches there has
been a tremendous improvement in the quality of automatic translation. However,
NMT output still lacks accuracy in some low-resource languages and sometimes
makes major errors that need extensive post-editing. This is particularly
noticeable with texts that do not follow common lexico-grammatical standards,
such as user generated content (UGC). In this paper we investigate the
challenges involved in translating book reviews from Arabic into English, with
particular focus on the errors that lead to incorrect translation of sentiment
polarity. Our study points to the special characteristics of Arabic UGC,
examines the sentiment transfer errors made by Google Translate of Arabic UGC
to English, analyzes why the problem occurs, and proposes an error typology
specific of the translation of Arabic UGC. Our analysis shows that the output
of online translation tools of Arabic UGC can either fail to transfer the
sentiment at all by producing a neutral target text, or completely flips the
sentiment polarity of the target word or phrase and hence delivers a wrong
affect message. We address this problem by fine-tuning an NMT model with
respect to sentiment polarity showing that this approach can significantly help
with correcting sentiment errors detected in the online translation of Arabic
UGC.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 18:01:52 GMT'}]",2020-10-28,"[['Saadany', 'Hadeel', ''], ['Orasan', 'Constantin', '']]"
1370169,2010.13839,Subhajit Chaudhury,"Thomas Carta, Subhajit Chaudhury, Kartik Talamadupula and Michiaki
  Tatsubori","VisualHints: A Visual-Lingual Environment for Multimodal Reinforcement
  Learning",Code is available at http://ibm.biz/VisualHints,,,,cs.LG cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present VisualHints, a novel environment for multimodal reinforcement
learning (RL) involving text-based interactions along with visual hints
(obtained from the environment). Real-life problems often demand that agents
interact with the environment using both natural language information and
visual perception towards solving a goal. However, most traditional RL
environments either solve pure vision-based tasks like Atari games or
video-based robotic manipulation; or entirely use natural language as a mode of
interaction, like Text-based games and dialog systems. In this work, we aim to
bridge this gap and unify these two approaches in a single environment for
multimodal RL. We introduce an extension of the TextWorld cooking environment
with the addition of visual clues interspersed throughout the environment. The
goal is to force an RL agent to use both text and visual features to predict
natural language action commands for solving the final task of cooking a meal.
We enable variations and difficulties in our environment to emulate various
interactive real-world scenarios. We present a baseline multimodal agent for
solving such problems using CNN-based feature extraction from visual hints and
LSTMs for textual feature extraction. We believe that our proposed
visual-lingual environment will facilitate novel problem settings for the RL
community.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 18:51:02 GMT'}]",2020-10-28,"[['Carta', 'Thomas', ''], ['Chaudhury', 'Subhajit', ''], ['Talamadupula', 'Kartik', ''], ['Tatsubori', 'Michiaki', '']]"
1370186,2010.13856,Ciprian Chelba,"Ciprian Chelba, Junpei Zhou, Yuezhang (Music) Li, Hideto Kazawa, Jeff
  Klingner, Mengmeng Niu","Data Troubles in Sentence Level Confidence Estimation for Machine
  Translation",,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The paper investigates the feasibility of confidence estimation for neural
machine translation models operating at the high end of the performance
spectrum. As a side product of the data annotation process necessary for
building such models we propose sentence level accuracy $SACC$ as a simple,
self-explanatory evaluation metric for quality of translation.
  Experiments on two different annotator pools, one comprised of non-expert
(crowd-sourced) and one of expert (professional) translators show that $SACC$
can vary greatly depending on the translation proficiency of the annotators,
despite the fact that both pools are about equally reliable according to
Krippendorff's alpha metric; the relatively low values of inter-annotator
agreement confirm the expectation that sentence-level binary labeling $good$ /
$needs\ work$ for translation out of context is very hard.
  For an English-Spanish translation model operating at $SACC = 0.89$ according
to a non-expert annotator pool we can derive a confidence estimate that labels
0.5-0.6 of the $good$ translations in an ""in-domain"" test set with 0.95
Precision. Switching to an expert annotator pool decreases $SACC$ dramatically:
$0.61$ for English-Spanish, measured on the exact same data as above. This
forces us to lower the CE model operating point to 0.9 Precision while labeling
correctly about 0.20-0.25 of the $good$ translations in the data.
  We find surprising the extent to which CE depends on the level of proficiency
of the annotator pool used for labeling the data. This leads to an important
recommendation we wish to make when tackling CE modeling in practice: it is
critical to match the end-user expectation for translation quality in the
desired domain with the demands of annotators assigning binary quality labels
to CE training data.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 19:20:29 GMT'}]",2020-10-28,"[['Chelba', 'Ciprian', '', 'Music'], ['Zhou', 'Junpei', '', 'Music'], ['Yuezhang', '', '', 'Music'], ['Li', '', ''], ['Kazawa', 'Hideto', ''], ['Klingner', 'Jeff', ''], ['Niu', 'Mengmeng', '']]"
1256634,2003.06279,Diego Amancio,Laura V. C. Quispe and Jorge A. V. Tohalino and Diego R. Amancio,"Using word embeddings to improve the discriminability of co-occurrence
  text networks",,,10.1016/j.physa.2020.125344,,cs.CL cs.SI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Word co-occurrence networks have been employed to analyze texts both in the
practical and theoretical scenarios. Despite the relative success in several
applications, traditional co-occurrence networks fail in establishing links
between similar words whenever they appear distant in the text. Here we
investigate whether the use of word embeddings as a tool to create virtual
links in co-occurrence networks may improve the quality of classification
systems. Our results revealed that the discriminability in the stylometry task
is improved when using Glove, Word2Vec and FastText. In addition, we found that
optimized results are obtained when stopwords are not disregarded and a simple
global thresholding strategy is used to establish virtual links. Because the
proposed approach is able to improve the representation of texts as complex
networks, we believe that it could be extended to study other natural language
processing tasks. Likewise, theoretical languages studies could benefit from
the adopted enriched representation of word co-occurrence networks.
","[{'version': 'v1', 'created': 'Fri, 13 Mar 2020 13:35:44 GMT'}]",2020-10-28,"[['Quispe', 'Laura V. C.', ''], ['Tohalino', 'Jorge A. V.', ''], ['Amancio', 'Diego R.', '']]"
1369939,2010.13609,Dumitru-Clementin Cercel,"Mircea-Adrian Tanase, Dumitru-Clementin Cercel and Costin-Gabriel
  Chiru","UPB at SemEval-2020 Task 12: Multilingual Offensive Language Detection
  on Social Media by Fine-tuning a Variety of BERT-based Models",,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Offensive language detection is one of the most challenging problem in the
natural language processing field, being imposed by the rising presence of this
phenomenon in online social media. This paper describes our Transformer-based
solutions for identifying offensive language on Twitter in five languages
(i.e., English, Arabic, Danish, Greek, and Turkish), which was employed in
Subtask A of the Offenseval 2020 shared task. Several neural architectures
(i.e., BERT, mBERT, Roberta, XLM-Roberta, and ALBERT), pre-trained using both
single-language and multilingual corpora, were fine-tuned and compared using
multiple combinations of datasets. Finally, the highest-scoring models were
used for our submissions in the competition, which ranked our team 21st of 85,
28th of 53, 19th of 39, 16th of 37, and 10th of 46 for English, Arabic, Danish,
Greek, and Turkish, respectively.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 14:28:29 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 09:21:21 GMT'}]",2020-10-28,"[['Tanase', 'Mircea-Adrian', ''], ['Cercel', 'Dumitru-Clementin', ''], ['Chiru', 'Costin-Gabriel', '']]"
1370200,2010.13870,Leon Bergen,"Charles Yu, Ryan Sie, Nico Tedeschi, Leon Bergen",Word Frequency Does Not Predict Grammatical Knowledge in Language Models,EMNLP 2020,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Neural language models learn, to varying degrees of accuracy, the grammatical
properties of natural languages. In this work, we investigate whether there are
systematic sources of variation in the language models' accuracy. Focusing on
subject-verb agreement and reflexive anaphora, we find that certain nouns are
systematically understood better than others, an effect which is robust across
grammatical tasks and different language models. Surprisingly, we find that
across four orders of magnitude, corpus frequency is unrelated to a noun's
performance on grammatical tasks. Finally, we find that a novel noun's
grammatical properties can be few-shot learned from various types of training
data. The results present a paradox: there should be less variation in
grammatical performance than is actually observed.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 19:51:36 GMT'}]",2020-10-28,"[['Yu', 'Charles', ''], ['Sie', 'Ryan', ''], ['Tedeschi', 'Nico', ''], ['Bergen', 'Leon', '']]"
1370208,2010.13878,Suyoun Kim,"Suyoun Kim, Yuan Shangguan, Jay Mahadeokar, Antoine Bruguier,
  Christian Fuegen, Michael L. Seltzer, Duc Le","Improved Neural Language Model Fusion for Streaming Recurrent Neural
  Network Transducer",submitted to ICASSP 2021,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recurrent Neural Network Transducer (RNN-T), like most end-to-end speech
recognition model architectures, has an implicit neural network language model
(NNLM) and cannot easily leverage unpaired text data during training. Previous
work has proposed various fusion methods to incorporate external NNLMs into
end-to-end ASR to address this weakness. In this paper, we propose extensions
to these techniques that allow RNN-T to exploit external NNLMs during both
training and inference time, resulting in 13-18% relative Word Error Rate
improvement on Librispeech compared to strong baselines. Furthermore, our
methods do not incur extra algorithmic latency and allow for flexible
plug-and-play of different NNLMs without re-training. We also share in-depth
analysis to better understand the benefits of the different NNLM fusion
methods. Our work provides a reliable technique for leveraging unpaired text
data to significantly improve RNN-T while keeping the system streamable,
flexible, and lightweight.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 20:10:12 GMT'}]",2020-10-28,"[['Kim', 'Suyoun', ''], ['Shangguan', 'Yuan', ''], ['Mahadeokar', 'Jay', ''], ['Bruguier', 'Antoine', ''], ['Fuegen', 'Christian', ''], ['Seltzer', 'Michael L.', ''], ['Le', 'Duc', '']]"
1370242,2010.13912,Chien-Sheng Wu,Chien-Sheng Wu and Caiming Xiong,Probing Task-Oriented Dialogue Representation from Language Models,EMNLP 2020,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper investigates pre-trained language models to find out which model
intrinsically carries the most informative representation for task-oriented
dialogue tasks. We approach the problem from two aspects: supervised classifier
probe and unsupervised mutual information probe. We fine-tune a feed-forward
layer as the classifier probe on top of a fixed pre-trained language model with
annotated labels in a supervised way. Meanwhile, we propose an unsupervised
mutual information probe to evaluate the mutual dependence between a real
clustering and a representation clustering. The goals of this empirical paper
are to 1) investigate probing techniques, especially from the unsupervised
mutual information aspect, 2) provide guidelines of pre-trained language model
selection for the dialogue research community, 3) find insights of pre-training
factors for dialogue application that may be the key to success.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 21:34:39 GMT'}]",2020-10-28,"[['Wu', 'Chien-Sheng', ''], ['Xiong', 'Caiming', '']]"
1370648,2010.14318,Peidong Wang,"Peidong Wang, Tara N. Sainath, Ron J. Weiss",Multitask Training with Text Data for End-to-End Speech Recognition,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a multitask training method for attention-based end-to-end speech
recognition models to better incorporate language level information. We
regularize the decoder in a sequence-to-sequence architecture by multitask
training it on both the speech recognition task and a next-token prediction
language modeling task. Trained on either the 100 hour subset of LibriSpeech or
the full 960 hour dataset, the proposed method leads to an 11% relative
performance improvement over the baseline and is comparable to language model
shallow fusion, without requiring an additional neural network during decoding.
Analyses of sample output sentences and the word error rate on rare words
demonstrate that the proposed method can incorporate language level information
effectively.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 14:29:28 GMT'}]",2020-10-28,"[['Wang', 'Peidong', ''], ['Sainath', 'Tara N.', ''], ['Weiss', 'Ron J.', '']]"
1252853,2003.02498,Palakorn Achananuparp,"Helena H. Lee, Ke Shu, Palakorn Achananuparp, Philips Kokoh Prasetyo,
  Yue Liu, Ee-Peng Lim, Lav R. Varshney","RecipeGPT: Generative Pre-training Based Cooking Recipe Generation and
  Evaluation System",Accepted to WWW 2020. Demo track paper,,10.1145/3366424.3383536,,cs.CL cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Interests in the automatic generation of cooking recipes have been growing
steadily over the past few years thanks to a large amount of online cooking
recipes. We present RecipeGPT, a novel online recipe generation and evaluation
system. The system provides two modes of text generations: (1) instruction
generation from given recipe title and ingredients; and (2) ingredient
generation from recipe title and cooking instructions. Its back-end text
generation module comprises a generative pre-trained language model GPT-2
fine-tuned on a large cooking recipe dataset. Moreover, the recipe evaluation
module allows the users to conveniently inspect the quality of the generated
recipe contents and store the results for future reference. RecipeGPT can be
accessed online at https://recipegpt.org/.
","[{'version': 'v1', 'created': 'Thu, 5 Mar 2020 09:25:30 GMT'}]",2020-10-28,"[['Lee', 'Helena H.', ''], ['Shu', 'Ke', ''], ['Achananuparp', 'Palakorn', ''], ['Prasetyo', 'Philips Kokoh', ''], ['Liu', 'Yue', ''], ['Lim', 'Ee-Peng', ''], ['Varshney', 'Lav R.', '']]"
1370250,2010.13920,Chien-Sheng Wu,Chien-Sheng Wu and Steven Hoi and Caiming Xiong,Improving Limited Labeled Dialogue State Tracking with Self-Supervision,EMNLP 2020 (findings),,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Existing dialogue state tracking (DST) models require plenty of labeled data.
However, collecting high-quality labels is costly, especially when the number
of domains increases. In this paper, we address a practical DST problem that is
rarely discussed, i.e., learning efficiently with limited labeled data. We
present and investigate two self-supervised objectives: preserving latent
consistency and modeling conversational behavior. We encourage a DST model to
have consistent latent distributions given a perturbed input, making it more
robust to an unseen scenario. We also add an auxiliary utterance generation
task, modeling a potential correlation between conversational behavior and
dialogue states. The experimental results show that our proposed
self-supervised signals can improve joint goal accuracy by 8.95\% when only 1\%
labeled data is used on the MultiWOZ dataset. We can achieve an additional
1.76\% improvement if some unlabeled data is jointly trained as semi-supervised
learning. We analyze and visualize how our proposed self-supervised signals
help the DST task and hope to stimulate future data-efficient DST research.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 21:57:42 GMT'}]",2020-10-28,"[['Wu', 'Chien-Sheng', ''], ['Hoi', 'Steven', ''], ['Xiong', 'Caiming', '']]"
1370274,2010.13944,Khyathi Raghavi Chandu,"Khyathi Raghavi Chandu, Ruo-Ping Dong, Alan Black",Reading Between the Lines: Exploring Infilling in Visual Narratives,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Generating long form narratives such as stories and procedures from multiple
modalities has been a long standing dream for artificial intelligence. In this
regard, there is often crucial subtext that is derived from the surrounding
contexts. The general seq2seq training methods render the models shorthanded
while attempting to bridge the gap between these neighbouring contexts. In this
paper, we tackle this problem by using \textit{infilling} techniques involving
prediction of missing steps in a narrative while generating textual
descriptions from a sequence of images. We also present a new large scale
\textit{visual procedure telling} (ViPT) dataset with a total of 46,200
procedures and around 340k pairwise images and textual descriptions that is
rich in such contextual dependencies. Generating steps using infilling
technique demonstrates the effectiveness in visual procedures with more
coherent texts. We conclusively show a METEOR score of 27.51 on procedures
which is higher than the state-of-the-art on visual storytelling. We also
demonstrate the effects of interposing new text with missing images during
inference. The code and the dataset will be publicly available at
https://visual-narratives.github.io/Visual-Narratives/.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 23:09:09 GMT'}]",2020-10-28,"[['Chandu', 'Khyathi Raghavi', ''], ['Dong', 'Ruo-Ping', ''], ['Black', 'Alan', '']]"
1370312,2010.13982,Hung-Ting Chen,"Hung-Ting Chen, Yu-Chieh Chao, Ta-Hsuan Chao, Wei-Yun Ma",Predict and Use Latent Patterns for Short-Text Conversation,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Many neural network models nowadays have achieved promising performances in
Chit-chat settings. The majority of them rely on an encoder for understanding
the post and a decoder for generating the response. Without given assigned
semantics, the models lack the fine-grained control over responses as the
semantic mapping between posts and responses is hidden on the fly within the
end-to-end manners. Some previous works utilize sampled latent words as a
controllable semantic form to drive the generated response around the work, but
few works attempt to use more complex semantic forms to guide the generation.
In this paper, we propose to use more detailed semantic forms, including latent
responses and part-of-speech sequences sampled from the corresponding
distributions, as the controllable semantics to guide the generation. Our
experimental results show that the richer semantics are not only able to
provide informative and diverse responses, but also increase the overall
performance of response quality, including fluency and coherence.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 01:31:42 GMT'}]",2020-10-28,"[['Chen', 'Hung-Ting', ''], ['Chao', 'Yu-Chieh', ''], ['Chao', 'Ta-Hsuan', ''], ['Ma', 'Wei-Yun', '']]"
1370146,2010.13816,Maarten Sap,"Xinyao Ma, Maarten Sap, Hannah Rashkin, Yejin Choi","PowerTransformer: Unsupervised Controllable Revision for Biased Language
  Correction",EMNLP 2020,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Unconscious biases continue to be prevalent in modern text and media, calling
for algorithms that can assist writers with bias correction. For example, a
female character in a story is often portrayed as passive and powerless (""She
daydreams about being a doctor"") while a man is portrayed as more proactive and
powerful (""He pursues his dream of being a doctor"").
  We formulate *Controllable Debiasing*, a new revision task that aims to
rewrite a given text to correct the implicit and potentially undesirable bias
in character portrayals. We then introduce PowerTransformer as an approach that
debiases text through the lens of connotation frames (Sap et al., 2017), which
encode pragmatic knowledge of implied power dynamics with respect to verb
predicates. One key challenge of our task is the lack of parallel corpora. To
address this challenge, we adopt an unsupervised approach using auxiliary
supervision with related tasks such as paraphrasing and self-supervision based
on a reconstruction loss, building on pretrained language models.
  Through comprehensive experiments based on automatic and human evaluations,
we demonstrate that our approach outperforms ablations and existing methods
from related tasks. Furthermore, we demonstrate the use of PowerTransformer as
a step toward mitigating the well-documented gender bias in character portrayal
in movie scripts.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 18:05:48 GMT'}]",2020-10-28,"[['Ma', 'Xinyao', ''], ['Sap', 'Maarten', ''], ['Rashkin', 'Hannah', ''], ['Choi', 'Yejin', '']]"
1369704,2010.13374,Bruce W. Lee,Bruce W. Lee and Jason Hyung-Jong Lee,"LXPER Index 2.0: Improving Text Readability Assessment for L2 English
  Learners in South Korea","NLP-TEA, Association for Computational Linguistics",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Most text readability assessment models are developed for the native readers
of English and have low accuracy for texts in foreign English Language Training
(ELT) curriculum. In this paper, we investigate a text readability assessment
model for L2 English learners in Korea. In accordance, we improve and expand
the Text Corpus of the Korean ELT curriculum (CoKEC-text). Each text is labeled
with its target grade level. We train our model with CoKEC-text and
significantly improve the accuracy of readability assessment for texts in the
Korean ELT curriculum.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 07:03:14 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 17:04:03 GMT'}]",2020-10-28,"[['Lee', 'Bruce W.', ''], ['Lee', 'Jason Hyung-Jong', '']]"
1159525,1908.01355,Johan Bos,Johan Bos,Separating Argument Structure from Logical Structure in AMR,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The AMR (Abstract Meaning Representation) formalism for representing meaning
of natural language sentences was not designed to deal with scope and
quantifiers. By extending AMR with indices for contexts and formulating
constraints on these contexts, a formalism is derived that makes correct
prediction for inferences involving negation and bound variables. The
attractive core predicate-argument structure of AMR is preserved. The resulting
framework is similar to that of Discourse Representation Theory.
","[{'version': 'v1', 'created': 'Sun, 4 Aug 2019 14:46:35 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 14:54:01 GMT'}]",2020-10-28,"[['Bos', 'Johan', '']]"
1369424,2010.13094,Masahiro Kaneko,Masahiro Kaneko and Danushka Bollegala,Autoencoding Improves Pre-trained Word Embeddings,COLING 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Prior work investigating the geometry of pre-trained word embeddings have
shown that word embeddings to be distributed in a narrow cone and by centering
and projecting using principal component vectors one can increase the accuracy
of a given set of pre-trained word embeddings. However, theoretically, this
post-processing step is equivalent to applying a linear autoencoder to minimise
the squared l2 reconstruction error. This result contradicts prior work (Mu and
Viswanath, 2018) that proposed to remove the top principal components from
pre-trained embeddings. We experimentally verify our theoretical claims and
show that retaining the top principal components is indeed useful for improving
pre-trained word embeddings, without requiring access to additional linguistic
resources or labelled data.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 11:30:05 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 07:51:34 GMT'}]",2020-10-28,"[['Kaneko', 'Masahiro', ''], ['Bollegala', 'Danushka', '']]"
1370585,2010.14255,Jianing Wang,Jianing Wang and Chong Su,"Improving Reinforcement Learning for Neural Relation Extraction with
  Hierarchical Memory Extractor","9 pages, 7 figures, WWW2021 submission paper",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Distant supervision relation extraction (DSRE) is an efficient method to
extract semantic relations on a large-scale heuristic labeling corpus. However,
it usually brings in a massive noisy data. In order to alleviate this problem,
many recent approaches adopt reinforcement learning (RL), which aims to select
correct data autonomously before relation classification. Although these RL
methods outperform conventional multi-instance learning-based methods, there
are still two neglected problems: 1) the existing RL methods ignore the
feedback of noisy data, 2) the reduction of training corpus exacerbates
long-tail problem. In this paper, we propose a novel framework to solve the two
problems mentioned above. Firstly, we design a novel reward function to obtain
feedback from both correct and noisy data. In addition, we use implicit
relations information to improve RL. Secondly, we propose the hierarchical
memory extractor (HME), which utilizes the gating mechanism to share the
semantics from correlative instances between data-rich and data-poor classes.
Moreover, we define a hierarchical weighted ranking loss function to implement
top-down search processing. Extensive experiments conducted on the widely used
NYT dataset show significant improvement over state-of-the-art baseline
methods.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 12:50:27 GMT'}]",2020-10-28,"[['Wang', 'Jianing', ''], ['Su', 'Chong', '']]"
1370565,2010.14235,Yao Lu,"Yao Lu, Yue Dong, Laurent Charlin","Multi-XScience: A Large-scale Dataset for Extreme Multi-document
  Summarization of Scientific Articles",EMNLP 2020,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Multi-document summarization is a challenging task for which there exists
little large-scale datasets. We propose Multi-XScience, a large-scale
multi-document summarization dataset created from scientific articles.
Multi-XScience introduces a challenging multi-document summarization task:
writing the related-work section of a paper based on its abstract and the
articles it references. Our work is inspired by extreme summarization, a
dataset construction protocol that favours abstractive modeling approaches.
Descriptive statistics and empirical results---using several state-of-the-art
models trained on the Multi-XScience dataset---reveal that Multi-XScience is
well suited for abstractive models.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 12:10:19 GMT'}]",2020-10-28,"[['Lu', 'Yao', ''], ['Dong', 'Yue', ''], ['Charlin', 'Laurent', '']]"
1370564,2010.14234,Muvazima Mansoor,"Muvazima Mansoor, Kirthika Gurumurthy, Anantharam R U, V R Badri
  Prasad",Global Sentiment Analysis Of COVID-19 Tweets Over Time,"7 pages, 20 figures, Submitted to ICDSBDA 2020",,,,cs.CL cs.LG cs.SI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The Coronavirus pandemic has affected the normal course of life. People
around the world have taken to social media to express their opinions and
general emotions regarding this phenomenon that has taken over the world by
storm. The social networking site, Twitter showed an unprecedented increase in
tweets related to the novel Coronavirus in a very short span of time. This
paper presents the global sentiment analysis of tweets related to Coronavirus
and how the sentiment of people in different countries has changed over time.
Furthermore, to determine the impact of Coronavirus on daily aspects of life,
tweets related to Work From Home (WFH) and Online Learning were scraped and the
change in sentiment over time was observed. In addition, various Machine
Learning models such as Long Short Term Memory (LSTM) and Artificial Neural
Networks (ANN) were implemented for sentiment classification and their
accuracies were determined. Exploratory data analysis was also performed for a
dataset providing information about the number of confirmed cases on a per-day
basis in a few of the worst-hit countries to provide a comparison between the
change in sentiment with the change in cases since the start of this pandemic
till June 2020.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 12:10:10 GMT'}]",2020-10-28,"[['Mansoor', 'Muvazima', ''], ['Gurumurthy', 'Kirthika', ''], ['U', 'Anantharam R', ''], ['Prasad', 'V R Badri', '']]"
1020672,1809.00656,Larry Moss,Alex Kruckman and Lawrence S. Moss,Exploring the Landscape of Relational Syllogistic Logics,,,10.1017/S1755020320000386,,math.LO cs.CL cs.LO,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper explores relational syllogistic logics, a family of logical
systems related to reasoning about relations in extensions of the classical
syllogistic. These are all decidable logical systems. We prove completeness
theorems and complexity results for a natural subfamily of relational
syllogistic logics, parametrized by constructors for terms and for sentences.
","[{'version': 'v1', 'created': 'Mon, 3 Sep 2018 16:57:54 GMT'}]",2020-10-28,"[['Kruckman', 'Alex', ''], ['Moss', 'Lawrence S.', '']]"
1370563,2010.14233,Ethan Chi,"Ethan A. Chi, Julian Salazar, and Katrin Kirchhoff","Align-Refine: Non-Autoregressive Speech Recognition via Iterative
  Realignment",,,,,eess.AS cs.CL cs.LG cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Non-autoregressive models greatly improve decoding speed over typical
sequence-to-sequence models, but suffer from degraded performance. Infilling
and iterative refinement models make up some of this gap by editing the outputs
of a non-autoregressive model, but are constrained in the edits that they can
make. We propose iterative realignment, where refinements occur over latent
alignments rather than output sequence space. We demonstrate this in speech
recognition with Align-Refine, an end-to-end Transformer-based model which
refines connectionist temporal classification (CTC) alignments to allow
length-changing insertions and deletions. Align-Refine outperforms Imputer and
Mask-CTC, matching an autoregressive baseline on WSJ at 1/14th the real-time
factor and attaining a LibriSpeech test-other WER of 9.0% without an LM. Our
model is strong even in one iteration with a shallower decoder.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 09:35:37 GMT'}]",2020-10-28,"[['Chi', 'Ethan A.', ''], ['Salazar', 'Julian', ''], ['Kirchhoff', 'Katrin', '']]"
831602,1703.08098,Dat Quoc Nguyen,Dat Quoc Nguyen,"A survey of embedding models of entities and relationships for knowledge
  graph completion","In Proceedings of the 14th Workshop on Graph-Based Natural Language
  Processing (TextGraphs 2020); 16 pages, 2 figures, 6 tables",,,,cs.CL cs.AI cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Knowledge graphs (KGs) of real-world facts about entities and their
relationships are useful resources for a variety of natural language processing
tasks. However, because knowledge graphs are typically incomplete, it is useful
to perform knowledge graph completion or link prediction, i.e. predict whether
a relationship not in the knowledge graph is likely to be true. This paper
serves as a comprehensive survey of embedding models of entities and
relationships for knowledge graph completion, summarizing up-to-date
experimental results on standard benchmark datasets and pointing out potential
future research directions.
","[{'version': 'v1', 'created': 'Thu, 23 Mar 2017 15:15:26 GMT'}, {'version': 'v2', 'created': 'Tue, 28 Mar 2017 15:28:08 GMT'}, {'version': 'v3', 'created': 'Sat, 3 Feb 2018 04:39:45 GMT'}, {'version': 'v4', 'created': 'Tue, 9 Apr 2019 02:26:26 GMT'}, {'version': 'v5', 'created': 'Sat, 27 Apr 2019 13:33:30 GMT'}, {'version': 'v6', 'created': 'Fri, 28 Feb 2020 07:06:36 GMT'}, {'version': 'v7', 'created': 'Wed, 22 Apr 2020 11:58:35 GMT'}, {'version': 'v8', 'created': 'Mon, 10 Aug 2020 08:35:07 GMT'}, {'version': 'v9', 'created': 'Tue, 27 Oct 2020 04:11:25 GMT'}]",2020-10-28,"[['Nguyen', 'Dat Quoc', '']]"
1370453,2010.14123,Viet Lai,"Viet Dac Lai, Tuan Ngo Nguyen, Thien Huu Nguyen","Event Detection: Gate Diversity and Syntactic Importance Scoresfor Graph
  Convolution Neural Networks",EMNLP 2020,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Recent studies on event detection (ED) haveshown that the syntactic
dependency graph canbe employed in graph convolution neural net-works (GCN) to
achieve state-of-the-art per-formance. However, the computation of thehidden
vectors in such graph-based models isagnostic to the trigger candidate words,
po-tentially leaving irrelevant information for thetrigger candidate for event
prediction. In addi-tion, the current models for ED fail to exploitthe overall
contextual importance scores of thewords, which can be obtained via the
depen-dency tree, to boost the performance. In thisstudy, we propose a novel
gating mechanismto filter noisy information in the hidden vec-tors of the GCN
models for ED based on theinformation from the trigger candidate. Wealso
introduce novel mechanisms to achievethe contextual diversity for the gates and
theimportance score consistency for the graphsand models in ED. The experiments
show thatthe proposed model achieves state-of-the-artperformance on two ED
datasets
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 08:28:28 GMT'}]",2020-10-28,"[['Lai', 'Viet Dac', ''], ['Nguyen', 'Tuan Ngo', ''], ['Nguyen', 'Thien Huu', '']]"
1370314,2010.13984,Siwon Kim,"Siwon Kim, Jihun Yi, Eunji Kim, and Sungroh Yoon",Interpretation of NLP models through input marginalization,"10 pages, 5 figures, to be published in the 2020 Conference on
  Empirical Methods in Natural Language Processing (EMNLP 2020)",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  To demystify the ""black box"" property of deep neural networks for natural
language processing (NLP), several methods have been proposed to interpret
their predictions by measuring the change in prediction probability after
erasing each token of an input. Since existing methods replace each token with
a predefined value (i.e., zero), the resulting sentence lies out of the
training data distribution, yielding misleading interpretations. In this study,
we raise the out-of-distribution problem induced by the existing interpretation
methods and present a remedy; we propose to marginalize each token out. We
interpret various NLP models trained for sentiment analysis and natural
language inference using the proposed method.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 01:40:41 GMT'}]",2020-10-28,"[['Kim', 'Siwon', ''], ['Yi', 'Jihun', ''], ['Kim', 'Eunji', ''], ['Yoon', 'Sungroh', '']]"
1370156,2010.13826,Cheng-I Lai,"Cheng-I Lai, Yung-Sung Chuang, Hung-Yi Lee, Shang-Wen Li, James Glass","Semi-Supervised Spoken Language Understanding via Self-Supervised Speech
  and Language Model Pretraining",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Much recent work on Spoken Language Understanding (SLU) is limited in at
least one of three ways: models were trained on oracle text input and neglected
ASR errors, models were trained to predict only intents without the slot
values, or models were trained on a large amount of in-house data. In this
paper, we propose a clean and general framework to learn semantics directly
from speech with semi-supervision from transcribed or untranscribed speech to
address these issues. Our framework is built upon pretrained end-to-end (E2E)
ASR and self-supervised language models, such as BERT, and fine-tuned on a
limited amount of target SLU data. We study two semi-supervised settings for
the ASR component: supervised pretraining on transcribed speech, and
unsupervised pretraining by replacing the ASR encoder with self-supervised
speech representations, such as wav2vec. In parallel, we identify two essential
criteria for evaluating SLU models: environmental noise-robustness and E2E
semantics evaluation. Experiments on ATIS show that our SLU framework with
speech as input can perform on par with those using oracle text as input in
semantics understanding, even though environmental noise is present and a
limited amount of labeled semantics data is available for training.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 18:21:27 GMT'}]",2020-10-28,"[['Lai', 'Cheng-I', ''], ['Chuang', 'Yung-Sung', ''], ['Lee', 'Hung-Yi', ''], ['Li', 'Shang-Wen', ''], ['Glass', 'James', '']]"
1370432,2010.14102,Wen Wu,"Wen Wu, Chao Zhang, Philip C. Woodland","Emotion recognition by fusing time synchronous and time asynchronous
  representations",,,,,cs.CL cs.LG cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, a novel two-branch neural network model structure is proposed
for multimodal emotion recognition, which consists of a time synchronous branch
(TSB) and a time asynchronous branch (TAB). To capture correlations between
each word and its acoustic realisation, the TSB combines speech and text
modalities at each input window frame and then does pooling across time to form
a single embedding vector. The TAB, by contrast, provides cross-utterance
information by integrating sentence text embeddings from a number of context
utterances into another embedding vector. The final emotion classification uses
both the TSB and the TAB embeddings. Experimental results on the IEMOCAP
dataset demonstrate that the two-branch structure achieves state-of-the-art
results in 4-way classification with all common test setups. When using
automatic speech recognition (ASR) output instead of manually transcribed
reference text, it is shown that the cross-utterance information considerably
improves the robustness against ASR errors. Furthermore, by incorporating an
extra class for all the other emotions, the final 5-way classification system
with ASR hypotheses can be viewed as a prototype for more realistic emotion
recognition systems.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 07:14:31 GMT'}]",2020-10-28,"[['Wu', 'Wen', ''], ['Zhang', 'Chao', ''], ['Woodland', 'Philip C.', '']]"
1370391,2010.14061,Yan Zeng,Yan Zeng and Jian-Yun Nie,"Multi-Domain Dialogue State Tracking -- A Purely Transformer-Based
  Generative Approach","[v0], 8 pages, 3 figures. arXiv admin note: text overlap with
  arXiv:2010.11137",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We investigate the problem of multi-domain Dialogue State Tracking (DST) with
open vocabulary. Existing approaches exploit BERT encoder and copy-based RNN
decoder, where the encoder first predicts the state operation, and then the
decoder generates new slot values. However, in this stacked encoder-decoder
structure, the operation prediction objective only affects the BERT encoder and
the value generation objective mainly affects the RNN decoder. In this paper,
we propose a purely Transformer-based framework that uses BERT as both encoder
and decoder. In so doing, the operation prediction objective and the value
generation objective can jointly optimize our model for DST. At the decoding
step, we re-use the hidden states of the encoder in the self-attention
mechanism of the corresponding decoder layer to construct a flat model
structure for effective parameter updating. Experimental results show that our
approach substantially outperforms the existing state-of-the-art framework, and
it also achieves very competitive performance to the best ontology-based
approaches.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 04:54:52 GMT'}]",2020-10-28,"[['Zeng', 'Yan', ''], ['Nie', 'Jian-Yun', '']]"
1370372,2010.14042,Kasturi Bhattacharjee,"Kasturi Bhattacharjee, Miguel Ballesteros, Rishita Anubhai, Smaranda
  Muresan, Jie Ma, Faisal Ladhak, Yaser Al-Onaizan","To BERT or Not to BERT: Comparing Task-specific and Task-agnostic
  Semi-Supervised Approaches for Sequence Tagging","Accepted in the Proceedings of 2020 Conference on Empirical Methods
  in Natural Language Processing (EMNLP
  2020)(https://2020.emnlp.org/papers/main)",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Leveraging large amounts of unlabeled data using Transformer-like
architectures, like BERT, has gained popularity in recent times owing to their
effectiveness in learning general representations that can then be further
fine-tuned for downstream tasks to much success. However, training these models
can be costly both from an economic and environmental standpoint. In this work,
we investigate how to effectively use unlabeled data: by exploring the
task-specific semi-supervised approach, Cross-View Training (CVT) and comparing
it with task-agnostic BERT in multiple settings that include domain and task
relevant English data. CVT uses a much lighter model architecture and we show
that it achieves similar performance to BERT on a set of sequence tagging
tasks, with lesser financial and environmental impact.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 04:03:47 GMT'}]",2020-10-28,"[['Bhattacharjee', 'Kasturi', ''], ['Ballesteros', 'Miguel', ''], ['Anubhai', 'Rishita', ''], ['Muresan', 'Smaranda', ''], ['Ma', 'Jie', ''], ['Ladhak', 'Faisal', ''], ['Al-Onaizan', 'Yaser', '']]"
1370359,2010.14029,Runxin Xu,"Runxin Xu, Zhuo Zhi, Jun Cao, Mingxuan Wang, Lei Li",Volctrans Parallel Corpus Filtering System for WMT 2020,WMT 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we describe our submissions to the WMT20 shared task on
parallel corpus filtering and alignment for low-resource conditions. The task
requires the participants to align potential parallel sentence pairs out of the
given document pairs, and score them so that low-quality pairs can be filtered.
Our system, Volctrans, is made of two modules, i.e., a mining module and a
scoring module. Based on the word alignment model, the mining module adopts an
iterative mining strategy to extract latent parallel sentences. In the scoring
module, an XLM-based scorer provides scores, followed by reranking mechanisms
and ensemble. Our submissions outperform the baseline by 3.x/2.x and 2.x/2.x
for km-en and ps-en on From Scratch/Fine-Tune conditions, which is the highest
among all submissions.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 03:20:04 GMT'}]",2020-10-28,"[['Xu', 'Runxin', ''], ['Zhi', 'Zhuo', ''], ['Cao', 'Jun', ''], ['Wang', 'Mingxuan', ''], ['Li', 'Lei', '']]"
1370321,2010.13991,Wei Zou,"Dongwei Jiang, Wubo Li, Miao Cao, Ruixiong Zhang, Wei Zou, Kun Han,
  Xiangang Li","Speech SIMCLR: Combining Contrastive and Reconstruction Objective for
  Self-supervised Speech Representation Learning",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Self-supervised visual pretraining has shown significant progress recently.
Among those methods, SimCLR greatly advanced the state of the art in
self-supervised and semi-supervised learning on ImageNet. The input feature
representations for speech and visual tasks are both continuous, so it is
natural to consider applying similar objective on speech representation
learning. In this paper, we propose Speech SimCLR, a new self-supervised
objective for speech representation learning. During training, Speech SimCLR
applies augmentation on raw speech and its spectrogram. Its objective is the
combination of contrastive loss that maximizes agreement between differently
augmented samples in the latent space and reconstruction loss of input
representation. The proposed method achieved competitive results on speech
emotion recognition and speech recognition. When used as feature extractor, our
best model achieved 5.89% word error rate on LibriSpeech test-clean set using
LibriSpeech 960 hours as pretraining data and LibriSpeech train-clean-100 set
as fine-tuning data, which is the lowest error rate obtained in this setup to
the best of our knowledge.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 02:09:06 GMT'}]",2020-10-28,"[['Jiang', 'Dongwei', ''], ['Li', 'Wubo', ''], ['Cao', 'Miao', ''], ['Zhang', 'Ruixiong', ''], ['Zou', 'Wei', ''], ['Han', 'Kun', ''], ['Li', 'Xiangang', '']]"
1339591,2008.11869,Xinsong Zhang,Xinsong Zhang and Hang Li,AMBERT: A Pre-trained Language Model with Multi-Grained Tokenization,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pre-trained language models such as BERT have exhibited remarkable
performances in many tasks in natural language understanding (NLU). The tokens
in the models are usually fine-grained in the sense that for languages like
English they are words or sub-words and for languages like Chinese they are
characters. In English, for example, there are multi-word expressions which
form natural lexical units and thus the use of coarse-grained tokenization also
appears to be reasonable. In fact, both fine-grained and coarse-grained
tokenizations have advantages and disadvantages for learning of pre-trained
language models. In this paper, we propose a novel pre-trained language model,
referred to as AMBERT (A Multi-grained BERT), on the basis of both fine-grained
and coarse-grained tokenizations. For English, AMBERT takes both the sequence
of words (fine-grained tokens) and the sequence of phrases (coarse-grained
tokens) as input after tokenization, employs one encoder for processing the
sequence of words and the other encoder for processing the sequence of the
phrases, utilizes shared parameters between the two encoders, and finally
creates a sequence of contextualized representations of the words and a
sequence of contextualized representations of the phrases. Experiments have
been conducted on benchmark datasets for Chinese and English, including CLUE,
GLUE, SQuAD and RACE. The results show that AMBERT outperforms the existing
best performing models in almost all cases, particularly the improvements are
significant for Chinese.
","[{'version': 'v1', 'created': 'Thu, 27 Aug 2020 00:23:48 GMT'}, {'version': 'v2', 'created': 'Tue, 1 Sep 2020 05:29:27 GMT'}, {'version': 'v3', 'created': 'Tue, 27 Oct 2020 06:53:33 GMT'}]",2020-10-28,"[['Zhang', 'Xinsong', ''], ['Li', 'Hang', '']]"
1279334,2004.14564,Brian Thompson,Brian Thompson and Matt Post,"Automatic Machine Translation Evaluation in Many Languages via Zero-Shot
  Paraphrasing",EMNLP2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We frame the task of machine translation evaluation as one of scoring machine
translation output with a sequence-to-sequence paraphraser, conditioned on a
human reference. We propose training the paraphraser as a multilingual NMT
system, treating paraphrasing as a zero-shot translation task (e.g., Czech to
Czech). This results in the paraphraser's output mode being centered around a
copy of the input sequence, which represents the best case scenario where the
MT system output matches a human reference. Our method is simple and intuitive,
and does not require human judgements for training. Our single model (trained
in 39 languages) outperforms or statistically ties with all prior metrics on
the WMT 2019 segment-level shared metrics task in all languages (excluding
Gujarati where the model had no training data). We also explore using our model
for the task of quality estimation as a metric--conditioning on the source
instead of the reference--and find that it significantly outperforms every
submission to the WMT 2019 shared task on quality estimation in every language
pair.
","[{'version': 'v1', 'created': 'Thu, 30 Apr 2020 03:32:34 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 23:54:02 GMT'}]",2020-10-29,"[['Thompson', 'Brian', ''], ['Post', 'Matt', '']]"
1187463,1910.03544,Jianguo Zhang,"Jian-Guo Zhang, Kazuma Hashimoto, Chien-Sheng Wu, Yao Wan, Philip S.
  Yu, Richard Socher, Caiming Xiong","Find or Classify? Dual Strategy for Slot-Value Predictions on
  Multi-Domain Dialog State Tracking","14 pages, accepted at the 9th Joint Conference on Lexical and
  Computational Semantics (*SEM 2020). This version fixes small errors",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Dialog state tracking (DST) is a core component in task-oriented dialog
systems. Existing approaches for DST mainly fall into one of two categories,
namely, ontology-based and ontology-free methods. An ontology-based method
selects a value from a candidate-value list for each target slot, while an
ontology-free method extracts spans from dialog contexts. Recent work
introduced a BERT-based model to strike a balance between the two methods by
pre-defining categorical and non-categorical slots. However, it is not clear
enough which slots are better handled by either of the two slot types, and the
way to use the pre-trained model has not been well investigated. In this paper,
we propose a simple yet effective dual-strategy model for DST, by adapting a
single BERT-style reading comprehension model to jointly handle both the
categorical and non-categorical slots. Our experiments on the MultiWOZ datasets
show that our method significantly outperforms the BERT-based counterpart,
finding that the key is a deep interaction between the domain-slot and context
information. When evaluated on noisy (MultiWOZ 2.0) and cleaner (MultiWOZ 2.1)
settings, our method performs competitively and robustly across the two
different settings. Our method sets the new state of the art in the noisy
setting, while performing more robustly than the best model in the cleaner
setting. We also conduct a comprehensive error analysis on the dataset,
including the effects of the dual strategy for each slot, to facilitate future
research.
","[{'version': 'v1', 'created': 'Tue, 8 Oct 2019 17:08:39 GMT'}, {'version': 'v2', 'created': 'Thu, 10 Oct 2019 08:04:12 GMT'}, {'version': 'v3', 'created': 'Tue, 29 Sep 2020 08:37:44 GMT'}, {'version': 'v4', 'created': 'Wed, 28 Oct 2020 10:07:01 GMT'}]",2020-10-29,"[['Zhang', 'Jian-Guo', ''], ['Hashimoto', 'Kazuma', ''], ['Wu', 'Chien-Sheng', ''], ['Wan', 'Yao', ''], ['Yu', 'Philip S.', ''], ['Socher', 'Richard', ''], ['Xiong', 'Caiming', '']]"
1342828,2009.01325,Ryan Lowe T.,"Nisan Stiennon, Long Ouyang, Jeff Wu, Daniel M. Ziegler, Ryan Lowe,
  Chelsea Voss, Alec Radford, Dario Amodei, Paul Christiano",Learning to summarize from human feedback,NeurIPS 2020 camera ready,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As language models become more powerful, training and evaluation are
increasingly bottlenecked by the data and metrics used for a particular task.
For example, summarization models are often trained to predict human reference
summaries and evaluated using ROUGE, but both of these metrics are rough
proxies for what we really care about---summary quality. In this work, we show
that it is possible to significantly improve summary quality by training a
model to optimize for human preferences. We collect a large, high-quality
dataset of human comparisons between summaries, train a model to predict the
human-preferred summary, and use that model as a reward function to fine-tune a
summarization policy using reinforcement learning. We apply our method to a
version of the TL;DR dataset of Reddit posts and find that our models
significantly outperform both human reference summaries and much larger models
fine-tuned with supervised learning alone. Our models also transfer to CNN/DM
news articles, producing summaries nearly as good as the human reference
without any news-specific fine-tuning. We conduct extensive analyses to
understand our human feedback dataset and fine-tuned models We establish that
our reward model generalizes to new datasets, and that optimizing our reward
model results in better summaries than optimizing ROUGE according to humans. We
hope the evidence from our paper motivates machine learning researchers to pay
closer attention to how their training loss affects the model behavior they
actually want.
","[{'version': 'v1', 'created': 'Wed, 2 Sep 2020 19:54:41 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 22:19:53 GMT'}]",2020-10-29,"[['Stiennon', 'Nisan', ''], ['Ouyang', 'Long', ''], ['Wu', 'Jeff', ''], ['Ziegler', 'Daniel M.', ''], ['Lowe', 'Ryan', ''], ['Voss', 'Chelsea', ''], ['Radford', 'Alec', ''], ['Amodei', 'Dario', ''], ['Christiano', 'Paul', '']]"
1201327,1911.02733,Xue Mengge,"Xue Mengge, Yu Bowen, Liu Tingwen, Zhang Yue, Meng Erli, Wang Bin",Porous Lattice-based Transformer Encoder for Chinese NER,"9 pages, 4 figures",COLING 2020,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Incorporating lattices into character-level Chinese named entity recognition
is an effective method to exploit explicit word information. Recent works
extend recurrent and convolutional neural networks to model lattice inputs.
However, due to the DAG structure or the variable-sized potential word set for
lattice inputs, these models prevent the convenient use of batched computation,
resulting in serious inefficient. In this paper, we propose a porous
lattice-based transformer encoder for Chinese named entity recognition, which
is capable to better exploit the GPU parallelism and batch the computation
owing to the mask mechanism in transformer. We first investigate the
lattice-aware self-attention coupled with relative position representations to
explore effective word information in the lattice structure. Besides, to
strengthen the local dependencies among neighboring tokens, we propose a novel
porous structure during self-attentional computation processing, in which every
two non-neighboring tokens are connected through a shared pivot node.
Experimental results on four datasets show that our model performs up to 9.47
times faster than state-of-the-art models, while is roughly on a par with its
performance. The source code of this paper can be obtained from
https://github.com/xxx/xxx.
","[{'version': 'v1', 'created': 'Thu, 7 Nov 2019 02:58:17 GMT'}, {'version': 'v2', 'created': 'Fri, 24 Apr 2020 14:46:51 GMT'}, {'version': 'v3', 'created': 'Wed, 28 Oct 2020 12:52:24 GMT'}]",2020-10-29,"[['Mengge', 'Xue', ''], ['Bowen', 'Yu', ''], ['Tingwen', 'Liu', ''], ['Yue', 'Zhang', ''], ['Erli', 'Meng', ''], ['Bin', 'Wang', '']]"
1290078,2005.10283,Bryan Eikema,Bryan Eikema and Wilker Aziz,"Is MAP Decoding All You Need? The Inadequacy of the Mode in Neural
  Machine Translation",COLING 2020 camera-ready,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Recent studies have revealed a number of pathologies of neural machine
translation (NMT) systems. Hypotheses explaining these mostly suggest there is
something fundamentally wrong with NMT as a model or its training algorithm,
maximum likelihood estimation (MLE). Most of this evidence was gathered using
maximum a posteriori (MAP) decoding, a decision rule aimed at identifying the
highest-scoring translation, i.e. the mode. We argue that the evidence
corroborates the inadequacy of MAP decoding more than casts doubt on the model
and its training algorithm. In this work, we show that translation
distributions do reproduce various statistics of the data well, but that beam
search strays from such statistics. We show that some of the known pathologies
and biases of NMT are due to MAP decoding and not to NMT's statistical
assumptions nor MLE. In particular, we show that the most likely translations
under the model accumulate so little probability mass that the mode can be
considered essentially arbitrary. We therefore advocate for the use of decision
rules that take into account the translation distribution holistically. We show
that an approximation to minimum Bayes risk decoding gives competitive results
confirming that NMT models do capture important aspects of translation well in
expectation.
","[{'version': 'v1', 'created': 'Wed, 20 May 2020 18:05:51 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 11:29:52 GMT'}]",2020-10-29,"[['Eikema', 'Bryan', ''], ['Aziz', 'Wilker', '']]"
1303020,2006.08506,Tobias Watzel,"Tobias Watzel, Ludwig K\""urzinger, Lujun Li, Gerhard Rigoll",Regularized Forward-Backward Decoder for Attention Models,,,,,eess.AS cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Nowadays, attention models are one of the popular candidates for speech
recognition. So far, many studies mainly focus on the encoder structure or the
attention module to enhance the performance of these models. However, mostly
ignore the decoder. In this paper, we propose a novel regularization technique
incorporating a second decoder during the training phase. This decoder is
optimized on time-reversed target labels beforehand and supports the standard
decoder during training by adding knowledge from future context. Since it is
only added during training, we are not changing the basic structure of the
network or adding complexity during decoding. We evaluate our approach on the
smaller TEDLIUMv2 and the larger LibriSpeech dataset, achieving consistent
improvements on both of them.
","[{'version': 'v1', 'created': 'Mon, 15 Jun 2020 16:04:16 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 14:00:52 GMT'}]",2020-10-29,"[['Watzel', 'Tobias', ''], ['Kürzinger', 'Ludwig', ''], ['Li', 'Lujun', ''], ['Rigoll', 'Gerhard', '']]"
1295146,2006.00632,Barbara Plank,Alan Ramponi and Barbara Plank,Neural Unsupervised Domain Adaptation in NLP---A Survey,"COLING 2020. Accompanying repository:
  https://github.com/bplank/awesome-neural-adaptation-in-NLP",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Deep neural networks excel at learning from labeled data and achieve
state-of-the-art resultson a wide array of Natural Language Processing tasks.
In contrast, learning from unlabeled data, especially under domain shift,
remains a challenge. Motivated by the latest advances, in this survey we review
neural unsupervised domain adaptation techniques which do not require labeled
target domain data. This is a more challenging yet a more widely applicable
setup. We outline methods, from early traditional non-neural methods to
pre-trained model transfer. We also revisit the notion of domain, and we
uncover a bias in the type of Natural Language Processing tasks which received
most attention. Lastly, we outline future directions, particularly the broader
need for out-of-distribution generalization of future NLP.
","[{'version': 'v1', 'created': 'Sun, 31 May 2020 22:34:14 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 08:24:14 GMT'}]",2020-10-29,"[['Ramponi', 'Alan', ''], ['Plank', 'Barbara', '']]"
1292163,2005.12368,Marija Stepanovi\'c,"Andreas Kirkedal, Marija Stepanovi\'c, Barbara Plank",FT Speech: Danish Parliament Speech Corpus,Accepted at Interspeech 2020,,10.21437/Interspeech.2020-3164,,cs.CL cs.LG cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper introduces FT Speech, a new speech corpus created from the
recorded meetings of the Danish Parliament, otherwise known as the Folketing
(FT). The corpus contains over 1,800 hours of transcribed speech by a total of
434 speakers. It is significantly larger in duration, vocabulary, and amount of
spontaneous speech than the existing public speech corpora for Danish, which
are largely limited to read-aloud and dictation data. We outline design
considerations, including the preprocessing methods and the alignment
procedure. To evaluate the quality of the corpus, we train automatic speech
recognition systems on the new resource and compare them to the systems trained
on the Danish part of Spr\r{a}kbanken, the largest public ASR corpus for Danish
to date. Our baseline results show that we achieve a 14.01 WER on the new
corpus. A combination of FT Speech with in-domain language data provides
comparable results to models trained specifically on Spr\r{a}kbanken, showing
that FT Speech transfers well to this data set. Interestingly, our results
demonstrate that the opposite is not the case. This shows that FT Speech
provides a valuable resource for promoting research on Danish ASR with more
spontaneous speech.
","[{'version': 'v1', 'created': 'Mon, 25 May 2020 19:51:18 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 13:36:44 GMT'}]",2020-10-29,"[['Kirkedal', 'Andreas', ''], ['Stepanović', 'Marija', ''], ['Plank', 'Barbara', '']]"
1364540,2010.08210,Xue Mengge,"Mengge Xue, Bowen Yu, Zhenyu Zhang, Tingwen Liu, Yue Zhang, Bin Wang",Coarse-to-Fine Pre-training for Named Entity Recognition,,EMNLP 2020,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  More recently, Named Entity Recognition hasachieved great advances aided by
pre-trainingapproaches such as BERT. However, currentpre-training techniques
focus on building lan-guage modeling objectives to learn a gen-eral
representation, ignoring the named entity-related knowledge. To this end, we
proposea NER-specific pre-training framework to in-ject coarse-to-fine
automatically mined entityknowledge into pre-trained models. Specifi-cally, we
first warm-up the model via an en-tity span identification task by training it
withWikipedia anchors, which can be deemed asgeneral-typed entities. Then we
leverage thegazetteer-based distant supervision strategy totrain the model
extract coarse-grained typedentities. Finally, we devise a
self-supervisedauxiliary task to mine the fine-grained namedentity knowledge
via clustering.Empiricalstudies on three public NER datasets demon-strate that
our framework achieves significantimprovements against several pre-trained
base-lines, establishing the new state-of-the-art per-formance on three
benchmarks. Besides, weshow that our framework gains promising re-sults without
using human-labeled trainingdata, demonstrating its effectiveness in label-few
and low-resource scenarios
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 07:39:20 GMT'}]",2020-10-29,"[['Xue', 'Mengge', ''], ['Yu', 'Bowen', ''], ['Zhang', 'Zhenyu', ''], ['Liu', 'Tingwen', ''], ['Zhang', 'Yue', ''], ['Wang', 'Bin', '']]"
1361978,2010.05648,Steffen Eger,Steffen Eger and Yannik Benz,From Hero to Z\'eroe: A Benchmark of Low-Level Adversarial Attacks,"Authors accidentally in wrong order; cannot be undone due to
  conference constraints. Accepted for publication at AACL 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Adversarial attacks are label-preserving modifications to inputs of machine
learning classifiers designed to fool machines but not humans. Natural Language
Processing (NLP) has mostly focused on high-level attack scenarios such as
paraphrasing input texts. We argue that these are less realistic in typical
application scenarios such as in social media, and instead focus on low-level
attacks on the character-level. Guided by human cognitive abilities and human
robustness, we propose the first large-scale catalogue and benchmark of
low-level adversarial attacks, which we dub Z\'eroe, encompassing nine
different attack modes including visual and phonetic adversaries. We show that
RoBERTa, NLP's current workhorse, fails on our attacks. Our dataset provides a
benchmark for testing robustness of future more human-like NLP models.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 12:35:36 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 12:53:05 GMT'}]",2020-10-29,"[['Eger', 'Steffen', ''], ['Benz', 'Yannik', '']]"
1359177,2010.02847,Haiyang Zhang,"Haiyang Zhang, Alison Sneyd and Mark Stevenson","Robustness and Reliability of Gender Bias Assessment in Word Embeddings:
  The Role of Base Pairs",Accepted at AACL-IJCNLP 2020,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  It has been shown that word embeddings can exhibit gender bias, and various
methods have been proposed to quantify this. However, the extent to which the
methods are capturing social stereotypes inherited from the data has been
debated. Bias is a complex concept and there exist multiple ways to define it.
Previous work has leveraged gender word pairs to measure bias and extract
biased analogies. We show that the reliance on these gendered pairs has strong
limitations: bias measures based off of them are not robust and cannot identify
common types of real-world bias, whilst analogies utilising them are unsuitable
indicators of bias. In particular, the well-known analogy ""man is to
computer-programmer as woman is to homemaker"" is due to word similarity rather
than societal bias. This has important implications for work on measuring bias
in embeddings and related work debiasing embeddings.
","[{'version': 'v1', 'created': 'Tue, 6 Oct 2020 16:09:05 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 21:24:16 GMT'}]",2020-10-29,"[['Zhang', 'Haiyang', ''], ['Sneyd', 'Alison', ''], ['Stevenson', 'Mark', '']]"
1356617,2010.00287,Ehsan Doostmohammadi,"Ehsan Doostmohammadi, Minoo Nassajian, Adel Rahimi","Joint Persian Word Segmentation Correction and Zero-Width Non-Joiner
  Recognition Using BERT",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Words are properly segmented in the Persian writing system; in practice,
however, these writing rules are often neglected, resulting in single words
being written disjointedly and multiple words written without any white spaces
between them. This paper addresses the problems of word segmentation and
zero-width non-joiner (ZWNJ) recognition in Persian, which we approach jointly
as a sequence labeling problem. We achieved a macro-averaged F1-score of 92.40%
on a carefully collected corpus of 500 sentences with a high level of
difficulty.
","[{'version': 'v1', 'created': 'Thu, 1 Oct 2020 10:32:17 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 09:40:18 GMT'}]",2020-10-29,"[['Doostmohammadi', 'Ehsan', ''], ['Nassajian', 'Minoo', ''], ['Rahimi', 'Adel', '']]"
1280566,2005.00771,Xiang Li,"Michael Boratko, Xiang Lorraine Li, Rajarshi Das, Tim O'Gorman, Dan
  Le, Andrew McCallum","ProtoQA: A Question Answering Dataset for Prototypical Common-Sense
  Reasoning",First four authors contribute equally,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Given questions regarding some prototypical situation such as Name something
that people usually do before they leave the house for work? a human can easily
answer them via acquired experiences. There can be multiple right answers for
such questions, with some more common for a situation than others. This paper
introduces a new question answering dataset for training and evaluating common
sense reasoning capabilities of artificial intelligence systems in such
prototypical situations. The training set is gathered from an existing set of
questions played in a long-running international game show FAMILY- FEUD. The
hidden evaluation set is created by gathering answers for each question from
100 crowd-workers. We also propose a generative evaluation task where a model
has to output a ranked list of answers, ideally covering all prototypical
answers for a question. After presenting multiple competitive baseline models,
we find that human performance still exceeds model scores on all evaluation
metrics with a meaningful gap, supporting the challenging nature of the task.
","[{'version': 'v1', 'created': 'Sat, 2 May 2020 09:40:05 GMT'}, {'version': 'v2', 'created': 'Tue, 6 Oct 2020 05:35:05 GMT'}, {'version': 'v3', 'created': 'Tue, 27 Oct 2020 21:23:03 GMT'}]",2020-10-29,"[['Boratko', 'Michael', ''], ['Li', 'Xiang Lorraine', ''], ['Das', 'Rajarshi', ''], [""O'Gorman"", 'Tim', ''], ['Le', 'Dan', ''], ['McCallum', 'Andrew', '']]"
1279954,2005.00159,Pratyush Maini,"Pratyush Maini, Keshav Kolluru, Danish Pruthi, Mausam","Why and when should you pool? Analyzing Pooling in Recurrent
  Architectures","Accepted to Findings of EMNLP 2020, to be presented at BlackBoxNLP.
  Updated Version",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pooling-based recurrent neural architectures consistently outperform their
counterparts without pooling. However, the reasons for their enhanced
performance are largely unexamined. In this work, we examine three commonly
used pooling techniques (mean-pooling, max-pooling, and attention), and propose
max-attention, a novel variant that effectively captures interactions among
predictive tokens in a sentence. We find that pooling-based architectures
substantially differ from their non-pooling equivalents in their learning
ability and positional biases--which elucidate their performance benefits. By
analyzing the gradient propagation, we discover that pooling facilitates better
gradient flow compared to BiLSTMs. Further, we expose how BiLSTMs are
positionally biased towards tokens in the beginning and the end of a sequence.
Pooling alleviates such biases. Consequently, we identify settings where
pooling offers large benefits: (i) in low resource scenarios, and (ii) when
important words lie towards the middle of the sentence. Among the pooling
techniques studied, max-attention is the most effective, resulting in
significant performance gains on several text classification tasks.
","[{'version': 'v1', 'created': 'Fri, 1 May 2020 00:47:37 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 02:11:02 GMT'}]",2020-10-29,"[['Maini', 'Pratyush', ''], ['Kolluru', 'Keshav', ''], ['Pruthi', 'Danish', ''], ['Mausam', '', '']]"
1332657,2008.04935,Brian Thompson,Brian Thompson and Matt Post,"Paraphrase Generation as Zero-Shot Multilingual Translation:
  Disentangling Semantic Similarity from Lexical and Syntactic Diversity",WMT2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent work has shown that a multilingual neural machine translation (NMT)
model can be used to judge how well a sentence paraphrases another sentence in
the same language (Thompson and Post, 2020); however, attempting to generate
paraphrases from such a model using standard beam search produces trivial
copies or near copies. We introduce a simple paraphrase generation algorithm
which discourages the production of n-grams that are present in the input. Our
approach enables paraphrase generation in many languages from a single
multilingual NMT model. Furthermore, the amount of lexical diversity between
the input and output can be controlled at generation time. We conduct a human
evaluation to compare our method to a paraphraser trained on the large English
synthetic paraphrase database ParaBank 2 (Hu et al., 2019c) and find that our
method produces paraphrases that better preserve meaning and are more
gramatical, for the same level of lexical diversity. Additional smaller human
assessments demonstrate our approach also works in two non-English languages.
","[{'version': 'v1', 'created': 'Tue, 11 Aug 2020 18:05:34 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 02:54:13 GMT'}]",2020-10-29,"[['Thompson', 'Brian', ''], ['Post', 'Matt', '']]"
1349467,2009.07964,Zhijing Jin,"Xiaoyu Xing, Zhijing Jin, Di Jin, Bingning Wang, Qi Zhang, and
  Xuanjing Huang","Tasty Burgers, Soggy Fries: Probing Aspect Robustness in Aspect-Based
  Sentiment Analysis","EMNLP 2020, long paper",,,,cs.CL cs.IR cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  Aspect-based sentiment analysis (ABSA) aims to predict the sentiment towards
a specific aspect in the text. However, existing ABSA test sets cannot be used
to probe whether a model can distinguish the sentiment of the target aspect
from the non-target aspects. To solve this problem, we develop a simple but
effective approach to enrich ABSA test sets. Specifically, we generate new
examples to disentangle the confounding sentiments of the non-target aspects
from the target aspect's sentiment. Based on the SemEval 2014 dataset, we
construct the Aspect Robustness Test Set (ARTS) as a comprehensive probe of the
aspect robustness of ABSA models. Over 92% data of ARTS show high fluency and
desired sentiment on all aspects by human evaluation. Using ARTS, we analyze
the robustness of nine ABSA models, and observe, surprisingly, that their
accuracy drops by up to 69.73%. We explore several ways to improve aspect
robustness, and find that adversarial training can improve models' performance
on ARTS by up to 32.85%. Our code and new test set are available at
https://github.com/zhijing-jin/ARTS_TestSet
","[{'version': 'v1', 'created': 'Wed, 16 Sep 2020 22:38:18 GMT'}, {'version': 'v2', 'created': 'Wed, 30 Sep 2020 05:36:10 GMT'}, {'version': 'v3', 'created': 'Sun, 4 Oct 2020 15:35:36 GMT'}, {'version': 'v4', 'created': 'Wed, 28 Oct 2020 08:19:36 GMT'}]",2020-10-29,"[['Xing', 'Xiaoyu', ''], ['Jin', 'Zhijing', ''], ['Jin', 'Di', ''], ['Wang', 'Bingning', ''], ['Zhang', 'Qi', ''], ['Huang', 'Xuanjing', '']]"
1303623,2006.09109,Steffen Eger,Steffen Eger and Johannes Daxenberger and Iryna Gurevych,"How to Probe Sentence Embeddings in Low-Resource Languages: On
  Structural Design Choices for Probing Task Evaluation",Accepted for Publication at CONLL 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Sentence encoders map sentences to real valued vectors for use in downstream
applications. To peek into these representations - e.g., to increase
interpretability of their results - probing tasks have been designed which
query them for linguistic knowledge. However, designing probing tasks for
lesser-resourced languages is tricky, because these often lack large-scale
annotated data or (high-quality) dependency parsers as a prerequisite of
probing task design in English. To investigate how to probe sentence embeddings
in such cases, we investigate sensitivity of probing task results to structural
design choices, conducting the first such large scale study. We show that
design choices like size of the annotated probing dataset and type of
classifier used for evaluation do (sometimes substantially) influence probing
outcomes. We then probe embeddings in a multilingual setup with design choices
that lie in a 'stable region', as we identify for English, and find that
results on English do not transfer to other languages. Fairer and more
comprehensive sentence-level probing evaluation should thus be carried out on
multiple languages in the future.
","[{'version': 'v1', 'created': 'Tue, 16 Jun 2020 12:37:50 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 12:38:37 GMT'}]",2020-10-29,"[['Eger', 'Steffen', ''], ['Daxenberger', 'Johannes', ''], ['Gurevych', 'Iryna', '']]"
1139420,1906.07234,Siyuan Feng,"Siyuan Feng, Tan Lee, Zhiyuan Peng","Combining Adversarial Training and Disentangled Speech Representation
  for Robust Zero-Resource Subword Modeling","5 pages, 3 figures, accepted for publication in INTERSPEECH 2019,
  Graz, Austria",,10.21437/Interspeech.2019-1337,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This study addresses the problem of unsupervised subword unit discovery from
untranscribed speech. It forms the basis of the ultimate goal of ZeroSpeech
2019, building text-to-speech systems without text labels. In this work, unit
discovery is formulated as a pipeline of phonetically discriminative feature
learning and unit inference. One major difficulty in robust unsupervised
feature learning is dealing with speaker variation. Here the robustness towards
speaker variation is achieved by applying adversarial training and FHVAE based
disentangled speech representation learning. A comparison of the two approaches
as well as their combination is studied in a DNN-bottleneck feature (DNN-BNF)
architecture. Experiments are conducted on ZeroSpeech 2019 and 2017.
Experimental results on ZeroSpeech 2017 show that both approaches are effective
while the latter is more prominent, and that their combination brings further
marginal improvement in across-speaker condition. Results on ZeroSpeech 2019
show that in the ABX discriminability task, our approaches significantly
outperform the official baseline, and are competitive to or even outperform the
official topline. The proposed unit sequence smoothing algorithm improves
synthesis quality, at a cost of slight decrease in ABX discriminability.
","[{'version': 'v1', 'created': 'Mon, 17 Jun 2019 19:40:46 GMT'}, {'version': 'v2', 'created': 'Wed, 3 Jul 2019 12:22:28 GMT'}, {'version': 'v3', 'created': 'Fri, 9 Aug 2019 15:55:00 GMT'}]",2020-10-29,"[['Feng', 'Siyuan', ''], ['Lee', 'Tan', ''], ['Peng', 'Zhiyuan', '']]"
1371089,2010.14759,Yufang Hou,Yufang Hou,"Fine-grained Information Status Classification Using Discourse
  Context-Aware BERT","accepted at COLING2020. arXiv admin note: substantial text overlap
  with arXiv:1908.04755",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Previous work on bridging anaphora recognition (Hou et al., 2013a) casts the
problem as a subtask of learning fine-grained information status (IS). However,
these systems heavily depend on many hand-crafted linguistic features. In this
paper, we propose a simple discourse context-aware BERT model for fine-grained
IS classification. On the ISNotes corpus (Markert et al., 2012), our model
achieves new state-of-the-art performance on fine-grained IS classification,
obtaining a 4.8 absolute overall accuracy improvement compared to Hou et al.
(2013a). More importantly, we also show an improvement of 10.5 F1 points for
bridging anaphora recognition without using any complex hand-crafted semantic
features designed for capturing the bridging phenomenon. We further analyze the
trained model and find that the most attended signals for each IS category
correspond well to linguistic notions of information status.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 22:30:17 GMT'}]",2020-10-29,"[['Hou', 'Yufang', '']]"
1371128,2010.14798,Shuai Zhang,"Shuai Zhang, Jiangyan Yi, Zhengkun Tian, Ye Bai, Jianhua Tao, Zhengqi
  wen","Decoupling Pronunciation and Language for End-to-end Code-switching
  Automatic Speech Recognition","5 pages, 1 figures",,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite the recent significant advances witnessed in end-to-end (E2E) ASR
system for code-switching, hunger for audio-text paired data limits the further
improvement of the models' performance. In this paper, we propose a decoupled
transformer model to use monolingual paired data and unpaired text data to
alleviate the problem of code-switching data shortage. The model is decoupled
into two parts: audio-to-phoneme (A2P) network and phoneme-to-text (P2T)
network. The A2P network can learn acoustic pattern scenarios using large-scale
monolingual paired data. Meanwhile, it generates multiple phoneme sequence
candidates for single audio data in real-time during the training process. Then
the generated phoneme-text paired data is used to train the P2T network. This
network can be pre-trained with large amounts of external unpaired text data.
By using monolingual data and unpaired text data, the decoupled transformer
model reduces the high dependency on code-switching paired training data of E2E
model to a certain extent. Finally, the two networks are optimized jointly
through attention fusion. We evaluate the proposed method on the public
Mandarin-English code-switching dataset. Compared with our transformer
baseline, the proposed method achieves 18.14% relative mix error rate
reduction.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 07:46:15 GMT'}]",2020-10-29,"[['Zhang', 'Shuai', ''], ['Yi', 'Jiangyan', ''], ['Tian', 'Zhengkun', ''], ['Bai', 'Ye', ''], ['Tao', 'Jianhua', ''], ['wen', 'Zhengqi', '']]"
1371202,2010.14872,Kristian Miok,"Kristian Miok, Gregor Pirs and Marko Robnik-Sikonja",Bayesian Methods for Semi-supervised Text Annotation,"Accepted for COLING 2020, The 14th Linguistic Annotation Workshop",,,,cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Human annotations are an important source of information in the development
of natural language understanding approaches. As under the pressure of
productivity annotators can assign different labels to a given text, the
quality of produced annotations frequently varies. This is especially the case
if decisions are difficult, with high cognitive load, requires awareness of
broader context, or careful consideration of background knowledge. To alleviate
the problem, we propose two semi-supervised methods to guide the annotation
process: a Bayesian deep learning model and a Bayesian ensemble method. Using a
Bayesian deep learning method, we can discover annotations that cannot be
trusted and might require reannotation. A recently proposed Bayesian ensemble
method helps us to combine the annotators' labels with predictions of trained
models. According to the results obtained from three hate speech detection
experiments, the proposed Bayesian methods can improve the annotations and
prediction performance of BERT models.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 10:42:04 GMT'}]",2020-10-29,"[['Miok', 'Kristian', ''], ['Pirs', 'Gregor', ''], ['Robnik-Sikonja', 'Marko', '']]"
1371171,2010.14841,Chengyu Wang,"Yiwu Yao, Yuchao Li, Chengyu Wang, Tianhang Yu, Houjiang Chen,
  Xiaotang Jiang, Jun Yang, Jun Huang, Wei Lin, Hui Shu, Chengfei Lv","INT8 Winograd Acceleration for Conv1D Equipped ASR Models Deployed on
  Mobile Devices",,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The intensive computation of Automatic Speech Recognition (ASR) models
obstructs them from being deployed on mobile devices. In this paper, we present
a novel quantized Winograd optimization pipeline, which combines the
quantization and fast convolution to achieve efficient inference acceleration
on mobile devices for ASR models. To avoid the information loss due to the
combination of quantization and Winograd convolution, a Range-Scaled
Quantization (RSQ) training method is proposed to expand the quantized
numerical range and to distill knowledge from high-precision values. Moreover,
an improved Conv1D equipped DFSMN (ConvDFSMN) model is designed for mobile
deployment. We conduct extensive experiments on both ConvDFSMN and Wav2letter
models. Results demonstrate the models can be effectively optimized with the
proposed pipeline. Especially, Wav2letter achieves 1.48* speedup with an
approximate 0.07% WER decrease on ARMv7-based mobile devices.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 09:25:49 GMT'}]",2020-10-29,"[['Yao', 'Yiwu', ''], ['Li', 'Yuchao', ''], ['Wang', 'Chengyu', ''], ['Yu', 'Tianhang', ''], ['Chen', 'Houjiang', ''], ['Jiang', 'Xiaotang', ''], ['Yang', 'Jun', ''], ['Huang', 'Jun', ''], ['Lin', 'Wei', ''], ['Shu', 'Hui', ''], ['Lv', 'Chengfei', '']]"
1371136,2010.14806,Xiao Pan,"Liwei Wu, Xiao Pan, Zehui Lin, Yaoming Zhu, Mingxuan Wang, Lei Li",The Volctrans Machine Translation System for WMT20,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper describes our VolcTrans system on WMT20 shared news translation
task. We participated in 8 translation directions. Our basic systems are based
on Transformer, with several variants (wider or deeper Transformers, dynamic
convolutions). The final system includes text pre-process, data selection,
synthetic data generation, advanced model ensemble, and multilingual
pre-training.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 08:08:12 GMT'}]",2020-10-29,"[['Wu', 'Liwei', ''], ['Pan', 'Xiao', ''], ['Lin', 'Zehui', ''], ['Zhu', 'Yaoming', ''], ['Wang', 'Mingxuan', ''], ['Li', 'Lei', '']]"
1371134,2010.14804,Benlai Tang,"Zhonghao Li, Benlai Tang, Xiang Yin, Yuan Wan, Ling Xu, Chen Shen,
  Zejun Ma","PPG-based singing voice conversion with adversarial representation
  learning",,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Singing voice conversion (SVC) aims to convert the voice of one singer to
that of other singers while keeping the singing content and melody. On top of
recent voice conversion works, we propose a novel model to steadily convert
songs while keeping their naturalness and intonation. We build an end-to-end
architecture, taking phonetic posteriorgrams (PPGs) as inputs and generating
mel spectrograms. Specifically, we implement two separate encoders: one encodes
PPGs as content, and the other compresses mel spectrograms to supply acoustic
and musical information. To improve the performance on timbre and melody, an
adversarial singer confusion module and a mel-regressive representation
learning module are designed for the model. Objective and subjective
experiments are conducted on our private Chinese singing corpus. Comparing with
the baselines, our methods can significantly improve the conversion performance
in terms of naturalness, melody, and voice similarity. Moreover, our PPG-based
method is proved to be robust for noisy sources.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 08:03:27 GMT'}]",2020-10-29,"[['Li', 'Zhonghao', ''], ['Tang', 'Benlai', ''], ['Yin', 'Xiang', ''], ['Wan', 'Yuan', ''], ['Xu', 'Ling', ''], ['Shen', 'Chen', ''], ['Ma', 'Zejun', '']]"
1371124,2010.14794,Kun Zhou,"Kun Zhou, Berrak Sisman, Rui Liu and Haizhou Li","Seen and Unseen emotional style transfer for voice conversion with a new
  emotional speech dataset",Submitted to ICASSP 2021,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Emotional voice conversion aims to transform emotional prosody in speech
while preserving the linguistic content and speaker identity. Prior studies
show that it is possible to disentangle emotional prosody using an
encoder-decoder network conditioned on discrete representation, such as one-hot
emotion labels. Such networks learn to remember a fixed set of emotional
styles. In this paper, we propose a novel framework based on variational
auto-encoding Wasserstein generative adversarial network (VAW-GAN), which makes
use of a pre-trained speech emotion recognition (SER) model to transfer
emotional style during training and at run-time inference. In this way, the
network is able to transfer both seen and unseen emotional style to a new
utterance. We show that the proposed framework achieves remarkable performance
by consistently outperforming the baseline framework. This paper also marks the
release of an emotional speech dataset (ESD) for voice conversion, which has
multiple speakers and languages.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 07:16:18 GMT'}]",2020-10-29,"[['Zhou', 'Kun', ''], ['Sisman', 'Berrak', ''], ['Liu', 'Rui', ''], ['Li', 'Haizhou', '']]"
1371114,2010.14784,Yuanhao Zhuo,Yuanhao Zhuo,"A Chinese Text Classification Method With Low Hardware Requirement Based
  on Improved Model Concatenation","5 pages, 2 figures, 5 tables",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In order to improve the accuracy performance of Chinese text classification
models with low hardware requirements, an improved concatenation-based model is
designed in this paper, which is a concatenation of 5 different sub-models,
including TextCNN, LSTM, and Bi-LSTM. Compared with the existing ensemble
learning method, for a text classification mission, this model's accuracy is 2%
higher. Meanwhile, the hardware requirements of this model are much lower than
the BERT-based model.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 06:32:41 GMT'}]",2020-10-29,"[['Zhuo', 'Yuanhao', '']]"
1371060,2010.14730,Xiaoyu Kou,"Xiaoyu Kou, Yankai Lin, Yuntao Li, Jiahao Xu, Peng Li, Jie Zhou, Yan
  Zhang",DisenE: Disentangling Knowledge Graph Embeddings,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Knowledge graph embedding (KGE), aiming to embed entities and relations into
low-dimensional vectors, has attracted wide attention recently. However, the
existing research is mainly based on the black-box neural models, which makes
it difficult to interpret the learned representation. In this paper, we
introduce DisenE, an end-to-end framework to learn disentangled knowledge graph
embeddings. Specially, we introduce an attention-based mechanism that enables
the model to explicitly focus on relevant components of entity embeddings
according to a given relation. Furthermore, we introduce two novel regularizers
to encourage each component of the entity representation to independently
reflect an isolated semantic aspect. Experimental results demonstrate that our
proposed DisenE investigates a perspective to address the interpretability of
KGE and is proved to be an effective way to improve the performance of link
prediction tasks. The code and datasets are released on
https://github.com/KXY-PUBLIC/DisenE.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 03:45:19 GMT'}]",2020-10-29,"[['Kou', 'Xiaoyu', ''], ['Lin', 'Yankai', ''], ['Li', 'Yuntao', ''], ['Xu', 'Jiahao', ''], ['Li', 'Peng', ''], ['Zhou', 'Jie', ''], ['Zhang', 'Yan', '']]"
1371055,2010.14725,Ruchao Fan,"Ruchao Fan, Wei Chu, Peng Chang, Jing Xiao","CASS-NAT: CTC Alignment-based Single Step Non-autoregressive Transformer
  for Speech Recognition",Submitted to ICASSP2021,,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a CTC alignment-based single step non-autoregressive transformer
(CASS-NAT) for speech recognition. Specifically, the CTC alignment contains the
information of (a) the number of tokens for decoder input, and (b) the time
span of acoustics for each token. The information are used to extract acoustic
representation for each token in parallel, referred to as token-level acoustic
embedding which substitutes the word embedding in autoregressive transformer
(AT) to achieve parallel generation in decoder. During inference, an
error-based alignment sampling method is proposed to be applied to the CTC
output space, reducing the WER and retaining the parallelism as well.
Experimental results show that the proposed method achieves WERs of 3.8%/9.1%
on Librispeech test clean/other dataset without an external LM, and a CER of
5.8% on Aishell1 Mandarin corpus, respectively1. Compared to the AT baseline,
the CASS-NAT has a performance reduction on WER, but is 51.2x faster in terms
of RTF. When decoding with an oracle CTC alignment, the lower bound of WER
without LM reaches 2.3% on the test-clean set, indicating the potential of the
proposed method.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 03:14:05 GMT'}]",2020-10-29,"[['Fan', 'Ruchao', ''], ['Chu', 'Wei', ''], ['Chang', 'Peng', ''], ['Xiao', 'Jing', '']]"
1272816,2004.08046,Dongyu Ru,"Dongyu Ru, Jiangtao Feng, Lin Qiu, Hao Zhou, Mingxuan Wang, Weinan
  Zhang, Yong Yu, Lei Li","Active Sentence Learning by Adversarial Uncertainty Sampling in Discrete
  Space",Accepted to EMNLP 2020 Findings,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Active learning for sentence understanding aims at discovering informative
unlabeled data for annotation and therefore reducing the demand for labeled
data. We argue that the typical uncertainty sampling method for active learning
is time-consuming and can hardly work in real-time, which may lead to
ineffective sample selection. We propose adversarial uncertainty sampling in
discrete space (AUSDS) to retrieve informative unlabeled samples more
efficiently. AUSDS maps sentences into latent space generated by the popular
pre-trained language models, and discover informative unlabeled text samples
for annotation via adversarial attack. The proposed approach is extremely
efficient compared with traditional uncertainty sampling with more than 10x
speedup. Experimental results on five datasets show that AUSDS outperforms
strong baselines on effectiveness.
","[{'version': 'v1', 'created': 'Fri, 17 Apr 2020 03:12:34 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 04:45:49 GMT'}]",2020-10-29,"[['Ru', 'Dongyu', ''], ['Feng', 'Jiangtao', ''], ['Qiu', 'Lin', ''], ['Zhou', 'Hao', ''], ['Wang', 'Mingxuan', ''], ['Zhang', 'Weinan', ''], ['Yu', 'Yong', ''], ['Li', 'Lei', '']]"
1371050,2010.14720,Songlin Yang,"Songlin Yang, Yong Jiang, Wenjuan Han, Kewei Tu",Second-Order Unsupervised Neural Dependency Parsing,COLING 2020 camera ready,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Most of the unsupervised dependency parsers are based on first-order
probabilistic generative models that only consider local parent-child
information. Inspired by second-order supervised dependency parsing, we
proposed a second-order extension of unsupervised neural dependency models that
incorporate grandparent-child or sibling information. We also propose a novel
design of the neural parameterization and optimization methods of the
dependency models. In second-order models, the number of grammar rules grows
cubically with the increase of vocabulary size, making it difficult to train
lexicalized models that may contain thousands of words. To circumvent this
problem while still benefiting from both second-order parsing and
lexicalization, we use the agreement-based learning framework to jointly train
a second-order unlexicalized model and a first-order lexicalized model.
Experiments on multiple datasets show the effectiveness of our second-order
models compared with recent state-of-the-art methods. Our joint model achieves
a 10% improvement over the previous state-of-the-art parser on the full WSJ
test set
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 03:01:33 GMT'}]",2020-10-29,"[['Yang', 'Songlin', ''], ['Jiang', 'Yong', ''], ['Han', 'Wenjuan', ''], ['Tu', 'Kewei', '']]"
1371037,2010.14707,Yang Qian,"Yang Qian, Yuanchun Jiang, Yidong Chai, Yezheng Liu, Jiansha Sun",TopicModel4J: A Java Package for Topic Models,,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Topic models provide a flexible and principled framework for exploring hidden
structure in high-dimensional co-occurrence data and are commonly used natural
language processing (NLP) of text. In this paper, we design and implement a
Java package, TopicModel4J, which contains 13 kinds of representative
algorithms for fitting topic models. The TopicModel4J in the Java programming
environment provides an easy-to-use interface for data analysts to run the
algorithms, and allow to easily input and output data. In addition, this
package provides a few unstructured text preprocessing techniques, such as
splitting textual data into words, lowercasing the words, preforming
lemmatization and removing the useless characters, URLs and stop words.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 02:33:41 GMT'}]",2020-10-29,"[['Qian', 'Yang', ''], ['Jiang', 'Yuanchun', ''], ['Chai', 'Yidong', ''], ['Liu', 'Yezheng', ''], ['Sun', 'Jiansha', '']]"
1371031,2010.14701,Samuel McCandlish,"Tom Henighan, Jared Kaplan, Mor Katz, Mark Chen, Christopher Hesse,
  Jacob Jackson, Heewoo Jun, Tom B. Brown, Prafulla Dhariwal, Scott Gray, Chris
  Hallacy, Benjamin Mann, Alec Radford, Aditya Ramesh, Nick Ryder, Daniel M.
  Ziegler, John Schulman, Dario Amodei, Sam McCandlish",Scaling Laws for Autoregressive Generative Modeling,"20+15 pages, 30 figures",,,,cs.LG cs.CL cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We identify empirical scaling laws for the cross-entropy loss in four
domains: generative image modeling, video modeling, multimodal
image$\leftrightarrow$text models, and mathematical problem solving. In all
cases autoregressive Transformers smoothly improve in performance as model size
and compute budgets increase, following a power-law plus constant scaling law.
The optimal model size also depends on the compute budget through a power-law,
with exponents that are nearly universal across all data domains.
  The cross-entropy loss has an information theoretic interpretation as
$S($True$) + D_{\mathrm{KL}}($True$||$Model$)$, and the empirical scaling laws
suggest a prediction for both the true data distribution's entropy and the KL
divergence between the true and model distributions. With this interpretation,
billion-parameter Transformers are nearly perfect models of the YFCC100M image
distribution downsampled to an $8\times 8$ resolution, and we can forecast the
model size needed to achieve any given reducible loss (ie $D_{\mathrm{KL}}$) in
nats/image for other resolutions.
  We find a number of additional scaling laws in specific domains: (a) we
identify a scaling relation for the mutual information between captions and
images in multimodal models, and show how to answer the question ""Is a picture
worth a thousand words?""; (b) in the case of mathematical problem solving, we
identify scaling laws for model performance when extrapolating beyond the
training distribution; (c) we finetune generative image models for ImageNet
classification and find smooth scaling of the classification loss and error
rate, even as the generative loss levels off. Taken together, these results
strengthen the case that scaling laws have important implications for neural
network performance, including on downstream tasks.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 02:17:24 GMT'}]",2020-10-29,"[['Henighan', 'Tom', ''], ['Kaplan', 'Jared', ''], ['Katz', 'Mor', ''], ['Chen', 'Mark', ''], ['Hesse', 'Christopher', ''], ['Jackson', 'Jacob', ''], ['Jun', 'Heewoo', ''], ['Brown', 'Tom B.', ''], ['Dhariwal', 'Prafulla', ''], ['Gray', 'Scott', ''], ['Hallacy', 'Chris', ''], ['Mann', 'Benjamin', ''], ['Radford', 'Alec', ''], ['Ramesh', 'Aditya', ''], ['Ryder', 'Nick', ''], ['Ziegler', 'Daniel M.', ''], ['Schulman', 'John', ''], ['Amodei', 'Dario', ''], ['McCandlish', 'Sam', '']]"
1371027,2010.14697,Claire Bowern,Luke Lindemann and Claire Bowern,"Character Entropy in Modern and Historical Texts: Comparison Metrics for
  an Undeciphered Manuscript",,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  This paper outlines the creation of three corpora for multilingual comparison
and analysis of the Voynich manuscript: a corpus of Voynich texts partitioned
by Currier language, scribal hand, and transcription system, a corpus of 294
language samples compiled from Wikipedia, and a corpus of eighteen transcribed
historical texts in eight languages. These corpora will be utilized in
subsequent work by the Voynich Working Group at Yale University.
  We demonstrate the utility of these corpora for studying characteristics of
the Voynich script and language, with an analysis of conditional character
entropy in Voynichese. We discuss the interaction between character entropy and
language, script size and type, glyph compositionality, scribal conventions and
abbreviations, positional character variants, and bigram frequency.
  This analysis characterizes the interaction between script compositionality,
character size, and predictability. We show that substantial manipulations of
glyph composition are not sufficient to align conditional entropy levels with
natural languages. The unusually predictable nature of the Voynichese script is
not attributable to a particular script or transcription system, underlying
language, or substitution cipher. Voynichese is distinct from every comparison
text in our corpora because character placement is highly constrained within
the word, and this may indicate the loss of phonemic distinctions from the
underlying language.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 01:53:59 GMT'}]",2020-10-29,"[['Lindemann', 'Luke', ''], ['Bowern', 'Claire', '']]"
1371008,2010.14678,Amir Pouran Ben Veyseh,"Amir Pouran Ben Veyseh, Franck Dernoncourt, Quan Hung Tran, Thien Huu
  Nguyen","What Does This Acronym Mean? Introducing a New Dataset for Acronym
  Identification and Disambiguation",accepted at COLING 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Acronyms are the short forms of phrases that facilitate conveying lengthy
sentences in documents and serve as one of the mainstays of writing. Due to
their importance, identifying acronyms and corresponding phrases (i.e., acronym
identification (AI)) and finding the correct meaning of each acronym (i.e.,
acronym disambiguation (AD)) are crucial for text understanding. Despite the
recent progress on this task, there are some limitations in the existing
datasets which hinder further improvement. More specifically, limited size of
manually annotated AI datasets or noises in the automatically created acronym
identification datasets obstruct designing advanced high-performing acronym
identification models. Moreover, the existing datasets are mostly limited to
the medical domain and ignore other domains. In order to address these two
limitations, we first create a manually annotated large AI dataset for
scientific domain. This dataset contains 17,506 sentences which is
substantially larger than previous scientific AI datasets. Next, we prepare an
AD dataset for scientific domain with 62,441 samples which is significantly
larger than the previous scientific AD dataset. Our experiments show that the
existing state-of-the-art models fall far behind human-level performance on
both datasets proposed by this work. In addition, we propose a new deep
learning model that utilizes the syntactical structure of the sentence to
expand an ambiguous acronym in a sentence. The proposed model outperforms the
state-of-the-art models on the new AD dataset, providing a strong baseline for
future research on this dataset.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 00:12:36 GMT'}]",2020-10-29,"[['Veyseh', 'Amir Pouran Ben', ''], ['Dernoncourt', 'Franck', ''], ['Tran', 'Quan Hung', ''], ['Nguyen', 'Thien Huu', '']]"
1370995,2010.14665,Yongqiang Wang,"Yongqiang Wang, Yangyang Shi, Frank Zhang, Chunyang Wu, Julian Chan,
  Ching-Feng Yeh, Alex Xiao","Transformer in action: a comparative study of transformer-based acoustic
  models for large scale speech recognition applications",submitted to ICASSP2021,,,,cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we summarize the application of transformer and its streamable
variant, Emformer based acoustic model for large scale speech recognition
applications. We compare the transformer based acoustic models with their LSTM
counterparts on industrial scale tasks. Specifically, we compare Emformer with
latency-controlled BLSTM (LCBLSTM) on medium latency tasks and LSTM on low
latency tasks. On a low latency voice assistant task, Emformer gets 24% to 26%
relative word error rate reductions (WERRs). For medium latency scenarios,
comparing with LCBLSTM with similar model size and latency, Emformer gets
significant WERR across four languages in video captioning datasets with 2-3
times inference real-time factors reduction.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 23:04:21 GMT'}]",2020-10-29,"[['Wang', 'Yongqiang', ''], ['Shi', 'Yangyang', ''], ['Zhang', 'Frank', ''], ['Wu', 'Chunyang', ''], ['Chan', 'Julian', ''], ['Yeh', 'Ching-Feng', ''], ['Xiao', 'Alex', '']]"
1370990,2010.14660,Pierre Dognin,"Pierre L. Dognin, Igor Melnyk, Inkit Padhi, Cicero Nogueira dos
  Santos, Payel Das",DualTKB: A Dual Learning Bridge between Text and Knowledge Base,"Equal Contributions of Authors Pierre L. Dognin, Igor Melnyk, and
  Inkit Padhi. Accepted at EMNLP'20",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this work, we present a dual learning approach for unsupervised text to
path and path to text transfers in Commonsense Knowledge Bases (KBs). We
investigate the impact of weak supervision by creating a weakly supervised
dataset and show that even a slight amount of supervision can significantly
improve the model performance and enable better-quality transfers. We examine
different model architectures, and evaluation metrics, proposing a novel
Commonsense KB completion metric tailored for generative models. Extensive
experimental results show that the proposed method compares very favorably to
the existing baselines. This approach is a viable step towards a more advanced
system for automatic KB construction/expansion and the reverse operation of KB
conversion to coherent textual descriptions.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 22:56:18 GMT'}]",2020-10-29,"[['Dognin', 'Pierre L.', ''], ['Melnyk', 'Igor', ''], ['Padhi', 'Inkit', ''], ['Santos', 'Cicero Nogueira dos', ''], ['Das', 'Payel', '']]"
1370979,2010.14649,Takashi Wada,"Takashi Wada, Tomoharu Iwata, Yuji Matsumoto, Timothy Baldwin, Jey Han
  Lau","Learning Contextualised Cross-lingual Word Embeddings for Extremely
  Low-Resource Languages Using Parallel Corpora",9 pages,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a new approach for learning contextualised cross-lingual word
embeddings based only on a small parallel corpus (e.g. a few hundred sentence
pairs). Our method obtains word embeddings via an LSTM-based encoder-decoder
model that performs bidirectional translation and reconstruction of the input
sentence. Through sharing model parameters among different languages, our model
jointly trains the word embeddings in a common multilingual space. We also
propose a simple method to combine word and subword embeddings to make use of
orthographic similarities across different languages. We base our experiments
on real-world data from endangered languages, namely Yongning Na,
Shipibo-Konibo and Griko. Our experiments on bilingual lexicon induction and
word alignment tasks show that our model outperforms existing methods by a
large margin for most language pairs. These results demonstrate that, contrary
to common belief, an encoder-decoder translation model is beneficial for
learning cross-lingual representations, even in extremely low-resource
scenarios.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 22:24:01 GMT'}]",2020-10-29,"[['Wada', 'Takashi', ''], ['Iwata', 'Tomoharu', ''], ['Matsumoto', 'Yuji', ''], ['Baldwin', 'Timothy', ''], ['Lau', 'Jey Han', '']]"
1370936,2010.14606,Arun Narayanan,"Arun Narayanan, Tara N. Sainath, Ruoming Pang, Jiahui Yu, Chung-Cheng
  Chiu, Rohit Prabhavalkar, Ehsan Variani, Trevor Strohman",Cascaded encoders for unifying streaming and non-streaming ASR,,,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  End-to-end (E2E) automatic speech recognition (ASR) models, by now, have
shown competitive performance on several benchmarks. These models are
structured to either operate in streaming or non-streaming mode. This work
presents cascaded encoders for building a single E2E ASR model that can operate
in both these modes simultaneously. The proposed model consists of streaming
and non-streaming encoders. Input features are first processed by the streaming
encoder; the non-streaming encoder operates exclusively on the output of the
streaming encoder. A single decoder then learns to decode either using the
output of the streaming or the non-streaming encoder. Results show that this
model achieves similar word error rates (WER) as a standalone streaming model
when operating in streaming mode, and obtains 10% -- 27% relative improvement
when operating in non-streaming mode. Our results also show that the proposed
approach outperforms existing E2E two-pass models, especially on long-form
speech.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 20:59:50 GMT'}]",2020-10-29,"[['Narayanan', 'Arun', ''], ['Sainath', 'Tara N.', ''], ['Pang', 'Ruoming', ''], ['Yu', 'Jiahui', ''], ['Chiu', 'Chung-Cheng', ''], ['Prabhavalkar', 'Rohit', ''], ['Variani', 'Ehsan', ''], ['Strohman', 'Trevor', '']]"
1370918,2010.14588,Robert Leaman,Robert Leaman and Zhiyong Lu,"A Comprehensive Dictionary and Term Variation Analysis for COVID-19 and
  SARS-CoV-2",Accepted EMNLP NLP-COVID Workshop,,,,cs.DL cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The number of unique terms in the scientific literature used to refer to
either SARS-CoV-2 or COVID-19 is remarkably large and has continued to increase
rapidly despite well-established standardized terms. This high degree of term
variation makes high recall identification of these important entities
difficult. In this manuscript we present an extensive dictionary of terms used
in the literature to refer to SARS-CoV-2 and COVID-19. We use a rule-based
approach to iteratively generate new term variants, then locate these variants
in a large text corpus. We compare our dictionary to an extensive collection of
terminological resources, demonstrating that our resource provides a
substantial number of additional terms. We use our dictionary to analyze the
usage of SARS-CoV-2 and COVID-19 terms over time and show that the number of
unique terms continues to grow rapidly. Our dictionary is freely available at
https://github.com/ncbi-nlp/CovidTermVar.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 19:51:53 GMT'}]",2020-10-29,"[['Leaman', 'Robert', ''], ['Lu', 'Zhiyong', '']]"
1370917,2010.14587,Jean-Baptiste Lamare,"Jean-Baptiste Lamare, Tobi Olatunji, Li Yao",On the diminishing return of labeling clinical reports,"Accepted at the EMNLP 2020 Clinical NLP workshop, 9 pages + 2 for
  references, 7 figures, 4 tables",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Ample evidence suggests that better machine learning models may be steadily
obtained by training on increasingly larger datasets on natural language
processing (NLP) problems from non-medical domains. Whether the same holds true
for medical NLP has by far not been thoroughly investigated. This work shows
that this is indeed not always the case. We reveal the somehow
counter-intuitive observation that performant medical NLP models may be
obtained with small amount of labeled data, quite the opposite to the common
belief, most likely due to the domain specificity of the problem. We show
quantitatively the effect of training data size on a fixed test set composed of
two of the largest public chest x-ray radiology report datasets on the task of
abnormality classification. The trained models not only make use of the
training data efficiently, but also outperform the current state-of-the-art
rule-based systems by a significant margin.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 19:51:04 GMT'}]",2020-10-29,"[['Lamare', 'Jean-Baptiste', ''], ['Olatunji', 'Tobi', ''], ['Yao', 'Li', '']]"
1370906,2010.14576,Jeniya Tabassum,"Jeniya Tabassum, Sydney Lee, Wei Xu, Alan Ritter","WNUT-2020 Task 1 Overview: Extracting Entities and Relations from Wet
  Lab Protocols",to appear in EMNLP 2020 (WNUT),,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents the results of the wet lab information extraction task at
WNUT 2020. This task consisted of two sub tasks: (1) a Named Entity Recognition
(NER) task with 13 participants and (2) a Relation Extraction (RE) task with 2
participants. We outline the task, data annotation process, corpus statistics,
and provide a high-level overview of the participating systems for each sub
task.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 19:34:53 GMT'}]",2020-10-29,"[['Tabassum', 'Jeniya', ''], ['Lee', 'Sydney', ''], ['Xu', 'Wei', ''], ['Ritter', 'Alan', '']]"
1370898,2010.14568,Kaiyu Yang,"Kaiyu Yang, Jia Deng",Strongly Incremental Constituency Parsing with Graph Neural Networks,Accepted to NeurIPS 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Parsing sentences into syntax trees can benefit downstream applications in
NLP. Transition-based parsers build trees by executing actions in a state
transition system. They are computationally efficient, and can leverage machine
learning to predict actions based on partial trees. However, existing
transition-based parsers are predominantly based on the shift-reduce transition
system, which does not align with how humans are known to parse sentences.
Psycholinguistic research suggests that human parsing is strongly incremental:
humans grow a single parse tree by adding exactly one token at each step. In
this paper, we propose a novel transition system called attach-juxtapose. It is
strongly incremental; it represents a partial sentence using a single tree;
each action adds exactly one token into the partial tree. Based on our
transition system, we develop a strongly incremental parser. At each step, it
encodes the partial tree using a graph neural network and predicts an action.
We evaluate our parser on Penn Treebank (PTB) and Chinese Treebank (CTB). On
PTB, it outperforms existing parsers trained with only constituency trees; and
it performs on par with state-of-the-art parsers that use dependency trees as
additional training data. On CTB, our parser establishes a new state of the
art. Code is available at
https://github.com/princeton-vl/attach-juxtapose-parser.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 19:19:38 GMT'}]",2020-10-29,"[['Yang', 'Kaiyu', ''], ['Deng', 'Jia', '']]"
1370887,2010.14557,Ruizhe Li,"Xiao Li, Guanyi Chen, Chenghua Lin, Ruizhe Li",DGST: a Dual-Generator Network for Text Style Transfer,"Accepted by EMNLP 2020, camera ready version",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose DGST, a novel and simple Dual-Generator network architecture for
text Style Transfer. Our model employs two generators only, and does not rely
on any discriminators or parallel corpus for training. Both quantitative and
qualitative experiments on the Yelp and IMDb datasets show that our model gives
competitive performance compared to several strong baselines with more
complicated architecture designs.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 18:54:51 GMT'}]",2020-10-29,"[['Li', 'Xiao', ''], ['Chen', 'Guanyi', ''], ['Lin', 'Chenghua', ''], ['Li', 'Ruizhe', '']]"
1370864,2010.14534,Marion Bartl,Marion Bartl and Malvina Nissim and Albert Gatt,"Unmasking Contextual Stereotypes: Measuring and Mitigating BERT's Gender
  Bias","10 pages, 4 figures, to appear in Proceedings of the 2nd Workshop on
  Gender Bias in Natural Language Processing at COLING 2020",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Contextualized word embeddings have been replacing standard embeddings as the
representational knowledge source of choice in NLP systems. Since a variety of
biases have previously been found in standard word embeddings, it is crucial to
assess biases encoded in their replacements as well. Focusing on BERT (Devlin
et al., 2018), we measure gender bias by studying associations between
gender-denoting target words and names of professions in English and German,
comparing the findings with real-world workforce statistics. We mitigate bias
by fine-tuning BERT on the GAP corpus (Webster et al., 2018), after applying
Counterfactual Data Substitution (CDS) (Maudslay et al., 2019). We show that
our method of measuring bias is appropriate for languages such as English, but
not for languages with a rich morphology and gender-marking, such as German.
Our results highlight the importance of investigating bias and mitigation
techniques cross-linguistically, especially in view of the current emphasis on
large-scale, multilingual language models.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 18:06:09 GMT'}]",2020-10-29,"[['Bartl', 'Marion', ''], ['Nissim', 'Malvina', ''], ['Gatt', 'Albert', '']]"
1146834,1907.02298,Zi Lin,"Junjie Cao, Zi Lin, Weiwei Sun, Xiaojun Wan","A Comparative Analysis of Knowledge-Intensive and Data-Intensive
  Semantic Parsers",submitted to the journal Computational Linguistics,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We present a phenomenon-oriented comparative analysis of the two dominant
approaches in task-independent semantic parsing: classic, knowledge-intensive
and neural, data-intensive models. To reflect state-of-the-art neural NLP
technologies, we introduce a new target structure-centric parser that can
produce semantic graphs much more accurately than previous data-driven parsers.
We then show that, in spite of comparable performance overall, knowledge- and
data-intensive models produce different types of errors, in a way that can be
explained by their theoretical properties. This analysis leads to new
directions for parser development.
","[{'version': 'v1', 'created': 'Thu, 4 Jul 2019 09:40:27 GMT'}, {'version': 'v2', 'created': 'Thu, 15 Aug 2019 10:36:59 GMT'}, {'version': 'v3', 'created': 'Wed, 28 Oct 2020 08:39:30 GMT'}]",2020-10-29,"[['Cao', 'Junjie', ''], ['Lin', 'Zi', ''], ['Sun', 'Weiwei', ''], ['Wan', 'Xiaojun', '']]"
1247530,2002.10107,Issa Annamoradnejad,"Issa Annamoradnejad, Mohammadamin Fazli, Jafar Habibi",Predicting Subjective Features of Questions of QA Websites using BERT,"5 pages, 4 figures, 2 tables","2020 6th International Conference on Web Research (ICWR), Tehran,
  Iran, 2020, pp. 240-244",10.1109/ICWR49608.2020.9122318,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Community Question-Answering websites, such as StackOverflow and Quora,
expect users to follow specific guidelines in order to maintain content
quality. These systems mainly rely on community reports for assessing contents,
which has serious problems such as the slow handling of violations, the loss of
normal and experienced users' time, the low quality of some reports, and
discouraging feedback to new users. Therefore, with the overall goal of
providing solutions for automating moderation actions in Q&A websites, we aim
to provide a model to predict 20 quality or subjective aspects of questions in
QA websites. To this end, we used data gathered by the CrowdSource team at
Google Research in 2019 and a fine-tuned pre-trained BERT model on our problem.
Based on the evaluation by Mean-Squared-Error (MSE), the model achieved a value
of 0.046 after 2 epochs of training, which did not improve substantially in the
next ones. Results confirm that by simple fine-tuning, we can achieve accurate
models in little time and on less amount of data.
","[{'version': 'v1', 'created': 'Mon, 24 Feb 2020 07:56:02 GMT'}, {'version': 'v2', 'created': 'Wed, 25 Mar 2020 08:10:16 GMT'}, {'version': 'v3', 'created': 'Tue, 30 Jun 2020 13:22:04 GMT'}, {'version': 'v4', 'created': 'Wed, 28 Oct 2020 14:37:39 GMT'}]",2020-10-29,"[['Annamoradnejad', 'Issa', ''], ['Fazli', 'Mohammadamin', ''], ['Habibi', 'Jafar', '']]"
1369332,2010.13002,Sam Shleifer,Sam Shleifer and Alexander M. Rush,Pre-trained Summarization Distillation,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent state-of-the-art approaches to summarization utilize large pre-trained
Transformer models. Distilling these models to smaller student models has
become critically important for practical use; however there are many different
distillation methods proposed by the NLP literature. Recent work on distilling
BERT for classification and regression tasks shows strong performance using
direct knowledge distillation. Alternatively, machine translation practitioners
distill using pseudo-labeling, where a small model is trained on the
translations of a larger model. A third, simpler approach is to 'shrink and
fine-tune' (SFT), which avoids any explicit distillation by copying parameters
to a smaller student model and then fine-tuning. We compare these three
approaches for distillation of Pegasus and BART, the current and former state
of the art, pre-trained summarization models, and find that SFT outperforms
knowledge distillation and pseudo-labeling on the CNN/DailyMail dataset, but
under-performs pseudo-labeling on the more abstractive XSUM dataset. PyTorch
Code and checkpoints of different sizes are available through Hugging Face
transformers here http://tiny.cc/4iy0tz.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 23:15:43 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 04:47:59 GMT'}]",2020-10-29,"[['Shleifer', 'Sam', ''], ['Rush', 'Alexander M.', '']]"
1371221,2010.14891,Mayuko Kori,"Mayuko Kori, Takeshi Tsukada and Naoki Kobayashi",A Cyclic Proof System for HFLN,27 pages,,,,cs.LO cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A cyclic proof system allows us to perform inductive reasoning without
explicit inductions. We propose a cyclic proof system for HFLN, which is a
higher-order predicate logic with natural numbers and alternating fixed-points.
Ours is the first cyclic proof system for a higher-order logic, to our
knowledge. Due to the presence of higher-order predicates and alternating
fixed-points, our cyclic proof system requires a more delicate global condition
on cyclic proofs than the original system of Brotherston and Simpson. We prove
the decidability of checking the global condition and soundness of this system,
and also prove a restricted form of standard completeness for an infinitary
variant of our cyclic proof system. A potential application of our cyclic proof
system is semi-automated verification of higher-order programs, based on
Kobayashi et al.'s recent work on reductions from program verification to HFLN
validity checking.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 11:19:53 GMT'}]",2020-10-29,"[['Kori', 'Mayuko', ''], ['Tsukada', 'Takeshi', ''], ['Kobayashi', 'Naoki', '']]"
1371250,2010.14920,Yuchen Liu,"Yuchen Liu, Junnan Zhu, Jiajun Zhang, and Chengqing Zong",Bridging the Modality Gap for Speech-to-Text Translation,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  End-to-end speech translation aims to translate speech in one language into
text in another language via an end-to-end way. Most existing methods employ an
encoder-decoder structure with a single encoder to learn acoustic
representation and semantic information simultaneously, which ignores the
speech-and-text modality differences and makes the encoder overloaded, leading
to great difficulty in learning such a model. To address these issues, we
propose a Speech-to-Text Adaptation for Speech Translation (STAST) model which
aims to improve the end-to-end model performance by bridging the modality gap
between speech and text. Specifically, we decouple the speech translation
encoder into three parts and introduce a shrink mechanism to match the length
of speech representation with that of the corresponding text transcription. To
obtain better semantic representation, we completely integrate a text-based
translation model into the STAST so that two tasks can be trained in the same
latent space. Furthermore, we introduce a cross-modal adaptation method to
close the distance between speech and text representation. Experimental results
on English-French and English-German speech translation corpora have shown that
our model significantly outperforms strong baselines, and achieves the new
state-of-the-art performance.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 12:33:04 GMT'}]",2020-10-29,"[['Liu', 'Yuchen', ''], ['Zhu', 'Junnan', ''], ['Zhang', 'Jiajun', ''], ['Zong', 'Chengqing', '']]"
1279293,2004.14523,Brian Thompson,Brian Thompson and Philipp Koehn,Exploiting Sentence Order in Document Alignment,EMNLP2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present a simple document alignment method that incorporates sentence
order information in both candidate generation and candidate re-scoring. Our
method results in 61% relative reduction in error compared to the best
previously published result on the WMT16 document alignment shared task. Our
method improves downstream MT performance on web-scraped Sinhala--English
documents from ParaCrawl, outperforming the document alignment method used in
the most recent ParaCrawl release. It also outperforms a comparable corpora
method which uses the same multilingual embeddings, demonstrating that
exploiting sentence order is beneficial even if the end goal is sentence-level
bitext.
","[{'version': 'v1', 'created': 'Thu, 30 Apr 2020 00:11:34 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 01:23:22 GMT'}]",2020-10-29,"[['Thompson', 'Brian', ''], ['Koehn', 'Philipp', '']]"
1371355,2010.15025,Xingchen Song,"Xingchen Song, Zhiyong Wu, Yiheng Huang, Chao Weng, Dan Su, Helen Meng",Non-Autoregressive Transformer ASR with CTC-Enhanced Decoder Input,submitted to ICASSP 2021,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Non-autoregressive (NAR) transformer models have achieved significantly
inference speedup but at the cost of inferior accuracy compared to
autoregressive (AR) models in automatic speech recognition (ASR). Most of the
NAR transformers take a fixed-length sequence filled with MASK tokens or a
redundant sequence copied from encoder states as decoder input, they cannot
provide efficient target-side information thus leading to accuracy degradation.
To address this problem, we propose a CTC-enhanced NAR transformer, which
generates target sequence by refining predictions of the CTC module.
Experimental results show that our method outperforms all previous NAR
counterparts and achieves 50x faster decoding speed than a strong AR baseline
with only 0.0 ~ 0.3 absolute CER degradation on Aishell-1 and Aishell-2
datasets.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 15:00:09 GMT'}]",2020-10-29,"[['Song', 'Xingchen', ''], ['Wu', 'Zhiyong', ''], ['Huang', 'Yiheng', ''], ['Weng', 'Chao', ''], ['Su', 'Dan', ''], ['Meng', 'Helen', '']]"
1371282,2010.14952,Isar Nejadgholi,Svetlana Kiritchenko and Isar Nejadgholi,Towards Ethics by Design in Online Abusive Content Detection,"14 pages, 2 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  To support safety and inclusion in online communications, significant efforts
in NLP research have been put towards addressing the problem of abusive content
detection, commonly defined as a supervised classification task. The research
effort has spread out across several closely related sub-areas, such as
detection of hate speech, toxicity, cyberbullying, etc. There is a pressing
need to consolidate the field under a common framework for task formulation,
dataset design and performance evaluation. Further, despite current
technologies achieving high classification accuracies, several ethical issues
have been revealed. We bring ethical issues to forefront and propose a unified
framework as a two-step process. First, online content is categorized around
personal and identity-related subject matters. Second, severity of abuse is
identified through comparative annotation within each category. The novel
framework is guided by the Ethics by Design principle and is a step towards
building more accurate and trusted models.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 13:10:24 GMT'}]",2020-10-29,"[['Kiritchenko', 'Svetlana', ''], ['Nejadgholi', 'Isar', '']]"
1371444,2010.15114,Kyle Aitken,"Kyle Aitken, Vinay V. Ramasesh, Ankush Garg, Yuan Cao, David Sussillo,
  Niru Maheswaranathan",The geometry of integration in text classification RNNs,"9+19 pages, 30 figures",,,,cs.LG cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite the widespread application of recurrent neural networks (RNNs) across
a variety of tasks, a unified understanding of how RNNs solve these tasks
remains elusive. In particular, it is unclear what dynamical patterns arise in
trained RNNs, and how those patterns depend on the training dataset or task.
This work addresses these questions in the context of a specific natural
language processing task: text classification. Using tools from dynamical
systems analysis, we study recurrent networks trained on a battery of both
natural and synthetic text classification tasks. We find the dynamics of these
trained RNNs to be both interpretable and low-dimensional. Specifically, across
architectures and datasets, RNNs accumulate evidence for each class as they
process the text, using a low-dimensional attractor manifold as the underlying
mechanism. Moreover, the dimensionality and geometry of the attractor manifold
are determined by the structure of the training dataset; in particular, we
describe how simple word-count statistics computed on the training dataset can
be used to predict these properties. Our observations span multiple
architectures and datasets, reflecting a common mechanism RNNs employ to
perform text classification. To the degree that integration of evidence towards
a decision is a common computational primitive, this work lays the foundation
for using dynamical systems techniques to study the inner workings of RNNs.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 17:58:53 GMT'}]",2020-10-29,"[['Aitken', 'Kyle', ''], ['Ramasesh', 'Vinay V.', ''], ['Garg', 'Ankush', ''], ['Cao', 'Yuan', ''], ['Sussillo', 'David', ''], ['Maheswaranathan', 'Niru', '']]"
1371397,2010.15067,Muhammed Tarik Altuncu,"M. Tarik Altuncu, Sophia N. Yaliraki, Mauricio Barahona","Graph-based Topic Extraction from Vector Embeddings of Text Documents:
  Application to a Corpus of News Articles",,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Production of news content is growing at an astonishing rate. To help manage
and monitor the sheer amount of text, there is an increasing need to develop
efficient methods that can provide insights into emerging content areas, and
stratify unstructured corpora of text into `topics' that stem intrinsically
from content similarity. Here we present an unsupervised framework that brings
together powerful vector embeddings from natural language processing with tools
from multiscale graph partitioning that can reveal natural partitions at
different resolutions without making a priori assumptions about the number of
clusters in the corpus. We show the advantages of graph-based clustering
through end-to-end comparisons with other popular clustering and topic
modelling methods, and also evaluate different text vector embeddings, from
classic Bag-of-Words to Doc2Vec to the recent transformers based model Bert.
This comparative work is showcased through an analysis of a corpus of US news
coverage during the presidential election year of 2016.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 16:20:05 GMT'}]",2020-10-29,"[['Altuncu', 'M. Tarik', ''], ['Yaliraki', 'Sophia N.', ''], ['Barahona', 'Mauricio', '']]"
1371420,2010.15090,Vishal Sunder,Vishal Sunder and Eric Fosler-Lussier,"Handling Class Imbalance in Low-Resource Dialogue Systems by Combining
  Few-Shot Classification and Interpolation","5 pages, 4 figures, 3 tables",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Utterance classification performance in low-resource dialogue systems is
constrained by an inevitably high degree of data imbalance in class labels. We
present a new end-to-end pairwise learning framework that is designed
specifically to tackle this phenomenon by inducing a few-shot classification
capability in the utterance representations and augmenting data through an
interpolation of utterance representations. Our approach is a general purpose
training methodology, agnostic to the neural architecture used for encoding
utterances. We show significant improvements in macro-F1 score over standard
cross-entropy training for three different neural architectures, demonstrating
improvements on a Virtual Patient dialogue dataset as well as a low-resourced
emulation of the Switchboard dialogue act classification dataset.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 17:05:24 GMT'}]",2020-10-29,"[['Sunder', 'Vishal', ''], ['Fosler-Lussier', 'Eric', '']]"
1371366,2010.15036,Usman Naseem,"Usman Naseem, Imran Razzak, Shah Khalid Khan, Mukesh Prasad","A Comprehensive Survey on Word Representation Models: From Classical to
  State-Of-The-Art Word Representation Language Models",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Word representation has always been an important research area in the history
of natural language processing (NLP). Understanding such complex text data is
imperative, given that it is rich in information and can be used widely across
various applications. In this survey, we explore different word representation
models and its power of expression, from the classical to modern-day
state-of-the-art word representation language models (LMS). We describe a
variety of text representation methods, and model designs have blossomed in the
context of NLP, including SOTA LMs. These models can transform large volumes of
text into effective vector representations capturing the same semantic
information. Further, such representations can be utilized by various machine
learning (ML) algorithms for a variety of NLP related tasks. In the end, this
survey briefly discusses the commonly used ML and DL based classifiers,
evaluation metrics and the applications of these word embeddings in different
NLP tasks.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 15:15:13 GMT'}]",2020-10-29,"[['Naseem', 'Usman', ''], ['Razzak', 'Imran', ''], ['Khan', 'Shah Khalid', ''], ['Prasad', 'Mukesh', '']]"
1371395,2010.15065,Amir Shanehsazzadeh,"Amir Shanehsazzadeh, David Belanger, David Dohan",Fixed-Length Protein Embeddings using Contextual Lenses,,,,,q-bio.BM cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The Basic Local Alignment Search Tool (BLAST) is currently the most popular
method for searching databases of biological sequences. BLAST compares
sequences via similarity defined by a weighted edit distance, which results in
it being computationally expensive. As opposed to working with edit distance, a
vector similarity approach can be accelerated substantially using modern
hardware or hashing techniques. Such an approach would require fixed-length
embeddings for biological sequences. There has been recent interest in learning
fixed-length protein embeddings using deep learning models under the hypothesis
that the hidden layers of supervised or semi-supervised models could produce
potentially useful vector embeddings. We consider transformer (BERT) protein
language models that are pretrained on the TrEMBL data set and learn
fixed-length embeddings on top of them with contextual lenses. The embeddings
are trained to predict the family a protein belongs to for sequences in the
Pfam database. We show that for nearest-neighbor family classification,
pretraining offers a noticeable boost in performance and that the corresponding
learned embeddings are competitive with BLAST. Furthermore, we show that the
raw transformer embeddings, obtained via static pooling, do not perform well on
nearest-neighbor family classification, which suggests that learning embeddings
in a supervised manner via contextual lenses may be a compute-efficient
alternative to fine-tuning.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 14:54:55 GMT'}]",2020-10-29,"[['Shanehsazzadeh', 'Amir', ''], ['Belanger', 'David', ''], ['Dohan', 'David', '']]"
1267866,2004.03096,Yiming Cui,"Nan Shao, Yiming Cui, Ting Liu, Shijin Wang, Guoping Hu",Is Graph Structure Necessary for Multi-hop Question Answering?,"6 pages, to appear at EMNLP 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, attempting to model texts as graph structure and introducing graph
neural networks to deal with it has become a trend in many NLP research areas.
In this paper, we investigate whether the graph structure is necessary for
multi-hop question answering. Our analysis is centered on HotpotQA. We
construct a strong baseline model to establish that, with the proper use of
pre-trained models, graph structure may not be necessary for multi-hop question
answering. We point out that both graph structure and adjacency matrix are
task-related prior knowledge, and graph-attention can be considered as a
special case of self-attention. Experiments and visualized analysis demonstrate
that graph-attention or the entire graph structure can be replaced by
self-attention or Transformers.
","[{'version': 'v1', 'created': 'Tue, 7 Apr 2020 02:59:42 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 09:29:19 GMT'}]",2020-10-30,"[['Shao', 'Nan', ''], ['Cui', 'Yiming', ''], ['Liu', 'Ting', ''], ['Wang', 'Shijin', ''], ['Hu', 'Guoping', '']]"
1356512,2010.00182,Yang Zhang,"Yang Zhang, Qiang Ma",Dual Attention Model for Citation Recommendation,,,,,cs.IR cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Based on an exponentially increasing number of academic articles, discovering
and citing comprehensive and appropriate resources has become a non-trivial
task. Conventional citation recommender methods suffer from severe information
loss. For example, they do not consider the section of the paper that the user
is writing and for which they need to find a citation, the relatedness between
the words in the local context (the text span that describes a citation), or
the importance on each word from the local context. These shortcomings make
such methods insufficient for recommending adequate citations to academic
manuscripts. In this study, we propose a novel embedding-based neural network
called ""dual attention model for citation recommendation (DACR)"" to recommend
citations during manuscript preparation. Our method adapts embedding of three
dimensions of semantic information: words in the local context, structural
contexts, and the section on which a user is working. A neural network is
designed to maximize the similarity between the embedding of the three input
(local context words, section and structural contexts) and the target citation
appearing in the context. The core of the neural network is composed of
self-attention and additive attention, where the former aims to capture the
relatedness between the contextual words and structural context, and the latter
aims to learn the importance of them. The experiments on real-world datasets
demonstrate the effectiveness of the proposed approach.
","[{'version': 'v1', 'created': 'Thu, 1 Oct 2020 02:41:47 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 11:27:20 GMT'}, {'version': 'v3', 'created': 'Wed, 28 Oct 2020 12:57:58 GMT'}, {'version': 'v4', 'created': 'Thu, 29 Oct 2020 12:31:26 GMT'}]",2020-10-30,"[['Zhang', 'Yang', ''], ['Ma', 'Qiang', '']]"
1371865,2010.15535,Craig Stewart,"Ricardo Rei, Craig Stewart, Catarina Farinha, Alon Lavie",Unbabel's Participation in the WMT20 Metrics Shared Task,WMT Metrics Shared Task 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present the contribution of the Unbabel team to the WMT 2020 Shared Task
on Metrics. We intend to participate on the segment-level, document-level and
system-level tracks on all language pairs, as well as the 'QE as a Metric'
track. Accordingly, we illustrate results of our models in these tracks with
reference to test sets from the previous year. Our submissions build upon the
recently proposed COMET framework: We train several estimator models to regress
on different human-generated quality scores and a novel ranking model trained
on relative ranks obtained from Direct Assessments. We also propose a simple
technique for converting segment-level predictions into a document-level score.
Overall, our systems achieve strong results for all language pairs on previous
test sets and in many cases set a new state-of-the-art.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 12:59:44 GMT'}]",2020-10-30,"[['Rei', 'Ricardo', ''], ['Stewart', 'Craig', ''], ['Farinha', 'Catarina', ''], ['Lavie', 'Alon', '']]"
1371796,2010.15466,Yuyang Nie,"Yuyang Nie, Yuanhe Tian, Yan Song, Xiang Ao, and Xiang Wan","Improving Named Entity Recognition with Attentive Ensemble of Syntactic
  Information","Natural Language Processing. 15 pages, 3 figures, Findings of
  EMNLP-2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Named entity recognition (NER) is highly sensitive to sentential syntactic
and semantic properties where entities may be extracted according to how they
are used and placed in the running text. To model such properties, one could
rely on existing resources to providing helpful knowledge to the NER task; some
existing studies proved the effectiveness of doing so, and yet are limited in
appropriately leveraging the knowledge such as distinguishing the important
ones for particular context. In this paper, we improve NER by leveraging
different types of syntactic information through attentive ensemble, which
functionalizes by the proposed key-value memory networks, syntax attention, and
the gate mechanism for encoding, weighting and aggregating such syntactic
information, respectively. Experimental results on six English and Chinese
benchmark datasets suggest the effectiveness of the proposed model and show
that it outperforms previous studies on all experiment datasets.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 10:25:17 GMT'}]",2020-10-30,"[['Nie', 'Yuyang', ''], ['Tian', 'Yuanhe', ''], ['Song', 'Yan', ''], ['Ao', 'Xiang', ''], ['Wan', 'Xiang', '']]"
1371788,2010.15458,Yuyang Nie,"Yuyang Nie, Yuanhe Tian, Xiang Wan, Yan Song, and Bo Dai","Named Entity Recognition for Social Media Texts with Semantic
  Augmentation","Natural Language Processing. 9 pages, 3 figures. EMNLP-2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Existing approaches for named entity recognition suffer from data sparsity
problems when conducted on short and informal texts, especially user-generated
social media content. Semantic augmentation is a potential way to alleviate
this problem. Given that rich semantic information is implicitly preserved in
pre-trained word embeddings, they are potential ideal resources for semantic
augmentation. In this paper, we propose a neural-based approach to NER for
social media texts where both local (from running text) and augmented semantics
are taken into account. In particular, we obtain the augmented semantic
information from a large-scale corpus, and propose an attentive semantic
augmentation module and a gate module to encode and aggregate such information,
respectively. Extensive experiments are performed on three benchmark datasets
collected from English and Chinese social media platforms, where the results
demonstrate the superiority of our approach to previous studies across all
three datasets.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 10:06:46 GMT'}]",2020-10-30,"[['Nie', 'Yuyang', ''], ['Tian', 'Yuanhe', ''], ['Wan', 'Xiang', ''], ['Song', 'Yan', ''], ['Dai', 'Bo', '']]"
1370914,2010.14584,Aleksandra Edwards Mrs,"Aleksandra Edwards, David Rogers, Jose Camacho-Collados, H\'el\`ene de
  Ribaupierre, Alun Preece","Predicting Themes within Complex Unstructured Texts: A Case Study on
  Safeguarding Reports","10 pages, 5 figures, workshop",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The task of text and sentence classification is associated with the need for
large amounts of labelled training data. The acquisition of high volumes of
labelled datasets can be expensive or unfeasible, especially for
highly-specialised domains for which documents are hard to obtain. Research on
the application of supervised classification based on small amounts of training
data is limited. In this paper, we address the combination of state-of-the-art
deep learning and classification methods and provide an insight into what
combination of methods fit the needs of small, domain-specific, and
terminologically-rich corpora. We focus on a real-world scenario related to a
collection of safeguarding reports comprising learning experiences and
reflections on tackling serious incidents involving children and vulnerable
adults. The relatively small volume of available reports and their use of
highly domain-specific terminology makes the application of automated
approaches difficult. We focus on the problem of automatically identifying the
main themes in a safeguarding report using supervised classification
approaches. Our results show the potential of deep learning models to simulate
subject-expert behaviour even for complex tasks with limited labelled data.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 19:48:23 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 09:15:14 GMT'}]",2020-10-30,"[['Edwards', 'Aleksandra', ''], ['Rogers', 'David', ''], ['Camacho-Collados', 'Jose', ''], ['de Ribaupierre', 'Hélène', ''], ['Preece', 'Alun', '']]"
1371767,2010.15437,Mana Ihori,"Mana Ihori, Ryo Masumura, Naoki Makishima, Tomohiro Tanaka, Akihiko
  Takashima, Shota Orihashi","Memory Attentive Fusion: External Language Model Integration for
  Transformer-based Sequence-to-Sequence Model",Accepted as a short paper at INLG 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents a novel fusion method for integrating an external
language model (LM) into the Transformer based sequence-to-sequence (seq2seq)
model. While paired data are basically required to train the seq2seq model, the
external LM can be trained with only unpaired data. Thus, it is important to
leverage memorized knowledge in the external LM for building the seq2seq model,
since it is hard to prepare a large amount of paired data. However, the
existing fusion methods assume that the LM is integrated with recurrent neural
network-based seq2seq models instead of the Transformer. Therefore, this paper
proposes a fusion method that can explicitly utilize network structures in the
Transformer. The proposed method, called {\bf memory attentive fusion},
leverages the Transformer-style attention mechanism that repeats source-target
attention in a multi-hop manner for reading the memorized knowledge in the LM.
Our experiments on two text-style conversion tasks demonstrate that the
proposed method performs better than conventional fusion methods.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 09:16:23 GMT'}]",2020-10-30,"[['Ihori', 'Mana', ''], ['Masumura', 'Ryo', ''], ['Makishima', 'Naoki', ''], ['Tanaka', 'Tomohiro', ''], ['Takashima', 'Akihiko', ''], ['Orihashi', 'Shota', '']]"
1370901,2010.14571,Isaac Caswell,"Isaac Caswell, Theresa Breiner, Daan van Esch, Ankur Bapna","Language ID in the Wild: Unexpected Challenges on the Path to a
  Thousand-Language Web Text Corpus",Accepted to COLING 2020. 9 pages with 8 page abstract,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Large text corpora are increasingly important for a wide variety of Natural
Language Processing (NLP) tasks, and automatic language identification (LangID)
is a core technology needed to collect such datasets in a multilingual context.
LangID is largely treated as solved in the literature, with models reported
that achieve over 90% average F1 on as many as 1,366 languages. We train LangID
models on up to 1,629 languages with comparable quality on held-out test sets,
but find that human-judged LangID accuracy for web-crawl text corpora created
using these models is only around 5% for many lower-resource languages,
suggesting a need for more robust evaluation. Further analysis revealed a
variety of error modes, arising from domain mismatch, class imbalance, language
similarity, and insufficiently expressive models. We propose two classes of
techniques to mitigate these errors: wordlist-based tunable-precision filters
(for which we release curated lists in about 500 languages) and
transformer-based semi-supervised LangID models, which increase median dataset
precision from 5.5% to 71.2%. These techniques enable us to create an initial
data set covering 100K or more relatively clean sentences in each of 500+
languages, paving the way towards a 1,000-language web text corpus.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 19:29:17 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 15:18:35 GMT'}]",2020-10-30,"[['Caswell', 'Isaac', ''], ['Breiner', 'Theresa', ''], ['van Esch', 'Daan', ''], ['Bapna', 'Ankur', '']]"
1371753,2010.15423,M\=arcis Pinnis,"Rihards Kri\v{s}lauks, M\=arcis Pinnis",Tilde at WMT 2020: News Task Systems,,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  This paper describes Tilde's submission to the WMT2020 shared task on news
translation for both directions of the English-Polish language pair in both the
constrained and the unconstrained tracks. We follow our submissions from the
previous years and build our baseline systems to be morphologically motivated
sub-word unit-based Transformer base models that we train using the Marian
machine translation toolkit. Additionally, we experiment with different
parallel and monolingual data selection schemes, as well as sampled
back-translation. Our final models are ensembles of Transformer base and
Transformer big models that feature right-to-left re-ranking.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 08:59:37 GMT'}]",2020-10-30,"[['Krišlauks', 'Rihards', ''], ['Pinnis', 'Mārcis', '']]"
1371741,2010.15411,Milan Gritta,"Milan Gritta, Gerasimos Lampouras and Ignacio Iacobacci","Conversation Graph: Data Augmentation, Training and Evaluation for
  Non-Deterministic Dialogue Management","Accepted at Transactions of Association of Computational Linguistics
  (to be presented at ACL 2021)",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Task-oriented dialogue systems typically rely on large amounts of
high-quality training data or require complex handcrafted rules. However,
existing datasets are often limited in size considering the complexity of the
dialogues. Additionally, conventional training signal inference is not suitable
for non-deterministic agent behaviour, i.e. considering multiple actions as
valid in identical dialogue states. We propose the Conversation Graph
(ConvGraph), a graph-based representation of dialogues that can be exploited
for data augmentation, multi-reference training and evaluation of
non-deterministic agents. ConvGraph generates novel dialogue paths to augment
data volume and diversity. Intrinsic and extrinsic evaluation across three
datasets shows that data augmentation and/or multi-reference training with
ConvGraph can improve dialogue success rates by up to 6.4%.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 08:23:24 GMT'}]",2020-10-30,"[['Gritta', 'Milan', ''], ['Lampouras', 'Gerasimos', ''], ['Iacobacci', 'Ignacio', '']]"
1371928,2010.15598,Micaela Kaplan,Micaela Kaplan,"May I Ask Who's Calling? Named Entity Recognition on Call Center
  Transcripts for Privacy Law Compliance",The 6th Workshop on Noisy User-generated Text (W-NUT) 2020 at EMNLP,"Proceedings of the 2020 EMNLP Workshop W-NUT: The Sixth Workshop
  on Noisy User-generated Text (2020) 1-6",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We investigate using Named Entity Recognition on a new type of user-generated
text: a call center conversation. These conversations combine problems from
spontaneous speech with problems novel to conversational Automated Speech
Recognition, including incorrect recognition, alongside other common problems
from noisy user-generated text. Using our own corpus with new annotations,
training custom contextual string embeddings, and applying a BiLSTM-CRF, we
match state-of-the-art results on our novel task.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 13:53:42 GMT'}]",2020-10-30,"[['Kaplan', 'Micaela', '']]"
1371696,2010.15366,Sung-Feng Huang,"Sung-Feng Huang, Shun-Po Chuang, Da-Rong Liu, Yi-Chen Chen, Gene-Ping
  Yang, Hung-yi Lee","Self-supervised Pre-training Reduces Label Permutation Instability of
  Speech Separation",submitted to ICASSP2021,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Speech separation has been well-developed while there are still problems
waiting to be solved. The main problem we focus on in this paper is the
frequent label permutation switching of permutation invariant training (PIT).
For N-speaker separation, there would be N! possible label permutations. How to
stably select correct label permutations is a long-standing problem. In this
paper, we utilize self-supervised pre-training to stabilize the label
permutations. Among several types of self-supervised tasks, speech enhancement
based pre-training tasks show significant effectiveness in our experiments.
When using off-the-shelf pre-trained models, training duration could be
shortened to one-third to two-thirds. Furthermore, even taking pre-training
time into account, the entire training process could still be shorter without a
performance drop when using a larger batch size.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 06:07:01 GMT'}]",2020-10-30,"[['Huang', 'Sung-Feng', ''], ['Chuang', 'Shun-Po', ''], ['Liu', 'Da-Rong', ''], ['Chen', 'Yi-Chen', ''], ['Yang', 'Gene-Ping', ''], ['Lee', 'Hung-yi', '']]"
1371690,2010.15360,Shaolei Wang,"Shaolei Wang, Zhongyuan Wang, Wanxiang Che, Ting Liu","Combining Self-Training and Self-Supervised Learning for Unsupervised
  Disfluency Detection",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Most existing approaches to disfluency detection heavily rely on
human-annotated corpora, which is expensive to obtain in practice. There have
been several proposals to alleviate this issue with, for instance,
self-supervised learning techniques, but they still require human-annotated
corpora. In this work, we explore the unsupervised learning paradigm which can
potentially work with unlabeled text corpora that are cheaper and easier to
obtain. Our model builds upon the recent work on Noisy Student Training, a
semi-supervised learning approach that extends the idea of self-training.
Experimental results on the commonly used English Switchboard test set show
that our approach achieves competitive performance compared to the previous
state-of-the-art supervised systems using contextualized word embeddings (e.g.
BERT and ELECTRA).
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 05:29:26 GMT'}]",2020-10-30,"[['Wang', 'Shaolei', ''], ['Wang', 'Zhongyuan', ''], ['Che', 'Wanxiang', ''], ['Liu', 'Ting', '']]"
1348756,2009.07253,Alexander Lin,"Alexander Lin, Jeremy Wohlwend, Howard Chen, and Tao Lei",Autoregressive Knowledge Distillation through Imitation Learning,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The performance of autoregressive models on natural language generation tasks
has dramatically improved due to the adoption of deep, self-attentive
architectures. However, these gains have come at the cost of hindering
inference speed, making state-of-the-art models cumbersome to deploy in
real-world, time-sensitive settings. We develop a compression technique for
autoregressive models that is driven by an imitation learning perspective on
knowledge distillation. The algorithm is designed to address the exposure bias
problem. On prototypical language generation tasks such as translation and
summarization, our method consistently outperforms other distillation
algorithms, such as sequence-level knowledge distillation. Student models
trained with our method attain 1.4 to 4.8 BLEU/ROUGE points higher than those
trained from scratch, while increasing inference speed by up to 14 times in
comparison to the teacher model.
","[{'version': 'v1', 'created': 'Tue, 15 Sep 2020 17:43:02 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 00:40:45 GMT'}]",2020-10-30,"[['Lin', 'Alexander', ''], ['Wohlwend', 'Jeremy', ''], ['Chen', 'Howard', ''], ['Lei', 'Tao', '']]"
1371646,2010.15316,Michal Malyska,"Alister D Costa, Stefan Denkovski, Michal Malyska, Sae Young Moon,
  Brandon Rufino, Zhen Yang, Taylor Killian, Marzyeh Ghassemi",Multiple Sclerosis Severity Classification From Clinical Text,EMNLP 2020 Clinical NLP workshop,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Multiple Sclerosis (MS) is a chronic, inflammatory and degenerative
neurological disease, which is monitored by a specialist using the Expanded
Disability Status Scale (EDSS) and recorded in unstructured text in the form of
a neurology consult note. An EDSS measurement contains an overall ""EDSS"" score
and several functional subscores. Typically, expert knowledge is required to
interpret consult notes and generate these scores. Previous approaches used
limited context length Word2Vec embeddings and keyword searches to predict
scores given a consult note, but often failed when scores were not explicitly
stated. In this work, we present MS-BERT, the first publicly available
transformer model trained on real clinical data other than MIMIC. Next, we
present MSBC, a classifier that applies MS-BERT to generate embeddings and
predict EDSS and functional subscores. Lastly, we explore combining MSBC with
other models through the use of Snorkel to generate scores for unlabelled
consult notes. MSBC achieves state-of-the-art performance on all metrics and
prediction tasks and outperforms the models generated from the Snorkel
ensemble. We improve Macro-F1 by 0.12 (to 0.88) for predicting EDSS and on
average by 0.29 (to 0.63) for predicting functional subscores over previous
Word2Vec CNN and rule-based approaches.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 02:15:23 GMT'}]",2020-10-30,"[['Costa', 'Alister D', ''], ['Denkovski', 'Stefan', ''], ['Malyska', 'Michal', ''], ['Moon', 'Sae Young', ''], ['Rufino', 'Brandon', ''], ['Yang', 'Zhen', ''], ['Killian', 'Taylor', ''], ['Ghassemi', 'Marzyeh', '']]"
1265269,2004.00499,Shengbin Jia,Shengbin Jia,Unique Chinese Linguistic Phenomena,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Linguistics holds unique characteristics of generality, stability, and
nationality, which will affect the formulation of extraction strategies and
should be incorporated into the relation extraction. Chinese open relation
extraction is not well-established, because of the complexity of Chinese
linguistics makes it harder to operate, and the methods for English are not
compatible with that for Chinese. The diversities between Chinese and English
linguistics are mainly reflected in morphology and syntax.
","[{'version': 'v1', 'created': 'Sun, 23 Feb 2020 12:13:48 GMT'}, {'version': 'v2', 'created': 'Fri, 31 Jul 2020 10:00:08 GMT'}, {'version': 'v3', 'created': 'Thu, 29 Oct 2020 06:07:07 GMT'}]",2020-10-30,"[['Jia', 'Shengbin', '']]"
1150762,1907.06226,Jipeng Qiang,Jipeng Qiang and Yun Li and Yi Zhu and Yunhao Yuan and Xindong Wu,Lexical Simplification with Pretrained Encoders,,,,,cs.CL cs.AI cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Lexical simplification (LS) aims to replace complex words in a given sentence
with their simpler alternatives of equivalent meaning. Recently unsupervised
lexical simplification approaches only rely on the complex word itself
regardless of the given sentence to generate candidate substitutions, which
will inevitably produce a large number of spurious candidates. We present a
simple LS approach that makes use of the Bidirectional Encoder Representations
from Transformers (BERT) which can consider both the given sentence and the
complex word during generating candidate substitutions for the complex word.
Specifically, we mask the complex word of the original sentence for feeding
into the BERT to predict the masked token. The predicted results will be used
as candidate substitutions. Despite being entirely unsupervised, experimental
results show that our approach obtains obvious improvement compared with these
baselines leveraging linguistic databases and parallel corpus, outperforming
the state-of-the-art by more than 12 Accuracy points on three well-known
benchmarks.
","[{'version': 'v1', 'created': 'Sun, 14 Jul 2019 14:19:22 GMT'}, {'version': 'v2', 'created': 'Tue, 16 Jul 2019 14:36:41 GMT'}, {'version': 'v3', 'created': 'Tue, 30 Jul 2019 03:36:12 GMT'}, {'version': 'v4', 'created': 'Fri, 16 Aug 2019 01:48:46 GMT'}, {'version': 'v5', 'created': 'Thu, 29 Oct 2020 03:21:25 GMT'}]",2020-10-30,"[['Qiang', 'Jipeng', ''], ['Li', 'Yun', ''], ['Zhu', 'Yi', ''], ['Yuan', 'Yunhao', ''], ['Wu', 'Xindong', '']]"
1371643,2010.15313,Keen You,Keen You and Dan Goldwasser,"""where is this relationship going?"": Understanding Relationship
  Trajectories in Narrative Text",Accepted to *Sem 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We examine a new commonsense reasoning task: given a narrative describing a
social interaction that centers on two protagonists, systems make inferences
about the underlying relationship trajectory. Specifically, we propose two
evaluation tasks: Relationship Outlook Prediction MCQ and Resolution Prediction
MCQ. In Relationship Outlook Prediction, a system maps an interaction to a
relationship outlook that captures how the interaction is expected to change
the relationship. In Resolution Prediction, a system attributes a given
relationship outlook to a particular resolution that explains the outcome.
These two tasks parallel two real-life questions that people frequently ponder
upon as they navigate different social situations: ""where is this relationship
going?"" and ""how did we end up here?"". To facilitate the investigation of human
social relationships through these two tasks, we construct a new dataset,
Social Narrative Tree, which consists of 1250 stories documenting a variety of
daily social interactions. The narratives encode a multitude of social elements
that interweave to give rise to rich commonsense knowledge of how relationships
evolve with respect to social interactions. We establish baseline performances
using language models and the accuracies are significantly lower than human
performance. The results demonstrate that models need to look beyond syntactic
and semantic signals to comprehend complex human relationships.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 02:07:05 GMT'}]",2020-10-30,"[['You', 'Keen', ''], ['Goldwasser', 'Dan', '']]"
1371930,2010.15600,Ciro Garcia Mr,Ciro Ivan Garcia Lopez,Three computational models and its equivalence,,,,,cs.LO cs.CC cs.CL cs.GL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  The study of computability has its origin in Hilbert's conference of 1900,
where an adjacent question, to the ones he asked, is to give a precise
description of the notion of algorithm. In the search for a good definition
arose three independent theories: Turing and the Turing machines, G\""odel and
the recursive functions, Church and the Lambda Calculus.
  Later there were established by Kleene that the classic models of computation
are equivalent. This fact is widely accepted by many textbooks and the proof is
omitted since the proof is tedious and unreadable. We intend to fill this gap
presenting the proof in a modern way, without forgetting the mathematical
details.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 05:55:19 GMT'}]",2020-10-30,"[['Lopez', 'Ciro Ivan Garcia', '']]"
1371983,2010.15653,Niko Moritz,"Niko Moritz, Takaaki Hori, Jonathan Le Roux","Semi-Supervised Speech Recognition via Graph-based Temporal
  Classification",Submitted to ICASSP 2021,,,,cs.LG cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Semi-supervised learning has demonstrated promising results in automatic
speech recognition (ASR) by self-training using a seed ASR model with
pseudo-labels generated for unlabeled data. The effectiveness of this approach
largely relies on the pseudo-label accuracy, for which typically only the
1-best ASR hypothesis is used. However, alternative ASR hypotheses of an N-best
list can provide more accurate labels for an unlabeled speech utterance and
also reflect uncertainties of the seed ASR model. In this paper, we propose a
generalized form of the connectionist temporal classification (CTC) objective
that accepts a graph representation of the training targets. The newly proposed
graph-based temporal classification (GTC) objective is applied for
self-training with WFST-based supervision, which is generated from an N-best
list of pseudo-labels. In this setup, GTC is used to learn not only a temporal
alignment, similarly to CTC, but also a label alignment to obtain the optimal
pseudo-label sequence from the weighted graph. Results show that this approach
can effectively exploit an N-best list of pseudo-labels with associated scores,
outperforming standard pseudo-labeling by a large margin, with ASR results
close to an oracle experiment in which the best hypotheses of the N-best lists
are selected manually.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 14:56:56 GMT'}]",2020-10-30,"[['Moritz', 'Niko', ''], ['Hori', 'Takaaki', ''], ['Roux', 'Jonathan Le', '']]"
1358840,2010.02510,Lily Ou,"Sophie Groenwold, Lily Ou, Aesha Parekh, Samhita Honnavalli, Sharon
  Levy, Diba Mirza, William Yang Wang","Investigating African-American Vernacular English in Transformer-Based
  Text Generation","7 pages, EMNLP 2020",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The growth of social media has encouraged the written use of African American
Vernacular English (AAVE), which has traditionally been used only in oral
contexts. However, NLP models have historically been developed using dominant
English varieties, such as Standard American English (SAE), due to text corpora
availability. We investigate the performance of GPT-2 on AAVE text by creating
a dataset of intent-equivalent parallel AAVE/SAE tweet pairs, thereby isolating
syntactic structure and AAVE- or SAE-specific language for each pair. We
evaluate each sample and its GPT-2 generated text with pretrained sentiment
classifiers and find that while AAVE text results in more classifications of
negative sentiment than SAE, the use of GPT-2 generally increases occurrences
of positive sentiment for both. Additionally, we conduct human evaluation of
AAVE and SAE text generated with GPT-2 to compare contextual rigor and overall
quality.
","[{'version': 'v1', 'created': 'Tue, 6 Oct 2020 06:27:02 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 04:00:46 GMT'}]",2020-10-30,"[['Groenwold', 'Sophie', ''], ['Ou', 'Lily', ''], ['Parekh', 'Aesha', ''], ['Honnavalli', 'Samhita', ''], ['Levy', 'Sharon', ''], ['Mirza', 'Diba', ''], ['Wang', 'William Yang', '']]"
1367089,2010.10759,Yangyang Shi,"Yangyang Shi, Yongqiang Wang, Chunyang Wu, Ching-Feng Yeh, Julian
  Chan, Frank Zhang, Duc Le, Mike Seltzer","Emformer: Efficient Memory Transformer Based Acoustic Model For Low
  Latency Streaming Speech Recognition","5 pages, 2 figures, submitted to ICASSP 2021",,,,cs.SD cs.CL cs.LG eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper proposes an efficient memory transformer Emformer for low latency
streaming speech recognition. In Emformer, the long-range history context is
distilled into an augmented memory bank to reduce self-attention's computation
complexity. A cache mechanism saves the computation for the key and value in
self-attention for the left context. Emformer applies a parallelized block
processing in training to support low latency models. We carry out experiments
on benchmark LibriSpeech data. Under average latency of 960 ms, Emformer gets
WER $2.50\%$ on test-clean and $5.62\%$ on test-other. Comparing with a strong
baseline augmented memory transformer (AM-TRF), Emformer gets $4.6$ folds
training speedup and $18\%$ relative real-time factor (RTF) reduction in
decoding with relative WER reduction $17\%$ on test-clean and $9\%$ on
test-other. For a low latency scenario with an average latency of 80 ms,
Emformer achieves WER $3.01\%$ on test-clean and $7.09\%$ on test-other.
Comparing with the LSTM baseline with the same latency and model size, Emformer
gets relative WER reduction $9\%$ and $16\%$ on test-clean and test-other,
respectively.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 04:38:09 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 19:59:08 GMT'}, {'version': 'v3', 'created': 'Thu, 29 Oct 2020 14:55:59 GMT'}]",2020-10-30,"[['Shi', 'Yangyang', ''], ['Wang', 'Yongqiang', ''], ['Wu', 'Chunyang', ''], ['Yeh', 'Ching-Feng', ''], ['Chan', 'Julian', ''], ['Zhang', 'Frank', ''], ['Le', 'Duc', ''], ['Seltzer', 'Mike', '']]"
1371388,2010.15058,Tomek Korbak,Tomasz Korbak and Julian Zubek and Joanna R\k{a}czaszek-Leonardi,Measuring non-trivial compositionality in emergent communication,"4th Workshop on Emergent Communication, NeurIPS 2020",,,,cs.NE cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Compositionality is an important explanatory target in emergent communication
and language evolution. The vast majority of computational models of
communication account for the emergence of only a very basic form of
compositionality: trivial compositionality. A compositional protocol is
trivially compositional if the meaning of a complex signal (e.g. blue circle)
boils down to the intersection of meanings of its constituents (e.g. the
intersection of the set of blue objects and the set of circles). A protocol is
non-trivially compositional (NTC) if the meaning of a complex signal (e.g.
biggest apple) is a more complex function of the meanings of their
constituents. In this paper, we review several metrics of compositionality used
in emergent communication and experimentally show that most of them fail to
detect NTC - i.e. they treat non-trivial compositionality as a failure of
compositionality. The one exception is tree reconstruction error, a metric
motivated by formal accounts of compositionality. These results emphasise
important limitations of emergent communication research that could hamper
progress on modelling the emergence of NTC.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 16:11:07 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 16:22:44 GMT'}]",2020-10-30,"[['Korbak', 'Tomasz', ''], ['Zubek', 'Julian', ''], ['Rączaszek-Leonardi', 'Joanna', '']]"
1301728,2006.07214,Andre Martins,"Andr\'e F. T. Martins, Ant\'onio Farinhas, Marcos Treviso, Vlad
  Niculae, Pedro M. Q. Aguiar, M\'ario A. T. Figueiredo",Sparse and Continuous Attention Mechanisms,Accepted for spotlight presentation at NeurIPS 2020,,,,cs.LG cs.CL cs.CV stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Exponential families are widely used in machine learning; they include many
distributions in continuous and discrete domains (e.g., Gaussian, Dirichlet,
Poisson, and categorical distributions via the softmax transformation).
Distributions in each of these families have fixed support. In contrast, for
finite domains, there has been recent work on sparse alternatives to softmax
(e.g. sparsemax and alpha-entmax), which have varying support, being able to
assign zero probability to irrelevant categories. This paper expands that work
in two directions: first, we extend alpha-entmax to continuous domains,
revealing a link with Tsallis statistics and deformed exponential families.
Second, we introduce continuous-domain attention mechanisms, deriving efficient
gradient backpropagation algorithms for alpha in {1,2}. Experiments on
attention-based text classification, machine translation, and visual question
answering illustrate the use of continuous attention in 1D and 2D, showing that
it allows attending to time intervals and compact regions.
","[{'version': 'v1', 'created': 'Fri, 12 Jun 2020 14:16:48 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 22:22:38 GMT'}, {'version': 'v3', 'created': 'Thu, 29 Oct 2020 08:39:54 GMT'}]",2020-10-30,"[['Martins', 'André F. T.', ''], ['Farinhas', 'António', ''], ['Treviso', 'Marcos', ''], ['Niculae', 'Vlad', ''], ['Aguiar', 'Pedro M. Q.', ''], ['Figueiredo', 'Mário A. T.', '']]"
1324516,2007.13002,Siyuan Feng,"Siyuan Feng, Odette Scharenborg","Unsupervised Subword Modeling Using Autoregressive Pretraining and
  Cross-Lingual Phone-Aware Modeling","5 pages, 3 figures. Accepted for publication in INTERSPEECH 2020,
  Shanghai, China",,10.21437/Interspeech.2020-1170,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This study addresses unsupervised subword modeling, i.e., learning feature
representations that can distinguish subword units of a language. The proposed
approach adopts a two-stage bottleneck feature (BNF) learning framework,
consisting of autoregressive predictive coding (APC) as a front-end and a
DNN-BNF model as a back-end. APC pretrained features are set as input features
to a DNN-BNF model. A language-mismatched ASR system is used to provide
cross-lingual phone labels for DNN-BNF model training. Finally, BNFs are
extracted as the subword-discriminative feature representation. A second aim of
this work is to investigate the robustness of our approach's effectiveness to
different amounts of training data. The results on Libri-light and the
ZeroSpeech 2017 databases show that APC is effective in front-end feature
pretraining. Our whole system outperforms the state of the art on both
databases. Cross-lingual phone labels for English data by a Dutch ASR
outperform those by a Mandarin ASR, possibly linked to the larger similarity of
Dutch compared to Mandarin with English. Our system is less sensitive to
training data amount when the training data is over 50 hours. APC pretraining
leads to a reduction of needed training material from over 5,000 hours to
around 200 hours with little performance degradation.
","[{'version': 'v1', 'created': 'Sat, 25 Jul 2020 19:41:41 GMT'}, {'version': 'v2', 'created': 'Thu, 6 Aug 2020 19:15:48 GMT'}]",2020-10-30,"[['Feng', 'Siyuan', ''], ['Scharenborg', 'Odette', '']]"
1371596,2010.15266,Abhinav Singh,"Abhinav Singh, Patrick Xia, Guanghui Qin, Mahsa Yarmohammadi, Benjamin
  Van Durme","CopyNext: Explicit Span Copying and Alignment in Sequence to Sequence
  Models",4th Workshop on Structured Prediction for NLP (EMNLP 2020),,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Copy mechanisms are employed in sequence to sequence models (seq2seq) to
generate reproductions of words from the input to the output. These frameworks,
operating at the lexical type level, fail to provide an explicit alignment that
records where each token was copied from. Further, they require contiguous
token sequences from the input (spans) to be copied individually. We present a
model with an explicit token-level copy operation and extend it to copying
entire spans. Our model provides hard alignments between spans in the input and
output, allowing for nontraditional applications of seq2seq, like information
extraction. We demonstrate the approach on Nested Named Entity Recognition,
achieving near state-of-the-art accuracy with an order of magnitude increase in
decoding speed.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 22:45:16 GMT'}]",2020-10-30,"[['Singh', 'Abhinav', ''], ['Xia', 'Patrick', ''], ['Qin', 'Guanghui', ''], ['Yarmohammadi', 'Mahsa', ''], ['Van Durme', 'Benjamin', '']]"
1294236,2005.14441,Xiang Hao,"Xiang Hao, Xiangdong Su, Zhiyu Wang, Qiang Zhang, Huali Xu and
  Guanglai Gao",SNR-Based Teachers-Student Technique for Speech Enhancement,"Published in 2020 IEEE International Conference on Multimedia and
  Expo (ICME 2020)",,10.1109/ICME46284.2020.9102846,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  It is very challenging for speech enhancement methods to achieves robust
performance under both high signal-to-noise ratio (SNR) and low SNR
simultaneously. In this paper, we propose a method that integrates an SNR-based
teachers-student technique and time-domain U-Net to deal with this problem.
Specifically, this method consists of multiple teacher models and a student
model. We first train the teacher models under multiple small-range SNRs that
do not coincide with each other so that they can perform speech enhancement
well within the specific SNR range. Then, we choose different teacher models to
supervise the training of the student model according to the SNR of the
training data. Eventually, the student model can perform speech enhancement
under both high SNR and low SNR. To evaluate the proposed method, we
constructed a dataset with an SNR ranging from -20dB to 20dB based on the
public dataset. We experimentally analyzed the effectiveness of the SNR-based
teachers-student technique and compared the proposed method with several
state-of-the-art methods.
","[{'version': 'v1', 'created': 'Fri, 29 May 2020 08:13:01 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 12:12:20 GMT'}]",2020-10-30,"[['Hao', 'Xiang', ''], ['Su', 'Xiangdong', ''], ['Wang', 'Zhiyu', ''], ['Zhang', 'Qiang', ''], ['Xu', 'Huali', ''], ['Gao', 'Guanglai', '']]"
1294230,2005.14435,Xiang Hao,"Xiang Hao, Shixue Wen, Xiangdong Su, Yun Liu, Guanglai Gao and Xiaofei
  Li",Sub-Band Knowledge Distillation Framework for Speech Enhancement,Published in Interspeech 2020,,10.21437/Interspeech.2020-1539,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In single-channel speech enhancement, methods based on full-band spectral
features have been widely studied. However, only a few methods pay attention to
non-full-band spectral features. In this paper, we explore a knowledge
distillation framework based on sub-band spectral mapping for single-channel
speech enhancement. Specifically, we divide the full frequency band into
multiple sub-bands and pre-train an elite-level sub-band enhancement model
(teacher model) for each sub-band. These teacher models are dedicated to
processing their own sub-bands. Next, under the teacher models' guidance, we
train a general sub-band enhancement model (student model) that works for all
sub-bands. Without increasing the number of model parameters and computational
complexity, the student model's performance is further improved. To evaluate
our proposed method, we conducted a large number of experiments on an
open-source data set. The final experimental results show that the guidance
from the elite-level teacher models dramatically improves the student model's
performance, which exceeds the full-band model by employing fewer parameters.
","[{'version': 'v1', 'created': 'Fri, 29 May 2020 07:55:12 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 12:14:59 GMT'}]",2020-10-30,"[['Hao', 'Xiang', ''], ['Wen', 'Shixue', ''], ['Su', 'Xiangdong', ''], ['Liu', 'Yun', ''], ['Gao', 'Guanglai', ''], ['Li', 'Xiaofei', '']]"
1292684,2005.12889,Ruixiang Cui,"Ruixiang Cui, Daniel Hershcovich",Refining Implicit Argument Annotation for UCCA,DMR 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Predicate-argument structure analysis is a central component in meaning
representations of text. The fact that some arguments are not explicitly
mentioned in a sentence gives rise to ambiguity in language understanding, and
renders it difficult for machines to interpret text correctly. However, only
few resources represent implicit roles for NLU, and existing studies in NLP
only make coarse distinctions between categories of arguments omitted from
linguistic form. This paper proposes a typology for fine-grained implicit
argument annotation on top of Universal Conceptual Cognitive Annotation's
foundational layer. The proposed implicit argument categorisation is driven by
theories of implicit role interpretation and consists of six types: Deictic,
Generic, Genre-based, Type-identifiable, Non-specific, and Iterated-set. We
exemplify our design by revisiting part of the UCCA EWT corpus, providing a new
dataset annotated with the refinement layer, and making a comparative analysis
with other schemes.
","[{'version': 'v1', 'created': 'Tue, 26 May 2020 17:24:15 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 16:07:33 GMT'}]",2020-10-30,"[['Cui', 'Ruixiang', ''], ['Hershcovich', 'Daniel', '']]"
1358810,2010.02480,Cheng-Han Chiang,"Cheng-Han Chiang, Sung-Feng Huang and Hung-yi Lee",Pretrained Language Model Embryology: The Birth of ALBERT,"Accepted to EMNLP 2020, short paper",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While behaviors of pretrained language models (LMs) have been thoroughly
examined, what happened during pretraining is rarely studied. We thus
investigate the developmental process from a set of randomly initialized
parameters to a totipotent language model, which we refer to as the embryology
of a pretrained language model. Our results show that ALBERT learns to
reconstruct and predict tokens of different parts of speech (POS) in different
learning speeds during pretraining. We also find that linguistic knowledge and
world knowledge do not generally improve as pretraining proceeds, nor do
downstream tasks' performance. These findings suggest that knowledge of a
pretrained model varies during pretraining, and having more pretrain steps does
not necessarily provide a model with more comprehensive knowledge. We will
provide source codes and pretrained models to reproduce our results at
https://github.com/d223302/albert-embryology.
","[{'version': 'v1', 'created': 'Tue, 6 Oct 2020 05:15:39 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 00:07:43 GMT'}]",2020-10-30,"[['Chiang', 'Cheng-Han', ''], ['Huang', 'Sung-Feng', ''], ['Lee', 'Hung-yi', '']]"
1201305,1911.02711,Sen Yang,"Sen Yang, Leyang Cui, Jun Xie and Yue Zhang",Making the Best Use of Review Summary for Sentiment Analysis,To be published in COLING-2020,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Sentiment analysis provides a useful overview of customer review contents.
Many review websites allow a user to enter a summary in addition to a full
review. Intuitively, summary information may give additional benefit for review
sentiment analysis. In this paper, we conduct a study to exploit methods for
better use of summary information. We start by finding out that the sentimental
signal distribution of a review and that of its corresponding summary are in
fact complementary to each other. We thus explore various architectures to
better guide the interactions between the two and propose a
hierarchically-refined review-centric attention model. Empirical results show
that our review-centric model can make better use of user-written summaries for
review sentiment analysis, and is also more effective compared to existing
methods when the user summary is replaced with summary generated by an
automatic summarization system.
","[{'version': 'v1', 'created': 'Thu, 7 Nov 2019 01:46:54 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 07:15:01 GMT'}]",2020-10-30,"[['Yang', 'Sen', ''], ['Cui', 'Leyang', ''], ['Xie', 'Jun', ''], ['Zhang', 'Yue', '']]"
1202469,1911.03875,Khalil Mrini,"Khalil Mrini, Franck Dernoncourt, Quan Tran, Trung Bui, Walter Chang,
  Ndapa Nakashole",Rethinking Self-Attention: Towards Interpretability in Neural Parsing,EMNLP 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Attention mechanisms have improved the performance of NLP tasks while
allowing models to remain explainable. Self-attention is currently widely used,
however interpretability is difficult due to the numerous attention
distributions. Recent work has shown that model representations can benefit
from label-specific information, while facilitating interpretation of
predictions. We introduce the Label Attention Layer: a new form of
self-attention where attention heads represent labels. We test our novel layer
by running constituency and dependency parsing experiments and show our new
model obtains new state-of-the-art results for both tasks on both the Penn
Treebank (PTB) and Chinese Treebank. Additionally, our model requires fewer
self-attention layers compared to existing work. Finally, we find that the
Label Attention heads learn relations between syntactic categories and show
pathways to analyze errors.
","[{'version': 'v1', 'created': 'Sun, 10 Nov 2019 08:17:11 GMT'}, {'version': 'v2', 'created': 'Sat, 2 May 2020 04:34:52 GMT'}, {'version': 'v3', 'created': 'Thu, 29 Oct 2020 06:17:11 GMT'}]",2020-10-30,"[['Mrini', 'Khalil', ''], ['Dernoncourt', 'Franck', ''], ['Tran', 'Quan', ''], ['Bui', 'Trung', ''], ['Chang', 'Walter', ''], ['Nakashole', 'Ndapa', '']]"
1217216,1912.05320,Carlos S. Armendariz,"Carlos Santos Armendariz, Matthew Purver, Matej Ul\v{c}ar, Senja
  Pollak, Nikola Ljube\v{s}i\'c, Marko Robnik-\v{S}ikonja, Mark
  Granroth-Wilding, Kristiina Vaik",CoSimLex: A Resource for Evaluating Graded Word Similarity in Context,,"Proceedings of the 12th Language Resources and Evaluation
  Conference (2020) 5878-5886",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  State of the art natural language processing tools are built on
context-dependent word embeddings, but no direct method for evaluating these
representations currently exists. Standard tasks and datasets for intrinsic
evaluation of embeddings are based on judgements of similarity, but ignore
context; standard tasks for word sense disambiguation take account of context
but do not provide continuous measures of meaning similarity. This paper
describes an effort to build a new dataset, CoSimLex, intended to fill this
gap. Building on the standard pairwise similarity task of SimLex-999, it
provides context-dependent similarity measures; covers not only discrete
differences in word sense but more subtle, graded changes in meaning; and
covers not only a well-resourced language (English) but a number of
less-resourced languages. We define the task and evaluation metrics, outline
the dataset collection methodology, and describe the status of the dataset so
far.
","[{'version': 'v1', 'created': 'Wed, 11 Dec 2019 14:02:59 GMT'}, {'version': 'v2', 'created': 'Wed, 18 Dec 2019 10:33:05 GMT'}, {'version': 'v3', 'created': 'Thu, 29 Oct 2020 15:22:27 GMT'}]",2020-10-30,"[['Armendariz', 'Carlos Santos', ''], ['Purver', 'Matthew', ''], ['Ulčar', 'Matej', ''], ['Pollak', 'Senja', ''], ['Ljubešić', 'Nikola', ''], ['Robnik-Šikonja', 'Marko', ''], ['Granroth-Wilding', 'Mark', ''], ['Vaik', 'Kristiina', '']]"
1371555,2010.15225,Dylan Ebert,"Dylan Ebert, Ellie Pavlick",A Visuospatial Dataset for Naturalistic Verb Learning,"9 pages, 3 figures, starsem 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We introduce a new dataset for training and evaluating grounded language
models. Our data is collected within a virtual reality environment and is
designed to emulate the quality of language data to which a pre-verbal child is
likely to have access: That is, naturalistic, spontaneous speech paired with
richly grounded visuospatial context. We use the collected data to compare
several distributional semantics models for verb learning. We evaluate neural
models based on 2D (pixel) features as well as feature-engineered models based
on 3D (symbolic, spatial) features, and show that neither modeling approach
achieves satisfactory performance. Our results are consistent with evidence
from child language acquisition that emphasizes the difficulty of learning
verbs from naive distributional data. We discuss avenues for future work on
cognitively-inspired grounded language learning, and release our corpus with
the intent of facilitating research on the topic.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 20:47:13 GMT'}]",2020-10-30,"[['Ebert', 'Dylan', ''], ['Pavlick', 'Ellie', '']]"
1362681,2010.06351,Fuli Luo,"Fuli Luo, Pengcheng Yang, Shicheng Li, Xuancheng Ren, Xu Sun","CAPT: Contrastive Pre-Training for Learning Denoised Sequence
  Representations",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pre-trained self-supervised models such as BERT have achieved striking
success in learning sequence representations, especially for natural language
processing. These models typically corrupt the given sequences with certain
types of noise, such as masking, shuffling, or substitution, and then try to
recover the original input. However, such pre-training approaches are prone to
learning representations that are covariant with the noise, leading to the
discrepancy between the pre-training and fine-tuning stage. To remedy this, we
present ContrAstive Pre-Training (CAPT) to learn noise invariant sequence
representations. The proposed CAPT encourages the consistency between
representations of the original sequence and its corrupted version via
unsupervised instance-wise training signals. In this way, it not only
alleviates the pretrain-finetune discrepancy induced by the noise of
pre-training, but also aids the pre-trained model in better capturing global
semantics of the input via more effective sentence-level supervision. Different
from most prior work that focuses on a particular modality, comprehensive
empirical evidence on 11 natural language understanding and cross-modal tasks
illustrates that CAPT is applicable for both language and vision-language
tasks, and obtains surprisingly consistent improvement, including 0.6% absolute
gain on GLUE benchmarks and 0.8% absolute increment on NLVR.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 13:08:34 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 09:30:12 GMT'}, {'version': 'v3', 'created': 'Thu, 29 Oct 2020 06:41:07 GMT'}]",2020-10-30,"[['Luo', 'Fuli', ''], ['Yang', 'Pengcheng', ''], ['Li', 'Shicheng', ''], ['Ren', 'Xuancheng', ''], ['Sun', 'Xu', '']]"
1372108,2010.15778,Timo Denk,Timo I. Denk and Ana Peleteiro Ramallo,Contextual BERT: Conditioning the Language Model Using a Global State,"Accepted at the TextGraphs-14 workshop at COLING'2020 - The 28th
  International Conference on Computational Linguistics",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  BERT is a popular language model whose main pre-training task is to fill in
the blank, i.e., predicting a word that was masked out of a sentence, based on
the remaining words. In some applications, however, having an additional
context can help the model make the right prediction, e.g., by taking the
domain or the time of writing into account. This motivates us to advance the
BERT architecture by adding a global state for conditioning on a fixed-sized
context. We present our two novel approaches and apply them to an industry
use-case, where we complete fashion outfits with missing articles, conditioned
on a specific customer. An experimental comparison to other methods from the
literature shows that our methods improve personalization significantly.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 17:25:20 GMT'}]",2020-10-30,"[['Denk', 'Timo I.', ''], ['Ramallo', 'Ana Peleteiro', '']]"
1371581,2010.15251,Marimuthu Kalimuthu,"Marimuthu Kalimuthu, Aditya Mogadala, Marius Mosbach, Dietrich Klakow",Fusion Models for Improved Visual Captioning,"Under review at ""Multi-Modal Deep Learning: Challenges and
  Applications"", ICPR-2020",,,,cs.CV cs.AI cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Visual captioning aims to generate textual descriptions given images.
Traditionally, the captioning models are trained on human annotated datasets
such as Flickr30k and MS-COCO, which are limited in size and diversity. This
limitation hinders the generalization capabilities of these models while also
rendering them to often make mistakes. Language models can, however, be trained
on vast amounts of freely available unlabelled data and have recently emerged
as successful language encoders and coherent text generators. Meanwhile,
several unimodal and multimodal fusion techniques have been proven to work well
for natural language generation and automatic speech recognition. Building on
these recent developments, and with an aim of improving the quality of
generated captions, the contribution of our work in this paper is two-fold:
First, we propose a generic multimodal model fusion framework for caption
generation as well as emendation where we utilize different fusion strategies
to integrate a pretrained Auxiliary Language Model (AuxLM) within the
traditional encoder-decoder visual captioning frameworks. Next, we employ the
same fusion strategies to integrate a pretrained Masked Language Model (MLM),
namely BERT, with a visual captioning model, viz. Show, Attend, and Tell, for
emending both syntactic and semantic errors in captions. Our caption emendation
experiments on three benchmark image captioning datasets, viz. Flickr8k,
Flickr30k, and MSCOCO, show improvements over the baseline, indicating the
usefulness of our proposed multimodal fusion strategies. Further, we perform a
preliminary qualitative analysis on the emended captions and identify error
categories based on the type of corrections.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 21:55:25 GMT'}]",2020-10-30,"[['Kalimuthu', 'Marimuthu', ''], ['Mogadala', 'Aditya', ''], ['Mosbach', 'Marius', ''], ['Klakow', 'Dietrich', '']]"
1372058,2010.15728,Hang Dong,"Hang Dong, V\'ictor Su\'arez-Paniagua, William Whiteley, Honghan Wu","Explainable Automated Coding of Clinical Notes using Hierarchical
  Label-wise Attention Networks and Label Embedding Initialisation","Structured abstract in full text, 17 pages, 5 figures, 4
  supplementary materials (3 extra pages), submitted to Journal of Biomedical
  Informatics",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Diagnostic or procedural coding of clinical notes aims to derive a coded
summary of disease-related information about patients. Such coding is usually
done manually in hospitals but could potentially be automated to improve the
efficiency and accuracy of medical coding. Recent studies on deep learning for
automated medical coding achieved promising performances. However, the
explainability of these models is usually poor, preventing them to be used
confidently in supporting clinical practice. Another limitation is that these
models mostly assume independence among labels, ignoring the complex
correlation among medical codes which can potentially be exploited to improve
the performance. We propose a Hierarchical Label-wise Attention Network (HLAN),
which aimed to interpret the model by quantifying importance (as attention
weights) of words and sentences related to each of the labels. Secondly, we
propose to enhance the major deep learning models with a label embedding (LE)
initialisation approach, which learns a dense, continuous vector representation
and then injects the representation into the final layers and the label-wise
attention layers in the models. We evaluated the methods using three settings
on the MIMIC-III discharge summaries: full codes, top-50 codes, and the UK NHS
COVID-19 shielding codes. Experiments were conducted to compare HLAN and LE
initialisation to the state-of-the-art neural network based methods. HLAN
achieved the best Micro-level AUC and $F_1$ on the top-50 code prediction and
comparable results on the NHS COVID-19 shielding code prediction to other
models. By highlighting the most salient words and sentences for each label,
HLAN showed more meaningful and comprehensive model interpretation compared to
its downgraded baselines and the CNN-based models. LE initialisation
consistently boosted most deep learning models for automated medical coding.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 16:21:26 GMT'}]",2020-10-30,"[['Dong', 'Hang', ''], ['Suárez-Paniagua', 'Víctor', ''], ['Whiteley', 'William', ''], ['Wu', 'Honghan', '']]"
1371932,2010.15602,Junhua Liu,Nachamma Sockalingam and Junhua Liu,Designing learning experiences for online teaching and learning,,,,,cs.CY cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Teaching is about constantly innovating strategies, ways and means to engage
diverse students in active and meaningful learning. In line with this, SUTD
adopts various student-centric teaching and learning teaching methods and
approaches. This means that our graduate/undergraduate instructors have to be
ready to teach using these student student-centric teaching and learning
pedagogies. In this article, I share my experiences of redesigning this
teaching course that is typically conducted face-to-face to a synchronous
online course and also invite one of the participant in this course to reflect
on his experience as a student.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 07:03:49 GMT'}]",2020-10-30,"[['Sockalingam', 'Nachamma', ''], ['Liu', 'Junhua', '']]"
1371479,2010.15149,Yiwei Luo,"Yiwei Luo, Dallas Card, Dan Jurafsky",DeSMOG: Detecting Stance in Media On Global Warming,"9 pages, 6 figures (excluding references and appendices). To appear
  in Findings of EMNLP 2020",Findings of EMNLP 2020,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Citing opinions is a powerful yet understudied strategy in argumentation. For
example, an environmental activist might say, ""Leading scientists agree that
global warming is a serious concern,"" framing a clause which affirms their own
stance (""that global warming is serious"") as an opinion endorsed (""[scientists]
agree"") by a reputable source (""leading""). In contrast, a global warming denier
might frame the same clause as the opinion of an untrustworthy source with a
predicate connoting doubt: ""Mistaken scientists claim [...]."" Our work studies
opinion-framing in the global warming (GW) debate, an increasingly partisan
issue that has received little attention in NLP. We introduce DeSMOG, a dataset
of stance-labeled GW sentences, and train a BERT classifier to study novel
aspects of argumentation in how different sides of a debate represent their own
and each other's opinions. From 56K news articles, we find that similar
linguistic devices for self-affirming and opponent-doubting discourse are used
across GW-accepting and skeptic media, though GW-skeptical media shows more
opponent-doubt. We also find that authors often characterize sources as
hypocritical, by ascribing opinions expressing the author's own view to source
entities known to publicly endorse the opposing view. We release our stance
dataset, model, and lexicons of framing devices for future work on
opinion-framing and the automatic detection of GW stance.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 18:01:02 GMT'}]",2020-10-30,"[['Luo', 'Yiwei', ''], ['Card', 'Dallas', ''], ['Jurafsky', 'Dan', '']]"
1371630,2010.15300,Emaad Manzoor,"Emaad Manzoor, Nihar B. Shah",Uncovering Latent Biases in Text: Method and Application to Peer Review,,,,,cs.CL cs.CY cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Quantifying systematic disparities in numerical quantities such as employment
rates and wages between population subgroups provides compelling evidence for
the existence of societal biases. However, biases in the text written for
members of different subgroups (such as in recommendation letters for male and
non-male candidates), though widely reported anecdotally, remain challenging to
quantify. In this work, we introduce a novel framework to quantify bias in text
caused by the visibility of subgroup membership indicators. We develop a
nonparametric estimation and inference procedure to estimate this bias. We then
formalize an identification strategy to causally link the estimated bias to the
visibility of subgroup membership indicators, provided observations from time
periods both before and after an identity-hiding policy change. We identify an
application wherein ""ground truth"" bias can be inferred to evaluate our
framework, instead of relying on synthetic or secondary data. Specifically, we
apply our framework to quantify biases in the text of peer reviews from a
reputed machine learning conference before and after the conference adopted a
double-blind reviewing policy. We show evidence of biases in the review ratings
that serves as ""ground truth"", and show that our proposed framework accurately
detects these biases from the review text without having access to the review
ratings.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 01:24:19 GMT'}]",2020-10-30,"[['Manzoor', 'Emaad', ''], ['Shah', 'Nihar B.', '']]"
