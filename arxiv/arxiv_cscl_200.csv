,id,submitter,authors,title,comments,journal-ref,doi,report-no,categories,license,abstract,versions,update_date,authors_parsed
1369845,2010.13515,Andrea Asperti,Andrea Asperti and Stefano Dal Bianco,Syllabification of the Divine Comedy,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We provide a syllabification algorithm for the Divine Comedy using techniques
from probabilistic and constraint programming. We particularly focus on the
synalephe, addressed in terms of the ""propensity"" of a word to take part in a
synalephe with adjacent words. We jointly provide an online vocabulary
containing, for each word, information about its syllabification, the location
of the tonic accent, and the aforementioned synalephe propensity, on the left
and right sides. The algorithm is intrinsically nondeterministic, producing
different possible syllabifications for each verse, with different likelihoods;
metric constraints relative to accents on the 10th, 4th and 6th syllables are
used to further reduce the solution space. The most likely syllabification is
hence returned as output. We believe that this work could be a major milestone
for a lot of different investigations. From the point of view of digital
humanities it opens new perspectives on computer assisted analysis of digital
sources, comprising automated detection of anomalous and problematic cases,
metric clustering of verses and their categorization, or more foundational
investigations addressing e.g. the phonetic roles of consonants and vowels.
From the point of view of text processing and deep learning, information about
syllabification and the location of accents opens a wide range of exciting
perspectives, from the possibility of automatic learning syllabification of
words and verses, to the improvement of generative models, aware of metric
issues, and more respectful of the expected musicality.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 12:14:14 GMT'}]",2020-10-27,"[['Asperti', 'Andrea', ''], ['Bianco', 'Stefano Dal', '']]"
1369874,2010.13544,Zhenzhen Li,"Zhenzhen Li, Jian-Yun Nie, Benyou Wang, Pan Du, Yuhan Zhang, Lixin
  Zou, and Dongsheng Li","Meta-Learning for Neural Relation Classification with Distant
  Supervision","10 pages, 7 figures; corrected one encoding error in CIKM pdf","In Proceedings of CIKM, pp. 815-824. 2020",10.1145/3340531.3412039,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Distant supervision provides a means to create a large number of weakly
labeled data at low cost for relation classification. However, the resulting
labeled instances are very noisy, containing data with wrong labels. Many
approaches have been proposed to select a subset of reliable instances for
neural model training, but they still suffer from noisy labeling problem or
underutilization of the weakly-labeled data. To better select more reliable
training instances, we introduce a small amount of manually labeled data as
reference to guide the selection process. In this paper, we propose a
meta-learning based approach, which learns to reweight noisy training data
under the guidance of reference data. As the clean reference data is usually
very small, we propose to augment it by dynamically distilling the most
reliable elite instances from the noisy data. Experiments on several datasets
demonstrate that the reference data can effectively guide the selection of
training data, and our augmented approach consistently improves the performance
of relation classification comparing to the existing state-of-the-art methods.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 12:52:28 GMT'}]",2020-10-27,"[['Li', 'Zhenzhen', ''], ['Nie', 'Jian-Yun', ''], ['Wang', 'Benyou', ''], ['Du', 'Pan', ''], ['Zhang', 'Yuhan', ''], ['Zou', 'Lixin', ''], ['Li', 'Dongsheng', '']]"
1369886,2010.13556,Yu Zhang,"Yu Zhang, Xiusi Chen, Yu Meng, Jiawei Han","Hierarchical Metadata-Aware Document Categorization under Weak
  Supervision",9 pages; Accepted to WSDM 2021,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Categorizing documents into a given label hierarchy is intuitively appealing
due to the ubiquity of hierarchical topic structures in massive text corpora.
Although related studies have achieved satisfying performance in fully
supervised hierarchical document classification, they usually require massive
human-annotated training data and only utilize text information. However, in
many domains, (1) annotations are quite expensive where very few training
samples can be acquired; (2) documents are accompanied by metadata information.
Hence, this paper studies how to integrate the label hierarchy, metadata, and
text signals for document categorization under weak supervision. We develop
HiMeCat, an embedding-based generative framework for our task. Specifically, we
propose a novel joint representation learning module that allows simultaneous
modeling of category dependencies, metadata information and textual semantics,
and we introduce a data augmentation module that hierarchically synthesizes
training documents to complement the original, small-scale training set. Our
experiments demonstrate a consistent improvement of HiMeCat over competitive
baselines and validate the contribution of our representation learning and data
augmentation modules.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 13:07:56 GMT'}]",2020-10-27,"[['Zhang', 'Yu', ''], ['Chen', 'Xiusi', ''], ['Meng', 'Yu', ''], ['Han', 'Jiawei', '']]"
1369915,2010.13585,Reza Marzban,"Reza Marzban, Christopher John Crick",Interpreting convolutional networks trained on textual data,"9 pages, 6 figures, 5 tables",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  There have been many advances in the artificial intelligence field due to the
emergence of deep learning. In almost all sub-fields, artificial neural
networks have reached or exceeded human-level performance. However, most of the
models are not interpretable. As a result, it is hard to trust their decisions,
especially in life and death scenarios. In recent years, there has been a
movement toward creating explainable artificial intelligence, but most work to
date has concentrated on image processing models, as it is easier for humans to
perceive visual patterns. There has been little work in other fields like
natural language processing. In this paper, we train a convolutional model on
textual data and analyze the global logic of the model by studying its filter
values. In the end, we find the most important words in our corpus to our
models logic and remove the rest (95%). New models trained on just the 5% most
important words can achieve the same performance as the original model while
reducing training time by more than half. Approaches such as this will help us
to understand NLP models, explain their decisions according to their word
choices, and improve them by finding blind spots and biases.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 20:12:05 GMT'}]",2020-10-27,"[['Marzban', 'Reza', ''], ['Crick', 'Christopher John', '']]"
1369918,2010.13588,Ozan Caglayan,"Ozan Caglayan, Pranava Madhyastha, Lucia Specia","Curious Case of Language Generation Evaluation Metrics: A Cautionary
  Tale","7 pages, accepted to COLING 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automatic evaluation of language generation systems is a well-studied problem
in Natural Language Processing. While novel metrics are proposed every year, a
few popular metrics remain as the de facto metrics to evaluate tasks such as
image captioning and machine translation, despite their known limitations. This
is partly due to ease of use, and partly because researchers expect to see them
and know how to interpret them. In this paper, we urge the community for more
careful consideration of how they automatically evaluate their models by
demonstrating important failure cases on multiple datasets, language pairs and
tasks. Our experiments show that metrics (i) usually prefer system outputs to
human-authored texts, (ii) can be insensitive to correct translations of rare
words, (iii) can yield surprisingly high scores when given a single sentence as
system output for the entire test set.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 13:57:20 GMT'}]",2020-10-27,"[['Caglayan', 'Ozan', ''], ['Madhyastha', 'Pranava', ''], ['Specia', 'Lucia', '']]"
1305141,2006.10627,Qian Liu,"Qian Liu, Shengnan An, Jian-Guang Lou, Bei Chen, Zeqi Lin, Yan Gao,
  Bin Zhou, Nanning Zheng, Dongmei Zhang",Compositional Generalization by Learning Analytical Expressions,To appear in NeurIPS 2020 (Spotlight),,,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Compositional generalization is a basic and essential intellective capability
of human beings, which allows us to recombine known parts readily. However,
existing neural network based models have been proven to be extremely deficient
in such a capability. Inspired by work in cognition which argues
compositionality can be captured by variable slots with symbolic functions, we
present a refreshing view that connects a memory-augmented neural model with
analytical expressions, to achieve compositional generalization. Our model
consists of two cooperative neural modules, Composer and Solver, fitting well
with the cognitive argument while being able to be trained in an end-to-end
manner via a hierarchical reinforcement learning algorithm. Experiments on the
well-known benchmark SCAN demonstrate that our model seizes a great ability of
compositional generalization, solving all challenges addressed by previous
works with 100% accuracies.
","[{'version': 'v1', 'created': 'Thu, 18 Jun 2020 15:50:57 GMT'}, {'version': 'v2', 'created': 'Sat, 24 Oct 2020 03:47:49 GMT'}]",2020-10-27,"[['Liu', 'Qian', ''], ['An', 'Shengnan', ''], ['Lou', 'Jian-Guang', ''], ['Chen', 'Bei', ''], ['Lin', 'Zeqi', ''], ['Gao', 'Yan', ''], ['Zhou', 'Bin', ''], ['Zheng', 'Nanning', ''], ['Zhang', 'Dongmei', '']]"
1306638,2006.12124,Anne Wu,"Anne Wu, Changhan Wang, Juan Pino, Jiatao Gu",Self-Supervised Representations Improve End-to-End Speech Translation,Accepted to INTERSPEECH 2020,,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  End-to-end speech-to-text translation can provide a simpler and smaller
system but is facing the challenge of data scarcity. Pre-training methods can
leverage unlabeled data and have been shown to be effective on data-scarce
settings. In this work, we explore whether self-supervised pre-trained speech
representations can benefit the speech translation task in both high- and
low-resource settings, whether they can transfer well to other languages, and
whether they can be effectively combined with other common methods that help
improve low-resource end-to-end speech translation such as using a pre-trained
high-resource speech recognition system. We demonstrate that self-supervised
pre-trained features can consistently improve the translation performance, and
cross-lingual transfer allows to extend to a variety of languages without or
with little tuning.
","[{'version': 'v1', 'created': 'Mon, 22 Jun 2020 10:28:38 GMT'}, {'version': 'v2', 'created': 'Sun, 25 Oct 2020 03:31:15 GMT'}]",2020-10-27,"[['Wu', 'Anne', ''], ['Wang', 'Changhan', ''], ['Pino', 'Juan', ''], ['Gu', 'Jiatao', '']]"
1369967,2010.13637,Peng Gao,"Peng Gao, Fei Shao, Xiaoyuan Liu, Xusheng Xiao, Zheng Qin, Fengyuan
  Xu, Prateek Mittal, Sanjeev R. Kulkarni, Dawn Song",Enabling Efficient Cyber Threat Hunting With Cyber Threat Intelligence,,,,,cs.CR cs.CL cs.DB,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Log-based cyber threat hunting has emerged as an important solution to
counter sophisticated cyber attacks. However, existing approaches require
non-trivial efforts of manual query construction and have overlooked the rich
external knowledge about threat behaviors provided by open-source Cyber Threat
Intelligence (OSCTI). To bridge the gap, we propose EffHunter, a system that
facilitates cyber threat hunting in computer systems using OSCTI. Built upon
mature system auditing frameworks, EffHunter provides (1) an unsupervised,
light-weight, and accurate NLP pipeline that extracts structured threat
behaviors from unstructured OSCTI text, (2) a concise and expressive
domain-specific query language, TBQL, to hunt for malicious system activities,
(3) a query synthesis mechanism that automatically synthesizes a TBQL query for
threat hunting from the extracted threat behaviors, and (4) an efficient query
execution engine to search the big audit logging data. Evaluations on a broad
set of attack cases demonstrate the accuracy and efficiency of EffHunter in
enabling practical threat hunting.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 14:54:01 GMT'}]",2020-10-27,"[['Gao', 'Peng', ''], ['Shao', 'Fei', ''], ['Liu', 'Xiaoyuan', ''], ['Xiao', 'Xusheng', ''], ['Qin', 'Zheng', ''], ['Xu', 'Fengyuan', ''], ['Mittal', 'Prateek', ''], ['Kulkarni', 'Sanjeev R.', ''], ['Song', 'Dawn', '']]"
1369988,2010.13658,Baosong Yang,"Tianchi Bi and Liang Yao and Baosong Yang and Haibo Zhang and Weihua
  Luo and Boxing Chen","Constraint Translation Candidates: A Bridge between Neural Query
  Translation and Cross-lingual Information Retrieval",SIGIR eCom 2020,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Query translation (QT) is a key component in cross-lingual information
retrieval system (CLIR). With the help of deep learning, neural machine
translation (NMT) has shown promising results on various tasks. However, NMT is
generally trained with large-scale out-of-domain data rather than in-domain
query translation pairs. Besides, the translation model lacks a mechanism at
the inference time to guarantee the generated words to match the search index.
The two shortages of QT result in readable texts for human but inadequate
candidates for the downstream retrieval task. In this paper, we propose a novel
approach to alleviate these problems by limiting the open target vocabulary
search space of QT to a set of important words mined from search index
database. The constraint translation candidates are employed at both of
training and inference time, thus guiding the translation model to learn and
generate well performing target queries. The proposed methods are exploited and
examined in a real-word CLIR system--Aliexpress e-Commerce search engine.
Experimental results demonstrate that our approach yields better performance on
both translation quality and retrieval accuracy than the strong NMT baseline.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 15:27:51 GMT'}]",2020-10-27,"[['Bi', 'Tianchi', ''], ['Yao', 'Liang', ''], ['Yang', 'Baosong', ''], ['Zhang', 'Haibo', ''], ['Luo', 'Weihua', ''], ['Chen', 'Boxing', '']]"
1369989,2010.13659,Baosong Yang,"Liang Yao and Baosong Yang and Haibo Zhang and Weihua Luo and Boxing
  Chen","Exploiting Neural Query Translation into Cross Lingual Information
  Retrieval",SIGIR eCom 2020,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As a crucial role in cross-language information retrieval (CLIR), query
translation has three main challenges: 1) the adequacy of translation; 2) the
lack of in-domain parallel training data; and 3) the requisite of low latency.
To this end, existing CLIR systems mainly exploit statistical-based machine
translation (SMT) rather than the advanced neural machine translation (NMT),
limiting the further improvements on both translation and retrieval quality. In
this paper, we investigate how to exploit neural query translation model into
CLIR system. Specifically, we propose a novel data augmentation method that
extracts query translation pairs according to user clickthrough data, thus to
alleviate the problem of domain-adaptation in NMT. Then, we introduce an
asynchronous strategy which is able to leverage the advantages of the real-time
in SMT and the veracity in NMT. Experimental results reveal that the proposed
approach yields better retrieval quality than strong baselines and can be well
applied into a real-world CLIR system, i.e. Aliexpress e-Commerce search
engine. Readers can examine and test their cases on our website:
https://aliexpress.com .
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 15:28:19 GMT'}]",2020-10-27,"[['Yao', 'Liang', ''], ['Yang', 'Baosong', ''], ['Zhang', 'Haibo', ''], ['Luo', 'Weihua', ''], ['Chen', 'Boxing', '']]"
1370004,2010.13674,Christina Niklaus,"Thiemo Wambsganss, Christina Niklaus, Matthias S\""ollner, Siegfried
  Handschuh, Jan Marco Leimeister",A Corpus for Argumentative Writing Support in German,"to be published in The 28th International Conference on Computational
  Linguistics (COLING 2020)",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we present a novel annotation approach to capture claims and
premises of arguments and their relations in student-written persuasive peer
reviews on business models in German language. We propose an annotation scheme
based on annotation guidelines that allows to model claims and premises as well
as support and attack relations for capturing the structure of argumentative
discourse in student-written peer reviews. We conduct an annotation study with
three annotators on 50 persuasive essays to evaluate our annotation scheme. The
obtained inter-rater agreement of $\alpha=0.57$ for argument components and
$\alpha=0.49$ for argumentative relations indicates that the proposed
annotation scheme successfully guides annotators to moderate agreement.
Finally, we present our freely available corpus of 1,000 persuasive
student-written peer reviews on business models and our annotation guidelines
to encourage future research on the design and development of argumentative
writing support systems for students.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 15:52:12 GMT'}]",2020-10-27,"[['Wambsganss', 'Thiemo', ''], ['Niklaus', 'Christina', ''], ['Söllner', 'Matthias', ''], ['Handschuh', 'Siegfried', ''], ['Leimeister', 'Jan Marco', '']]"
1370018,2010.13688,Alexander Kalinowski,"Alexander Kalinowski, Yuan An","A Survey of Embedding Space Alignment Methods for Language and Knowledge
  Graphs","27 pages, 2 figures",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Neural embedding approaches have become a staple in the fields of computer
vision, natural language processing, and more recently, graph analytics. Given
the pervasive nature of these algorithms, the natural question becomes how to
exploit the embedding spaces to map, or align, embeddings of different data
sources. To this end, we survey the current research landscape on word,
sentence and knowledge graph embedding algorithms. We provide a classification
of the relevant alignment techniques and discuss benchmark datasets used in
this field of research. By gathering these diverse approaches into a singular
survey, we hope to further motivate research into alignment of embedding spaces
of varied data types and sources.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 16:08:13 GMT'}]",2020-10-27,"[['Kalinowski', 'Alexander', ''], ['An', 'Yuan', '']]"
1279583,2004.14813,Liying Cheng,"Liying Cheng, Dekun Wu, Lidong Bing, Yan Zhang, Zhanming Jie, Wei Lu,
  Luo Si",ENT-DESC: Entity Description Generation by Exploring Knowledge Graph,"11 pages, 6 figures, accepted by EMNLP 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Previous works on knowledge-to-text generation take as input a few RDF
triples or key-value pairs conveying the knowledge of some entities to generate
a natural language description. Existing datasets, such as WIKIBIO, WebNLG, and
E2E, basically have a good alignment between an input triple/pair set and its
output text. However, in practice, the input knowledge could be more than
enough, since the output description may only cover the most significant
knowledge. In this paper, we introduce a large-scale and challenging dataset to
facilitate the study of such a practical scenario in KG-to-text. Our dataset
involves retrieving abundant knowledge of various types of main entities from a
large knowledge graph (KG), which makes the current graph-to-sequence models
severely suffer from the problems of information loss and parameter explosion
while generating the descriptions. We address these challenges by proposing a
multi-graph structure that is able to represent the original graph information
more comprehensively. Furthermore, we also incorporate aggregation methods that
learn to extract the rich graph information. Extensive experiments demonstrate
the effectiveness of our model architecture.
","[{'version': 'v1', 'created': 'Thu, 30 Apr 2020 14:16:19 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 07:33:32 GMT'}]",2020-10-27,"[['Cheng', 'Liying', ''], ['Wu', 'Dekun', ''], ['Bing', 'Lidong', ''], ['Zhang', 'Yan', ''], ['Jie', 'Zhanming', ''], ['Lu', 'Wei', ''], ['Si', 'Luo', '']]"
1295328,2006.00814,Maha Elbayad,"Maha Elbayad, Michael Ustaszewski, Emmanuelle Esperan\c{c}a-Rodier,
  Francis Brunet Manquat, Laurent Besacier","Online Versus Offline NMT Quality: An In-depth Analysis on
  English-German and German-English",Accepted at COLING 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We conduct in this work an evaluation study comparing offline and online
neural machine translation architectures. Two sequence-to-sequence models:
convolutional Pervasive Attention (Elbayad et al. 2018) and attention-based
Transformer (Vaswani et al. 2017) are considered. We investigate, for both
architectures, the impact of online decoding constraints on the translation
quality through a carefully designed human evaluation on English-German and
German-English language pairs, the latter being particularly sensitive to
latency constraints. The evaluation results allow us to identify the strengths
and shortcomings of each model when we shift to the online setup.
","[{'version': 'v1', 'created': 'Mon, 1 Jun 2020 09:43:54 GMT'}, {'version': 'v2', 'created': 'Sat, 24 Oct 2020 13:36:00 GMT'}]",2020-10-27,"[['Elbayad', 'Maha', ''], ['Ustaszewski', 'Michael', ''], ['Esperança-Rodier', 'Emmanuelle', ''], ['Manquat', 'Francis Brunet', ''], ['Besacier', 'Laurent', '']]"
1369303,2010.12973,Andros Tjandra,"Andros Tjandra, Ruoming Pang, Yu Zhang, Shigeki Karita","Unsupervised Learning of Disentangled Speech Content and Style
  Representation",Submitted to ICASSP 2021,,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present an approach for unsupervised learning of speech representation
disentangling contents and styles. Our model consists of: (1) a local encoder
that captures per-frame information; (2) a global encoder that captures
per-utterance information; and (3) a conditional decoder that reconstructs
speech given local and global latent variables. Our experiments show that (1)
the local latent variables encode speech contents, as reconstructed speech can
be recognized by ASR with low word error rates (WER), even with a different
global encoding; (2) the global latent variables encode speaker style, as
reconstructed speech shares speaker identity with the source utterance of the
global encoding. Additionally, we demonstrate an useful application from our
pre-trained model, where we can train a speaker recognition model from the
global latent variables and achieve high accuracy by fine-tuning with as few
data as one label per speaker.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 20:16:03 GMT'}]",2020-10-27,"[['Tjandra', 'Andros', ''], ['Pang', 'Ruoming', ''], ['Zhang', 'Yu', ''], ['Karita', 'Shigeki', '']]"
1279693,2004.14923,Arturo Oncevay,"Arturo Oncevay, Barry Haddow, Alexandra Birch","Bridging Linguistic Typology and Multilingual Machine Translation with
  Multi-View Language Representations",Accepted at EMNLP 2020. Camera-ready version,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Sparse language vectors from linguistic typology databases and learned
embeddings from tasks like multilingual machine translation have been
investigated in isolation, without analysing how they could benefit from each
other's language characterisation. We propose to fuse both views using singular
vector canonical correlation analysis and study what kind of information is
induced from each source. By inferring typological features and language
phylogenies, we observe that our representations embed typology and strengthen
correlations with language relationships. We then take advantage of our
multi-view language vector space for multilingual machine translation, where we
achieve competitive overall translation accuracy in tasks that require
information about language similarities, such as language clustering and
ranking candidates for multilingual transfer. With our method, which is also
released as a tool, we can easily project and assess new languages without
expensive retraining of massive multilingual or ranking models, which are major
disadvantages of related approaches.
","[{'version': 'v1', 'created': 'Thu, 30 Apr 2020 16:25:39 GMT'}, {'version': 'v2', 'created': 'Sun, 25 Oct 2020 20:51:46 GMT'}]",2020-10-27,"[['Oncevay', 'Arturo', ''], ['Haddow', 'Barry', ''], ['Birch', 'Alexandra', '']]"
1286997,2005.07202,Shoya Wada,"Shoya Wada, Toshihiro Takeda, Shiro Manabe, Shozo Konishi, Jun
  Kamohara, and Yasushi Matsumura","A pre-training technique to localize medical BERT and to enhance
  biomedical BERT","We made the pre-trained weights of ouBioBERT and the source code for
  fine-tuning freely available at
  https://github.com/sy-wada/blue_benchmark_with_transformers",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Bidirectional Encoder Representations from Transformers (BERT) models for
medical specialties, such as BioBERT and clinicalBERT, have significantly
improved in performing biomedical text mining tasks and have enabled extracting
valuable information from biomedical literature; however, only English speakers
benefit due to the significant scarcity of high-quality medical documents, such
as PubMed, in each language. Therefore, we propose a method to train a
high-performance BERT model using a small corpus. We introduce the method to
train a BERT model on a small medical corpus both in English and in Japanese,
and we present the evaluation of each model in terms of the biomedical language
understanding evaluation (BLUE) benchmark and the medical document
classification task in Japanese, respectively. After confirming their
satisfactory performances, we applied our method to develop a model comparable
to the publicly available models. OuBioBERT, short for Bidirectional Encoder
Representations from Transformers for Biomedical Text Mining by Osaka
University, achieved the best score in terms of the BLUE benchmark. The total
score is 1.1 points above that of BioBERT and 0.3 points above that of the
ablated model trained without our proposed method. This proposed technique is
an effective approach to develop localized medical BERT models and to enhance
domain-specific models in the biomedical domain.
","[{'version': 'v1', 'created': 'Thu, 14 May 2020 18:00:01 GMT'}, {'version': 'v2', 'created': 'Sun, 25 Oct 2020 04:22:24 GMT'}]",2020-10-27,"[['Wada', 'Shoya', ''], ['Takeda', 'Toshihiro', ''], ['Manabe', 'Shiro', ''], ['Konishi', 'Shozo', ''], ['Kamohara', 'Jun', ''], ['Matsumura', 'Yasushi', '']]"
1369982,2010.13652,Thomas Winters,"Thomas Winters, Pieter Delobelle",Dutch Humor Detection by Generating Negative Examples,"Accepted at the Proceedings of the 32st Benelux Conference on
  Artificial Intelligence (BNAIC 2020) and the 29th Belgian Dutch Conference on
  Machine Learning (Benelearn 2020)",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Detecting if a text is humorous is a hard task to do computationally, as it
usually requires linguistic and common sense insights. In machine learning,
humor detection is usually modeled as a binary classification task, trained to
predict if the given text is a joke or another type of text. Rather than using
completely different non-humorous texts, we propose using text generation
algorithms for imitating the original joke dataset to increase the difficulty
for the learning algorithm. We constructed several different joke and non-joke
datasets to test the humor detection abilities of different language
technologies. In particular, we compare the humor detection capabilities of
classic neural network approaches with the state-of-the-art Dutch language
model RobBERT. In doing so, we create and compare the first Dutch humor
detection systems. We found that while other language models perform well when
the non-jokes came from completely different domains, RobBERT was the only one
that was able to distinguish jokes from generated negative examples. This
performance illustrates the usefulness of using text generation to create
negative datasets for humor recognition, and also shows that transformer models
are a large step forward in humor detection.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 15:15:10 GMT'}]",2020-10-27,"[['Winters', 'Thomas', ''], ['Delobelle', 'Pieter', '']]"
1369721,2010.13391,Amir Pouran Ben Veyseh,"Amir Pouran Ben Veyseh, Tuan Ngo Nguyen, Thien Huu Nguyen","Graph Transformer Networks with Syntactic and Semantic Structures for
  Event Argument Extraction",accepted at EMNLP 2020 findings,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The goal of Event Argument Extraction (EAE) is to find the role of each
entity mention for a given event trigger word. It has been shown in the
previous works that the syntactic structures of the sentences are helpful for
the deep learning models for EAE. However, a major problem in such prior works
is that they fail to exploit the semantic structures of the sentences to induce
effective representations for EAE. Consequently, in this work, we propose a
novel model for EAE that exploits both syntactic and semantic structures of the
sentences with the Graph Transformer Networks (GTNs) to learn more effective
sentence structures for EAE. In addition, we introduce a novel inductive bias
based on information bottleneck to improve generalization of the EAE models.
Extensive experiments are performed to demonstrate the benefits of the proposed
model, leading to state-of-the-art performance for EAE on standard datasets.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 07:41:40 GMT'}]",2020-10-27,"[['Veyseh', 'Amir Pouran Ben', ''], ['Nguyen', 'Tuan Ngo', ''], ['Nguyen', 'Thien Huu', '']]"
1369787,2010.13457,Henry Turner,"Henry Turner, Giulio Lovisotto and Ivan Martinovic","Speaker Anonymization with Distribution-Preserving X-Vector Generation
  for the VoicePrivacy Challenge 2020",,,,,cs.SD cs.CL cs.CR eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we present a Distribution-Preserving Voice Anonymization
technique, as our submission to the VoicePrivacy Challenge 2020. We notice that
the challenge baseline system generates fake X-vectors which are very similar
to each other, significantly more so than those extracted from organic
speakers. This difference arises from averaging many X-vectors from a pool of
speakers in the anonymization processs, causing a loss of information. We
propose a new method to generate fake X-vectors which overcomes these
limitations by preserving the distributional properties of X-vectors and their
intra-similarity. We use population data to learn the properties of the
X-vector space, before fitting a generative model which we use to sample fake
X-vectors. We show how this approach generates X-vectors that more closely
follow the expected intra-similarity distribution of organic speaker X-vectors.
Our method can be easily integrated with others as the anonymization component
of the system and removes the need to distribute a pool of speakers to use
during the anonymization. Our approach leads to an increase in EER of up to
16.8\% in males and 8.4\% in females in scenarios where enrollment and trial
utterances are anonymized versus the baseline solution, demonstrating the
diversity of our generated voices.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 09:53:56 GMT'}]",2020-10-27,"[['Turner', 'Henry', ''], ['Lovisotto', 'Giulio', ''], ['Martinovic', 'Ivan', '']]"
1369712,2010.13382,Young Jin Kim,Young Jin Kim and Hany Hassan Awadalla,"FastFormers: Highly Efficient Transformer Models for Natural Language
  Understanding",Accepted to SustaiNLP 2020 at EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Transformer-based models are the state-of-the-art for Natural Language
Understanding (NLU) applications. Models are getting bigger and better on
various tasks. However, Transformer models remain computationally challenging
since they are not efficient at inference-time compared to traditional
approaches. In this paper, we present FastFormers, a set of recipes to achieve
efficient inference-time performance for Transformer-based models on various
NLU tasks. We show how carefully utilizing knowledge distillation, structured
pruning and numerical optimization can lead to drastic improvements on
inference efficiency. We provide effective recipes that can guide practitioners
to choose the best settings for various NLU tasks and pretrained models.
Applying the proposed recipes to the SuperGLUE benchmark, we achieve from 9.8x
up to 233.9x speed-up compared to out-of-the-box models on CPU. On GPU, we also
achieve up to 12.4x speed-up with the presented methods. We show that
FastFormers can drastically reduce cost of serving 100 million requests from
4,223 USD to just 18 USD on an Azure F16s_v2 instance. This translates to a
sustainable runtime by reducing energy consumption 6.9x - 125.8x according to
the metrics used in the SustaiNLP 2020 shared task.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 07:25:15 GMT'}]",2020-10-27,"[['Kim', 'Young Jin', ''], ['Awadalla', 'Hany Hassan', '']]"
1369339,2010.13009,Jianguo Zhang,"Jian-Guo Zhang, Kazuma Hashimoto, Wenhao Liu, Chien-Sheng Wu, Yao Wan,
  Philip S. Yu, Richard Socher, Caiming Xiong","Discriminative Nearest Neighbor Few-Shot Intent Detection by
  Transferring Natural Language Inference","19 pages, accepted by EMNLP 2020 main conference as a long paper.
  Code will be available at https://github.com/salesforce/DNNC-few-shot-intent",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Intent detection is one of the core components of goal-oriented dialog
systems, and detecting out-of-scope (OOS) intents is also a practically
important skill. Few-shot learning is attracting much attention to mitigate
data scarcity, but OOS detection becomes even more challenging. In this paper,
we present a simple yet effective approach, discriminative nearest neighbor
classification with deep self-attention. Unlike softmax classifiers, we
leverage BERT-style pairwise encoding to train a binary classifier that
estimates the best matched training example for a user input. We propose to
boost the discriminative ability by transferring a natural language inference
(NLI) model. Our extensive experiments on a large-scale multi-domain intent
detection task show that our method achieves more stable and accurate in-domain
and OOS detection accuracy than RoBERTa-based classifiers and embedding-based
nearest neighbor approaches. More notably, the NLI transfer enables our 10-shot
model to perform competitively with 50-shot or even full-shot classifiers,
while we can keep the inference time constant by leveraging a faster embedding
retrieval model.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 00:39:32 GMT'}]",2020-10-27,"[['Zhang', 'Jian-Guo', ''], ['Hashimoto', 'Kazuma', ''], ['Liu', 'Wenhao', ''], ['Wu', 'Chien-Sheng', ''], ['Wan', 'Yao', ''], ['Yu', 'Philip S.', ''], ['Socher', 'Richard', ''], ['Xiong', 'Caiming', '']]"
1369358,2010.13028,Sayyed Zahiri,Sayyed M. Zahiri and Ali Ahmadvand,"CRAB: Class Representation Attentive BERT for Hate Speech Identification
  in Social Media",,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In recent years, social media platforms have hosted an explosion of hate
speech and objectionable content. The urgent need for effective automatic hate
speech detection models have drawn remarkable investment from companies and
researchers. Social media posts are generally short and their semantics could
drastically be altered by even a single token. Thus, it is crucial for this
task to learn context-aware input representations, and consider relevancy
scores between input embeddings and class representations as an additional
signal. To accommodate these needs, this paper introduces CRAB (Class
Representation Attentive BERT), a neural model for detecting hate speech in
social media. The model benefits from two semantic representations: (i)
trainable token-wise and sentence-wise class representations, and (ii)
contextualized input embeddings from state-of-the-art BERT encoder. To
investigate effectiveness of CRAB, we train our model on Twitter data and
compare it against strong baselines. Our results show that CRAB achieves 1.89%
relative improved Macro-averaged F1 over state-of-the-art baseline. The results
of this research open an opportunity for the future research on automated
abusive behavior detection in social media
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 04:11:30 GMT'}]",2020-10-27,"[['Zahiri', 'Sayyed M.', ''], ['Ahmadvand', 'Ali', '']]"
1328086,2008.00364,Qian Li,"Qian Li, Hao Peng, Jianxin Li, Congying Xia, Renyu Yang, Lichao Sun,
  Philip S. Yu, Lifang He",A Survey on Text Classification: From Shallow to Deep Learning,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Text classification is the most fundamental and essential task in natural
language processing. The last decade has seen a surge of research in this area
due to the unprecedented success of deep learning. Numerous methods, datasets,
and evaluation metrics have been proposed in the literature, raising the need
for a comprehensive and updated survey. This paper fills the gap by reviewing
the state of the art approaches from 1961 to 2020, focusing on models from
shallow to deep learning. We create a taxonomy for text classification
according to the text involved and the models used for feature extraction and
classification. We then discuss each of these categories in detail, dealing
with both the technical developments and benchmark datasets that support tests
of predictions. A comprehensive comparison between different techniques, as
well as identifying the pros and cons of various evaluation metrics are also
provided in this survey. Finally, we conclude by summarizing key implications,
future research directions, and the challenges facing the research area.
","[{'version': 'v1', 'created': 'Sun, 2 Aug 2020 00:09:03 GMT'}, {'version': 'v2', 'created': 'Tue, 4 Aug 2020 06:13:59 GMT'}, {'version': 'v3', 'created': 'Sun, 11 Oct 2020 04:15:57 GMT'}, {'version': 'v4', 'created': 'Tue, 13 Oct 2020 07:05:36 GMT'}, {'version': 'v5', 'created': 'Mon, 26 Oct 2020 02:46:42 GMT'}]",2020-10-27,"[['Li', 'Qian', ''], ['Peng', 'Hao', ''], ['Li', 'Jianxin', ''], ['Xia', 'Congying', ''], ['Yang', 'Renyu', ''], ['Sun', 'Lichao', ''], ['Yu', 'Philip S.', ''], ['He', 'Lifang', '']]"
1369361,2010.13031,Jian Du,"Xiaoying Li, Suyuan Peng, Jian Du","Towards Medical Knowmetrics: Representing and Computing Medical
  Knowledge using Semantic Predications as the Knowledge Unit and the
  Uncertainty as the Knowledge Context",,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  In China, Prof. Hongzhou Zhao and Zeyuan Liu are the pioneers of the concept
""knowledge unit"" and ""knowmetrics"" for measuring knowledge. However, the
definition of ""computable knowledge object"" remains controversial so far in
different fields. For example, it is defined as 1) quantitative scientific
concept in natural science and engineering, 2) knowledge point in the field of
education research, and 3) semantic predications, i.e.,
Subject-Predicate-Object (SPO) triples in biomedical fields. The Semantic
MEDLINE Database (SemMedDB), a high-quality public repository of SPO triples
extracted from medical literature, provides a basic data infrastructure for
measuring medical knowledge. In general, the study of extracting SPO triples as
computable knowledge unit from unstructured scientific text has been
overwhelmingly focusing on scientific knowledge per se. Since the SPO triples
would be possibly extracted from hypothetical, speculative statements or even
conflicting and contradictory assertions, the knowledge status (i.e., the
uncertainty), which serves as an integral and critical part of scientific
knowledge has been largely overlooked. This article aims to put forward a
framework for Medical Knowmetrics using the SPO triples as the knowledge unit
and the uncertainty as the knowledge context. The lung cancer publications
dataset is used to validate the proposed framework. The uncertainty of medical
knowledge and how its status evolves over time indirectly reflect the strength
of competing knowledge claims, and the probability of certainty for a given SPO
triple. We try to discuss the new insights using the uncertainty-centric
approaches to detect research fronts, and identify knowledge claims with high
certainty level, in order to improve the efficacy of knowledge-driven decision
support.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 04:27:43 GMT'}]",2020-10-27,"[['Li', 'Xiaoying', ''], ['Peng', 'Suyuan', ''], ['Du', 'Jian', '']]"
1369370,2010.13040,Zhaoning Li,Zhaoning Li and Jiangtao Ren,Fine-tuning ERNIE for chest abnormal imaging signs extraction,"30 pages, 5 figures, 8 tables",J. Biomed. Inform. 108 (2020),10.1016/j.jbi.2020.103492,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Chest imaging reports describe the results of chest radiography procedures.
Automatic extraction of abnormal imaging signs from chest imaging reports has a
pivotal role in clinical research and a wide range of downstream medical tasks.
However, there are few studies on information extraction from Chinese chest
imaging reports. In this paper, we formulate chest abnormal imaging sign
extraction as a sequence tagging and matching problem. On this basis, we
propose a transferred abnormal imaging signs extractor with pretrained ERNIE as
the backbone, named EASON (fine-tuning ERNIE with CRF for Abnormal Signs
ExtractiON), which can address the problem of data insufficiency. In addition,
to assign the attributes (the body part and degree) to corresponding abnormal
imaging signs from the results of the sequence tagging model, we design a
simple but effective tag2relation algorithm based on the nature of chest
imaging report text. We evaluate our method on the corpus provided by a medical
big data company, and the experimental results demonstrate that our method
achieves significant and consistent improvement compared to other baselines.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 05:18:14 GMT'}]",2020-10-27,"[['Li', 'Zhaoning', ''], ['Ren', 'Jiangtao', '']]"
1369377,2010.13047,Hirofumi Inaguma,"Hirofumi Inaguma, Yosuke Higuchi, Kevin Duh, Tatsuya Kawahara, Shinji
  Watanabe","Orthros: Non-autoregressive End-to-end Speech Translation with
  Dual-decoder",,,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Fast inference speed is an important goal towards real-world deployment of
speech translation (ST) systems. End-to-end (E2E) models based on the
encoder-decoder architecture are more suitable for this goal than traditional
cascaded systems, but their effectiveness regarding decoding speed has not been
explored so far. Inspired by recent progress in non-autoregressive (NAR)
methods in text-based translation, which generates target tokens in parallel by
eliminating conditional dependencies, we study the problem of NAR decoding for
E2E-ST. We propose a novel NAR E2E-ST framework, Orthoros, in which both NAR
and autoregressive (AR) decoders are jointly trained on the shared speech
encoder. The latter is used for selecting better translation among various
length candidates generated from the former, which dramatically improves the
effectiveness of a large length beam with negligible overhead. We further
investigate effective length prediction methods from speech inputs and the
impact of vocabulary sizes. Experiments on four benchmarks show the
effectiveness of the proposed method in improving inference speed while
maintaining competitive translation quality compared to state-of-the-art AR
E2E-ST systems.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 06:35:30 GMT'}]",2020-10-27,"[['Inaguma', 'Hirofumi', ''], ['Higuchi', 'Yosuke', ''], ['Duh', 'Kevin', ''], ['Kawahara', 'Tatsuya', ''], ['Watanabe', 'Shinji', '']]"
1369719,2010.13389,Amir Pouran Ben Veyseh,"Amir Pouran Ben Veyseh, Nasim Nour, Franck Dernoncourt, Quan Hung
  Tran, Dejing Dou, Thien Huu Nguyen","Improving Aspect-based Sentiment Analysis with Gated Graph Convolutional
  Networks and Syntax-based Regulation",accepted at EMNLP 2020 findings,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Aspect-based Sentiment Analysis (ABSA) seeks to predict the sentiment
polarity of a sentence toward a specific aspect. Recently, it has been shown
that dependency trees can be integrated into deep learning models to produce
the state-of-the-art performance for ABSA. However, these models tend to
compute the hidden/representation vectors without considering the aspect terms
and fail to benefit from the overall contextual importance scores of the words
that can be obtained from the dependency tree for ABSA. In this work, we
propose a novel graph-based deep learning model to overcome these two issues of
the prior work on ABSA. In our model, gate vectors are generated from the
representation vectors of the aspect terms to customize the hidden vectors of
the graph-based models toward the aspect terms. In addition, we propose a
mechanism to obtain the importance scores for each word in the sentences based
on the dependency trees that are then injected into the model to improve the
representation vectors for ABSA. The proposed model achieves the
state-of-the-art performance on three benchmark datasets.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 07:36:24 GMT'}]",2020-10-27,"[['Veyseh', 'Amir Pouran Ben', ''], ['Nour', 'Nasim', ''], ['Dernoncourt', 'Franck', ''], ['Tran', 'Quan Hung', ''], ['Dou', 'Dejing', ''], ['Nguyen', 'Thien Huu', '']]"
1369387,2010.13057,Sathvik Nair,"Sathvik Nair, Mahesh Srinivasan, Stephan Meylan","Contextualized Word Embeddings Encode Aspects of Human-Like Word Sense
  Knowledge","To appear in proceedings of the Cognitive Aspects of the Lexicon
  Workshop at the 28th International Conference on Computational Linguistics
  (COLING)",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Understanding context-dependent variation in word meanings is a key aspect of
human language comprehension supported by the lexicon. Lexicographic resources
(e.g., WordNet) capture only some of this context-dependent variation; for
example, they often do not encode how closely senses, or discretized word
meanings, are related to one another. Our work investigates whether recent
advances in NLP, specifically contextualized word embeddings, capture
human-like distinctions between English word senses, such as polysemy and
homonymy. We collect data from a behavioral, web-based experiment, in which
participants provide judgments of the relatedness of multiple WordNet senses of
a word in a two-dimensional spatial arrangement task. We find that
participants' judgments of the relatedness between senses are correlated with
distances between senses in the BERT embedding space. Homonymous senses (e.g.,
bat as mammal vs. bat as sports equipment) are reliably more distant from one
another in the embedding space than polysemous ones (e.g., chicken as animal
vs. chicken as meat). Our findings point towards the potential utility of
continuous-space representations of sense meanings.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 07:56:52 GMT'}]",2020-10-27,"[['Nair', 'Sathvik', ''], ['Srinivasan', 'Mahesh', ''], ['Meylan', 'Stephan', '']]"
1369392,2010.13062,Zhixiang Li,"Mengzhe Li, Yudan Wang, Ying Zhao and Zhixiang Li","Transgender Community Sentiment Analysis from Social Media Data: A
  Natural Language Processing Approach","5 pages, 1 figures",,,,cs.CL,http://creativecommons.org/publicdomain/zero/1.0/,"  Transgender community is experiencing a huge disparity in mental health
conditions compared with the general population. Interpreting the social medial
data posted by transgender people may help us understand the sentiments of
these sexual minority groups better and apply early interventions. In this
study, we manually categorize 300 social media comments posted by transgender
people to the sentiment of negative, positive, and neutral. 5 machine learning
algorithms and 2 deep neural networks are adopted to build sentiment analysis
classifiers based on the annotated data. Results show that our annotations are
reliable with a high Cohen's Kappa score over 0.8 across all three classes.
LSTM model yields an optimal performance of accuracy over 0.85 and AUC of
0.876. Our next step will focus on using advanced natural language processing
algorithms on a larger annotated dataset.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 08:13:34 GMT'}]",2020-10-27,"[['Li', 'Mengzhe', ''], ['Wang', 'Yudan', ''], ['Zhao', 'Ying', ''], ['Li', 'Zhixiang', '']]"
1369379,2010.13049,Gongqi Lin,"Gongqi Lin, Yuan Miao, Xiaoyong Yang, Wenwu Ou, Lizhen Cui, Wei Guo,
  Chunyan Miao",Commonsense knowledge adversarial dataset that challenges ELECTRA,To appear in ICARCV2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Commonsense knowledge is critical in human reading comprehension. While
machine comprehension has made significant progress in recent years, the
ability in handling commonsense knowledge remains limited. Synonyms are one of
the most widely used commonsense knowledge. Constructing adversarial dataset is
an important approach to find weak points of machine comprehension models and
support the design of solutions. To investigate machine comprehension models'
ability in handling the commonsense knowledge, we created a Question and Answer
Dataset with common knowledge of Synonyms (QADS). QADS are questions generated
based on SQuAD 2.0 by applying commonsense knowledge of synonyms. The synonyms
are extracted from WordNet. Words often have multiple meanings and synonyms. We
used an enhanced Lesk algorithm to perform word sense disambiguation to
identify synonyms for the context. ELECTRA achieves the state-of-art result on
the SQuAD 2.0 dataset in 2019. With scale, ELECTRA can achieve similar
performance as BERT does. However, QADS shows that ELECTRA has little ability
to handle commonsense knowledge of synonyms. In our experiment, ELECTRA-small
can achieve 70% accuracy on SQuAD 2.0, but only 20% on QADS. ELECTRA-large did
not perform much better. Its accuracy on SQuAD 2.0 is 88% but dropped
significantly to 26% on QADS. In our earlier experiments, BERT, although also
failed badly on QADS, was not as bad as ELECTRA. The result shows that even
top-performing NLP models have little ability to handle commonsense knowledge
which is essential in reading comprehension.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 07:17:45 GMT'}]",2020-10-27,"[['Lin', 'Gongqi', ''], ['Miao', 'Yuan', ''], ['Yang', 'Xiaoyong', ''], ['Ou', 'Wenwu', ''], ['Cui', 'Lizhen', ''], ['Guo', 'Wei', ''], ['Miao', 'Chunyan', '']]"
1369600,2010.13270,Yosuke Higuchi,"Yosuke Higuchi, Hirofumi Inaguma, Shinji Watanabe, Tetsuji Ogawa,
  Tetsunori Kobayashi",Improved Mask-CTC for Non-Autoregressive End-to-End ASR,Submitted to ICASSP2021,,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  For real-world deployment of automatic speech recognition (ASR), the system
is desired to be capable of fast inference while relieving the requirement of
computational resources. The recently proposed end-to-end ASR system based on
mask-predict with connectionist temporal classification (CTC), Mask-CTC,
fulfills this demand by generating tokens in a non-autoregressive fashion.
While Mask-CTC achieves remarkably fast inference speed, its recognition
performance falls behind that of conventional autoregressive (AR) systems. To
boost the performance of Mask-CTC, we first propose to enhance the encoder
network architecture by employing a recently proposed architecture called
Conformer. Next, we propose new training and decoding methods by introducing
auxiliary objective to predict the length of a partial target sequence, which
allows the model to delete or insert tokens during inference. Experimental
results on different ASR tasks show that the proposed approaches improve
Mask-CTC significantly, outperforming a standard CTC model (15.5% $\rightarrow$
9.1% WER on WSJ). Moreover, Mask-CTC now achieves competitive results to AR
models with no degradation of inference speed ($<$ 0.1 RTF using CPU). We also
show a potential application of Mask-CTC to end-to-end speech translation.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 01:22:35 GMT'}]",2020-10-27,"[['Higuchi', 'Yosuke', ''], ['Inaguma', 'Hirofumi', ''], ['Watanabe', 'Shinji', ''], ['Ogawa', 'Tetsuji', ''], ['Kobayashi', 'Tetsunori', '']]"
1321824,2007.10310,Changhan Wang,"Changhan Wang, Anne Wu, Juan Pino",CoVoST 2 and Massively Multilingual Speech-to-Text Translation,,,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Speech translation has recently become an increasingly popular topic of
research, partly due to the development of benchmark datasets. Nevertheless,
current datasets cover a limited number of languages. With the aim to foster
research in massive multilingual speech translation and speech translation for
low resource language pairs, we release CoVoST 2, a large-scale multilingual
speech translation corpus covering translations from 21 languages into English
and from English into 15 languages. This represents the largest open dataset
available to date from total volume and language coverage perspective. Data
sanity checks provide evidence about the quality of the data, which is released
under CC0 license. We also provide extensive speech recognition, bilingual and
multilingual machine translation and speech translation baselines with
open-source implementation.
","[{'version': 'v1', 'created': 'Mon, 20 Jul 2020 17:53:35 GMT'}, {'version': 'v2', 'created': 'Thu, 20 Aug 2020 17:53:10 GMT'}, {'version': 'v3', 'created': 'Sat, 24 Oct 2020 06:07:01 GMT'}]",2020-10-27,"[['Wang', 'Changhan', ''], ['Wu', 'Anne', ''], ['Pino', 'Juan', '']]"
1369708,2010.13378,Amir Pouran Ben Veyseh,"Amir Pouran Ben Veyseh, Nasim Nouri, Franck Dernoncourt, Dejing Dou,
  Thien Huu Nguyen","Introducing Syntactic Structures into Target Opinion Word Extraction
  with Deep Learning",accepted at EMNLP 2020 main conference,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Targeted opinion word extraction (TOWE) is a sub-task of aspect based
sentiment analysis (ABSA) which aims to find the opinion words for a given
aspect-term in a sentence. Despite their success for TOWE, the current deep
learning models fail to exploit the syntactic information of the sentences that
have been proved to be useful for TOWE in the prior research. In this work, we
propose to incorporate the syntactic structures of the sentences into the deep
learning models for TOWE, leveraging the syntax-based opinion possibility
scores and the syntactic connections between the words. We also introduce a
novel regularization technique to improve the performance of the deep learning
models based on the representation distinctions between the words in TOWE. The
proposed model is extensively analyzed and achieves the state-of-the-art
performance on four benchmark datasets.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 07:13:17 GMT'}]",2020-10-27,"[['Veyseh', 'Amir Pouran Ben', ''], ['Nouri', 'Nasim', ''], ['Dernoncourt', 'Franck', ''], ['Dou', 'Dejing', ''], ['Nguyen', 'Thien Huu', '']]"
1274534,2004.09764,Fang Xianghong,"Xianghong Fang and Haoli Bai and Zenglin Xu and Michael Lyu and Irwin
  King",Discrete Auto-regressive Variational Attention Models for Text Modeling,"10 pages, 4 figures",,,,cs.LG cs.CL stat.ML,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Variational autoencoders (VAEs) have been widely applied for text modeling.
In practice, however, they are troubled by two challenges: information
underrepresentation and posterior collapse. The former arises as only the last
hidden state of LSTM encoder is transformed into the latent space, which is
generally insufficient to summarize the data. The latter is a long-standing
problem during the training of VAEs as the optimization is trapped to a
disastrous local optimum. In this paper, we propose Discrete Auto-regressive
Variational Attention Model (DAVAM) to address the challenges. Specifically, we
introduce an auto-regressive variational attention approach to enrich the
latent space by effectively capturing the semantic dependency from the input.
We further design discrete latent space for the variational attention and
mathematically show that our model is free from posterior collapse. Extensive
experiments on language modeling tasks demonstrate the superiority of DAVAM
against several VAE counterparts.
","[{'version': 'v1', 'created': 'Tue, 21 Apr 2020 05:49:04 GMT'}, {'version': 'v2', 'created': 'Sun, 25 Oct 2020 08:02:24 GMT'}]",2020-10-27,"[['Fang', 'Xianghong', ''], ['Bai', 'Haoli', ''], ['Xu', 'Zenglin', ''], ['Lyu', 'Michael', ''], ['King', 'Irwin', '']]"
1326856,2007.15342,Ramon Ferrer i Cancho,"Ramon Ferrer-i-Cancho, Carlos G\'omez-Rodr\'iguez, Juan Luis Esteban
  and Llu\'is Alemany-Puig",The optimality of syntactic dependency distances,"results on the zeta score have been corrected; format of the article
  has changed; some figures/tables have been resized; typos corrected",,,,cs.CL cs.DM physics.soc-ph,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  It is often stated that human languages, as other biological systems, are
shaped by cost-cutting pressures but, to what extent? Attempts to quantify the
degree of optimality of languages by means of an optimality score have been
scarce and focused mostly on English. Here we recast the problem of the
optimality of the word order of a sentence as an optimization problem on a
spatial network where the vertices are words, arcs indicate syntactic
dependencies and the space is defined by the linear order of the words in the
sentence. We introduce a new score to quantify the cognitive pressure to reduce
the distance between linked words in a sentence. The analysis of sentences from
93 languages representing 19 linguistic families reveals that half of languages
are optimized to a 70% or more. The score indicates that distances are not
significantly reduced in a few languages and confirms two theoretical
predictions, i.e. that longer sentences are more optimized and that distances
are more likely to be longer than expected by chance in short sentences. We
present a new hierarchical ranking of languages by their degree of
optimization. The statistical advantages of the new score call for a
reevaluation of the evolution of dependency distance over time in languages as
well as the relationship between dependency distance and linguistic competence.
Finally, the principles behind the design of the score can be extended to
develop more powerful normalizations of topological distances or physical
distances in more dimensions.
","[{'version': 'v1', 'created': 'Thu, 30 Jul 2020 09:40:41 GMT'}, {'version': 'v2', 'created': 'Sun, 25 Oct 2020 22:15:22 GMT'}]",2020-10-27,"[['Ferrer-i-Cancho', 'Ramon', ''], ['Gómez-Rodríguez', 'Carlos', ''], ['Esteban', 'Juan Luis', ''], ['Alemany-Puig', 'Lluís', '']]"
1369522,2010.13192,Alexandra Chronopoulou,"Alexandra Chronopoulou, Dario Stojanovski, Viktor Hangya, Alexander
  Fraser","The LMU Munich System for the WMT 2020 Unsupervised Machine Translation
  Shared Task",WMT Unsupervised Shared Task 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper describes the submission of LMU Munich to the WMT 2020
unsupervised shared task, in two language directions, German<->Upper Sorbian.
Our core unsupervised neural machine translation (UNMT) system follows the
strategy of Chronopoulou et al. (2020), using a monolingual pretrained language
generation model (on German) and fine-tuning it on both German and Upper
Sorbian, before initializing a UNMT model, which is trained with online
backtranslation. Pseudo-parallel data obtained from an unsupervised statistical
machine translation (USMT) system is used to fine-tune the UNMT model. We also
apply BPE-Dropout to the low resource (Upper Sorbian) data to obtain a more
robust system. We additionally experiment with residual adapters and find them
useful in the Upper Sorbian->German direction. We explore sampling during
backtranslation and curriculum learning to use SMT translations in a more
principled way. Finally, we ensemble our best-performing systems and reach a
BLEU score of 32.4 on German->Upper Sorbian and 35.2 on Upper Sorbian->German.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 19:04:03 GMT'}]",2020-10-27,"[['Chronopoulou', 'Alexandra', ''], ['Stojanovski', 'Dario', ''], ['Hangya', 'Viktor', ''], ['Fraser', 'Alexander', '']]"
1280356,2005.00561,Anna Rogers,"Sai Prasanna, Anna Rogers, Anna Rumshisky","When BERT Plays the Lottery, All Tickets Are Winning",EMNLP 2020 camera-ready,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Transformer-based models were shown to be reducible to a smaller number
of self-attention heads and layers. We consider this phenomenon from the
perspective of the lottery ticket hypothesis, using both structured and
magnitude pruning. For fine-tuned BERT, we show that (a) it is possible to find
subnetworks achieving performance that is comparable with that of the full
model, and (b) similarly-sized subnetworks sampled from the rest of the model
perform worse. Strikingly, with structured pruning even the worst possible
subnetworks remain highly trainable, indicating that most pre-trained BERT
weights are potentially useful. We also study the ""good"" subnetworks to see if
their success can be attributed to superior linguistic knowledge, but find them
unstable, and not explained by meaningful self-attention patterns.
","[{'version': 'v1', 'created': 'Fri, 1 May 2020 18:24:42 GMT'}, {'version': 'v2', 'created': 'Sat, 24 Oct 2020 10:15:27 GMT'}]",2020-10-27,"[['Prasanna', 'Sai', ''], ['Rogers', 'Anna', ''], ['Rumshisky', 'Anna', '']]"
1369498,2010.13168,Tenzin Singhay Bhotia,"Vaibhav Kumar, Tenzin Singhay Bhotia, Vaibhav Kumar","Fair Embedding Engine: A Library for Analyzing and Mitigating Gender
  Bias in Word Embeddings","6 pages, 3 figures",,,,cs.CL cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Non-contextual word embedding models have been shown to inherit human-like
stereotypical biases of gender, race and religion from the training corpora. To
counter this issue, a large body of research has emerged which aims to mitigate
these biases while keeping the syntactic and semantic utility of embeddings
intact. This paper describes Fair Embedding Engine (FEE), a library for
analysing and mitigating gender bias in word embeddings. FEE combines various
state of the art techniques for quantifying, visualising and mitigating gender
bias in word embeddings under a standard abstraction. FEE will aid
practitioners in fast track analysis of existing debiasing methods on their
embedding models. Further, it will allow rapid prototyping of new methods by
evaluating their performance on a suite of standard metrics.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 17:31:12 GMT'}]",2020-10-27,"[['Kumar', 'Vaibhav', ''], ['Bhotia', 'Tenzin Singhay', ''], ['Kumar', 'Vaibhav', '']]"
1369458,2010.13128,Mokanarangan Thayaparan,"Mokanarangan Thayaparan, Marco Valentino, Andr\'e Freitas","ExplanationLP: Abductive Reasoning for Explainable Science Question
  Answering",,,,,cs.AI cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a novel approach for answering and explaining multiple-choice
science questions by reasoning on grounding and abstract inference chains. This
paper frames question answering as an abductive reasoning problem, constructing
plausible explanations for each choice and then selecting the candidate with
the best explanation as the final answer. Our system, ExplanationLP, elicits
explanations by constructing a weighted graph of relevant facts for each
candidate answer and extracting the facts that satisfy certain structural and
semantic constraints. To extract the explanations, we employ a linear
programming formalism designed to select the optimal subgraph. The graphs'
weighting function is composed of a set of parameters, which we fine-tune to
optimize answer selection performance. We carry out our experiments on the
WorldTree and ARC-Challenge corpus to empirically demonstrate the following
conclusions: (1) Grounding-Abstract inference chains provides the semantic
control to perform explainable abductive reasoning (2) Efficiency and
robustness in learning with a fewer number of parameters by outperforming
contemporary explainable and transformer-based approaches in a similar setting
(3) Generalisability by outperforming SOTA explainable approaches on general
science question sets.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 14:49:24 GMT'}]",2020-10-27,"[['Thayaparan', 'Mokanarangan', ''], ['Valentino', 'Marco', ''], ['Freitas', 'André', '']]"
1369435,2010.13105,Gyuwan Kim,"Seongbin Kim, Gyuwan Kim, Seongjin Shin, Sangmin Lee","Two-stage Textual Knowledge Distillation to Speech Encoder for Spoken
  Language Understanding","Preprint; 5 pages, 1 figure",,,,cs.CL cs.LG cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  End-to-end approaches open a new way for more accurate and efficient spoken
language understanding (SLU) systems by alleviating the drawbacks of
traditional pipeline systems. Previous works exploit textual information for an
SLU model via pre-training with automatic speech recognition or fine-tuning
with knowledge distillation. To utilize textual information more effectively,
this work proposes a two-stage textual knowledge distillation method that
matches utterance-level representations and predicted logits of two modalities
during pre-training and fine-tuning, sequentially. We use vq-wav2vec BERT as a
speech encoder because it captures general and rich features. Furthermore, we
improve the performance, especially in a low-resource scenario, with data
augmentation methods by randomly masking spans of discrete audio tokens and
contextualized hidden representations. Consequently, we push the
state-of-the-art on the Fluent Speech Commands, achieving 99.7% test accuracy
in the full dataset setting and 99.5% in the 10% subset setting. Throughout the
ablation studies, we empirically verify that all used methods are crucial to
the final performance, providing the best practice for spoken language
understanding. Code to reproduce our results will be available upon
publication.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 12:36:05 GMT'}]",2020-10-27,"[['Kim', 'Seongbin', ''], ['Kim', 'Gyuwan', ''], ['Shin', 'Seongjin', ''], ['Lee', 'Sangmin', '']]"
1267434,2004.02664,Qingyu Zhou,"Qingyu Zhou, Furu Wei, Ming Zhou","At Which Level Should We Extract? An Empirical Analysis on Extractive
  Document Summarization",To appear at COLING 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Extractive methods have been proven effective in automatic document
summarization. Previous works perform this task by identifying informative
contents at sentence level. However, it is unclear whether performing
extraction at sentence level is the best solution. In this work, we show that
unnecessity and redundancy issues exist when extracting full sentences, and
extracting sub-sentential units is a promising alternative. Specifically, we
propose extracting sub-sentential units based on the constituency parsing tree.
A neural extractive model which leverages the sub-sentential information and
extracts them is presented. Extensive experiments and analyses show that
extracting sub-sentential units performs competitively comparing to full
sentence extraction under the evaluation of both automatic and human
evaluations. Hopefully, our work could provide some inspiration of the basic
extraction units in extractive summarization for future research.
","[{'version': 'v1', 'created': 'Mon, 6 Apr 2020 13:35:10 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 08:35:19 GMT'}]",2020-10-27,"[['Zhou', 'Qingyu', ''], ['Wei', 'Furu', ''], ['Zhou', 'Ming', '']]"
1370795,2010.14465,Marta R. Costa-juss\`a,Marta R. Costa-juss\`a and Christine Basta and Gerard I. G\'allego,Evaluating Gender Bias in Speech Translation,"Preprint, Submitted to ICASSP 2021",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The scientific community is more and more aware of the necessity to embrace
pluralism and consistently represent major and minor social groups. In this
direction, there is an urgent need to provide evaluation sets and protocols to
measure existing biases in our automatic systems. This paper introduces WinoST,
a new freely available challenge set for evaluating gender bias in speech
translation. WinoST is the speech version of WinoMT which is an MT challenge
set and both follow an evaluation protocol to measure gender accuracy. Using a
state-of-the-art end-to-end speech translation system, we report the gender
bias evaluation on 4 language pairs, and we show that gender accuracy in speech
translation is more than 23% lower than in MT.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 17:24:27 GMT'}]",2020-10-28,"[['Costa-jussà', 'Marta R.', ''], ['Basta', 'Christine', ''], ['Gállego', 'Gerard I.', '']]"
1370809,2010.14479,Sugat Chaturvedi,"Rochana Chaturvedi, Sugat Chaturvedi",It's All in the Name: A Character Based Approach To Infer Religion,,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Demographic inference from text has received a surge of attention in the
field of natural language processing in the last decade. In this paper, we use
personal names to infer religion in South Asia - where religion is a salient
social division, and yet, disaggregated data on it remains scarce. Existing
work predicts religion using dictionary based method, and therefore, can not
classify unseen names. We use character based models which learn character
patterns and, therefore, can classify unseen names as well with high accuracy.
These models are also much faster and can easily be scaled to large data sets.
We improve our classifier by combining the name of an individual with that of
their parent/spouse and achieve remarkably high accuracy. Finally, we trace the
classification decisions of a convolutional neural network model using
layer-wise relevance propagation which can explain the predictions of complex
non-linear classifiers and circumvent their purported black box nature. We show
how character patterns learned by the classifier are rooted in the linguistic
origins of names.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 17:38:11 GMT'}]",2020-10-28,"[['Chaturvedi', 'Rochana', ''], ['Chaturvedi', 'Sugat', '']]"
960680,1803.10547,Nurendra Choudhary,"Nurendra Choudhary, Rajat Singh, Ishita Bindlish and Manish
  Shrivastava",Neural Network Architecture for Credibility Assessment of Textual Claims,"Best Paper Award at 19th International Conference on Computational
  Linguistics and Intelligent Text Processing, March 2018, Hanoi, Vietnam",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Text articles with false claims, especially news, have recently become
aggravating for the Internet users. These articles are in wide circulation and
readers face difficulty discerning fact from fiction. Previous work on
credibility assessment has focused on factual analysis and linguistic features.
The task's main challenge is the distinction between the features of true and
false articles. In this paper, we propose a novel approach called Credibility
Outcome (CREDO) which aims at scoring the credibility of an article in an open
domain setting.
  CREDO consists of different modules for capturing various features
responsible for the credibility of an article. These features includes
credibility of the article's source and author, semantic similarity between the
article and related credible articles retrieved from a knowledge base, and
sentiments conveyed by the article. A neural network architecture learns the
contribution of each of these modules to the overall credibility of an article.
Experiments on Snopes dataset reveals that CREDO outperforms the
state-of-the-art approaches based on linguistic features.
","[{'version': 'v1', 'created': 'Wed, 28 Mar 2018 11:50:32 GMT'}, {'version': 'v2', 'created': 'Fri, 30 Mar 2018 10:42:04 GMT'}, {'version': 'v3', 'created': 'Mon, 26 Oct 2020 21:30:25 GMT'}]",2020-10-28,"[['Choudhary', 'Nurendra', ''], ['Singh', 'Rajat', ''], ['Bindlish', 'Ishita', ''], ['Shrivastava', 'Manish', '']]"
1370811,2010.14481,Biao Zhang,"Biao Zhang, Ivan Titov, Rico Sennrich",Fast Interleaved Bidirectional Sequence Generation,"WMT2020, source code is at
  https://github.com/bzhangGo/zero/tree/master/docs/interleaved_bidirectional_transformer",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Independence assumptions during sequence generation can speed up inference,
but parallel generation of highly inter-dependent tokens comes at a cost in
quality. Instead of assuming independence between neighbouring tokens
(semi-autoregressive decoding, SA), we take inspiration from bidirectional
sequence generation and introduce a decoder that generates target words from
the left-to-right and right-to-left directions simultaneously. We show that we
can easily convert a standard architecture for unidirectional decoding into a
bidirectional decoder by simply interleaving the two directions and adapting
the word positions and self-attention masks. Our interleaved bidirectional
decoder (IBDecoder) retains the model simplicity and training efficiency of the
standard Transformer, and on five machine translation tasks and two document
summarization tasks, achieves a decoding speedup of ~2X compared to
autoregressive decoding with comparable quality. Notably, it outperforms
left-to-right SA because the independence assumptions in IBDecoder are more
felicitous. To achieve even higher speedups, we explore hybrid models where we
either simultaneously predict multiple neighbouring tokens per direction, or
perform multi-directional decoding by partitioning the target sequence. These
methods achieve speedups to 4X-11X across different tasks at the cost of <1
BLEU or <0.5 ROUGE (on average). Source code is released at
https://github.com/bzhangGo/zero.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 17:38:51 GMT'}]",2020-10-28,"[['Zhang', 'Biao', ''], ['Titov', 'Ivan', ''], ['Sennrich', 'Rico', '']]"
1246301,2002.08878,Clement Moulin-Frier,Cl\'ement Moulin-Frier and Pierre-Yves Oudeyer,"Multi-Agent Reinforcement Learning as a Computational Tool for Language
  Evolution Research: Historical Context and Future Challenges",,"Challenges and Opportunities for Multi-Agent Reinforcement
  Learning (COMARL AAAI 2020-2021), AAAI Spring Symposium Series, Stanford
  University, Palo Alto, California, USA",,,cs.MA cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Computational models of emergent communication in agent populations are
currently gaining interest in the machine learning community due to recent
advances in Multi-Agent Reinforcement Learning (MARL). Current contributions
are however still relatively disconnected from the earlier theoretical and
computational literature aiming at understanding how language might have
emerged from a prelinguistic substance. The goal of this paper is to position
recent MARL contributions within the historical context of language evolution
research, as well as to extract from this theoretical and computational
background a few challenges for future research.
","[{'version': 'v1', 'created': 'Thu, 20 Feb 2020 17:26:46 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 13:54:46 GMT'}]",2020-10-28,"[['Moulin-Frier', 'Clément', ''], ['Oudeyer', 'Pierre-Yves', '']]"
1352508,2009.11005,Khang Nguyen,Khang Phuoc-Quy Nguyen and Kiet Van Nguyen,"Exploiting Vietnamese Social Media Characteristics for Textual Emotion
  Recognition in Vietnamese","6 pages, 9 tables, 2 figures of table, conference",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Textual emotion recognition has been a promising research topic in recent
years. Many researchers aim to build more accurate and robust emotion detection
systems. In this paper, we conduct several experiments to indicate how data
pre-processing affects a machine learning method on textual emotion
recognition. These experiments are performed on the Vietnamese Social Media
Emotion Corpus (UIT-VSMEC) as the benchmark dataset. We explore Vietnamese
social media characteristics to propose different pre-processing techniques,
and key-clause extraction with emotional context to improve the machine
performance on UIT-VSMEC. Our experimental evaluation shows that with
appropriate pre-processing techniques based on Vietnamese social media
characteristics, Multinomial Logistic Regression (MLR) achieves the best
F1-score of 64.40%, a significant improvement of 4.66% over the CNN model built
by the authors of UIT-VSMEC (59.74%).
","[{'version': 'v1', 'created': 'Wed, 23 Sep 2020 08:49:39 GMT'}, {'version': 'v2', 'created': 'Fri, 25 Sep 2020 15:46:49 GMT'}, {'version': 'v3', 'created': 'Tue, 27 Oct 2020 14:39:40 GMT'}]",2020-10-28,"[['Nguyen', 'Khang Phuoc-Quy', ''], ['Van Nguyen', 'Kiet', '']]"
1280128,2005.00333,Edoardo Maria Ponti,"Edoardo Maria Ponti, Goran Glava\v{s}, Olga Majewska, Qianchu Liu,
  Ivan Vuli\'c and Anna Korhonen",XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In order to simulate human language capacity, natural language processing
systems must be able to reason about the dynamics of everyday situations,
including their possible causes and effects. Moreover, they should be able to
generalise the acquired world knowledge to new languages, modulo cultural
differences. Advances in machine reasoning and cross-lingual transfer depend on
the availability of challenging evaluation benchmarks. Motivated by both
demands, we introduce Cross-lingual Choice of Plausible Alternatives (XCOPA), a
typologically diverse multilingual dataset for causal commonsense reasoning in
11 languages, which includes resource-poor languages like Eastern Apur\'imac
Quechua and Haitian Creole. We evaluate a range of state-of-the-art models on
this novel dataset, revealing that the performance of current methods based on
multilingual pretraining and zero-shot fine-tuning falls short compared to
translation-based transfer. Finally, we propose strategies to adapt
multilingual models to out-of-sample resource-lean languages where only a small
corpus or a bilingual dictionary is available, and report substantial
improvements over the random baseline. The XCOPA dataset is freely available at
github.com/cambridgeltl/xcopa.
","[{'version': 'v1', 'created': 'Fri, 1 May 2020 12:22:33 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 23:23:58 GMT'}]",2020-10-28,"[['Ponti', 'Edoardo Maria', ''], ['Glavaš', 'Goran', ''], ['Majewska', 'Olga', ''], ['Liu', 'Qianchu', ''], ['Vulić', 'Ivan', ''], ['Korhonen', 'Anna', '']]"
1353816,2009.12313,Iacer Calixto,Victor Milewski and Marie-Francine Moens and Iacer Calixto,Are scene graphs good enough to improve Image Captioning?,"Published at AACL-IJCNLP 2020. 12 pages, 5 figures",,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Many top-performing image captioning models rely solely on object features
computed with an object detection model to generate image descriptions.
However, recent studies propose to directly use scene graphs to introduce
information about object relations into captioning, hoping to better describe
interactions between objects. In this work, we thoroughly investigate the use
of scene graphs in image captioning. We empirically study whether using
additional scene graph encoders can lead to better image descriptions and
propose a conditional graph attention network (C-GAT), where the image
captioning decoder state is used to condition the graph updates. Finally, we
determine to what extent noise in the predicted scene graphs influence caption
quality. Overall, we find no significant difference between models that use
scene graph features and models that only use object detection features across
different captioning metrics, which suggests that existing scene graph
generation models are still too noisy to be useful in image captioning.
Moreover, although the quality of predicted scene graphs is very low in
general, when using high quality scene graphs we obtain gains of up to 3.3
CIDEr compared to a strong Bottom-Up Top-Down baseline. We open source code to
reproduce all our experiments in
https://github.com/iacercalixto/butd-image-captioning.
","[{'version': 'v1', 'created': 'Fri, 25 Sep 2020 16:09:08 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 17:55:55 GMT'}]",2020-10-28,"[['Milewski', 'Victor', ''], ['Moens', 'Marie-Francine', ''], ['Calixto', 'Iacer', '']]"
1370778,2010.14448,Xavier Ferrer Aran,"Xavier Ferrer-Aran, Tom van Nuenen, Natalia Criado, Jose M. Such",Discovering and Interpreting Conceptual Biases in Online Communities,,,,,cs.CL cs.AI cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language carries implicit human biases, functioning both as a reflection and
a perpetuation of stereotypes that people carry with them. Recently, ML-based
NLP methods such as word embeddings have been shown to learn such language
biases with striking accuracy. This capability of word embeddings has been
successfully exploited as a tool to quantify and study human biases. However,
previous studies only consider a predefined set of conceptual biases to attest
(e.g., whether gender is more or less associated with particular jobs), or just
discover biased words without helping to understand their meaning at the
conceptual level. As such, these approaches are either unable to find
conceptual biases that have not been defined in advance, or the biases they
find are difficult to interpret and study. This makes existing approaches
unsuitable to discover and interpret biases in online communities, as such
communities may carry different biases than those in mainstream culture. This
paper proposes a general, data-driven approach to automatically discover and
help interpret conceptual biases encoded in word embeddings. We apply this
approach to study the conceptual biases present in the language used in online
communities and experimentally show the validity and stability of our method.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 17:07:12 GMT'}]",2020-10-28,"[['Ferrer-Aran', 'Xavier', ''], ['van Nuenen', 'Tom', ''], ['Criado', 'Natalia', ''], ['Such', 'Jose M.', '']]"
1370794,2010.14464,Lukasz Borchmann,"{\L}ukasz Borchmann, Dawid Jurkiewicz, Filip Grali\'nski, Tomasz
  G\'orecki","Dynamic Boundary Time Warping for Sub-sequence Matching with Few
  Examples",,,,,cs.DS cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The paper presents a novel method of finding a fragment in a long temporal
sequence similar to the set of shorter sequences. We are the first to propose
an algorithm for such a search that does not rely on computing the average
sequence from query examples. Instead, we use query examples as is, utilizing
all of them simultaneously. The introduced method based on the Dynamic Time
Warping (DTW) technique is suited explicitly for few-shot query-by-example
retrieval tasks. We evaluate it on two different few-shot problems from the
field of Natural Language Processing. The results show it either outperforms
baselines and previous approaches or achieves comparable results when a low
number of examples is available.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 17:23:18 GMT'}]",2020-10-28,"[['Borchmann', 'Łukasz', ''], ['Jurkiewicz', 'Dawid', ''], ['Graliński', 'Filip', ''], ['Górecki', 'Tomasz', '']]"
998122,1807.00914,Edoardo Maria Ponti,"Edoardo Maria Ponti, Helen O'Horan, Yevgeni Berzak, Ivan Vuli\'c, Roi
  Reichart, Thierry Poibeau, Ekaterina Shutova, Anna Korhonen","Modeling Language Variation and Universals: A Survey on Typological
  Linguistics for Natural Language Processing",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Linguistic typology aims to capture structural and semantic variation across
the world's languages. A large-scale typology could provide excellent guidance
for multilingual Natural Language Processing (NLP), particularly for languages
that suffer from the lack of human labeled resources. We present an extensive
literature survey on the use of typological information in the development of
NLP techniques. Our survey demonstrates that to date, the use of information in
existing typological databases has resulted in consistent but modest
improvements in system performance. We show that this is due to both intrinsic
limitations of databases (in terms of coverage and feature granularity) and
under-employment of the typological features included in them. We advocate for
a new approach that adapts the broad and discrete nature of typological
categories to the contextual and continuous nature of machine learning
algorithms used in contemporary NLP. In particular, we suggest that such
approach could be facilitated by recent developments in data-driven induction
of typological knowledge.
","[{'version': 'v1', 'created': 'Mon, 2 Jul 2018 22:09:59 GMT'}, {'version': 'v2', 'created': 'Wed, 27 Feb 2019 19:55:28 GMT'}, {'version': 'v3', 'created': 'Mon, 26 Oct 2020 23:23:45 GMT'}]",2020-10-28,"[['Ponti', 'Edoardo Maria', ''], [""O'Horan"", 'Helen', ''], ['Berzak', 'Yevgeni', ''], ['Vulić', 'Ivan', ''], ['Reichart', 'Roi', ''], ['Poibeau', 'Thierry', ''], ['Shutova', 'Ekaterina', ''], ['Korhonen', 'Anna', '']]"
1355762,2009.14259,Peter Jansen,Peter A. Jansen,"Visually-Grounded Planning without Vision: Language Models Infer
  Detailed Plans from High-level Instructions","Accepted to Findings of EMNLP. V2: corrected typo Table 1; margins
  Table 3",,,,cs.CL cs.CV,http://creativecommons.org/licenses/by/4.0/,"  The recently proposed ALFRED challenge task aims for a virtual robotic agent
to complete complex multi-step everyday tasks in a virtual home environment
from high-level natural language directives, such as ""put a hot piece of bread
on a plate"". Currently, the best-performing models are able to complete less
than 5% of these tasks successfully. In this work we focus on modeling the
translation problem of converting natural language directives into detailed
multi-step sequences of actions that accomplish those goals in the virtual
environment. We empirically demonstrate that it is possible to generate gold
multi-step plans from language directives alone without any visual input in 26%
of unseen cases. When a small amount of visual information is incorporated,
namely the starting location in the virtual environment, our best-performing
GPT-2 model successfully generates gold command sequences in 58% of cases. Our
results suggest that contextualized language models may provide strong visual
semantic planning modules for grounded virtual agents.
","[{'version': 'v1', 'created': 'Tue, 29 Sep 2020 18:52:39 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 19:16:00 GMT'}]",2020-10-28,"[['Jansen', 'Peter A.', '']]"
776112,1610.00765,Edoardo Maria Ponti,"Edoardo Maria Ponti, Elisabetta Jezek, Bernardo Magnini","Distributed Representations of Lexical Sets and Prototypes in Causal
  Alternation Verbs","5 pages, 4 figures, accepted at: Third Italian Conference on
  Computational Linguistics (CLIC-it). 5-6 December 2016, Napoli (Italy)",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Lexical sets contain the words filling an argument slot of a verb, and are in
part determined by selectional preferences. The purpose of this paper is to
unravel the properties of lexical sets through distributional semantics. We
investigate 1) whether lexical set behave as prototypical categories with a
centre and a periphery; 2) whether they are polymorphic, i.e. composed by
subcategories; 3) whether the distance between lexical sets of different
arguments is explanatory of verb properties. In particular, our case study are
lexical sets of causative-inchoative verbs in Italian. Having studied several
vector models, we find that 1) based on spatial distance from the centroid,
object fillers are scattered uniformly across the category, whereas
intransitive subject fillers lie on its edge; 2) a correlation exists between
the amount of verb senses and that of clusters discovered automatically,
especially for intransitive subjects; 3) the distance between the centroids of
object and intransitive subject is correlated with other properties of verbs,
such as their cross-lingual tendency to appear in the intransitive pattern
rather than transitive one. This paper is noncommittal with respect to the
hypothesis that this connection is underpinned by a semantic reason, namely the
spontaneity of the event denoted by the verb.
","[{'version': 'v1', 'created': 'Mon, 3 Oct 2016 21:50:27 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 23:48:14 GMT'}]",2020-10-28,"[['Ponti', 'Edoardo Maria', ''], ['Jezek', 'Elisabetta', ''], ['Magnini', 'Bernardo', '']]"
1362519,2010.06189,Zhengbao Jiang,"Zhengbao Jiang, Antonios Anastasopoulos, Jun Araki, Haibo Ding, Graham
  Neubig","X-FACTR: Multilingual Factual Knowledge Retrieval from Pretrained
  Language Models",EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language models (LMs) have proven surprisingly successful at capturing
factual knowledge by completing cloze-style fill-in-the-blank questions such as
""Punta Cana is located in _."" However, while knowledge is both written and
queried in many languages, studies on LMs' factual representation ability have
almost invariably been performed on English. To assess factual knowledge
retrieval in LMs in different languages, we create a multilingual benchmark of
cloze-style probes for 23 typologically diverse languages. To properly handle
language variations, we expand probing methods from single- to multi-word
entities, and develop several decoding algorithms to generate multi-token
predictions. Extensive experimental results provide insights about how well (or
poorly) current state-of-the-art LMs perform at this task in languages with
more or fewer available resources. We further propose a code-switching-based
method to improve the ability of multilingual LMs to access knowledge, and
verify its effectiveness on several benchmark languages. Benchmark data and
code have been released at https://x-factr.github.io.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 05:29:56 GMT'}, {'version': 'v2', 'created': 'Wed, 14 Oct 2020 22:23:17 GMT'}, {'version': 'v3', 'created': 'Tue, 27 Oct 2020 15:30:03 GMT'}]",2020-10-28,"[['Jiang', 'Zhengbao', ''], ['Anastasopoulos', 'Antonios', ''], ['Araki', 'Jun', ''], ['Ding', 'Haibo', ''], ['Neubig', 'Graham', '']]"
1362726,2010.06396,Ekta Sood,"Ekta Sood, Simon Tannert, Diego Frassinelli, Andreas Bulling and Ngoc
  Thang Vu","Interpreting Attention Models with Human Visual Attention in Machine
  Reading Comprehension",CoNLL 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While neural networks with attention mechanisms have achieved superior
performance on many natural language processing tasks, it remains unclear to
which extent learned attention resembles human visual attention. In this paper,
we propose a new method that leverages eye-tracking data to investigate the
relationship between human visual attention and neural attention in machine
reading comprehension. To this end, we introduce a novel 23 participant eye
tracking dataset - MQA-RC, in which participants read movie plots and answered
pre-defined questions. We compare state of the art networks based on long
short-term memory (LSTM), convolutional neural models (CNN) and XLNet
Transformer architectures. We find that higher similarity to human attention
and performance significantly correlates to the LSTM and CNN models. However,
we show this relationship does not hold true for the XLNet models -- despite
the fact that the XLNet performs best on this challenging task. Our results
suggest that different architectures seem to learn rather different neural
attention strategies and similarity of neural to human attention does not
guarantee best performance.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 13:51:57 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 14:47:51 GMT'}]",2020-10-28,"[['Sood', 'Ekta', ''], ['Tannert', 'Simon', ''], ['Frassinelli', 'Diego', ''], ['Bulling', 'Andreas', ''], ['Vu', 'Ngoc Thang', '']]"
1364221,2010.07891,Ekta Sood,"Ekta Sood, Simon Tannert, Philipp Mueller, Andreas Bulling","Improving Natural Language Processing Tasks with Human Gaze-Guided
  Neural Attention",NeurIPS 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A lack of corpora has so far limited advances in integrating human gaze data
as a supervisory signal in neural attention mechanisms for natural language
processing(NLP). We propose a novel hybrid text saliency model(TSM) that, for
the first time, combines a cognitive model of reading with explicit human gaze
supervision in a single machine learning framework. On four different corpora
we demonstrate that our hybrid TSM duration predictions are highly correlated
with human gaze ground truth. We further propose a novel joint modeling
approach to integrate TSM predictions into the attention layer of a network
designed for a specific upstream NLP task without the need for any
task-specific human gaze data. We demonstrate that our joint model outperforms
the state of the art in paraphrase generation on the Quora Question Pairs
corpus by more than 10% in BLEU-4 and achieves state of the art performance for
sentence compression on the challenging Google Sentence Compression corpus. As
such, our work introduces a practical approach for bridging between data-driven
and cognitive models and demonstrates a new way to integrate human gaze-guided
neural attention into NLP tasks.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 17:14:09 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 16:16:18 GMT'}]",2020-10-28,"[['Sood', 'Ekta', ''], ['Tannert', 'Simon', ''], ['Mueller', 'Philipp', ''], ['Bulling', 'Andreas', '']]"
1177919,1909.07881,Palakorn Achananuparp,"Helena Lee, Palakorn Achananuparp, Yue Liu, Ee-Peng Lim, Lav R.
  Varshney","Estimating Glycemic Impact of Cooking Recipes via Online Crowdsourcing
  and Machine Learning","To appear in the Proceedings of Digital Public Health 2019 as short
  paper",,10.1145/3357729.3357748,,cs.CY cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Consumption of diets with low glycemic impact is highly recommended for
diabetics and pre-diabetics as it helps maintain their blood glucose levels.
However, laboratory analysis of dietary glycemic potency is time-consuming and
expensive. In this paper, we explore a data-driven approach utilizing online
crowdsourcing and machine learning to estimate the glycemic impact of cooking
recipes. We show that a commonly used healthiness metric may not always be
effective in determining recipes suitable for diabetics, thus emphasizing the
importance of the glycemic-impact estimation task. Our best classification
model, trained on nutritional and crowdsourced data obtained from Amazon
Mechanical Turk (AMT), can accurately identify recipes which are unhealthful
for diabetics.
","[{'version': 'v1', 'created': 'Tue, 17 Sep 2019 15:14:51 GMT'}]",2020-10-28,"[['Lee', 'Helena', ''], ['Achananuparp', 'Palakorn', ''], ['Liu', 'Yue', ''], ['Lim', 'Ee-Peng', ''], ['Varshney', 'Lav R.', '']]"
1299720,2006.05206,Jayden Macklin-Cordes,"Jayden L. Macklin-Cordes, Erich R. Round",Re-evaluating phoneme frequencies,"29pp (3 figures, 3 tables). This article has been provisionally
  accepted for publication (Frontiers in Psychology, Language Sciences).
  Supplementary information, data and code available at
  http://doi.org/10.5281/zenodo.3886212",,10.3389/fpsyg.2020.570895,,cs.CL physics.soc-ph stat.AP,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Causal processes can give rise to distinctive distributions in the linguistic
variables that they affect. Consequently, a secure understanding of a
variable's distribution can hold a key to understanding the forces that have
causally shaped it. A storied distribution in linguistics has been Zipf's law,
a kind of power law. In the wake of a major debate in the sciences around
power-law hypotheses and the unreliability of earlier methods of evaluating
them, here we re-evaluate the distributions claimed to characterize phoneme
frequencies. We infer the fit of power laws and three alternative distributions
to 166 Australian languages, using a maximum likelihood framework. We find
evidence supporting earlier results, but also nuancing them and increasing our
understanding of them. Most notably, phonemic inventories appear to have a
Zipfian-like frequency structure among their most-frequent members (though
perhaps also a lognormal structure) but a geometric (or exponential) structure
among the least-frequent. We compare these new insights the kinds of causal
processes that affect the evolution of phonemic inventories over time, and
identify a potential account for why, despite there being an important role for
phonetic substance in phonemic change, we could still expect inventories with
highly diverse phonetic content to share similar distributions of phoneme
frequencies. We conclude with priorities for future work in this promising
program of research.
","[{'version': 'v1', 'created': 'Tue, 9 Jun 2020 12:05:10 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 03:56:14 GMT'}]",2020-10-28,"[['Macklin-Cordes', 'Jayden L.', ''], ['Round', 'Erich R.', '']]"
1367182,2010.10852,Huy To Quoc,"Huy Quoc To, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen, Anh Gia-Tuan
  Nguyen","Gender Prediction Based on Vietnamese Names with Machine Learning
  Techniques","6 pages, 6 figures",,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  As biological gender is one of the aspects of presenting individual human,
much work has been done on gender classification based on people names. The
proposals for English and Chinese languages are tremendous; still, there have
been few works done for Vietnamese so far. We propose a new dataset for gender
prediction based on Vietnamese names. This dataset comprises over 26,000 full
names annotated with genders. This dataset is available on our website for
research purposes. In addition, this paper describes six machine learning
algorithms (Support Vector Machine, Multinomial Naive Bayes, Bernoulli Naive
Bayes, Decision Tree, Random Forrest and Logistic Regression) and a deep
learning model (LSTM) with fastText word embedding for gender prediction on
Vietnamese names. We create a dataset and investigate the impact of each name
component on detecting gender. As a result, the best F1-score that we have
achieved is up to 96\% on LSTM model and we generate a web API based on our
trained model.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 09:25:48 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 02:21:32 GMT'}, {'version': 'v3', 'created': 'Tue, 27 Oct 2020 01:29:35 GMT'}]",2020-10-28,"[['To', 'Huy Quoc', ''], ['Van Nguyen', 'Kiet', ''], ['Nguyen', 'Ngan Luu-Thuy', ''], ['Nguyen', 'Anh Gia-Tuan', '']]"
1236866,2001.11453,Edoardo Maria Ponti,"Edoardo M. Ponti, Ivan Vuli\'c, Ryan Cotterell, Marinela Parovic, Roi
  Reichart and Anna Korhonen","Parameter Space Factorization for Zero-Shot Learning across Tasks and
  Languages",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Most combinations of NLP tasks and language varieties lack in-domain examples
for supervised training because of the paucity of annotated data. How can
neural models make sample-efficient generalizations from task--language
combinations with available data to low-resource ones? In this work, we propose
a Bayesian generative model for the space of neural parameters. We assume that
this space can be factorized into latent variables for each language and each
task. We infer the posteriors over such latent variables based on data from
seen task--language combinations through variational inference. This enables
zero-shot classification on unseen combinations at prediction time. For
instance, given training data for named entity recognition (NER) in Vietnamese
and for part-of-speech (POS) tagging in Wolof, our model can perform accurate
predictions for NER in Wolof. In particular, we experiment with a typologically
diverse sample of 33 languages from 4 continents and 11 families, and show that
our model yields comparable or better results than state-of-the-art, zero-shot
cross-lingual transfer methods. Moreover, we demonstrate that approximate
Bayesian model averaging results in smoother predictive distributions, whose
entropy strongly correlates with accuracy. Hence, the proposed framework also
offers robust estimates of uncertainty.
","[{'version': 'v1', 'created': 'Thu, 30 Jan 2020 16:58:56 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 23:30:01 GMT'}]",2020-10-28,"[['Ponti', 'Edoardo M.', ''], ['Vulić', 'Ivan', ''], ['Cotterell', 'Ryan', ''], ['Parovic', 'Marinela', ''], ['Reichart', 'Roi', ''], ['Korhonen', 'Anna', '']]"
1304040,2006.09526,Chau Tran,"Chau Tran, Yuqing Tang, Xian Li, Jiatao Gu",Cross-lingual Retrieval for Iterative Self-Supervised Training,,NeurIPS 2020,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent studies have demonstrated the cross-lingual alignment ability of
multilingual pretrained language models. In this work, we found that the
cross-lingual alignment can be further improved by training seq2seq models on
sentence pairs mined using their own encoder outputs. We utilized these
findings to develop a new approach -- cross-lingual retrieval for iterative
self-supervised training (CRISS), where mining and training processes are
applied iteratively, improving cross-lingual alignment and translation ability
at the same time. Using this method, we achieved state-of-the-art unsupervised
machine translation results on 9 language directions with an average
improvement of 2.4 BLEU, and on the Tatoeba sentence retrieval task in the
XTREME benchmark on 16 languages with an average improvement of 21.5% in
absolute accuracy. Furthermore, CRISS also brings an additional 1.8 BLEU
improvement on average compared to mBART, when finetuned on supervised machine
translation downstream tasks.
","[{'version': 'v1', 'created': 'Tue, 16 Jun 2020 21:30:51 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 23:25:31 GMT'}]",2020-10-28,"[['Tran', 'Chau', ''], ['Tang', 'Yuqing', ''], ['Li', 'Xian', ''], ['Gu', 'Jiatao', '']]"
1367362,2010.11032,Leshem Choshen,"Leshem Choshen, Dmitry Nikolaev, Yevgeni Berzak, Omri Abend",Classifying Syntactic Errors in Learner Language,CoNLL 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present a method for classifying syntactic errors in learner language,
namely errors whose correction alters the morphosyntactic structure of a
sentence.
  The methodology builds on the established Universal Dependencies syntactic
representation scheme, and provides complementary information to other
error-classification systems.
  Unlike existing error classification methods, our method is applicable across
languages, which we showcase by producing a detailed picture of syntactic
errors in learner English and learner Russian. We further demonstrate the
utility of the methodology for analyzing the outputs of leading Grammatical
Error Correction (GEC) systems.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 14:28:22 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 14:58:14 GMT'}]",2020-10-28,"[['Choshen', 'Leshem', ''], ['Nikolaev', 'Dmitry', ''], ['Berzak', 'Yevgeni', ''], ['Abend', 'Omri', '']]"
1370769,2010.14439,Bill Yuchen Lin,"Bill Yuchen Lin, Haitian Sun, Bhuwan Dhingra, Manzil Zaheer, Xiang
  Ren, William W. Cohen",Differentiable Open-Ended Commonsense Reasoning,Work in progress. Project page: https://yuchenlin.xyz/opencsr/,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Current commonsense reasoning research mainly focuses on developing models
that use commonsense knowledge to answer multiple-choice questions. However,
systems designed to answer multiple-choice questions may not be useful in
applications that do not provide a small list of possible candidate answers to
choose from. As a step towards making commonsense reasoning research more
realistic, we propose to study open-ended commonsense reasoning (OpenCSR) --
the task of answering a commonsense question without any pre-defined choices,
using as a resource only a corpus of commonsense facts written in natural
language. The task is challenging due to a much larger decision space, and
because many commonsense questions require multi-hop reasoning. We propose an
efficient differentiable model for multi-hop reasoning over knowledge facts,
named DrFact. We evaluate our approach on a collection of re-formatted,
open-ended versions of popular tests targeting commonsense reasoning, and show
that our approach outperforms strong baseline methods by a large margin.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 10:07:00 GMT'}]",2020-10-28,"[['Lin', 'Bill Yuchen', ''], ['Sun', 'Haitian', ''], ['Dhingra', 'Bhuwan', ''], ['Zaheer', 'Manzil', ''], ['Ren', 'Xiang', ''], ['Cohen', 'William W.', '']]"
1329286,2008.01564,Bruce Lee,"Bruce W. Lee, Jason Hyung-Jong Lee","LXPER Index: a curriculum-specific text readability assessment model for
  EFL students in Korea","8 pages, 2 figures, 7 tables",,10.14569/IJACSA.2020.0110801,,cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Automatic readability assessment is one of the most important applications of
Natural Language Processing (NLP) in education. Since automatic readability
assessment allows the fast selection of appropriate reading material for
readers at all levels of proficiency, it can be particularly useful for the
English education of English as Foreign Language (EFL) students around the
world. Most readability assessment models are developed for the native readers
of English and have low accuracy for texts in the non-native English Language
Training (ELT) curriculum. We introduce LXPER Index, which is a readability
assessment model for non-native EFL readers in the ELT curriculum of Korea. Our
experiments show that our new model, trained with CoKEC-text (Text Corpus of
the Korean ELT Curriculum), significantly improves the accuracy of automatic
readability assessment for texts in the Korean ELT curriculum.
","[{'version': 'v1', 'created': 'Sat, 1 Aug 2020 11:55:03 GMT'}]",2020-10-28,"[['Lee', 'Bruce W.', ''], ['Lee', 'Jason Hyung-Jong', '']]"
1280414,2005.00619,Gabriel Ilharco,"Gabriel Ilharco, Rowan Zellers, Ali Farhadi, Hannaneh Hajishirzi","Probing Contextual Language Models for Common Ground with Visual
  Representations",,,,,cs.CL cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While large-scale contextual language models have enjoyed great success
recently, much remains to be understood about what is encoded in their
representations. In this work, we characterize how contextual representations
of concrete nouns extracted by trained language models relate to the physical
properties of the objects they refer to. Our approach uses a probing model that
examines how effective these language representations are in discerning between
different visual representations. We show that many recent language models
yield representations that are useful in retrieving semantically aligned image
patches, and explore the role of context in this process. Much weaker results
are found in control experiments, attesting the selectivity of the probe. All
examined models greatly under-perform humans in retrieval, highlighting
substantial room for future progress. Altogether, our findings shed new
empirical insights on language grounding and its materialization in contextual
language models.
","[{'version': 'v1', 'created': 'Fri, 1 May 2020 21:28:28 GMT'}, {'version': 'v2', 'created': 'Tue, 6 Oct 2020 17:19:20 GMT'}, {'version': 'v3', 'created': 'Fri, 23 Oct 2020 22:12:40 GMT'}, {'version': 'v4', 'created': 'Tue, 27 Oct 2020 16:40:01 GMT'}]",2020-10-28,"[['Ilharco', 'Gabriel', ''], ['Zellers', 'Rowan', ''], ['Farhadi', 'Ali', ''], ['Hajishirzi', 'Hannaneh', '']]"
1370672,2010.14342,Guanyi Chen,"Guanyi Chen, Yinhe Zheng, Yupei Du",Listener's Social Identity Matters in Personalised Response Generation,Long paper accepted at INLG 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Personalised response generation enables generating human-like responses by
means of assigning the generator a social identity. However, pragmatics theory
suggests that human beings adjust the way of speaking based on not only who
they are but also whom they are talking to. In other words, when modelling
personalised dialogues, it might be favourable if we also take the listener's
social identity into consideration. To validate this idea, we use gender as a
typical example of a social variable to investigate how the listener's identity
influences the language used in Chinese dialogues on social media. Also, we
build personalised generators. The experiment results demonstrate that the
listener's identity indeed matters in the language use of responses and that
the response generator can capture such differences in language use. More
interestingly, by additionally modelling the listener's identity, the
personalised response generator performs better in its own identity.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 14:57:21 GMT'}]",2020-10-28,"[['Chen', 'Guanyi', ''], ['Zheng', 'Yinhe', ''], ['Du', 'Yupei', '']]"
1370434,2010.14104,"Bj\""orn Bebensee","Bj\""orn Bebensee, Byoung-Tak Zhang",Co-attentional Transformers for Story-Based Video Understanding,"10 pages, 2 figures, submitted to ICASSP 2021",,,,cs.CV cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Inspired by recent trends in vision and language learning, we explore
applications of attention mechanisms for visio-lingual fusion within an
application to story-based video understanding. Like other video-based QA
tasks, video story understanding requires agents to grasp complex temporal
dependencies. However, as it focuses on the narrative aspect of video it also
requires understanding of the interactions between different characters, as
well as their actions and their motivations. We propose a novel co-attentional
transformer model to better capture long-term dependencies seen in visual
stories such as dramas and measure its performance on the video question
answering task. We evaluate our approach on the recently introduced DramaQA
dataset which features character-centered video story understanding questions.
Our model outperforms the baseline model by 8 percentage points overall, at
least 4.95 and up to 12.8 percentage points on all difficulty levels and
manages to beat the winner of the DramaQA challenge.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 07:17:09 GMT'}]",2020-10-28,"[['Bebensee', 'Björn', ''], ['Zhang', 'Byoung-Tak', '']]"
1370601,2010.14271,Ming Gong,"Junhao Liu, Linjun Shou, Jian Pei, Ming Gong, Min Yang, Daxin Jiang","Cross-lingual Machine Reading Comprehension with Language Branch
  Knowledge Distillation",Accepted as long paper in COLING 2020,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Cross-lingual Machine Reading Comprehension (CLMRC) remains a challenging
problem due to the lack of large-scale annotated datasets in low-source
languages, such as Arabic, Hindi, and Vietnamese. Many previous approaches use
translation data by translating from a rich-source language, such as English,
to low-source languages as auxiliary supervision. However, how to effectively
leverage translation data and reduce the impact of noise introduced by
translation remains onerous. In this paper, we tackle this challenge and
enhance the cross-lingual transferring performance by a novel augmentation
approach named Language Branch Machine Reading Comprehension (LBMRC). A
language branch is a group of passages in one single language paired with
questions in all target languages. We train multiple machine reading
comprehension (MRC) models proficient in individual language based on LBMRC.
Then, we devise a multilingual distillation approach to amalgamate knowledge
from multiple language branch models to a single model for all target
languages. Combining the LBMRC and multilingual distillation can be more robust
to the data noises, therefore, improving the model's cross-lingual ability.
Meanwhile, the produced single multilingual model is applicable to all target
languages, which saves the cost of training, inference, and maintenance for
multiple models. Extensive experiments on two CLMRC benchmarks clearly show the
effectiveness of our proposed method.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 13:12:17 GMT'}]",2020-10-28,"[['Liu', 'Junhao', ''], ['Shou', 'Linjun', ''], ['Pei', 'Jian', ''], ['Gong', 'Ming', ''], ['Yang', 'Min', ''], ['Jiang', 'Daxin', '']]"
1370144,2010.13814,Constantin Orasan,"Hadeel Saadany, Constantin Orasan","Is it Great or Terrible? Preserving Sentiment in Neural Machine
  Translation of Arabic Reviews",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Since the advent of Neural Machine Translation (NMT) approaches there has
been a tremendous improvement in the quality of automatic translation. However,
NMT output still lacks accuracy in some low-resource languages and sometimes
makes major errors that need extensive post-editing. This is particularly
noticeable with texts that do not follow common lexico-grammatical standards,
such as user generated content (UGC). In this paper we investigate the
challenges involved in translating book reviews from Arabic into English, with
particular focus on the errors that lead to incorrect translation of sentiment
polarity. Our study points to the special characteristics of Arabic UGC,
examines the sentiment transfer errors made by Google Translate of Arabic UGC
to English, analyzes why the problem occurs, and proposes an error typology
specific of the translation of Arabic UGC. Our analysis shows that the output
of online translation tools of Arabic UGC can either fail to transfer the
sentiment at all by producing a neutral target text, or completely flips the
sentiment polarity of the target word or phrase and hence delivers a wrong
affect message. We address this problem by fine-tuning an NMT model with
respect to sentiment polarity showing that this approach can significantly help
with correcting sentiment errors detected in the online translation of Arabic
UGC.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 18:01:52 GMT'}]",2020-10-28,"[['Saadany', 'Hadeel', ''], ['Orasan', 'Constantin', '']]"
1370169,2010.13839,Subhajit Chaudhury,"Thomas Carta, Subhajit Chaudhury, Kartik Talamadupula and Michiaki
  Tatsubori","VisualHints: A Visual-Lingual Environment for Multimodal Reinforcement
  Learning",Code is available at http://ibm.biz/VisualHints,,,,cs.LG cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present VisualHints, a novel environment for multimodal reinforcement
learning (RL) involving text-based interactions along with visual hints
(obtained from the environment). Real-life problems often demand that agents
interact with the environment using both natural language information and
visual perception towards solving a goal. However, most traditional RL
environments either solve pure vision-based tasks like Atari games or
video-based robotic manipulation; or entirely use natural language as a mode of
interaction, like Text-based games and dialog systems. In this work, we aim to
bridge this gap and unify these two approaches in a single environment for
multimodal RL. We introduce an extension of the TextWorld cooking environment
with the addition of visual clues interspersed throughout the environment. The
goal is to force an RL agent to use both text and visual features to predict
natural language action commands for solving the final task of cooking a meal.
We enable variations and difficulties in our environment to emulate various
interactive real-world scenarios. We present a baseline multimodal agent for
solving such problems using CNN-based feature extraction from visual hints and
LSTMs for textual feature extraction. We believe that our proposed
visual-lingual environment will facilitate novel problem settings for the RL
community.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 18:51:02 GMT'}]",2020-10-28,"[['Carta', 'Thomas', ''], ['Chaudhury', 'Subhajit', ''], ['Talamadupula', 'Kartik', ''], ['Tatsubori', 'Michiaki', '']]"
1370186,2010.13856,Ciprian Chelba,"Ciprian Chelba, Junpei Zhou, Yuezhang (Music) Li, Hideto Kazawa, Jeff
  Klingner, Mengmeng Niu","Data Troubles in Sentence Level Confidence Estimation for Machine
  Translation",,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The paper investigates the feasibility of confidence estimation for neural
machine translation models operating at the high end of the performance
spectrum. As a side product of the data annotation process necessary for
building such models we propose sentence level accuracy $SACC$ as a simple,
self-explanatory evaluation metric for quality of translation.
  Experiments on two different annotator pools, one comprised of non-expert
(crowd-sourced) and one of expert (professional) translators show that $SACC$
can vary greatly depending on the translation proficiency of the annotators,
despite the fact that both pools are about equally reliable according to
Krippendorff's alpha metric; the relatively low values of inter-annotator
agreement confirm the expectation that sentence-level binary labeling $good$ /
$needs\ work$ for translation out of context is very hard.
  For an English-Spanish translation model operating at $SACC = 0.89$ according
to a non-expert annotator pool we can derive a confidence estimate that labels
0.5-0.6 of the $good$ translations in an ""in-domain"" test set with 0.95
Precision. Switching to an expert annotator pool decreases $SACC$ dramatically:
$0.61$ for English-Spanish, measured on the exact same data as above. This
forces us to lower the CE model operating point to 0.9 Precision while labeling
correctly about 0.20-0.25 of the $good$ translations in the data.
  We find surprising the extent to which CE depends on the level of proficiency
of the annotator pool used for labeling the data. This leads to an important
recommendation we wish to make when tackling CE modeling in practice: it is
critical to match the end-user expectation for translation quality in the
desired domain with the demands of annotators assigning binary quality labels
to CE training data.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 19:20:29 GMT'}]",2020-10-28,"[['Chelba', 'Ciprian', '', 'Music'], ['Zhou', 'Junpei', '', 'Music'], ['Yuezhang', '', '', 'Music'], ['Li', '', ''], ['Kazawa', 'Hideto', ''], ['Klingner', 'Jeff', ''], ['Niu', 'Mengmeng', '']]"
1256634,2003.06279,Diego Amancio,Laura V. C. Quispe and Jorge A. V. Tohalino and Diego R. Amancio,"Using word embeddings to improve the discriminability of co-occurrence
  text networks",,,10.1016/j.physa.2020.125344,,cs.CL cs.SI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Word co-occurrence networks have been employed to analyze texts both in the
practical and theoretical scenarios. Despite the relative success in several
applications, traditional co-occurrence networks fail in establishing links
between similar words whenever they appear distant in the text. Here we
investigate whether the use of word embeddings as a tool to create virtual
links in co-occurrence networks may improve the quality of classification
systems. Our results revealed that the discriminability in the stylometry task
is improved when using Glove, Word2Vec and FastText. In addition, we found that
optimized results are obtained when stopwords are not disregarded and a simple
global thresholding strategy is used to establish virtual links. Because the
proposed approach is able to improve the representation of texts as complex
networks, we believe that it could be extended to study other natural language
processing tasks. Likewise, theoretical languages studies could benefit from
the adopted enriched representation of word co-occurrence networks.
","[{'version': 'v1', 'created': 'Fri, 13 Mar 2020 13:35:44 GMT'}]",2020-10-28,"[['Quispe', 'Laura V. C.', ''], ['Tohalino', 'Jorge A. V.', ''], ['Amancio', 'Diego R.', '']]"
1369939,2010.13609,Dumitru-Clementin Cercel,"Mircea-Adrian Tanase, Dumitru-Clementin Cercel and Costin-Gabriel
  Chiru","UPB at SemEval-2020 Task 12: Multilingual Offensive Language Detection
  on Social Media by Fine-tuning a Variety of BERT-based Models",,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Offensive language detection is one of the most challenging problem in the
natural language processing field, being imposed by the rising presence of this
phenomenon in online social media. This paper describes our Transformer-based
solutions for identifying offensive language on Twitter in five languages
(i.e., English, Arabic, Danish, Greek, and Turkish), which was employed in
Subtask A of the Offenseval 2020 shared task. Several neural architectures
(i.e., BERT, mBERT, Roberta, XLM-Roberta, and ALBERT), pre-trained using both
single-language and multilingual corpora, were fine-tuned and compared using
multiple combinations of datasets. Finally, the highest-scoring models were
used for our submissions in the competition, which ranked our team 21st of 85,
28th of 53, 19th of 39, 16th of 37, and 10th of 46 for English, Arabic, Danish,
Greek, and Turkish, respectively.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 14:28:29 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 09:21:21 GMT'}]",2020-10-28,"[['Tanase', 'Mircea-Adrian', ''], ['Cercel', 'Dumitru-Clementin', ''], ['Chiru', 'Costin-Gabriel', '']]"
1370200,2010.13870,Leon Bergen,"Charles Yu, Ryan Sie, Nico Tedeschi, Leon Bergen",Word Frequency Does Not Predict Grammatical Knowledge in Language Models,EMNLP 2020,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Neural language models learn, to varying degrees of accuracy, the grammatical
properties of natural languages. In this work, we investigate whether there are
systematic sources of variation in the language models' accuracy. Focusing on
subject-verb agreement and reflexive anaphora, we find that certain nouns are
systematically understood better than others, an effect which is robust across
grammatical tasks and different language models. Surprisingly, we find that
across four orders of magnitude, corpus frequency is unrelated to a noun's
performance on grammatical tasks. Finally, we find that a novel noun's
grammatical properties can be few-shot learned from various types of training
data. The results present a paradox: there should be less variation in
grammatical performance than is actually observed.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 19:51:36 GMT'}]",2020-10-28,"[['Yu', 'Charles', ''], ['Sie', 'Ryan', ''], ['Tedeschi', 'Nico', ''], ['Bergen', 'Leon', '']]"
1370208,2010.13878,Suyoun Kim,"Suyoun Kim, Yuan Shangguan, Jay Mahadeokar, Antoine Bruguier,
  Christian Fuegen, Michael L. Seltzer, Duc Le","Improved Neural Language Model Fusion for Streaming Recurrent Neural
  Network Transducer",submitted to ICASSP 2021,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recurrent Neural Network Transducer (RNN-T), like most end-to-end speech
recognition model architectures, has an implicit neural network language model
(NNLM) and cannot easily leverage unpaired text data during training. Previous
work has proposed various fusion methods to incorporate external NNLMs into
end-to-end ASR to address this weakness. In this paper, we propose extensions
to these techniques that allow RNN-T to exploit external NNLMs during both
training and inference time, resulting in 13-18% relative Word Error Rate
improvement on Librispeech compared to strong baselines. Furthermore, our
methods do not incur extra algorithmic latency and allow for flexible
plug-and-play of different NNLMs without re-training. We also share in-depth
analysis to better understand the benefits of the different NNLM fusion
methods. Our work provides a reliable technique for leveraging unpaired text
data to significantly improve RNN-T while keeping the system streamable,
flexible, and lightweight.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 20:10:12 GMT'}]",2020-10-28,"[['Kim', 'Suyoun', ''], ['Shangguan', 'Yuan', ''], ['Mahadeokar', 'Jay', ''], ['Bruguier', 'Antoine', ''], ['Fuegen', 'Christian', ''], ['Seltzer', 'Michael L.', ''], ['Le', 'Duc', '']]"
1370242,2010.13912,Chien-Sheng Wu,Chien-Sheng Wu and Caiming Xiong,Probing Task-Oriented Dialogue Representation from Language Models,EMNLP 2020,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper investigates pre-trained language models to find out which model
intrinsically carries the most informative representation for task-oriented
dialogue tasks. We approach the problem from two aspects: supervised classifier
probe and unsupervised mutual information probe. We fine-tune a feed-forward
layer as the classifier probe on top of a fixed pre-trained language model with
annotated labels in a supervised way. Meanwhile, we propose an unsupervised
mutual information probe to evaluate the mutual dependence between a real
clustering and a representation clustering. The goals of this empirical paper
are to 1) investigate probing techniques, especially from the unsupervised
mutual information aspect, 2) provide guidelines of pre-trained language model
selection for the dialogue research community, 3) find insights of pre-training
factors for dialogue application that may be the key to success.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 21:34:39 GMT'}]",2020-10-28,"[['Wu', 'Chien-Sheng', ''], ['Xiong', 'Caiming', '']]"
1370648,2010.14318,Peidong Wang,"Peidong Wang, Tara N. Sainath, Ron J. Weiss",Multitask Training with Text Data for End-to-End Speech Recognition,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a multitask training method for attention-based end-to-end speech
recognition models to better incorporate language level information. We
regularize the decoder in a sequence-to-sequence architecture by multitask
training it on both the speech recognition task and a next-token prediction
language modeling task. Trained on either the 100 hour subset of LibriSpeech or
the full 960 hour dataset, the proposed method leads to an 11% relative
performance improvement over the baseline and is comparable to language model
shallow fusion, without requiring an additional neural network during decoding.
Analyses of sample output sentences and the word error rate on rare words
demonstrate that the proposed method can incorporate language level information
effectively.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 14:29:28 GMT'}]",2020-10-28,"[['Wang', 'Peidong', ''], ['Sainath', 'Tara N.', ''], ['Weiss', 'Ron J.', '']]"
1252853,2003.02498,Palakorn Achananuparp,"Helena H. Lee, Ke Shu, Palakorn Achananuparp, Philips Kokoh Prasetyo,
  Yue Liu, Ee-Peng Lim, Lav R. Varshney","RecipeGPT: Generative Pre-training Based Cooking Recipe Generation and
  Evaluation System",Accepted to WWW 2020. Demo track paper,,10.1145/3366424.3383536,,cs.CL cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Interests in the automatic generation of cooking recipes have been growing
steadily over the past few years thanks to a large amount of online cooking
recipes. We present RecipeGPT, a novel online recipe generation and evaluation
system. The system provides two modes of text generations: (1) instruction
generation from given recipe title and ingredients; and (2) ingredient
generation from recipe title and cooking instructions. Its back-end text
generation module comprises a generative pre-trained language model GPT-2
fine-tuned on a large cooking recipe dataset. Moreover, the recipe evaluation
module allows the users to conveniently inspect the quality of the generated
recipe contents and store the results for future reference. RecipeGPT can be
accessed online at https://recipegpt.org/.
","[{'version': 'v1', 'created': 'Thu, 5 Mar 2020 09:25:30 GMT'}]",2020-10-28,"[['Lee', 'Helena H.', ''], ['Shu', 'Ke', ''], ['Achananuparp', 'Palakorn', ''], ['Prasetyo', 'Philips Kokoh', ''], ['Liu', 'Yue', ''], ['Lim', 'Ee-Peng', ''], ['Varshney', 'Lav R.', '']]"
1370250,2010.13920,Chien-Sheng Wu,Chien-Sheng Wu and Steven Hoi and Caiming Xiong,Improving Limited Labeled Dialogue State Tracking with Self-Supervision,EMNLP 2020 (findings),,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Existing dialogue state tracking (DST) models require plenty of labeled data.
However, collecting high-quality labels is costly, especially when the number
of domains increases. In this paper, we address a practical DST problem that is
rarely discussed, i.e., learning efficiently with limited labeled data. We
present and investigate two self-supervised objectives: preserving latent
consistency and modeling conversational behavior. We encourage a DST model to
have consistent latent distributions given a perturbed input, making it more
robust to an unseen scenario. We also add an auxiliary utterance generation
task, modeling a potential correlation between conversational behavior and
dialogue states. The experimental results show that our proposed
self-supervised signals can improve joint goal accuracy by 8.95\% when only 1\%
labeled data is used on the MultiWOZ dataset. We can achieve an additional
1.76\% improvement if some unlabeled data is jointly trained as semi-supervised
learning. We analyze and visualize how our proposed self-supervised signals
help the DST task and hope to stimulate future data-efficient DST research.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 21:57:42 GMT'}]",2020-10-28,"[['Wu', 'Chien-Sheng', ''], ['Hoi', 'Steven', ''], ['Xiong', 'Caiming', '']]"
1370274,2010.13944,Khyathi Raghavi Chandu,"Khyathi Raghavi Chandu, Ruo-Ping Dong, Alan Black",Reading Between the Lines: Exploring Infilling in Visual Narratives,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Generating long form narratives such as stories and procedures from multiple
modalities has been a long standing dream for artificial intelligence. In this
regard, there is often crucial subtext that is derived from the surrounding
contexts. The general seq2seq training methods render the models shorthanded
while attempting to bridge the gap between these neighbouring contexts. In this
paper, we tackle this problem by using \textit{infilling} techniques involving
prediction of missing steps in a narrative while generating textual
descriptions from a sequence of images. We also present a new large scale
\textit{visual procedure telling} (ViPT) dataset with a total of 46,200
procedures and around 340k pairwise images and textual descriptions that is
rich in such contextual dependencies. Generating steps using infilling
technique demonstrates the effectiveness in visual procedures with more
coherent texts. We conclusively show a METEOR score of 27.51 on procedures
which is higher than the state-of-the-art on visual storytelling. We also
demonstrate the effects of interposing new text with missing images during
inference. The code and the dataset will be publicly available at
https://visual-narratives.github.io/Visual-Narratives/.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 23:09:09 GMT'}]",2020-10-28,"[['Chandu', 'Khyathi Raghavi', ''], ['Dong', 'Ruo-Ping', ''], ['Black', 'Alan', '']]"
1370312,2010.13982,Hung-Ting Chen,"Hung-Ting Chen, Yu-Chieh Chao, Ta-Hsuan Chao, Wei-Yun Ma",Predict and Use Latent Patterns for Short-Text Conversation,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Many neural network models nowadays have achieved promising performances in
Chit-chat settings. The majority of them rely on an encoder for understanding
the post and a decoder for generating the response. Without given assigned
semantics, the models lack the fine-grained control over responses as the
semantic mapping between posts and responses is hidden on the fly within the
end-to-end manners. Some previous works utilize sampled latent words as a
controllable semantic form to drive the generated response around the work, but
few works attempt to use more complex semantic forms to guide the generation.
In this paper, we propose to use more detailed semantic forms, including latent
responses and part-of-speech sequences sampled from the corresponding
distributions, as the controllable semantics to guide the generation. Our
experimental results show that the richer semantics are not only able to
provide informative and diverse responses, but also increase the overall
performance of response quality, including fluency and coherence.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 01:31:42 GMT'}]",2020-10-28,"[['Chen', 'Hung-Ting', ''], ['Chao', 'Yu-Chieh', ''], ['Chao', 'Ta-Hsuan', ''], ['Ma', 'Wei-Yun', '']]"
1370146,2010.13816,Maarten Sap,"Xinyao Ma, Maarten Sap, Hannah Rashkin, Yejin Choi","PowerTransformer: Unsupervised Controllable Revision for Biased Language
  Correction",EMNLP 2020,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Unconscious biases continue to be prevalent in modern text and media, calling
for algorithms that can assist writers with bias correction. For example, a
female character in a story is often portrayed as passive and powerless (""She
daydreams about being a doctor"") while a man is portrayed as more proactive and
powerful (""He pursues his dream of being a doctor"").
  We formulate *Controllable Debiasing*, a new revision task that aims to
rewrite a given text to correct the implicit and potentially undesirable bias
in character portrayals. We then introduce PowerTransformer as an approach that
debiases text through the lens of connotation frames (Sap et al., 2017), which
encode pragmatic knowledge of implied power dynamics with respect to verb
predicates. One key challenge of our task is the lack of parallel corpora. To
address this challenge, we adopt an unsupervised approach using auxiliary
supervision with related tasks such as paraphrasing and self-supervision based
on a reconstruction loss, building on pretrained language models.
  Through comprehensive experiments based on automatic and human evaluations,
we demonstrate that our approach outperforms ablations and existing methods
from related tasks. Furthermore, we demonstrate the use of PowerTransformer as
a step toward mitigating the well-documented gender bias in character portrayal
in movie scripts.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 18:05:48 GMT'}]",2020-10-28,"[['Ma', 'Xinyao', ''], ['Sap', 'Maarten', ''], ['Rashkin', 'Hannah', ''], ['Choi', 'Yejin', '']]"
1369704,2010.13374,Bruce W. Lee,Bruce W. Lee and Jason Hyung-Jong Lee,"LXPER Index 2.0: Improving Text Readability Assessment for L2 English
  Learners in South Korea","NLP-TEA, Association for Computational Linguistics",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Most text readability assessment models are developed for the native readers
of English and have low accuracy for texts in foreign English Language Training
(ELT) curriculum. In this paper, we investigate a text readability assessment
model for L2 English learners in Korea. In accordance, we improve and expand
the Text Corpus of the Korean ELT curriculum (CoKEC-text). Each text is labeled
with its target grade level. We train our model with CoKEC-text and
significantly improve the accuracy of readability assessment for texts in the
Korean ELT curriculum.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 07:03:14 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 17:04:03 GMT'}]",2020-10-28,"[['Lee', 'Bruce W.', ''], ['Lee', 'Jason Hyung-Jong', '']]"
1159525,1908.01355,Johan Bos,Johan Bos,Separating Argument Structure from Logical Structure in AMR,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The AMR (Abstract Meaning Representation) formalism for representing meaning
of natural language sentences was not designed to deal with scope and
quantifiers. By extending AMR with indices for contexts and formulating
constraints on these contexts, a formalism is derived that makes correct
prediction for inferences involving negation and bound variables. The
attractive core predicate-argument structure of AMR is preserved. The resulting
framework is similar to that of Discourse Representation Theory.
","[{'version': 'v1', 'created': 'Sun, 4 Aug 2019 14:46:35 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 14:54:01 GMT'}]",2020-10-28,"[['Bos', 'Johan', '']]"
1369424,2010.13094,Masahiro Kaneko,Masahiro Kaneko and Danushka Bollegala,Autoencoding Improves Pre-trained Word Embeddings,COLING 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Prior work investigating the geometry of pre-trained word embeddings have
shown that word embeddings to be distributed in a narrow cone and by centering
and projecting using principal component vectors one can increase the accuracy
of a given set of pre-trained word embeddings. However, theoretically, this
post-processing step is equivalent to applying a linear autoencoder to minimise
the squared l2 reconstruction error. This result contradicts prior work (Mu and
Viswanath, 2018) that proposed to remove the top principal components from
pre-trained embeddings. We experimentally verify our theoretical claims and
show that retaining the top principal components is indeed useful for improving
pre-trained word embeddings, without requiring access to additional linguistic
resources or labelled data.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 11:30:05 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 07:51:34 GMT'}]",2020-10-28,"[['Kaneko', 'Masahiro', ''], ['Bollegala', 'Danushka', '']]"
1370585,2010.14255,Jianing Wang,Jianing Wang and Chong Su,"Improving Reinforcement Learning for Neural Relation Extraction with
  Hierarchical Memory Extractor","9 pages, 7 figures, WWW2021 submission paper",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Distant supervision relation extraction (DSRE) is an efficient method to
extract semantic relations on a large-scale heuristic labeling corpus. However,
it usually brings in a massive noisy data. In order to alleviate this problem,
many recent approaches adopt reinforcement learning (RL), which aims to select
correct data autonomously before relation classification. Although these RL
methods outperform conventional multi-instance learning-based methods, there
are still two neglected problems: 1) the existing RL methods ignore the
feedback of noisy data, 2) the reduction of training corpus exacerbates
long-tail problem. In this paper, we propose a novel framework to solve the two
problems mentioned above. Firstly, we design a novel reward function to obtain
feedback from both correct and noisy data. In addition, we use implicit
relations information to improve RL. Secondly, we propose the hierarchical
memory extractor (HME), which utilizes the gating mechanism to share the
semantics from correlative instances between data-rich and data-poor classes.
Moreover, we define a hierarchical weighted ranking loss function to implement
top-down search processing. Extensive experiments conducted on the widely used
NYT dataset show significant improvement over state-of-the-art baseline
methods.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 12:50:27 GMT'}]",2020-10-28,"[['Wang', 'Jianing', ''], ['Su', 'Chong', '']]"
1370565,2010.14235,Yao Lu,"Yao Lu, Yue Dong, Laurent Charlin","Multi-XScience: A Large-scale Dataset for Extreme Multi-document
  Summarization of Scientific Articles",EMNLP 2020,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Multi-document summarization is a challenging task for which there exists
little large-scale datasets. We propose Multi-XScience, a large-scale
multi-document summarization dataset created from scientific articles.
Multi-XScience introduces a challenging multi-document summarization task:
writing the related-work section of a paper based on its abstract and the
articles it references. Our work is inspired by extreme summarization, a
dataset construction protocol that favours abstractive modeling approaches.
Descriptive statistics and empirical results---using several state-of-the-art
models trained on the Multi-XScience dataset---reveal that Multi-XScience is
well suited for abstractive models.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 12:10:19 GMT'}]",2020-10-28,"[['Lu', 'Yao', ''], ['Dong', 'Yue', ''], ['Charlin', 'Laurent', '']]"
1370564,2010.14234,Muvazima Mansoor,"Muvazima Mansoor, Kirthika Gurumurthy, Anantharam R U, V R Badri
  Prasad",Global Sentiment Analysis Of COVID-19 Tweets Over Time,"7 pages, 20 figures, Submitted to ICDSBDA 2020",,,,cs.CL cs.LG cs.SI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The Coronavirus pandemic has affected the normal course of life. People
around the world have taken to social media to express their opinions and
general emotions regarding this phenomenon that has taken over the world by
storm. The social networking site, Twitter showed an unprecedented increase in
tweets related to the novel Coronavirus in a very short span of time. This
paper presents the global sentiment analysis of tweets related to Coronavirus
and how the sentiment of people in different countries has changed over time.
Furthermore, to determine the impact of Coronavirus on daily aspects of life,
tweets related to Work From Home (WFH) and Online Learning were scraped and the
change in sentiment over time was observed. In addition, various Machine
Learning models such as Long Short Term Memory (LSTM) and Artificial Neural
Networks (ANN) were implemented for sentiment classification and their
accuracies were determined. Exploratory data analysis was also performed for a
dataset providing information about the number of confirmed cases on a per-day
basis in a few of the worst-hit countries to provide a comparison between the
change in sentiment with the change in cases since the start of this pandemic
till June 2020.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 12:10:10 GMT'}]",2020-10-28,"[['Mansoor', 'Muvazima', ''], ['Gurumurthy', 'Kirthika', ''], ['U', 'Anantharam R', ''], ['Prasad', 'V R Badri', '']]"
1020672,1809.00656,Larry Moss,Alex Kruckman and Lawrence S. Moss,Exploring the Landscape of Relational Syllogistic Logics,,,10.1017/S1755020320000386,,math.LO cs.CL cs.LO,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper explores relational syllogistic logics, a family of logical
systems related to reasoning about relations in extensions of the classical
syllogistic. These are all decidable logical systems. We prove completeness
theorems and complexity results for a natural subfamily of relational
syllogistic logics, parametrized by constructors for terms and for sentences.
","[{'version': 'v1', 'created': 'Mon, 3 Sep 2018 16:57:54 GMT'}]",2020-10-28,"[['Kruckman', 'Alex', ''], ['Moss', 'Lawrence S.', '']]"
1370563,2010.14233,Ethan Chi,"Ethan A. Chi, Julian Salazar, and Katrin Kirchhoff","Align-Refine: Non-Autoregressive Speech Recognition via Iterative
  Realignment",,,,,eess.AS cs.CL cs.LG cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Non-autoregressive models greatly improve decoding speed over typical
sequence-to-sequence models, but suffer from degraded performance. Infilling
and iterative refinement models make up some of this gap by editing the outputs
of a non-autoregressive model, but are constrained in the edits that they can
make. We propose iterative realignment, where refinements occur over latent
alignments rather than output sequence space. We demonstrate this in speech
recognition with Align-Refine, an end-to-end Transformer-based model which
refines connectionist temporal classification (CTC) alignments to allow
length-changing insertions and deletions. Align-Refine outperforms Imputer and
Mask-CTC, matching an autoregressive baseline on WSJ at 1/14th the real-time
factor and attaining a LibriSpeech test-other WER of 9.0% without an LM. Our
model is strong even in one iteration with a shallower decoder.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 09:35:37 GMT'}]",2020-10-28,"[['Chi', 'Ethan A.', ''], ['Salazar', 'Julian', ''], ['Kirchhoff', 'Katrin', '']]"
831602,1703.08098,Dat Quoc Nguyen,Dat Quoc Nguyen,"A survey of embedding models of entities and relationships for knowledge
  graph completion","In Proceedings of the 14th Workshop on Graph-Based Natural Language
  Processing (TextGraphs 2020); 16 pages, 2 figures, 6 tables",,,,cs.CL cs.AI cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Knowledge graphs (KGs) of real-world facts about entities and their
relationships are useful resources for a variety of natural language processing
tasks. However, because knowledge graphs are typically incomplete, it is useful
to perform knowledge graph completion or link prediction, i.e. predict whether
a relationship not in the knowledge graph is likely to be true. This paper
serves as a comprehensive survey of embedding models of entities and
relationships for knowledge graph completion, summarizing up-to-date
experimental results on standard benchmark datasets and pointing out potential
future research directions.
","[{'version': 'v1', 'created': 'Thu, 23 Mar 2017 15:15:26 GMT'}, {'version': 'v2', 'created': 'Tue, 28 Mar 2017 15:28:08 GMT'}, {'version': 'v3', 'created': 'Sat, 3 Feb 2018 04:39:45 GMT'}, {'version': 'v4', 'created': 'Tue, 9 Apr 2019 02:26:26 GMT'}, {'version': 'v5', 'created': 'Sat, 27 Apr 2019 13:33:30 GMT'}, {'version': 'v6', 'created': 'Fri, 28 Feb 2020 07:06:36 GMT'}, {'version': 'v7', 'created': 'Wed, 22 Apr 2020 11:58:35 GMT'}, {'version': 'v8', 'created': 'Mon, 10 Aug 2020 08:35:07 GMT'}, {'version': 'v9', 'created': 'Tue, 27 Oct 2020 04:11:25 GMT'}]",2020-10-28,"[['Nguyen', 'Dat Quoc', '']]"
1370453,2010.14123,Viet Lai,"Viet Dac Lai, Tuan Ngo Nguyen, Thien Huu Nguyen","Event Detection: Gate Diversity and Syntactic Importance Scoresfor Graph
  Convolution Neural Networks",EMNLP 2020,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Recent studies on event detection (ED) haveshown that the syntactic
dependency graph canbe employed in graph convolution neural net-works (GCN) to
achieve state-of-the-art per-formance. However, the computation of thehidden
vectors in such graph-based models isagnostic to the trigger candidate words,
po-tentially leaving irrelevant information for thetrigger candidate for event
prediction. In addi-tion, the current models for ED fail to exploitthe overall
contextual importance scores of thewords, which can be obtained via the
depen-dency tree, to boost the performance. In thisstudy, we propose a novel
gating mechanismto filter noisy information in the hidden vec-tors of the GCN
models for ED based on theinformation from the trigger candidate. Wealso
introduce novel mechanisms to achievethe contextual diversity for the gates and
theimportance score consistency for the graphsand models in ED. The experiments
show thatthe proposed model achieves state-of-the-artperformance on two ED
datasets
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 08:28:28 GMT'}]",2020-10-28,"[['Lai', 'Viet Dac', ''], ['Nguyen', 'Tuan Ngo', ''], ['Nguyen', 'Thien Huu', '']]"
1370314,2010.13984,Siwon Kim,"Siwon Kim, Jihun Yi, Eunji Kim, and Sungroh Yoon",Interpretation of NLP models through input marginalization,"10 pages, 5 figures, to be published in the 2020 Conference on
  Empirical Methods in Natural Language Processing (EMNLP 2020)",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  To demystify the ""black box"" property of deep neural networks for natural
language processing (NLP), several methods have been proposed to interpret
their predictions by measuring the change in prediction probability after
erasing each token of an input. Since existing methods replace each token with
a predefined value (i.e., zero), the resulting sentence lies out of the
training data distribution, yielding misleading interpretations. In this study,
we raise the out-of-distribution problem induced by the existing interpretation
methods and present a remedy; we propose to marginalize each token out. We
interpret various NLP models trained for sentiment analysis and natural
language inference using the proposed method.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 01:40:41 GMT'}]",2020-10-28,"[['Kim', 'Siwon', ''], ['Yi', 'Jihun', ''], ['Kim', 'Eunji', ''], ['Yoon', 'Sungroh', '']]"
1370156,2010.13826,Cheng-I Lai,"Cheng-I Lai, Yung-Sung Chuang, Hung-Yi Lee, Shang-Wen Li, James Glass","Semi-Supervised Spoken Language Understanding via Self-Supervised Speech
  and Language Model Pretraining",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Much recent work on Spoken Language Understanding (SLU) is limited in at
least one of three ways: models were trained on oracle text input and neglected
ASR errors, models were trained to predict only intents without the slot
values, or models were trained on a large amount of in-house data. In this
paper, we propose a clean and general framework to learn semantics directly
from speech with semi-supervision from transcribed or untranscribed speech to
address these issues. Our framework is built upon pretrained end-to-end (E2E)
ASR and self-supervised language models, such as BERT, and fine-tuned on a
limited amount of target SLU data. We study two semi-supervised settings for
the ASR component: supervised pretraining on transcribed speech, and
unsupervised pretraining by replacing the ASR encoder with self-supervised
speech representations, such as wav2vec. In parallel, we identify two essential
criteria for evaluating SLU models: environmental noise-robustness and E2E
semantics evaluation. Experiments on ATIS show that our SLU framework with
speech as input can perform on par with those using oracle text as input in
semantics understanding, even though environmental noise is present and a
limited amount of labeled semantics data is available for training.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 18:21:27 GMT'}]",2020-10-28,"[['Lai', 'Cheng-I', ''], ['Chuang', 'Yung-Sung', ''], ['Lee', 'Hung-Yi', ''], ['Li', 'Shang-Wen', ''], ['Glass', 'James', '']]"
1370432,2010.14102,Wen Wu,"Wen Wu, Chao Zhang, Philip C. Woodland","Emotion recognition by fusing time synchronous and time asynchronous
  representations",,,,,cs.CL cs.LG cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, a novel two-branch neural network model structure is proposed
for multimodal emotion recognition, which consists of a time synchronous branch
(TSB) and a time asynchronous branch (TAB). To capture correlations between
each word and its acoustic realisation, the TSB combines speech and text
modalities at each input window frame and then does pooling across time to form
a single embedding vector. The TAB, by contrast, provides cross-utterance
information by integrating sentence text embeddings from a number of context
utterances into another embedding vector. The final emotion classification uses
both the TSB and the TAB embeddings. Experimental results on the IEMOCAP
dataset demonstrate that the two-branch structure achieves state-of-the-art
results in 4-way classification with all common test setups. When using
automatic speech recognition (ASR) output instead of manually transcribed
reference text, it is shown that the cross-utterance information considerably
improves the robustness against ASR errors. Furthermore, by incorporating an
extra class for all the other emotions, the final 5-way classification system
with ASR hypotheses can be viewed as a prototype for more realistic emotion
recognition systems.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 07:14:31 GMT'}]",2020-10-28,"[['Wu', 'Wen', ''], ['Zhang', 'Chao', ''], ['Woodland', 'Philip C.', '']]"
1370391,2010.14061,Yan Zeng,Yan Zeng and Jian-Yun Nie,"Multi-Domain Dialogue State Tracking -- A Purely Transformer-Based
  Generative Approach","[v0], 8 pages, 3 figures. arXiv admin note: text overlap with
  arXiv:2010.11137",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We investigate the problem of multi-domain Dialogue State Tracking (DST) with
open vocabulary. Existing approaches exploit BERT encoder and copy-based RNN
decoder, where the encoder first predicts the state operation, and then the
decoder generates new slot values. However, in this stacked encoder-decoder
structure, the operation prediction objective only affects the BERT encoder and
the value generation objective mainly affects the RNN decoder. In this paper,
we propose a purely Transformer-based framework that uses BERT as both encoder
and decoder. In so doing, the operation prediction objective and the value
generation objective can jointly optimize our model for DST. At the decoding
step, we re-use the hidden states of the encoder in the self-attention
mechanism of the corresponding decoder layer to construct a flat model
structure for effective parameter updating. Experimental results show that our
approach substantially outperforms the existing state-of-the-art framework, and
it also achieves very competitive performance to the best ontology-based
approaches.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 04:54:52 GMT'}]",2020-10-28,"[['Zeng', 'Yan', ''], ['Nie', 'Jian-Yun', '']]"
1370372,2010.14042,Kasturi Bhattacharjee,"Kasturi Bhattacharjee, Miguel Ballesteros, Rishita Anubhai, Smaranda
  Muresan, Jie Ma, Faisal Ladhak, Yaser Al-Onaizan","To BERT or Not to BERT: Comparing Task-specific and Task-agnostic
  Semi-Supervised Approaches for Sequence Tagging","Accepted in the Proceedings of 2020 Conference on Empirical Methods
  in Natural Language Processing (EMNLP
  2020)(https://2020.emnlp.org/papers/main)",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Leveraging large amounts of unlabeled data using Transformer-like
architectures, like BERT, has gained popularity in recent times owing to their
effectiveness in learning general representations that can then be further
fine-tuned for downstream tasks to much success. However, training these models
can be costly both from an economic and environmental standpoint. In this work,
we investigate how to effectively use unlabeled data: by exploring the
task-specific semi-supervised approach, Cross-View Training (CVT) and comparing
it with task-agnostic BERT in multiple settings that include domain and task
relevant English data. CVT uses a much lighter model architecture and we show
that it achieves similar performance to BERT on a set of sequence tagging
tasks, with lesser financial and environmental impact.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 04:03:47 GMT'}]",2020-10-28,"[['Bhattacharjee', 'Kasturi', ''], ['Ballesteros', 'Miguel', ''], ['Anubhai', 'Rishita', ''], ['Muresan', 'Smaranda', ''], ['Ma', 'Jie', ''], ['Ladhak', 'Faisal', ''], ['Al-Onaizan', 'Yaser', '']]"
1370359,2010.14029,Runxin Xu,"Runxin Xu, Zhuo Zhi, Jun Cao, Mingxuan Wang, Lei Li",Volctrans Parallel Corpus Filtering System for WMT 2020,WMT 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we describe our submissions to the WMT20 shared task on
parallel corpus filtering and alignment for low-resource conditions. The task
requires the participants to align potential parallel sentence pairs out of the
given document pairs, and score them so that low-quality pairs can be filtered.
Our system, Volctrans, is made of two modules, i.e., a mining module and a
scoring module. Based on the word alignment model, the mining module adopts an
iterative mining strategy to extract latent parallel sentences. In the scoring
module, an XLM-based scorer provides scores, followed by reranking mechanisms
and ensemble. Our submissions outperform the baseline by 3.x/2.x and 2.x/2.x
for km-en and ps-en on From Scratch/Fine-Tune conditions, which is the highest
among all submissions.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 03:20:04 GMT'}]",2020-10-28,"[['Xu', 'Runxin', ''], ['Zhi', 'Zhuo', ''], ['Cao', 'Jun', ''], ['Wang', 'Mingxuan', ''], ['Li', 'Lei', '']]"
1370321,2010.13991,Wei Zou,"Dongwei Jiang, Wubo Li, Miao Cao, Ruixiong Zhang, Wei Zou, Kun Han,
  Xiangang Li","Speech SIMCLR: Combining Contrastive and Reconstruction Objective for
  Self-supervised Speech Representation Learning",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Self-supervised visual pretraining has shown significant progress recently.
Among those methods, SimCLR greatly advanced the state of the art in
self-supervised and semi-supervised learning on ImageNet. The input feature
representations for speech and visual tasks are both continuous, so it is
natural to consider applying similar objective on speech representation
learning. In this paper, we propose Speech SimCLR, a new self-supervised
objective for speech representation learning. During training, Speech SimCLR
applies augmentation on raw speech and its spectrogram. Its objective is the
combination of contrastive loss that maximizes agreement between differently
augmented samples in the latent space and reconstruction loss of input
representation. The proposed method achieved competitive results on speech
emotion recognition and speech recognition. When used as feature extractor, our
best model achieved 5.89% word error rate on LibriSpeech test-clean set using
LibriSpeech 960 hours as pretraining data and LibriSpeech train-clean-100 set
as fine-tuning data, which is the lowest error rate obtained in this setup to
the best of our knowledge.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 02:09:06 GMT'}]",2020-10-28,"[['Jiang', 'Dongwei', ''], ['Li', 'Wubo', ''], ['Cao', 'Miao', ''], ['Zhang', 'Ruixiong', ''], ['Zou', 'Wei', ''], ['Han', 'Kun', ''], ['Li', 'Xiangang', '']]"
1339591,2008.11869,Xinsong Zhang,Xinsong Zhang and Hang Li,AMBERT: A Pre-trained Language Model with Multi-Grained Tokenization,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pre-trained language models such as BERT have exhibited remarkable
performances in many tasks in natural language understanding (NLU). The tokens
in the models are usually fine-grained in the sense that for languages like
English they are words or sub-words and for languages like Chinese they are
characters. In English, for example, there are multi-word expressions which
form natural lexical units and thus the use of coarse-grained tokenization also
appears to be reasonable. In fact, both fine-grained and coarse-grained
tokenizations have advantages and disadvantages for learning of pre-trained
language models. In this paper, we propose a novel pre-trained language model,
referred to as AMBERT (A Multi-grained BERT), on the basis of both fine-grained
and coarse-grained tokenizations. For English, AMBERT takes both the sequence
of words (fine-grained tokens) and the sequence of phrases (coarse-grained
tokens) as input after tokenization, employs one encoder for processing the
sequence of words and the other encoder for processing the sequence of the
phrases, utilizes shared parameters between the two encoders, and finally
creates a sequence of contextualized representations of the words and a
sequence of contextualized representations of the phrases. Experiments have
been conducted on benchmark datasets for Chinese and English, including CLUE,
GLUE, SQuAD and RACE. The results show that AMBERT outperforms the existing
best performing models in almost all cases, particularly the improvements are
significant for Chinese.
","[{'version': 'v1', 'created': 'Thu, 27 Aug 2020 00:23:48 GMT'}, {'version': 'v2', 'created': 'Tue, 1 Sep 2020 05:29:27 GMT'}, {'version': 'v3', 'created': 'Tue, 27 Oct 2020 06:53:33 GMT'}]",2020-10-28,"[['Zhang', 'Xinsong', ''], ['Li', 'Hang', '']]"
1279334,2004.14564,Brian Thompson,Brian Thompson and Matt Post,"Automatic Machine Translation Evaluation in Many Languages via Zero-Shot
  Paraphrasing",EMNLP2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We frame the task of machine translation evaluation as one of scoring machine
translation output with a sequence-to-sequence paraphraser, conditioned on a
human reference. We propose training the paraphraser as a multilingual NMT
system, treating paraphrasing as a zero-shot translation task (e.g., Czech to
Czech). This results in the paraphraser's output mode being centered around a
copy of the input sequence, which represents the best case scenario where the
MT system output matches a human reference. Our method is simple and intuitive,
and does not require human judgements for training. Our single model (trained
in 39 languages) outperforms or statistically ties with all prior metrics on
the WMT 2019 segment-level shared metrics task in all languages (excluding
Gujarati where the model had no training data). We also explore using our model
for the task of quality estimation as a metric--conditioning on the source
instead of the reference--and find that it significantly outperforms every
submission to the WMT 2019 shared task on quality estimation in every language
pair.
","[{'version': 'v1', 'created': 'Thu, 30 Apr 2020 03:32:34 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 23:54:02 GMT'}]",2020-10-29,"[['Thompson', 'Brian', ''], ['Post', 'Matt', '']]"
1187463,1910.03544,Jianguo Zhang,"Jian-Guo Zhang, Kazuma Hashimoto, Chien-Sheng Wu, Yao Wan, Philip S.
  Yu, Richard Socher, Caiming Xiong","Find or Classify? Dual Strategy for Slot-Value Predictions on
  Multi-Domain Dialog State Tracking","14 pages, accepted at the 9th Joint Conference on Lexical and
  Computational Semantics (*SEM 2020). This version fixes small errors",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Dialog state tracking (DST) is a core component in task-oriented dialog
systems. Existing approaches for DST mainly fall into one of two categories,
namely, ontology-based and ontology-free methods. An ontology-based method
selects a value from a candidate-value list for each target slot, while an
ontology-free method extracts spans from dialog contexts. Recent work
introduced a BERT-based model to strike a balance between the two methods by
pre-defining categorical and non-categorical slots. However, it is not clear
enough which slots are better handled by either of the two slot types, and the
way to use the pre-trained model has not been well investigated. In this paper,
we propose a simple yet effective dual-strategy model for DST, by adapting a
single BERT-style reading comprehension model to jointly handle both the
categorical and non-categorical slots. Our experiments on the MultiWOZ datasets
show that our method significantly outperforms the BERT-based counterpart,
finding that the key is a deep interaction between the domain-slot and context
information. When evaluated on noisy (MultiWOZ 2.0) and cleaner (MultiWOZ 2.1)
settings, our method performs competitively and robustly across the two
different settings. Our method sets the new state of the art in the noisy
setting, while performing more robustly than the best model in the cleaner
setting. We also conduct a comprehensive error analysis on the dataset,
including the effects of the dual strategy for each slot, to facilitate future
research.
","[{'version': 'v1', 'created': 'Tue, 8 Oct 2019 17:08:39 GMT'}, {'version': 'v2', 'created': 'Thu, 10 Oct 2019 08:04:12 GMT'}, {'version': 'v3', 'created': 'Tue, 29 Sep 2020 08:37:44 GMT'}, {'version': 'v4', 'created': 'Wed, 28 Oct 2020 10:07:01 GMT'}]",2020-10-29,"[['Zhang', 'Jian-Guo', ''], ['Hashimoto', 'Kazuma', ''], ['Wu', 'Chien-Sheng', ''], ['Wan', 'Yao', ''], ['Yu', 'Philip S.', ''], ['Socher', 'Richard', ''], ['Xiong', 'Caiming', '']]"
1342828,2009.01325,Ryan Lowe T.,"Nisan Stiennon, Long Ouyang, Jeff Wu, Daniel M. Ziegler, Ryan Lowe,
  Chelsea Voss, Alec Radford, Dario Amodei, Paul Christiano",Learning to summarize from human feedback,NeurIPS 2020 camera ready,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As language models become more powerful, training and evaluation are
increasingly bottlenecked by the data and metrics used for a particular task.
For example, summarization models are often trained to predict human reference
summaries and evaluated using ROUGE, but both of these metrics are rough
proxies for what we really care about---summary quality. In this work, we show
that it is possible to significantly improve summary quality by training a
model to optimize for human preferences. We collect a large, high-quality
dataset of human comparisons between summaries, train a model to predict the
human-preferred summary, and use that model as a reward function to fine-tune a
summarization policy using reinforcement learning. We apply our method to a
version of the TL;DR dataset of Reddit posts and find that our models
significantly outperform both human reference summaries and much larger models
fine-tuned with supervised learning alone. Our models also transfer to CNN/DM
news articles, producing summaries nearly as good as the human reference
without any news-specific fine-tuning. We conduct extensive analyses to
understand our human feedback dataset and fine-tuned models We establish that
our reward model generalizes to new datasets, and that optimizing our reward
model results in better summaries than optimizing ROUGE according to humans. We
hope the evidence from our paper motivates machine learning researchers to pay
closer attention to how their training loss affects the model behavior they
actually want.
","[{'version': 'v1', 'created': 'Wed, 2 Sep 2020 19:54:41 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 22:19:53 GMT'}]",2020-10-29,"[['Stiennon', 'Nisan', ''], ['Ouyang', 'Long', ''], ['Wu', 'Jeff', ''], ['Ziegler', 'Daniel M.', ''], ['Lowe', 'Ryan', ''], ['Voss', 'Chelsea', ''], ['Radford', 'Alec', ''], ['Amodei', 'Dario', ''], ['Christiano', 'Paul', '']]"
1201327,1911.02733,Xue Mengge,"Xue Mengge, Yu Bowen, Liu Tingwen, Zhang Yue, Meng Erli, Wang Bin",Porous Lattice-based Transformer Encoder for Chinese NER,"9 pages, 4 figures",COLING 2020,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Incorporating lattices into character-level Chinese named entity recognition
is an effective method to exploit explicit word information. Recent works
extend recurrent and convolutional neural networks to model lattice inputs.
However, due to the DAG structure or the variable-sized potential word set for
lattice inputs, these models prevent the convenient use of batched computation,
resulting in serious inefficient. In this paper, we propose a porous
lattice-based transformer encoder for Chinese named entity recognition, which
is capable to better exploit the GPU parallelism and batch the computation
owing to the mask mechanism in transformer. We first investigate the
lattice-aware self-attention coupled with relative position representations to
explore effective word information in the lattice structure. Besides, to
strengthen the local dependencies among neighboring tokens, we propose a novel
porous structure during self-attentional computation processing, in which every
two non-neighboring tokens are connected through a shared pivot node.
Experimental results on four datasets show that our model performs up to 9.47
times faster than state-of-the-art models, while is roughly on a par with its
performance. The source code of this paper can be obtained from
https://github.com/xxx/xxx.
","[{'version': 'v1', 'created': 'Thu, 7 Nov 2019 02:58:17 GMT'}, {'version': 'v2', 'created': 'Fri, 24 Apr 2020 14:46:51 GMT'}, {'version': 'v3', 'created': 'Wed, 28 Oct 2020 12:52:24 GMT'}]",2020-10-29,"[['Mengge', 'Xue', ''], ['Bowen', 'Yu', ''], ['Tingwen', 'Liu', ''], ['Yue', 'Zhang', ''], ['Erli', 'Meng', ''], ['Bin', 'Wang', '']]"
1290078,2005.10283,Bryan Eikema,Bryan Eikema and Wilker Aziz,"Is MAP Decoding All You Need? The Inadequacy of the Mode in Neural
  Machine Translation",COLING 2020 camera-ready,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Recent studies have revealed a number of pathologies of neural machine
translation (NMT) systems. Hypotheses explaining these mostly suggest there is
something fundamentally wrong with NMT as a model or its training algorithm,
maximum likelihood estimation (MLE). Most of this evidence was gathered using
maximum a posteriori (MAP) decoding, a decision rule aimed at identifying the
highest-scoring translation, i.e. the mode. We argue that the evidence
corroborates the inadequacy of MAP decoding more than casts doubt on the model
and its training algorithm. In this work, we show that translation
distributions do reproduce various statistics of the data well, but that beam
search strays from such statistics. We show that some of the known pathologies
and biases of NMT are due to MAP decoding and not to NMT's statistical
assumptions nor MLE. In particular, we show that the most likely translations
under the model accumulate so little probability mass that the mode can be
considered essentially arbitrary. We therefore advocate for the use of decision
rules that take into account the translation distribution holistically. We show
that an approximation to minimum Bayes risk decoding gives competitive results
confirming that NMT models do capture important aspects of translation well in
expectation.
","[{'version': 'v1', 'created': 'Wed, 20 May 2020 18:05:51 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 11:29:52 GMT'}]",2020-10-29,"[['Eikema', 'Bryan', ''], ['Aziz', 'Wilker', '']]"
1303020,2006.08506,Tobias Watzel,"Tobias Watzel, Ludwig K\""urzinger, Lujun Li, Gerhard Rigoll",Regularized Forward-Backward Decoder for Attention Models,,,,,eess.AS cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Nowadays, attention models are one of the popular candidates for speech
recognition. So far, many studies mainly focus on the encoder structure or the
attention module to enhance the performance of these models. However, mostly
ignore the decoder. In this paper, we propose a novel regularization technique
incorporating a second decoder during the training phase. This decoder is
optimized on time-reversed target labels beforehand and supports the standard
decoder during training by adding knowledge from future context. Since it is
only added during training, we are not changing the basic structure of the
network or adding complexity during decoding. We evaluate our approach on the
smaller TEDLIUMv2 and the larger LibriSpeech dataset, achieving consistent
improvements on both of them.
","[{'version': 'v1', 'created': 'Mon, 15 Jun 2020 16:04:16 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 14:00:52 GMT'}]",2020-10-29,"[['Watzel', 'Tobias', ''], ['Kürzinger', 'Ludwig', ''], ['Li', 'Lujun', ''], ['Rigoll', 'Gerhard', '']]"
1295146,2006.00632,Barbara Plank,Alan Ramponi and Barbara Plank,Neural Unsupervised Domain Adaptation in NLP---A Survey,"COLING 2020. Accompanying repository:
  https://github.com/bplank/awesome-neural-adaptation-in-NLP",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Deep neural networks excel at learning from labeled data and achieve
state-of-the-art resultson a wide array of Natural Language Processing tasks.
In contrast, learning from unlabeled data, especially under domain shift,
remains a challenge. Motivated by the latest advances, in this survey we review
neural unsupervised domain adaptation techniques which do not require labeled
target domain data. This is a more challenging yet a more widely applicable
setup. We outline methods, from early traditional non-neural methods to
pre-trained model transfer. We also revisit the notion of domain, and we
uncover a bias in the type of Natural Language Processing tasks which received
most attention. Lastly, we outline future directions, particularly the broader
need for out-of-distribution generalization of future NLP.
","[{'version': 'v1', 'created': 'Sun, 31 May 2020 22:34:14 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 08:24:14 GMT'}]",2020-10-29,"[['Ramponi', 'Alan', ''], ['Plank', 'Barbara', '']]"
1292163,2005.12368,Marija Stepanovi\'c,"Andreas Kirkedal, Marija Stepanovi\'c, Barbara Plank",FT Speech: Danish Parliament Speech Corpus,Accepted at Interspeech 2020,,10.21437/Interspeech.2020-3164,,cs.CL cs.LG cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper introduces FT Speech, a new speech corpus created from the
recorded meetings of the Danish Parliament, otherwise known as the Folketing
(FT). The corpus contains over 1,800 hours of transcribed speech by a total of
434 speakers. It is significantly larger in duration, vocabulary, and amount of
spontaneous speech than the existing public speech corpora for Danish, which
are largely limited to read-aloud and dictation data. We outline design
considerations, including the preprocessing methods and the alignment
procedure. To evaluate the quality of the corpus, we train automatic speech
recognition systems on the new resource and compare them to the systems trained
on the Danish part of Spr\r{a}kbanken, the largest public ASR corpus for Danish
to date. Our baseline results show that we achieve a 14.01 WER on the new
corpus. A combination of FT Speech with in-domain language data provides
comparable results to models trained specifically on Spr\r{a}kbanken, showing
that FT Speech transfers well to this data set. Interestingly, our results
demonstrate that the opposite is not the case. This shows that FT Speech
provides a valuable resource for promoting research on Danish ASR with more
spontaneous speech.
","[{'version': 'v1', 'created': 'Mon, 25 May 2020 19:51:18 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 13:36:44 GMT'}]",2020-10-29,"[['Kirkedal', 'Andreas', ''], ['Stepanović', 'Marija', ''], ['Plank', 'Barbara', '']]"
1364540,2010.08210,Xue Mengge,"Mengge Xue, Bowen Yu, Zhenyu Zhang, Tingwen Liu, Yue Zhang, Bin Wang",Coarse-to-Fine Pre-training for Named Entity Recognition,,EMNLP 2020,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  More recently, Named Entity Recognition hasachieved great advances aided by
pre-trainingapproaches such as BERT. However, currentpre-training techniques
focus on building lan-guage modeling objectives to learn a gen-eral
representation, ignoring the named entity-related knowledge. To this end, we
proposea NER-specific pre-training framework to in-ject coarse-to-fine
automatically mined entityknowledge into pre-trained models. Specifi-cally, we
first warm-up the model via an en-tity span identification task by training it
withWikipedia anchors, which can be deemed asgeneral-typed entities. Then we
leverage thegazetteer-based distant supervision strategy totrain the model
extract coarse-grained typedentities. Finally, we devise a
self-supervisedauxiliary task to mine the fine-grained namedentity knowledge
via clustering.Empiricalstudies on three public NER datasets demon-strate that
our framework achieves significantimprovements against several pre-trained
base-lines, establishing the new state-of-the-art per-formance on three
benchmarks. Besides, weshow that our framework gains promising re-sults without
using human-labeled trainingdata, demonstrating its effectiveness in label-few
and low-resource scenarios
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 07:39:20 GMT'}]",2020-10-29,"[['Xue', 'Mengge', ''], ['Yu', 'Bowen', ''], ['Zhang', 'Zhenyu', ''], ['Liu', 'Tingwen', ''], ['Zhang', 'Yue', ''], ['Wang', 'Bin', '']]"
1361978,2010.05648,Steffen Eger,Steffen Eger and Yannik Benz,From Hero to Z\'eroe: A Benchmark of Low-Level Adversarial Attacks,"Authors accidentally in wrong order; cannot be undone due to
  conference constraints. Accepted for publication at AACL 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Adversarial attacks are label-preserving modifications to inputs of machine
learning classifiers designed to fool machines but not humans. Natural Language
Processing (NLP) has mostly focused on high-level attack scenarios such as
paraphrasing input texts. We argue that these are less realistic in typical
application scenarios such as in social media, and instead focus on low-level
attacks on the character-level. Guided by human cognitive abilities and human
robustness, we propose the first large-scale catalogue and benchmark of
low-level adversarial attacks, which we dub Z\'eroe, encompassing nine
different attack modes including visual and phonetic adversaries. We show that
RoBERTa, NLP's current workhorse, fails on our attacks. Our dataset provides a
benchmark for testing robustness of future more human-like NLP models.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 12:35:36 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 12:53:05 GMT'}]",2020-10-29,"[['Eger', 'Steffen', ''], ['Benz', 'Yannik', '']]"
1359177,2010.02847,Haiyang Zhang,"Haiyang Zhang, Alison Sneyd and Mark Stevenson","Robustness and Reliability of Gender Bias Assessment in Word Embeddings:
  The Role of Base Pairs",Accepted at AACL-IJCNLP 2020,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  It has been shown that word embeddings can exhibit gender bias, and various
methods have been proposed to quantify this. However, the extent to which the
methods are capturing social stereotypes inherited from the data has been
debated. Bias is a complex concept and there exist multiple ways to define it.
Previous work has leveraged gender word pairs to measure bias and extract
biased analogies. We show that the reliance on these gendered pairs has strong
limitations: bias measures based off of them are not robust and cannot identify
common types of real-world bias, whilst analogies utilising them are unsuitable
indicators of bias. In particular, the well-known analogy ""man is to
computer-programmer as woman is to homemaker"" is due to word similarity rather
than societal bias. This has important implications for work on measuring bias
in embeddings and related work debiasing embeddings.
","[{'version': 'v1', 'created': 'Tue, 6 Oct 2020 16:09:05 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 21:24:16 GMT'}]",2020-10-29,"[['Zhang', 'Haiyang', ''], ['Sneyd', 'Alison', ''], ['Stevenson', 'Mark', '']]"
1356617,2010.00287,Ehsan Doostmohammadi,"Ehsan Doostmohammadi, Minoo Nassajian, Adel Rahimi","Joint Persian Word Segmentation Correction and Zero-Width Non-Joiner
  Recognition Using BERT",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Words are properly segmented in the Persian writing system; in practice,
however, these writing rules are often neglected, resulting in single words
being written disjointedly and multiple words written without any white spaces
between them. This paper addresses the problems of word segmentation and
zero-width non-joiner (ZWNJ) recognition in Persian, which we approach jointly
as a sequence labeling problem. We achieved a macro-averaged F1-score of 92.40%
on a carefully collected corpus of 500 sentences with a high level of
difficulty.
","[{'version': 'v1', 'created': 'Thu, 1 Oct 2020 10:32:17 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 09:40:18 GMT'}]",2020-10-29,"[['Doostmohammadi', 'Ehsan', ''], ['Nassajian', 'Minoo', ''], ['Rahimi', 'Adel', '']]"
1280566,2005.00771,Xiang Li,"Michael Boratko, Xiang Lorraine Li, Rajarshi Das, Tim O'Gorman, Dan
  Le, Andrew McCallum","ProtoQA: A Question Answering Dataset for Prototypical Common-Sense
  Reasoning",First four authors contribute equally,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Given questions regarding some prototypical situation such as Name something
that people usually do before they leave the house for work? a human can easily
answer them via acquired experiences. There can be multiple right answers for
such questions, with some more common for a situation than others. This paper
introduces a new question answering dataset for training and evaluating common
sense reasoning capabilities of artificial intelligence systems in such
prototypical situations. The training set is gathered from an existing set of
questions played in a long-running international game show FAMILY- FEUD. The
hidden evaluation set is created by gathering answers for each question from
100 crowd-workers. We also propose a generative evaluation task where a model
has to output a ranked list of answers, ideally covering all prototypical
answers for a question. After presenting multiple competitive baseline models,
we find that human performance still exceeds model scores on all evaluation
metrics with a meaningful gap, supporting the challenging nature of the task.
","[{'version': 'v1', 'created': 'Sat, 2 May 2020 09:40:05 GMT'}, {'version': 'v2', 'created': 'Tue, 6 Oct 2020 05:35:05 GMT'}, {'version': 'v3', 'created': 'Tue, 27 Oct 2020 21:23:03 GMT'}]",2020-10-29,"[['Boratko', 'Michael', ''], ['Li', 'Xiang Lorraine', ''], ['Das', 'Rajarshi', ''], [""O'Gorman"", 'Tim', ''], ['Le', 'Dan', ''], ['McCallum', 'Andrew', '']]"
1279954,2005.00159,Pratyush Maini,"Pratyush Maini, Keshav Kolluru, Danish Pruthi, Mausam","Why and when should you pool? Analyzing Pooling in Recurrent
  Architectures","Accepted to Findings of EMNLP 2020, to be presented at BlackBoxNLP.
  Updated Version",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pooling-based recurrent neural architectures consistently outperform their
counterparts without pooling. However, the reasons for their enhanced
performance are largely unexamined. In this work, we examine three commonly
used pooling techniques (mean-pooling, max-pooling, and attention), and propose
max-attention, a novel variant that effectively captures interactions among
predictive tokens in a sentence. We find that pooling-based architectures
substantially differ from their non-pooling equivalents in their learning
ability and positional biases--which elucidate their performance benefits. By
analyzing the gradient propagation, we discover that pooling facilitates better
gradient flow compared to BiLSTMs. Further, we expose how BiLSTMs are
positionally biased towards tokens in the beginning and the end of a sequence.
Pooling alleviates such biases. Consequently, we identify settings where
pooling offers large benefits: (i) in low resource scenarios, and (ii) when
important words lie towards the middle of the sentence. Among the pooling
techniques studied, max-attention is the most effective, resulting in
significant performance gains on several text classification tasks.
","[{'version': 'v1', 'created': 'Fri, 1 May 2020 00:47:37 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 02:11:02 GMT'}]",2020-10-29,"[['Maini', 'Pratyush', ''], ['Kolluru', 'Keshav', ''], ['Pruthi', 'Danish', ''], ['Mausam', '', '']]"
1332657,2008.04935,Brian Thompson,Brian Thompson and Matt Post,"Paraphrase Generation as Zero-Shot Multilingual Translation:
  Disentangling Semantic Similarity from Lexical and Syntactic Diversity",WMT2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent work has shown that a multilingual neural machine translation (NMT)
model can be used to judge how well a sentence paraphrases another sentence in
the same language (Thompson and Post, 2020); however, attempting to generate
paraphrases from such a model using standard beam search produces trivial
copies or near copies. We introduce a simple paraphrase generation algorithm
which discourages the production of n-grams that are present in the input. Our
approach enables paraphrase generation in many languages from a single
multilingual NMT model. Furthermore, the amount of lexical diversity between
the input and output can be controlled at generation time. We conduct a human
evaluation to compare our method to a paraphraser trained on the large English
synthetic paraphrase database ParaBank 2 (Hu et al., 2019c) and find that our
method produces paraphrases that better preserve meaning and are more
gramatical, for the same level of lexical diversity. Additional smaller human
assessments demonstrate our approach also works in two non-English languages.
","[{'version': 'v1', 'created': 'Tue, 11 Aug 2020 18:05:34 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 02:54:13 GMT'}]",2020-10-29,"[['Thompson', 'Brian', ''], ['Post', 'Matt', '']]"
1349467,2009.07964,Zhijing Jin,"Xiaoyu Xing, Zhijing Jin, Di Jin, Bingning Wang, Qi Zhang, and
  Xuanjing Huang","Tasty Burgers, Soggy Fries: Probing Aspect Robustness in Aspect-Based
  Sentiment Analysis","EMNLP 2020, long paper",,,,cs.CL cs.IR cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  Aspect-based sentiment analysis (ABSA) aims to predict the sentiment towards
a specific aspect in the text. However, existing ABSA test sets cannot be used
to probe whether a model can distinguish the sentiment of the target aspect
from the non-target aspects. To solve this problem, we develop a simple but
effective approach to enrich ABSA test sets. Specifically, we generate new
examples to disentangle the confounding sentiments of the non-target aspects
from the target aspect's sentiment. Based on the SemEval 2014 dataset, we
construct the Aspect Robustness Test Set (ARTS) as a comprehensive probe of the
aspect robustness of ABSA models. Over 92% data of ARTS show high fluency and
desired sentiment on all aspects by human evaluation. Using ARTS, we analyze
the robustness of nine ABSA models, and observe, surprisingly, that their
accuracy drops by up to 69.73%. We explore several ways to improve aspect
robustness, and find that adversarial training can improve models' performance
on ARTS by up to 32.85%. Our code and new test set are available at
https://github.com/zhijing-jin/ARTS_TestSet
","[{'version': 'v1', 'created': 'Wed, 16 Sep 2020 22:38:18 GMT'}, {'version': 'v2', 'created': 'Wed, 30 Sep 2020 05:36:10 GMT'}, {'version': 'v3', 'created': 'Sun, 4 Oct 2020 15:35:36 GMT'}, {'version': 'v4', 'created': 'Wed, 28 Oct 2020 08:19:36 GMT'}]",2020-10-29,"[['Xing', 'Xiaoyu', ''], ['Jin', 'Zhijing', ''], ['Jin', 'Di', ''], ['Wang', 'Bingning', ''], ['Zhang', 'Qi', ''], ['Huang', 'Xuanjing', '']]"
1303623,2006.09109,Steffen Eger,Steffen Eger and Johannes Daxenberger and Iryna Gurevych,"How to Probe Sentence Embeddings in Low-Resource Languages: On
  Structural Design Choices for Probing Task Evaluation",Accepted for Publication at CONLL 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Sentence encoders map sentences to real valued vectors for use in downstream
applications. To peek into these representations - e.g., to increase
interpretability of their results - probing tasks have been designed which
query them for linguistic knowledge. However, designing probing tasks for
lesser-resourced languages is tricky, because these often lack large-scale
annotated data or (high-quality) dependency parsers as a prerequisite of
probing task design in English. To investigate how to probe sentence embeddings
in such cases, we investigate sensitivity of probing task results to structural
design choices, conducting the first such large scale study. We show that
design choices like size of the annotated probing dataset and type of
classifier used for evaluation do (sometimes substantially) influence probing
outcomes. We then probe embeddings in a multilingual setup with design choices
that lie in a 'stable region', as we identify for English, and find that
results on English do not transfer to other languages. Fairer and more
comprehensive sentence-level probing evaluation should thus be carried out on
multiple languages in the future.
","[{'version': 'v1', 'created': 'Tue, 16 Jun 2020 12:37:50 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 12:38:37 GMT'}]",2020-10-29,"[['Eger', 'Steffen', ''], ['Daxenberger', 'Johannes', ''], ['Gurevych', 'Iryna', '']]"
1139420,1906.07234,Siyuan Feng,"Siyuan Feng, Tan Lee, Zhiyuan Peng","Combining Adversarial Training and Disentangled Speech Representation
  for Robust Zero-Resource Subword Modeling","5 pages, 3 figures, accepted for publication in INTERSPEECH 2019,
  Graz, Austria",,10.21437/Interspeech.2019-1337,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This study addresses the problem of unsupervised subword unit discovery from
untranscribed speech. It forms the basis of the ultimate goal of ZeroSpeech
2019, building text-to-speech systems without text labels. In this work, unit
discovery is formulated as a pipeline of phonetically discriminative feature
learning and unit inference. One major difficulty in robust unsupervised
feature learning is dealing with speaker variation. Here the robustness towards
speaker variation is achieved by applying adversarial training and FHVAE based
disentangled speech representation learning. A comparison of the two approaches
as well as their combination is studied in a DNN-bottleneck feature (DNN-BNF)
architecture. Experiments are conducted on ZeroSpeech 2019 and 2017.
Experimental results on ZeroSpeech 2017 show that both approaches are effective
while the latter is more prominent, and that their combination brings further
marginal improvement in across-speaker condition. Results on ZeroSpeech 2019
show that in the ABX discriminability task, our approaches significantly
outperform the official baseline, and are competitive to or even outperform the
official topline. The proposed unit sequence smoothing algorithm improves
synthesis quality, at a cost of slight decrease in ABX discriminability.
","[{'version': 'v1', 'created': 'Mon, 17 Jun 2019 19:40:46 GMT'}, {'version': 'v2', 'created': 'Wed, 3 Jul 2019 12:22:28 GMT'}, {'version': 'v3', 'created': 'Fri, 9 Aug 2019 15:55:00 GMT'}]",2020-10-29,"[['Feng', 'Siyuan', ''], ['Lee', 'Tan', ''], ['Peng', 'Zhiyuan', '']]"
1371089,2010.14759,Yufang Hou,Yufang Hou,"Fine-grained Information Status Classification Using Discourse
  Context-Aware BERT","accepted at COLING2020. arXiv admin note: substantial text overlap
  with arXiv:1908.04755",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Previous work on bridging anaphora recognition (Hou et al., 2013a) casts the
problem as a subtask of learning fine-grained information status (IS). However,
these systems heavily depend on many hand-crafted linguistic features. In this
paper, we propose a simple discourse context-aware BERT model for fine-grained
IS classification. On the ISNotes corpus (Markert et al., 2012), our model
achieves new state-of-the-art performance on fine-grained IS classification,
obtaining a 4.8 absolute overall accuracy improvement compared to Hou et al.
(2013a). More importantly, we also show an improvement of 10.5 F1 points for
bridging anaphora recognition without using any complex hand-crafted semantic
features designed for capturing the bridging phenomenon. We further analyze the
trained model and find that the most attended signals for each IS category
correspond well to linguistic notions of information status.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 22:30:17 GMT'}]",2020-10-29,"[['Hou', 'Yufang', '']]"
1371128,2010.14798,Shuai Zhang,"Shuai Zhang, Jiangyan Yi, Zhengkun Tian, Ye Bai, Jianhua Tao, Zhengqi
  wen","Decoupling Pronunciation and Language for End-to-end Code-switching
  Automatic Speech Recognition","5 pages, 1 figures",,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite the recent significant advances witnessed in end-to-end (E2E) ASR
system for code-switching, hunger for audio-text paired data limits the further
improvement of the models' performance. In this paper, we propose a decoupled
transformer model to use monolingual paired data and unpaired text data to
alleviate the problem of code-switching data shortage. The model is decoupled
into two parts: audio-to-phoneme (A2P) network and phoneme-to-text (P2T)
network. The A2P network can learn acoustic pattern scenarios using large-scale
monolingual paired data. Meanwhile, it generates multiple phoneme sequence
candidates for single audio data in real-time during the training process. Then
the generated phoneme-text paired data is used to train the P2T network. This
network can be pre-trained with large amounts of external unpaired text data.
By using monolingual data and unpaired text data, the decoupled transformer
model reduces the high dependency on code-switching paired training data of E2E
model to a certain extent. Finally, the two networks are optimized jointly
through attention fusion. We evaluate the proposed method on the public
Mandarin-English code-switching dataset. Compared with our transformer
baseline, the proposed method achieves 18.14% relative mix error rate
reduction.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 07:46:15 GMT'}]",2020-10-29,"[['Zhang', 'Shuai', ''], ['Yi', 'Jiangyan', ''], ['Tian', 'Zhengkun', ''], ['Bai', 'Ye', ''], ['Tao', 'Jianhua', ''], ['wen', 'Zhengqi', '']]"
1371202,2010.14872,Kristian Miok,"Kristian Miok, Gregor Pirs and Marko Robnik-Sikonja",Bayesian Methods for Semi-supervised Text Annotation,"Accepted for COLING 2020, The 14th Linguistic Annotation Workshop",,,,cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Human annotations are an important source of information in the development
of natural language understanding approaches. As under the pressure of
productivity annotators can assign different labels to a given text, the
quality of produced annotations frequently varies. This is especially the case
if decisions are difficult, with high cognitive load, requires awareness of
broader context, or careful consideration of background knowledge. To alleviate
the problem, we propose two semi-supervised methods to guide the annotation
process: a Bayesian deep learning model and a Bayesian ensemble method. Using a
Bayesian deep learning method, we can discover annotations that cannot be
trusted and might require reannotation. A recently proposed Bayesian ensemble
method helps us to combine the annotators' labels with predictions of trained
models. According to the results obtained from three hate speech detection
experiments, the proposed Bayesian methods can improve the annotations and
prediction performance of BERT models.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 10:42:04 GMT'}]",2020-10-29,"[['Miok', 'Kristian', ''], ['Pirs', 'Gregor', ''], ['Robnik-Sikonja', 'Marko', '']]"
1371171,2010.14841,Chengyu Wang,"Yiwu Yao, Yuchao Li, Chengyu Wang, Tianhang Yu, Houjiang Chen,
  Xiaotang Jiang, Jun Yang, Jun Huang, Wei Lin, Hui Shu, Chengfei Lv","INT8 Winograd Acceleration for Conv1D Equipped ASR Models Deployed on
  Mobile Devices",,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The intensive computation of Automatic Speech Recognition (ASR) models
obstructs them from being deployed on mobile devices. In this paper, we present
a novel quantized Winograd optimization pipeline, which combines the
quantization and fast convolution to achieve efficient inference acceleration
on mobile devices for ASR models. To avoid the information loss due to the
combination of quantization and Winograd convolution, a Range-Scaled
Quantization (RSQ) training method is proposed to expand the quantized
numerical range and to distill knowledge from high-precision values. Moreover,
an improved Conv1D equipped DFSMN (ConvDFSMN) model is designed for mobile
deployment. We conduct extensive experiments on both ConvDFSMN and Wav2letter
models. Results demonstrate the models can be effectively optimized with the
proposed pipeline. Especially, Wav2letter achieves 1.48* speedup with an
approximate 0.07% WER decrease on ARMv7-based mobile devices.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 09:25:49 GMT'}]",2020-10-29,"[['Yao', 'Yiwu', ''], ['Li', 'Yuchao', ''], ['Wang', 'Chengyu', ''], ['Yu', 'Tianhang', ''], ['Chen', 'Houjiang', ''], ['Jiang', 'Xiaotang', ''], ['Yang', 'Jun', ''], ['Huang', 'Jun', ''], ['Lin', 'Wei', ''], ['Shu', 'Hui', ''], ['Lv', 'Chengfei', '']]"
1371136,2010.14806,Xiao Pan,"Liwei Wu, Xiao Pan, Zehui Lin, Yaoming Zhu, Mingxuan Wang, Lei Li",The Volctrans Machine Translation System for WMT20,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper describes our VolcTrans system on WMT20 shared news translation
task. We participated in 8 translation directions. Our basic systems are based
on Transformer, with several variants (wider or deeper Transformers, dynamic
convolutions). The final system includes text pre-process, data selection,
synthetic data generation, advanced model ensemble, and multilingual
pre-training.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 08:08:12 GMT'}]",2020-10-29,"[['Wu', 'Liwei', ''], ['Pan', 'Xiao', ''], ['Lin', 'Zehui', ''], ['Zhu', 'Yaoming', ''], ['Wang', 'Mingxuan', ''], ['Li', 'Lei', '']]"
1371134,2010.14804,Benlai Tang,"Zhonghao Li, Benlai Tang, Xiang Yin, Yuan Wan, Ling Xu, Chen Shen,
  Zejun Ma","PPG-based singing voice conversion with adversarial representation
  learning",,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Singing voice conversion (SVC) aims to convert the voice of one singer to
that of other singers while keeping the singing content and melody. On top of
recent voice conversion works, we propose a novel model to steadily convert
songs while keeping their naturalness and intonation. We build an end-to-end
architecture, taking phonetic posteriorgrams (PPGs) as inputs and generating
mel spectrograms. Specifically, we implement two separate encoders: one encodes
PPGs as content, and the other compresses mel spectrograms to supply acoustic
and musical information. To improve the performance on timbre and melody, an
adversarial singer confusion module and a mel-regressive representation
learning module are designed for the model. Objective and subjective
experiments are conducted on our private Chinese singing corpus. Comparing with
the baselines, our methods can significantly improve the conversion performance
in terms of naturalness, melody, and voice similarity. Moreover, our PPG-based
method is proved to be robust for noisy sources.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 08:03:27 GMT'}]",2020-10-29,"[['Li', 'Zhonghao', ''], ['Tang', 'Benlai', ''], ['Yin', 'Xiang', ''], ['Wan', 'Yuan', ''], ['Xu', 'Ling', ''], ['Shen', 'Chen', ''], ['Ma', 'Zejun', '']]"
1371124,2010.14794,Kun Zhou,"Kun Zhou, Berrak Sisman, Rui Liu and Haizhou Li","Seen and Unseen emotional style transfer for voice conversion with a new
  emotional speech dataset",Submitted to ICASSP 2021,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Emotional voice conversion aims to transform emotional prosody in speech
while preserving the linguistic content and speaker identity. Prior studies
show that it is possible to disentangle emotional prosody using an
encoder-decoder network conditioned on discrete representation, such as one-hot
emotion labels. Such networks learn to remember a fixed set of emotional
styles. In this paper, we propose a novel framework based on variational
auto-encoding Wasserstein generative adversarial network (VAW-GAN), which makes
use of a pre-trained speech emotion recognition (SER) model to transfer
emotional style during training and at run-time inference. In this way, the
network is able to transfer both seen and unseen emotional style to a new
utterance. We show that the proposed framework achieves remarkable performance
by consistently outperforming the baseline framework. This paper also marks the
release of an emotional speech dataset (ESD) for voice conversion, which has
multiple speakers and languages.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 07:16:18 GMT'}]",2020-10-29,"[['Zhou', 'Kun', ''], ['Sisman', 'Berrak', ''], ['Liu', 'Rui', ''], ['Li', 'Haizhou', '']]"
1371114,2010.14784,Yuanhao Zhuo,Yuanhao Zhuo,"A Chinese Text Classification Method With Low Hardware Requirement Based
  on Improved Model Concatenation","5 pages, 2 figures, 5 tables",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In order to improve the accuracy performance of Chinese text classification
models with low hardware requirements, an improved concatenation-based model is
designed in this paper, which is a concatenation of 5 different sub-models,
including TextCNN, LSTM, and Bi-LSTM. Compared with the existing ensemble
learning method, for a text classification mission, this model's accuracy is 2%
higher. Meanwhile, the hardware requirements of this model are much lower than
the BERT-based model.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 06:32:41 GMT'}]",2020-10-29,"[['Zhuo', 'Yuanhao', '']]"
1371060,2010.14730,Xiaoyu Kou,"Xiaoyu Kou, Yankai Lin, Yuntao Li, Jiahao Xu, Peng Li, Jie Zhou, Yan
  Zhang",DisenE: Disentangling Knowledge Graph Embeddings,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Knowledge graph embedding (KGE), aiming to embed entities and relations into
low-dimensional vectors, has attracted wide attention recently. However, the
existing research is mainly based on the black-box neural models, which makes
it difficult to interpret the learned representation. In this paper, we
introduce DisenE, an end-to-end framework to learn disentangled knowledge graph
embeddings. Specially, we introduce an attention-based mechanism that enables
the model to explicitly focus on relevant components of entity embeddings
according to a given relation. Furthermore, we introduce two novel regularizers
to encourage each component of the entity representation to independently
reflect an isolated semantic aspect. Experimental results demonstrate that our
proposed DisenE investigates a perspective to address the interpretability of
KGE and is proved to be an effective way to improve the performance of link
prediction tasks. The code and datasets are released on
https://github.com/KXY-PUBLIC/DisenE.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 03:45:19 GMT'}]",2020-10-29,"[['Kou', 'Xiaoyu', ''], ['Lin', 'Yankai', ''], ['Li', 'Yuntao', ''], ['Xu', 'Jiahao', ''], ['Li', 'Peng', ''], ['Zhou', 'Jie', ''], ['Zhang', 'Yan', '']]"
1371055,2010.14725,Ruchao Fan,"Ruchao Fan, Wei Chu, Peng Chang, Jing Xiao","CASS-NAT: CTC Alignment-based Single Step Non-autoregressive Transformer
  for Speech Recognition",Submitted to ICASSP2021,,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a CTC alignment-based single step non-autoregressive transformer
(CASS-NAT) for speech recognition. Specifically, the CTC alignment contains the
information of (a) the number of tokens for decoder input, and (b) the time
span of acoustics for each token. The information are used to extract acoustic
representation for each token in parallel, referred to as token-level acoustic
embedding which substitutes the word embedding in autoregressive transformer
(AT) to achieve parallel generation in decoder. During inference, an
error-based alignment sampling method is proposed to be applied to the CTC
output space, reducing the WER and retaining the parallelism as well.
Experimental results show that the proposed method achieves WERs of 3.8%/9.1%
on Librispeech test clean/other dataset without an external LM, and a CER of
5.8% on Aishell1 Mandarin corpus, respectively1. Compared to the AT baseline,
the CASS-NAT has a performance reduction on WER, but is 51.2x faster in terms
of RTF. When decoding with an oracle CTC alignment, the lower bound of WER
without LM reaches 2.3% on the test-clean set, indicating the potential of the
proposed method.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 03:14:05 GMT'}]",2020-10-29,"[['Fan', 'Ruchao', ''], ['Chu', 'Wei', ''], ['Chang', 'Peng', ''], ['Xiao', 'Jing', '']]"
1272816,2004.08046,Dongyu Ru,"Dongyu Ru, Jiangtao Feng, Lin Qiu, Hao Zhou, Mingxuan Wang, Weinan
  Zhang, Yong Yu, Lei Li","Active Sentence Learning by Adversarial Uncertainty Sampling in Discrete
  Space",Accepted to EMNLP 2020 Findings,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Active learning for sentence understanding aims at discovering informative
unlabeled data for annotation and therefore reducing the demand for labeled
data. We argue that the typical uncertainty sampling method for active learning
is time-consuming and can hardly work in real-time, which may lead to
ineffective sample selection. We propose adversarial uncertainty sampling in
discrete space (AUSDS) to retrieve informative unlabeled samples more
efficiently. AUSDS maps sentences into latent space generated by the popular
pre-trained language models, and discover informative unlabeled text samples
for annotation via adversarial attack. The proposed approach is extremely
efficient compared with traditional uncertainty sampling with more than 10x
speedup. Experimental results on five datasets show that AUSDS outperforms
strong baselines on effectiveness.
","[{'version': 'v1', 'created': 'Fri, 17 Apr 2020 03:12:34 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 04:45:49 GMT'}]",2020-10-29,"[['Ru', 'Dongyu', ''], ['Feng', 'Jiangtao', ''], ['Qiu', 'Lin', ''], ['Zhou', 'Hao', ''], ['Wang', 'Mingxuan', ''], ['Zhang', 'Weinan', ''], ['Yu', 'Yong', ''], ['Li', 'Lei', '']]"
1371050,2010.14720,Songlin Yang,"Songlin Yang, Yong Jiang, Wenjuan Han, Kewei Tu",Second-Order Unsupervised Neural Dependency Parsing,COLING 2020 camera ready,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Most of the unsupervised dependency parsers are based on first-order
probabilistic generative models that only consider local parent-child
information. Inspired by second-order supervised dependency parsing, we
proposed a second-order extension of unsupervised neural dependency models that
incorporate grandparent-child or sibling information. We also propose a novel
design of the neural parameterization and optimization methods of the
dependency models. In second-order models, the number of grammar rules grows
cubically with the increase of vocabulary size, making it difficult to train
lexicalized models that may contain thousands of words. To circumvent this
problem while still benefiting from both second-order parsing and
lexicalization, we use the agreement-based learning framework to jointly train
a second-order unlexicalized model and a first-order lexicalized model.
Experiments on multiple datasets show the effectiveness of our second-order
models compared with recent state-of-the-art methods. Our joint model achieves
a 10% improvement over the previous state-of-the-art parser on the full WSJ
test set
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 03:01:33 GMT'}]",2020-10-29,"[['Yang', 'Songlin', ''], ['Jiang', 'Yong', ''], ['Han', 'Wenjuan', ''], ['Tu', 'Kewei', '']]"
1371037,2010.14707,Yang Qian,"Yang Qian, Yuanchun Jiang, Yidong Chai, Yezheng Liu, Jiansha Sun",TopicModel4J: A Java Package for Topic Models,,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Topic models provide a flexible and principled framework for exploring hidden
structure in high-dimensional co-occurrence data and are commonly used natural
language processing (NLP) of text. In this paper, we design and implement a
Java package, TopicModel4J, which contains 13 kinds of representative
algorithms for fitting topic models. The TopicModel4J in the Java programming
environment provides an easy-to-use interface for data analysts to run the
algorithms, and allow to easily input and output data. In addition, this
package provides a few unstructured text preprocessing techniques, such as
splitting textual data into words, lowercasing the words, preforming
lemmatization and removing the useless characters, URLs and stop words.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 02:33:41 GMT'}]",2020-10-29,"[['Qian', 'Yang', ''], ['Jiang', 'Yuanchun', ''], ['Chai', 'Yidong', ''], ['Liu', 'Yezheng', ''], ['Sun', 'Jiansha', '']]"
1371031,2010.14701,Samuel McCandlish,"Tom Henighan, Jared Kaplan, Mor Katz, Mark Chen, Christopher Hesse,
  Jacob Jackson, Heewoo Jun, Tom B. Brown, Prafulla Dhariwal, Scott Gray, Chris
  Hallacy, Benjamin Mann, Alec Radford, Aditya Ramesh, Nick Ryder, Daniel M.
  Ziegler, John Schulman, Dario Amodei, Sam McCandlish",Scaling Laws for Autoregressive Generative Modeling,"20+15 pages, 30 figures",,,,cs.LG cs.CL cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We identify empirical scaling laws for the cross-entropy loss in four
domains: generative image modeling, video modeling, multimodal
image$\leftrightarrow$text models, and mathematical problem solving. In all
cases autoregressive Transformers smoothly improve in performance as model size
and compute budgets increase, following a power-law plus constant scaling law.
The optimal model size also depends on the compute budget through a power-law,
with exponents that are nearly universal across all data domains.
  The cross-entropy loss has an information theoretic interpretation as
$S($True$) + D_{\mathrm{KL}}($True$||$Model$)$, and the empirical scaling laws
suggest a prediction for both the true data distribution's entropy and the KL
divergence between the true and model distributions. With this interpretation,
billion-parameter Transformers are nearly perfect models of the YFCC100M image
distribution downsampled to an $8\times 8$ resolution, and we can forecast the
model size needed to achieve any given reducible loss (ie $D_{\mathrm{KL}}$) in
nats/image for other resolutions.
  We find a number of additional scaling laws in specific domains: (a) we
identify a scaling relation for the mutual information between captions and
images in multimodal models, and show how to answer the question ""Is a picture
worth a thousand words?""; (b) in the case of mathematical problem solving, we
identify scaling laws for model performance when extrapolating beyond the
training distribution; (c) we finetune generative image models for ImageNet
classification and find smooth scaling of the classification loss and error
rate, even as the generative loss levels off. Taken together, these results
strengthen the case that scaling laws have important implications for neural
network performance, including on downstream tasks.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 02:17:24 GMT'}]",2020-10-29,"[['Henighan', 'Tom', ''], ['Kaplan', 'Jared', ''], ['Katz', 'Mor', ''], ['Chen', 'Mark', ''], ['Hesse', 'Christopher', ''], ['Jackson', 'Jacob', ''], ['Jun', 'Heewoo', ''], ['Brown', 'Tom B.', ''], ['Dhariwal', 'Prafulla', ''], ['Gray', 'Scott', ''], ['Hallacy', 'Chris', ''], ['Mann', 'Benjamin', ''], ['Radford', 'Alec', ''], ['Ramesh', 'Aditya', ''], ['Ryder', 'Nick', ''], ['Ziegler', 'Daniel M.', ''], ['Schulman', 'John', ''], ['Amodei', 'Dario', ''], ['McCandlish', 'Sam', '']]"
1371027,2010.14697,Claire Bowern,Luke Lindemann and Claire Bowern,"Character Entropy in Modern and Historical Texts: Comparison Metrics for
  an Undeciphered Manuscript",,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  This paper outlines the creation of three corpora for multilingual comparison
and analysis of the Voynich manuscript: a corpus of Voynich texts partitioned
by Currier language, scribal hand, and transcription system, a corpus of 294
language samples compiled from Wikipedia, and a corpus of eighteen transcribed
historical texts in eight languages. These corpora will be utilized in
subsequent work by the Voynich Working Group at Yale University.
  We demonstrate the utility of these corpora for studying characteristics of
the Voynich script and language, with an analysis of conditional character
entropy in Voynichese. We discuss the interaction between character entropy and
language, script size and type, glyph compositionality, scribal conventions and
abbreviations, positional character variants, and bigram frequency.
  This analysis characterizes the interaction between script compositionality,
character size, and predictability. We show that substantial manipulations of
glyph composition are not sufficient to align conditional entropy levels with
natural languages. The unusually predictable nature of the Voynichese script is
not attributable to a particular script or transcription system, underlying
language, or substitution cipher. Voynichese is distinct from every comparison
text in our corpora because character placement is highly constrained within
the word, and this may indicate the loss of phonemic distinctions from the
underlying language.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 01:53:59 GMT'}]",2020-10-29,"[['Lindemann', 'Luke', ''], ['Bowern', 'Claire', '']]"
1371008,2010.14678,Amir Pouran Ben Veyseh,"Amir Pouran Ben Veyseh, Franck Dernoncourt, Quan Hung Tran, Thien Huu
  Nguyen","What Does This Acronym Mean? Introducing a New Dataset for Acronym
  Identification and Disambiguation",accepted at COLING 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Acronyms are the short forms of phrases that facilitate conveying lengthy
sentences in documents and serve as one of the mainstays of writing. Due to
their importance, identifying acronyms and corresponding phrases (i.e., acronym
identification (AI)) and finding the correct meaning of each acronym (i.e.,
acronym disambiguation (AD)) are crucial for text understanding. Despite the
recent progress on this task, there are some limitations in the existing
datasets which hinder further improvement. More specifically, limited size of
manually annotated AI datasets or noises in the automatically created acronym
identification datasets obstruct designing advanced high-performing acronym
identification models. Moreover, the existing datasets are mostly limited to
the medical domain and ignore other domains. In order to address these two
limitations, we first create a manually annotated large AI dataset for
scientific domain. This dataset contains 17,506 sentences which is
substantially larger than previous scientific AI datasets. Next, we prepare an
AD dataset for scientific domain with 62,441 samples which is significantly
larger than the previous scientific AD dataset. Our experiments show that the
existing state-of-the-art models fall far behind human-level performance on
both datasets proposed by this work. In addition, we propose a new deep
learning model that utilizes the syntactical structure of the sentence to
expand an ambiguous acronym in a sentence. The proposed model outperforms the
state-of-the-art models on the new AD dataset, providing a strong baseline for
future research on this dataset.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 00:12:36 GMT'}]",2020-10-29,"[['Veyseh', 'Amir Pouran Ben', ''], ['Dernoncourt', 'Franck', ''], ['Tran', 'Quan Hung', ''], ['Nguyen', 'Thien Huu', '']]"
1370995,2010.14665,Yongqiang Wang,"Yongqiang Wang, Yangyang Shi, Frank Zhang, Chunyang Wu, Julian Chan,
  Ching-Feng Yeh, Alex Xiao","Transformer in action: a comparative study of transformer-based acoustic
  models for large scale speech recognition applications",submitted to ICASSP2021,,,,cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we summarize the application of transformer and its streamable
variant, Emformer based acoustic model for large scale speech recognition
applications. We compare the transformer based acoustic models with their LSTM
counterparts on industrial scale tasks. Specifically, we compare Emformer with
latency-controlled BLSTM (LCBLSTM) on medium latency tasks and LSTM on low
latency tasks. On a low latency voice assistant task, Emformer gets 24% to 26%
relative word error rate reductions (WERRs). For medium latency scenarios,
comparing with LCBLSTM with similar model size and latency, Emformer gets
significant WERR across four languages in video captioning datasets with 2-3
times inference real-time factors reduction.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 23:04:21 GMT'}]",2020-10-29,"[['Wang', 'Yongqiang', ''], ['Shi', 'Yangyang', ''], ['Zhang', 'Frank', ''], ['Wu', 'Chunyang', ''], ['Chan', 'Julian', ''], ['Yeh', 'Ching-Feng', ''], ['Xiao', 'Alex', '']]"
1370990,2010.14660,Pierre Dognin,"Pierre L. Dognin, Igor Melnyk, Inkit Padhi, Cicero Nogueira dos
  Santos, Payel Das",DualTKB: A Dual Learning Bridge between Text and Knowledge Base,"Equal Contributions of Authors Pierre L. Dognin, Igor Melnyk, and
  Inkit Padhi. Accepted at EMNLP'20",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this work, we present a dual learning approach for unsupervised text to
path and path to text transfers in Commonsense Knowledge Bases (KBs). We
investigate the impact of weak supervision by creating a weakly supervised
dataset and show that even a slight amount of supervision can significantly
improve the model performance and enable better-quality transfers. We examine
different model architectures, and evaluation metrics, proposing a novel
Commonsense KB completion metric tailored for generative models. Extensive
experimental results show that the proposed method compares very favorably to
the existing baselines. This approach is a viable step towards a more advanced
system for automatic KB construction/expansion and the reverse operation of KB
conversion to coherent textual descriptions.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 22:56:18 GMT'}]",2020-10-29,"[['Dognin', 'Pierre L.', ''], ['Melnyk', 'Igor', ''], ['Padhi', 'Inkit', ''], ['Santos', 'Cicero Nogueira dos', ''], ['Das', 'Payel', '']]"
1370979,2010.14649,Takashi Wada,"Takashi Wada, Tomoharu Iwata, Yuji Matsumoto, Timothy Baldwin, Jey Han
  Lau","Learning Contextualised Cross-lingual Word Embeddings for Extremely
  Low-Resource Languages Using Parallel Corpora",9 pages,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a new approach for learning contextualised cross-lingual word
embeddings based only on a small parallel corpus (e.g. a few hundred sentence
pairs). Our method obtains word embeddings via an LSTM-based encoder-decoder
model that performs bidirectional translation and reconstruction of the input
sentence. Through sharing model parameters among different languages, our model
jointly trains the word embeddings in a common multilingual space. We also
propose a simple method to combine word and subword embeddings to make use of
orthographic similarities across different languages. We base our experiments
on real-world data from endangered languages, namely Yongning Na,
Shipibo-Konibo and Griko. Our experiments on bilingual lexicon induction and
word alignment tasks show that our model outperforms existing methods by a
large margin for most language pairs. These results demonstrate that, contrary
to common belief, an encoder-decoder translation model is beneficial for
learning cross-lingual representations, even in extremely low-resource
scenarios.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 22:24:01 GMT'}]",2020-10-29,"[['Wada', 'Takashi', ''], ['Iwata', 'Tomoharu', ''], ['Matsumoto', 'Yuji', ''], ['Baldwin', 'Timothy', ''], ['Lau', 'Jey Han', '']]"
1370936,2010.14606,Arun Narayanan,"Arun Narayanan, Tara N. Sainath, Ruoming Pang, Jiahui Yu, Chung-Cheng
  Chiu, Rohit Prabhavalkar, Ehsan Variani, Trevor Strohman",Cascaded encoders for unifying streaming and non-streaming ASR,,,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  End-to-end (E2E) automatic speech recognition (ASR) models, by now, have
shown competitive performance on several benchmarks. These models are
structured to either operate in streaming or non-streaming mode. This work
presents cascaded encoders for building a single E2E ASR model that can operate
in both these modes simultaneously. The proposed model consists of streaming
and non-streaming encoders. Input features are first processed by the streaming
encoder; the non-streaming encoder operates exclusively on the output of the
streaming encoder. A single decoder then learns to decode either using the
output of the streaming or the non-streaming encoder. Results show that this
model achieves similar word error rates (WER) as a standalone streaming model
when operating in streaming mode, and obtains 10% -- 27% relative improvement
when operating in non-streaming mode. Our results also show that the proposed
approach outperforms existing E2E two-pass models, especially on long-form
speech.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 20:59:50 GMT'}]",2020-10-29,"[['Narayanan', 'Arun', ''], ['Sainath', 'Tara N.', ''], ['Pang', 'Ruoming', ''], ['Yu', 'Jiahui', ''], ['Chiu', 'Chung-Cheng', ''], ['Prabhavalkar', 'Rohit', ''], ['Variani', 'Ehsan', ''], ['Strohman', 'Trevor', '']]"
1370918,2010.14588,Robert Leaman,Robert Leaman and Zhiyong Lu,"A Comprehensive Dictionary and Term Variation Analysis for COVID-19 and
  SARS-CoV-2",Accepted EMNLP NLP-COVID Workshop,,,,cs.DL cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The number of unique terms in the scientific literature used to refer to
either SARS-CoV-2 or COVID-19 is remarkably large and has continued to increase
rapidly despite well-established standardized terms. This high degree of term
variation makes high recall identification of these important entities
difficult. In this manuscript we present an extensive dictionary of terms used
in the literature to refer to SARS-CoV-2 and COVID-19. We use a rule-based
approach to iteratively generate new term variants, then locate these variants
in a large text corpus. We compare our dictionary to an extensive collection of
terminological resources, demonstrating that our resource provides a
substantial number of additional terms. We use our dictionary to analyze the
usage of SARS-CoV-2 and COVID-19 terms over time and show that the number of
unique terms continues to grow rapidly. Our dictionary is freely available at
https://github.com/ncbi-nlp/CovidTermVar.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 19:51:53 GMT'}]",2020-10-29,"[['Leaman', 'Robert', ''], ['Lu', 'Zhiyong', '']]"
1370917,2010.14587,Jean-Baptiste Lamare,"Jean-Baptiste Lamare, Tobi Olatunji, Li Yao",On the diminishing return of labeling clinical reports,"Accepted at the EMNLP 2020 Clinical NLP workshop, 9 pages + 2 for
  references, 7 figures, 4 tables",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Ample evidence suggests that better machine learning models may be steadily
obtained by training on increasingly larger datasets on natural language
processing (NLP) problems from non-medical domains. Whether the same holds true
for medical NLP has by far not been thoroughly investigated. This work shows
that this is indeed not always the case. We reveal the somehow
counter-intuitive observation that performant medical NLP models may be
obtained with small amount of labeled data, quite the opposite to the common
belief, most likely due to the domain specificity of the problem. We show
quantitatively the effect of training data size on a fixed test set composed of
two of the largest public chest x-ray radiology report datasets on the task of
abnormality classification. The trained models not only make use of the
training data efficiently, but also outperform the current state-of-the-art
rule-based systems by a significant margin.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 19:51:04 GMT'}]",2020-10-29,"[['Lamare', 'Jean-Baptiste', ''], ['Olatunji', 'Tobi', ''], ['Yao', 'Li', '']]"
1370906,2010.14576,Jeniya Tabassum,"Jeniya Tabassum, Sydney Lee, Wei Xu, Alan Ritter","WNUT-2020 Task 1 Overview: Extracting Entities and Relations from Wet
  Lab Protocols",to appear in EMNLP 2020 (WNUT),,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents the results of the wet lab information extraction task at
WNUT 2020. This task consisted of two sub tasks: (1) a Named Entity Recognition
(NER) task with 13 participants and (2) a Relation Extraction (RE) task with 2
participants. We outline the task, data annotation process, corpus statistics,
and provide a high-level overview of the participating systems for each sub
task.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 19:34:53 GMT'}]",2020-10-29,"[['Tabassum', 'Jeniya', ''], ['Lee', 'Sydney', ''], ['Xu', 'Wei', ''], ['Ritter', 'Alan', '']]"
1370898,2010.14568,Kaiyu Yang,"Kaiyu Yang, Jia Deng",Strongly Incremental Constituency Parsing with Graph Neural Networks,Accepted to NeurIPS 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Parsing sentences into syntax trees can benefit downstream applications in
NLP. Transition-based parsers build trees by executing actions in a state
transition system. They are computationally efficient, and can leverage machine
learning to predict actions based on partial trees. However, existing
transition-based parsers are predominantly based on the shift-reduce transition
system, which does not align with how humans are known to parse sentences.
Psycholinguistic research suggests that human parsing is strongly incremental:
humans grow a single parse tree by adding exactly one token at each step. In
this paper, we propose a novel transition system called attach-juxtapose. It is
strongly incremental; it represents a partial sentence using a single tree;
each action adds exactly one token into the partial tree. Based on our
transition system, we develop a strongly incremental parser. At each step, it
encodes the partial tree using a graph neural network and predicts an action.
We evaluate our parser on Penn Treebank (PTB) and Chinese Treebank (CTB). On
PTB, it outperforms existing parsers trained with only constituency trees; and
it performs on par with state-of-the-art parsers that use dependency trees as
additional training data. On CTB, our parser establishes a new state of the
art. Code is available at
https://github.com/princeton-vl/attach-juxtapose-parser.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 19:19:38 GMT'}]",2020-10-29,"[['Yang', 'Kaiyu', ''], ['Deng', 'Jia', '']]"
1370887,2010.14557,Ruizhe Li,"Xiao Li, Guanyi Chen, Chenghua Lin, Ruizhe Li",DGST: a Dual-Generator Network for Text Style Transfer,"Accepted by EMNLP 2020, camera ready version",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose DGST, a novel and simple Dual-Generator network architecture for
text Style Transfer. Our model employs two generators only, and does not rely
on any discriminators or parallel corpus for training. Both quantitative and
qualitative experiments on the Yelp and IMDb datasets show that our model gives
competitive performance compared to several strong baselines with more
complicated architecture designs.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 18:54:51 GMT'}]",2020-10-29,"[['Li', 'Xiao', ''], ['Chen', 'Guanyi', ''], ['Lin', 'Chenghua', ''], ['Li', 'Ruizhe', '']]"
1370864,2010.14534,Marion Bartl,Marion Bartl and Malvina Nissim and Albert Gatt,"Unmasking Contextual Stereotypes: Measuring and Mitigating BERT's Gender
  Bias","10 pages, 4 figures, to appear in Proceedings of the 2nd Workshop on
  Gender Bias in Natural Language Processing at COLING 2020",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Contextualized word embeddings have been replacing standard embeddings as the
representational knowledge source of choice in NLP systems. Since a variety of
biases have previously been found in standard word embeddings, it is crucial to
assess biases encoded in their replacements as well. Focusing on BERT (Devlin
et al., 2018), we measure gender bias by studying associations between
gender-denoting target words and names of professions in English and German,
comparing the findings with real-world workforce statistics. We mitigate bias
by fine-tuning BERT on the GAP corpus (Webster et al., 2018), after applying
Counterfactual Data Substitution (CDS) (Maudslay et al., 2019). We show that
our method of measuring bias is appropriate for languages such as English, but
not for languages with a rich morphology and gender-marking, such as German.
Our results highlight the importance of investigating bias and mitigation
techniques cross-linguistically, especially in view of the current emphasis on
large-scale, multilingual language models.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 18:06:09 GMT'}]",2020-10-29,"[['Bartl', 'Marion', ''], ['Nissim', 'Malvina', ''], ['Gatt', 'Albert', '']]"
1146834,1907.02298,Zi Lin,"Junjie Cao, Zi Lin, Weiwei Sun, Xiaojun Wan","A Comparative Analysis of Knowledge-Intensive and Data-Intensive
  Semantic Parsers",submitted to the journal Computational Linguistics,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We present a phenomenon-oriented comparative analysis of the two dominant
approaches in task-independent semantic parsing: classic, knowledge-intensive
and neural, data-intensive models. To reflect state-of-the-art neural NLP
technologies, we introduce a new target structure-centric parser that can
produce semantic graphs much more accurately than previous data-driven parsers.
We then show that, in spite of comparable performance overall, knowledge- and
data-intensive models produce different types of errors, in a way that can be
explained by their theoretical properties. This analysis leads to new
directions for parser development.
","[{'version': 'v1', 'created': 'Thu, 4 Jul 2019 09:40:27 GMT'}, {'version': 'v2', 'created': 'Thu, 15 Aug 2019 10:36:59 GMT'}, {'version': 'v3', 'created': 'Wed, 28 Oct 2020 08:39:30 GMT'}]",2020-10-29,"[['Cao', 'Junjie', ''], ['Lin', 'Zi', ''], ['Sun', 'Weiwei', ''], ['Wan', 'Xiaojun', '']]"
1247530,2002.10107,Issa Annamoradnejad,"Issa Annamoradnejad, Mohammadamin Fazli, Jafar Habibi",Predicting Subjective Features of Questions of QA Websites using BERT,"5 pages, 4 figures, 2 tables","2020 6th International Conference on Web Research (ICWR), Tehran,
  Iran, 2020, pp. 240-244",10.1109/ICWR49608.2020.9122318,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Community Question-Answering websites, such as StackOverflow and Quora,
expect users to follow specific guidelines in order to maintain content
quality. These systems mainly rely on community reports for assessing contents,
which has serious problems such as the slow handling of violations, the loss of
normal and experienced users' time, the low quality of some reports, and
discouraging feedback to new users. Therefore, with the overall goal of
providing solutions for automating moderation actions in Q&A websites, we aim
to provide a model to predict 20 quality or subjective aspects of questions in
QA websites. To this end, we used data gathered by the CrowdSource team at
Google Research in 2019 and a fine-tuned pre-trained BERT model on our problem.
Based on the evaluation by Mean-Squared-Error (MSE), the model achieved a value
of 0.046 after 2 epochs of training, which did not improve substantially in the
next ones. Results confirm that by simple fine-tuning, we can achieve accurate
models in little time and on less amount of data.
","[{'version': 'v1', 'created': 'Mon, 24 Feb 2020 07:56:02 GMT'}, {'version': 'v2', 'created': 'Wed, 25 Mar 2020 08:10:16 GMT'}, {'version': 'v3', 'created': 'Tue, 30 Jun 2020 13:22:04 GMT'}, {'version': 'v4', 'created': 'Wed, 28 Oct 2020 14:37:39 GMT'}]",2020-10-29,"[['Annamoradnejad', 'Issa', ''], ['Fazli', 'Mohammadamin', ''], ['Habibi', 'Jafar', '']]"
1369332,2010.13002,Sam Shleifer,Sam Shleifer and Alexander M. Rush,Pre-trained Summarization Distillation,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent state-of-the-art approaches to summarization utilize large pre-trained
Transformer models. Distilling these models to smaller student models has
become critically important for practical use; however there are many different
distillation methods proposed by the NLP literature. Recent work on distilling
BERT for classification and regression tasks shows strong performance using
direct knowledge distillation. Alternatively, machine translation practitioners
distill using pseudo-labeling, where a small model is trained on the
translations of a larger model. A third, simpler approach is to 'shrink and
fine-tune' (SFT), which avoids any explicit distillation by copying parameters
to a smaller student model and then fine-tuning. We compare these three
approaches for distillation of Pegasus and BART, the current and former state
of the art, pre-trained summarization models, and find that SFT outperforms
knowledge distillation and pseudo-labeling on the CNN/DailyMail dataset, but
under-performs pseudo-labeling on the more abstractive XSUM dataset. PyTorch
Code and checkpoints of different sizes are available through Hugging Face
transformers here http://tiny.cc/4iy0tz.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 23:15:43 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 04:47:59 GMT'}]",2020-10-29,"[['Shleifer', 'Sam', ''], ['Rush', 'Alexander M.', '']]"
1371221,2010.14891,Mayuko Kori,"Mayuko Kori, Takeshi Tsukada and Naoki Kobayashi",A Cyclic Proof System for HFLN,27 pages,,,,cs.LO cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A cyclic proof system allows us to perform inductive reasoning without
explicit inductions. We propose a cyclic proof system for HFLN, which is a
higher-order predicate logic with natural numbers and alternating fixed-points.
Ours is the first cyclic proof system for a higher-order logic, to our
knowledge. Due to the presence of higher-order predicates and alternating
fixed-points, our cyclic proof system requires a more delicate global condition
on cyclic proofs than the original system of Brotherston and Simpson. We prove
the decidability of checking the global condition and soundness of this system,
and also prove a restricted form of standard completeness for an infinitary
variant of our cyclic proof system. A potential application of our cyclic proof
system is semi-automated verification of higher-order programs, based on
Kobayashi et al.'s recent work on reductions from program verification to HFLN
validity checking.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 11:19:53 GMT'}]",2020-10-29,"[['Kori', 'Mayuko', ''], ['Tsukada', 'Takeshi', ''], ['Kobayashi', 'Naoki', '']]"
1371250,2010.14920,Yuchen Liu,"Yuchen Liu, Junnan Zhu, Jiajun Zhang, and Chengqing Zong",Bridging the Modality Gap for Speech-to-Text Translation,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  End-to-end speech translation aims to translate speech in one language into
text in another language via an end-to-end way. Most existing methods employ an
encoder-decoder structure with a single encoder to learn acoustic
representation and semantic information simultaneously, which ignores the
speech-and-text modality differences and makes the encoder overloaded, leading
to great difficulty in learning such a model. To address these issues, we
propose a Speech-to-Text Adaptation for Speech Translation (STAST) model which
aims to improve the end-to-end model performance by bridging the modality gap
between speech and text. Specifically, we decouple the speech translation
encoder into three parts and introduce a shrink mechanism to match the length
of speech representation with that of the corresponding text transcription. To
obtain better semantic representation, we completely integrate a text-based
translation model into the STAST so that two tasks can be trained in the same
latent space. Furthermore, we introduce a cross-modal adaptation method to
close the distance between speech and text representation. Experimental results
on English-French and English-German speech translation corpora have shown that
our model significantly outperforms strong baselines, and achieves the new
state-of-the-art performance.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 12:33:04 GMT'}]",2020-10-29,"[['Liu', 'Yuchen', ''], ['Zhu', 'Junnan', ''], ['Zhang', 'Jiajun', ''], ['Zong', 'Chengqing', '']]"
1279293,2004.14523,Brian Thompson,Brian Thompson and Philipp Koehn,Exploiting Sentence Order in Document Alignment,EMNLP2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present a simple document alignment method that incorporates sentence
order information in both candidate generation and candidate re-scoring. Our
method results in 61% relative reduction in error compared to the best
previously published result on the WMT16 document alignment shared task. Our
method improves downstream MT performance on web-scraped Sinhala--English
documents from ParaCrawl, outperforming the document alignment method used in
the most recent ParaCrawl release. It also outperforms a comparable corpora
method which uses the same multilingual embeddings, demonstrating that
exploiting sentence order is beneficial even if the end goal is sentence-level
bitext.
","[{'version': 'v1', 'created': 'Thu, 30 Apr 2020 00:11:34 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 01:23:22 GMT'}]",2020-10-29,"[['Thompson', 'Brian', ''], ['Koehn', 'Philipp', '']]"
1371355,2010.15025,Xingchen Song,"Xingchen Song, Zhiyong Wu, Yiheng Huang, Chao Weng, Dan Su, Helen Meng",Non-Autoregressive Transformer ASR with CTC-Enhanced Decoder Input,submitted to ICASSP 2021,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Non-autoregressive (NAR) transformer models have achieved significantly
inference speedup but at the cost of inferior accuracy compared to
autoregressive (AR) models in automatic speech recognition (ASR). Most of the
NAR transformers take a fixed-length sequence filled with MASK tokens or a
redundant sequence copied from encoder states as decoder input, they cannot
provide efficient target-side information thus leading to accuracy degradation.
To address this problem, we propose a CTC-enhanced NAR transformer, which
generates target sequence by refining predictions of the CTC module.
Experimental results show that our method outperforms all previous NAR
counterparts and achieves 50x faster decoding speed than a strong AR baseline
with only 0.0 ~ 0.3 absolute CER degradation on Aishell-1 and Aishell-2
datasets.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 15:00:09 GMT'}]",2020-10-29,"[['Song', 'Xingchen', ''], ['Wu', 'Zhiyong', ''], ['Huang', 'Yiheng', ''], ['Weng', 'Chao', ''], ['Su', 'Dan', ''], ['Meng', 'Helen', '']]"
1371282,2010.14952,Isar Nejadgholi,Svetlana Kiritchenko and Isar Nejadgholi,Towards Ethics by Design in Online Abusive Content Detection,"14 pages, 2 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  To support safety and inclusion in online communications, significant efforts
in NLP research have been put towards addressing the problem of abusive content
detection, commonly defined as a supervised classification task. The research
effort has spread out across several closely related sub-areas, such as
detection of hate speech, toxicity, cyberbullying, etc. There is a pressing
need to consolidate the field under a common framework for task formulation,
dataset design and performance evaluation. Further, despite current
technologies achieving high classification accuracies, several ethical issues
have been revealed. We bring ethical issues to forefront and propose a unified
framework as a two-step process. First, online content is categorized around
personal and identity-related subject matters. Second, severity of abuse is
identified through comparative annotation within each category. The novel
framework is guided by the Ethics by Design principle and is a step towards
building more accurate and trusted models.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 13:10:24 GMT'}]",2020-10-29,"[['Kiritchenko', 'Svetlana', ''], ['Nejadgholi', 'Isar', '']]"
1371444,2010.15114,Kyle Aitken,"Kyle Aitken, Vinay V. Ramasesh, Ankush Garg, Yuan Cao, David Sussillo,
  Niru Maheswaranathan",The geometry of integration in text classification RNNs,"9+19 pages, 30 figures",,,,cs.LG cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite the widespread application of recurrent neural networks (RNNs) across
a variety of tasks, a unified understanding of how RNNs solve these tasks
remains elusive. In particular, it is unclear what dynamical patterns arise in
trained RNNs, and how those patterns depend on the training dataset or task.
This work addresses these questions in the context of a specific natural
language processing task: text classification. Using tools from dynamical
systems analysis, we study recurrent networks trained on a battery of both
natural and synthetic text classification tasks. We find the dynamics of these
trained RNNs to be both interpretable and low-dimensional. Specifically, across
architectures and datasets, RNNs accumulate evidence for each class as they
process the text, using a low-dimensional attractor manifold as the underlying
mechanism. Moreover, the dimensionality and geometry of the attractor manifold
are determined by the structure of the training dataset; in particular, we
describe how simple word-count statistics computed on the training dataset can
be used to predict these properties. Our observations span multiple
architectures and datasets, reflecting a common mechanism RNNs employ to
perform text classification. To the degree that integration of evidence towards
a decision is a common computational primitive, this work lays the foundation
for using dynamical systems techniques to study the inner workings of RNNs.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 17:58:53 GMT'}]",2020-10-29,"[['Aitken', 'Kyle', ''], ['Ramasesh', 'Vinay V.', ''], ['Garg', 'Ankush', ''], ['Cao', 'Yuan', ''], ['Sussillo', 'David', ''], ['Maheswaranathan', 'Niru', '']]"
1371397,2010.15067,Muhammed Tarik Altuncu,"M. Tarik Altuncu, Sophia N. Yaliraki, Mauricio Barahona","Graph-based Topic Extraction from Vector Embeddings of Text Documents:
  Application to a Corpus of News Articles",,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Production of news content is growing at an astonishing rate. To help manage
and monitor the sheer amount of text, there is an increasing need to develop
efficient methods that can provide insights into emerging content areas, and
stratify unstructured corpora of text into `topics' that stem intrinsically
from content similarity. Here we present an unsupervised framework that brings
together powerful vector embeddings from natural language processing with tools
from multiscale graph partitioning that can reveal natural partitions at
different resolutions without making a priori assumptions about the number of
clusters in the corpus. We show the advantages of graph-based clustering
through end-to-end comparisons with other popular clustering and topic
modelling methods, and also evaluate different text vector embeddings, from
classic Bag-of-Words to Doc2Vec to the recent transformers based model Bert.
This comparative work is showcased through an analysis of a corpus of US news
coverage during the presidential election year of 2016.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 16:20:05 GMT'}]",2020-10-29,"[['Altuncu', 'M. Tarik', ''], ['Yaliraki', 'Sophia N.', ''], ['Barahona', 'Mauricio', '']]"
1371420,2010.15090,Vishal Sunder,Vishal Sunder and Eric Fosler-Lussier,"Handling Class Imbalance in Low-Resource Dialogue Systems by Combining
  Few-Shot Classification and Interpolation","5 pages, 4 figures, 3 tables",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Utterance classification performance in low-resource dialogue systems is
constrained by an inevitably high degree of data imbalance in class labels. We
present a new end-to-end pairwise learning framework that is designed
specifically to tackle this phenomenon by inducing a few-shot classification
capability in the utterance representations and augmenting data through an
interpolation of utterance representations. Our approach is a general purpose
training methodology, agnostic to the neural architecture used for encoding
utterances. We show significant improvements in macro-F1 score over standard
cross-entropy training for three different neural architectures, demonstrating
improvements on a Virtual Patient dialogue dataset as well as a low-resourced
emulation of the Switchboard dialogue act classification dataset.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 17:05:24 GMT'}]",2020-10-29,"[['Sunder', 'Vishal', ''], ['Fosler-Lussier', 'Eric', '']]"
1371366,2010.15036,Usman Naseem,"Usman Naseem, Imran Razzak, Shah Khalid Khan, Mukesh Prasad","A Comprehensive Survey on Word Representation Models: From Classical to
  State-Of-The-Art Word Representation Language Models",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Word representation has always been an important research area in the history
of natural language processing (NLP). Understanding such complex text data is
imperative, given that it is rich in information and can be used widely across
various applications. In this survey, we explore different word representation
models and its power of expression, from the classical to modern-day
state-of-the-art word representation language models (LMS). We describe a
variety of text representation methods, and model designs have blossomed in the
context of NLP, including SOTA LMs. These models can transform large volumes of
text into effective vector representations capturing the same semantic
information. Further, such representations can be utilized by various machine
learning (ML) algorithms for a variety of NLP related tasks. In the end, this
survey briefly discusses the commonly used ML and DL based classifiers,
evaluation metrics and the applications of these word embeddings in different
NLP tasks.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 15:15:13 GMT'}]",2020-10-29,"[['Naseem', 'Usman', ''], ['Razzak', 'Imran', ''], ['Khan', 'Shah Khalid', ''], ['Prasad', 'Mukesh', '']]"
1371395,2010.15065,Amir Shanehsazzadeh,"Amir Shanehsazzadeh, David Belanger, David Dohan",Fixed-Length Protein Embeddings using Contextual Lenses,,,,,q-bio.BM cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The Basic Local Alignment Search Tool (BLAST) is currently the most popular
method for searching databases of biological sequences. BLAST compares
sequences via similarity defined by a weighted edit distance, which results in
it being computationally expensive. As opposed to working with edit distance, a
vector similarity approach can be accelerated substantially using modern
hardware or hashing techniques. Such an approach would require fixed-length
embeddings for biological sequences. There has been recent interest in learning
fixed-length protein embeddings using deep learning models under the hypothesis
that the hidden layers of supervised or semi-supervised models could produce
potentially useful vector embeddings. We consider transformer (BERT) protein
language models that are pretrained on the TrEMBL data set and learn
fixed-length embeddings on top of them with contextual lenses. The embeddings
are trained to predict the family a protein belongs to for sequences in the
Pfam database. We show that for nearest-neighbor family classification,
pretraining offers a noticeable boost in performance and that the corresponding
learned embeddings are competitive with BLAST. Furthermore, we show that the
raw transformer embeddings, obtained via static pooling, do not perform well on
nearest-neighbor family classification, which suggests that learning embeddings
in a supervised manner via contextual lenses may be a compute-efficient
alternative to fine-tuning.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 14:54:55 GMT'}]",2020-10-29,"[['Shanehsazzadeh', 'Amir', ''], ['Belanger', 'David', ''], ['Dohan', 'David', '']]"
1267866,2004.03096,Yiming Cui,"Nan Shao, Yiming Cui, Ting Liu, Shijin Wang, Guoping Hu",Is Graph Structure Necessary for Multi-hop Question Answering?,"6 pages, to appear at EMNLP 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, attempting to model texts as graph structure and introducing graph
neural networks to deal with it has become a trend in many NLP research areas.
In this paper, we investigate whether the graph structure is necessary for
multi-hop question answering. Our analysis is centered on HotpotQA. We
construct a strong baseline model to establish that, with the proper use of
pre-trained models, graph structure may not be necessary for multi-hop question
answering. We point out that both graph structure and adjacency matrix are
task-related prior knowledge, and graph-attention can be considered as a
special case of self-attention. Experiments and visualized analysis demonstrate
that graph-attention or the entire graph structure can be replaced by
self-attention or Transformers.
","[{'version': 'v1', 'created': 'Tue, 7 Apr 2020 02:59:42 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 09:29:19 GMT'}]",2020-10-30,"[['Shao', 'Nan', ''], ['Cui', 'Yiming', ''], ['Liu', 'Ting', ''], ['Wang', 'Shijin', ''], ['Hu', 'Guoping', '']]"
1356512,2010.00182,Yang Zhang,"Yang Zhang, Qiang Ma",Dual Attention Model for Citation Recommendation,,,,,cs.IR cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Based on an exponentially increasing number of academic articles, discovering
and citing comprehensive and appropriate resources has become a non-trivial
task. Conventional citation recommender methods suffer from severe information
loss. For example, they do not consider the section of the paper that the user
is writing and for which they need to find a citation, the relatedness between
the words in the local context (the text span that describes a citation), or
the importance on each word from the local context. These shortcomings make
such methods insufficient for recommending adequate citations to academic
manuscripts. In this study, we propose a novel embedding-based neural network
called ""dual attention model for citation recommendation (DACR)"" to recommend
citations during manuscript preparation. Our method adapts embedding of three
dimensions of semantic information: words in the local context, structural
contexts, and the section on which a user is working. A neural network is
designed to maximize the similarity between the embedding of the three input
(local context words, section and structural contexts) and the target citation
appearing in the context. The core of the neural network is composed of
self-attention and additive attention, where the former aims to capture the
relatedness between the contextual words and structural context, and the latter
aims to learn the importance of them. The experiments on real-world datasets
demonstrate the effectiveness of the proposed approach.
","[{'version': 'v1', 'created': 'Thu, 1 Oct 2020 02:41:47 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 11:27:20 GMT'}, {'version': 'v3', 'created': 'Wed, 28 Oct 2020 12:57:58 GMT'}, {'version': 'v4', 'created': 'Thu, 29 Oct 2020 12:31:26 GMT'}]",2020-10-30,"[['Zhang', 'Yang', ''], ['Ma', 'Qiang', '']]"
1371865,2010.15535,Craig Stewart,"Ricardo Rei, Craig Stewart, Catarina Farinha, Alon Lavie",Unbabel's Participation in the WMT20 Metrics Shared Task,WMT Metrics Shared Task 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present the contribution of the Unbabel team to the WMT 2020 Shared Task
on Metrics. We intend to participate on the segment-level, document-level and
system-level tracks on all language pairs, as well as the 'QE as a Metric'
track. Accordingly, we illustrate results of our models in these tracks with
reference to test sets from the previous year. Our submissions build upon the
recently proposed COMET framework: We train several estimator models to regress
on different human-generated quality scores and a novel ranking model trained
on relative ranks obtained from Direct Assessments. We also propose a simple
technique for converting segment-level predictions into a document-level score.
Overall, our systems achieve strong results for all language pairs on previous
test sets and in many cases set a new state-of-the-art.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 12:59:44 GMT'}]",2020-10-30,"[['Rei', 'Ricardo', ''], ['Stewart', 'Craig', ''], ['Farinha', 'Catarina', ''], ['Lavie', 'Alon', '']]"
1371796,2010.15466,Yuyang Nie,"Yuyang Nie, Yuanhe Tian, Yan Song, Xiang Ao, and Xiang Wan","Improving Named Entity Recognition with Attentive Ensemble of Syntactic
  Information","Natural Language Processing. 15 pages, 3 figures, Findings of
  EMNLP-2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Named entity recognition (NER) is highly sensitive to sentential syntactic
and semantic properties where entities may be extracted according to how they
are used and placed in the running text. To model such properties, one could
rely on existing resources to providing helpful knowledge to the NER task; some
existing studies proved the effectiveness of doing so, and yet are limited in
appropriately leveraging the knowledge such as distinguishing the important
ones for particular context. In this paper, we improve NER by leveraging
different types of syntactic information through attentive ensemble, which
functionalizes by the proposed key-value memory networks, syntax attention, and
the gate mechanism for encoding, weighting and aggregating such syntactic
information, respectively. Experimental results on six English and Chinese
benchmark datasets suggest the effectiveness of the proposed model and show
that it outperforms previous studies on all experiment datasets.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 10:25:17 GMT'}]",2020-10-30,"[['Nie', 'Yuyang', ''], ['Tian', 'Yuanhe', ''], ['Song', 'Yan', ''], ['Ao', 'Xiang', ''], ['Wan', 'Xiang', '']]"
1371788,2010.15458,Yuyang Nie,"Yuyang Nie, Yuanhe Tian, Xiang Wan, Yan Song, and Bo Dai","Named Entity Recognition for Social Media Texts with Semantic
  Augmentation","Natural Language Processing. 9 pages, 3 figures. EMNLP-2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Existing approaches for named entity recognition suffer from data sparsity
problems when conducted on short and informal texts, especially user-generated
social media content. Semantic augmentation is a potential way to alleviate
this problem. Given that rich semantic information is implicitly preserved in
pre-trained word embeddings, they are potential ideal resources for semantic
augmentation. In this paper, we propose a neural-based approach to NER for
social media texts where both local (from running text) and augmented semantics
are taken into account. In particular, we obtain the augmented semantic
information from a large-scale corpus, and propose an attentive semantic
augmentation module and a gate module to encode and aggregate such information,
respectively. Extensive experiments are performed on three benchmark datasets
collected from English and Chinese social media platforms, where the results
demonstrate the superiority of our approach to previous studies across all
three datasets.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 10:06:46 GMT'}]",2020-10-30,"[['Nie', 'Yuyang', ''], ['Tian', 'Yuanhe', ''], ['Wan', 'Xiang', ''], ['Song', 'Yan', ''], ['Dai', 'Bo', '']]"
1370914,2010.14584,Aleksandra Edwards Mrs,"Aleksandra Edwards, David Rogers, Jose Camacho-Collados, H\'el\`ene de
  Ribaupierre, Alun Preece","Predicting Themes within Complex Unstructured Texts: A Case Study on
  Safeguarding Reports","10 pages, 5 figures, workshop",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The task of text and sentence classification is associated with the need for
large amounts of labelled training data. The acquisition of high volumes of
labelled datasets can be expensive or unfeasible, especially for
highly-specialised domains for which documents are hard to obtain. Research on
the application of supervised classification based on small amounts of training
data is limited. In this paper, we address the combination of state-of-the-art
deep learning and classification methods and provide an insight into what
combination of methods fit the needs of small, domain-specific, and
terminologically-rich corpora. We focus on a real-world scenario related to a
collection of safeguarding reports comprising learning experiences and
reflections on tackling serious incidents involving children and vulnerable
adults. The relatively small volume of available reports and their use of
highly domain-specific terminology makes the application of automated
approaches difficult. We focus on the problem of automatically identifying the
main themes in a safeguarding report using supervised classification
approaches. Our results show the potential of deep learning models to simulate
subject-expert behaviour even for complex tasks with limited labelled data.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 19:48:23 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 09:15:14 GMT'}]",2020-10-30,"[['Edwards', 'Aleksandra', ''], ['Rogers', 'David', ''], ['Camacho-Collados', 'Jose', ''], ['de Ribaupierre', 'Hélène', ''], ['Preece', 'Alun', '']]"
1371767,2010.15437,Mana Ihori,"Mana Ihori, Ryo Masumura, Naoki Makishima, Tomohiro Tanaka, Akihiko
  Takashima, Shota Orihashi","Memory Attentive Fusion: External Language Model Integration for
  Transformer-based Sequence-to-Sequence Model",Accepted as a short paper at INLG 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents a novel fusion method for integrating an external
language model (LM) into the Transformer based sequence-to-sequence (seq2seq)
model. While paired data are basically required to train the seq2seq model, the
external LM can be trained with only unpaired data. Thus, it is important to
leverage memorized knowledge in the external LM for building the seq2seq model,
since it is hard to prepare a large amount of paired data. However, the
existing fusion methods assume that the LM is integrated with recurrent neural
network-based seq2seq models instead of the Transformer. Therefore, this paper
proposes a fusion method that can explicitly utilize network structures in the
Transformer. The proposed method, called {\bf memory attentive fusion},
leverages the Transformer-style attention mechanism that repeats source-target
attention in a multi-hop manner for reading the memorized knowledge in the LM.
Our experiments on two text-style conversion tasks demonstrate that the
proposed method performs better than conventional fusion methods.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 09:16:23 GMT'}]",2020-10-30,"[['Ihori', 'Mana', ''], ['Masumura', 'Ryo', ''], ['Makishima', 'Naoki', ''], ['Tanaka', 'Tomohiro', ''], ['Takashima', 'Akihiko', ''], ['Orihashi', 'Shota', '']]"
1370901,2010.14571,Isaac Caswell,"Isaac Caswell, Theresa Breiner, Daan van Esch, Ankur Bapna","Language ID in the Wild: Unexpected Challenges on the Path to a
  Thousand-Language Web Text Corpus",Accepted to COLING 2020. 9 pages with 8 page abstract,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Large text corpora are increasingly important for a wide variety of Natural
Language Processing (NLP) tasks, and automatic language identification (LangID)
is a core technology needed to collect such datasets in a multilingual context.
LangID is largely treated as solved in the literature, with models reported
that achieve over 90% average F1 on as many as 1,366 languages. We train LangID
models on up to 1,629 languages with comparable quality on held-out test sets,
but find that human-judged LangID accuracy for web-crawl text corpora created
using these models is only around 5% for many lower-resource languages,
suggesting a need for more robust evaluation. Further analysis revealed a
variety of error modes, arising from domain mismatch, class imbalance, language
similarity, and insufficiently expressive models. We propose two classes of
techniques to mitigate these errors: wordlist-based tunable-precision filters
(for which we release curated lists in about 500 languages) and
transformer-based semi-supervised LangID models, which increase median dataset
precision from 5.5% to 71.2%. These techniques enable us to create an initial
data set covering 100K or more relatively clean sentences in each of 500+
languages, paving the way towards a 1,000-language web text corpus.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 19:29:17 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 15:18:35 GMT'}]",2020-10-30,"[['Caswell', 'Isaac', ''], ['Breiner', 'Theresa', ''], ['van Esch', 'Daan', ''], ['Bapna', 'Ankur', '']]"
1371753,2010.15423,M\=arcis Pinnis,"Rihards Kri\v{s}lauks, M\=arcis Pinnis",Tilde at WMT 2020: News Task Systems,,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  This paper describes Tilde's submission to the WMT2020 shared task on news
translation for both directions of the English-Polish language pair in both the
constrained and the unconstrained tracks. We follow our submissions from the
previous years and build our baseline systems to be morphologically motivated
sub-word unit-based Transformer base models that we train using the Marian
machine translation toolkit. Additionally, we experiment with different
parallel and monolingual data selection schemes, as well as sampled
back-translation. Our final models are ensembles of Transformer base and
Transformer big models that feature right-to-left re-ranking.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 08:59:37 GMT'}]",2020-10-30,"[['Krišlauks', 'Rihards', ''], ['Pinnis', 'Mārcis', '']]"
1371741,2010.15411,Milan Gritta,"Milan Gritta, Gerasimos Lampouras and Ignacio Iacobacci","Conversation Graph: Data Augmentation, Training and Evaluation for
  Non-Deterministic Dialogue Management","Accepted at Transactions of Association of Computational Linguistics
  (to be presented at ACL 2021)",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Task-oriented dialogue systems typically rely on large amounts of
high-quality training data or require complex handcrafted rules. However,
existing datasets are often limited in size considering the complexity of the
dialogues. Additionally, conventional training signal inference is not suitable
for non-deterministic agent behaviour, i.e. considering multiple actions as
valid in identical dialogue states. We propose the Conversation Graph
(ConvGraph), a graph-based representation of dialogues that can be exploited
for data augmentation, multi-reference training and evaluation of
non-deterministic agents. ConvGraph generates novel dialogue paths to augment
data volume and diversity. Intrinsic and extrinsic evaluation across three
datasets shows that data augmentation and/or multi-reference training with
ConvGraph can improve dialogue success rates by up to 6.4%.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 08:23:24 GMT'}]",2020-10-30,"[['Gritta', 'Milan', ''], ['Lampouras', 'Gerasimos', ''], ['Iacobacci', 'Ignacio', '']]"
1371928,2010.15598,Micaela Kaplan,Micaela Kaplan,"May I Ask Who's Calling? Named Entity Recognition on Call Center
  Transcripts for Privacy Law Compliance",The 6th Workshop on Noisy User-generated Text (W-NUT) 2020 at EMNLP,"Proceedings of the 2020 EMNLP Workshop W-NUT: The Sixth Workshop
  on Noisy User-generated Text (2020) 1-6",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We investigate using Named Entity Recognition on a new type of user-generated
text: a call center conversation. These conversations combine problems from
spontaneous speech with problems novel to conversational Automated Speech
Recognition, including incorrect recognition, alongside other common problems
from noisy user-generated text. Using our own corpus with new annotations,
training custom contextual string embeddings, and applying a BiLSTM-CRF, we
match state-of-the-art results on our novel task.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 13:53:42 GMT'}]",2020-10-30,"[['Kaplan', 'Micaela', '']]"
1371696,2010.15366,Sung-Feng Huang,"Sung-Feng Huang, Shun-Po Chuang, Da-Rong Liu, Yi-Chen Chen, Gene-Ping
  Yang, Hung-yi Lee","Self-supervised Pre-training Reduces Label Permutation Instability of
  Speech Separation",submitted to ICASSP2021,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Speech separation has been well-developed while there are still problems
waiting to be solved. The main problem we focus on in this paper is the
frequent label permutation switching of permutation invariant training (PIT).
For N-speaker separation, there would be N! possible label permutations. How to
stably select correct label permutations is a long-standing problem. In this
paper, we utilize self-supervised pre-training to stabilize the label
permutations. Among several types of self-supervised tasks, speech enhancement
based pre-training tasks show significant effectiveness in our experiments.
When using off-the-shelf pre-trained models, training duration could be
shortened to one-third to two-thirds. Furthermore, even taking pre-training
time into account, the entire training process could still be shorter without a
performance drop when using a larger batch size.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 06:07:01 GMT'}]",2020-10-30,"[['Huang', 'Sung-Feng', ''], ['Chuang', 'Shun-Po', ''], ['Liu', 'Da-Rong', ''], ['Chen', 'Yi-Chen', ''], ['Yang', 'Gene-Ping', ''], ['Lee', 'Hung-yi', '']]"
1371690,2010.15360,Shaolei Wang,"Shaolei Wang, Zhongyuan Wang, Wanxiang Che, Ting Liu","Combining Self-Training and Self-Supervised Learning for Unsupervised
  Disfluency Detection",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Most existing approaches to disfluency detection heavily rely on
human-annotated corpora, which is expensive to obtain in practice. There have
been several proposals to alleviate this issue with, for instance,
self-supervised learning techniques, but they still require human-annotated
corpora. In this work, we explore the unsupervised learning paradigm which can
potentially work with unlabeled text corpora that are cheaper and easier to
obtain. Our model builds upon the recent work on Noisy Student Training, a
semi-supervised learning approach that extends the idea of self-training.
Experimental results on the commonly used English Switchboard test set show
that our approach achieves competitive performance compared to the previous
state-of-the-art supervised systems using contextualized word embeddings (e.g.
BERT and ELECTRA).
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 05:29:26 GMT'}]",2020-10-30,"[['Wang', 'Shaolei', ''], ['Wang', 'Zhongyuan', ''], ['Che', 'Wanxiang', ''], ['Liu', 'Ting', '']]"
1348756,2009.07253,Alexander Lin,"Alexander Lin, Jeremy Wohlwend, Howard Chen, and Tao Lei",Autoregressive Knowledge Distillation through Imitation Learning,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The performance of autoregressive models on natural language generation tasks
has dramatically improved due to the adoption of deep, self-attentive
architectures. However, these gains have come at the cost of hindering
inference speed, making state-of-the-art models cumbersome to deploy in
real-world, time-sensitive settings. We develop a compression technique for
autoregressive models that is driven by an imitation learning perspective on
knowledge distillation. The algorithm is designed to address the exposure bias
problem. On prototypical language generation tasks such as translation and
summarization, our method consistently outperforms other distillation
algorithms, such as sequence-level knowledge distillation. Student models
trained with our method attain 1.4 to 4.8 BLEU/ROUGE points higher than those
trained from scratch, while increasing inference speed by up to 14 times in
comparison to the teacher model.
","[{'version': 'v1', 'created': 'Tue, 15 Sep 2020 17:43:02 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 00:40:45 GMT'}]",2020-10-30,"[['Lin', 'Alexander', ''], ['Wohlwend', 'Jeremy', ''], ['Chen', 'Howard', ''], ['Lei', 'Tao', '']]"
1371646,2010.15316,Michal Malyska,"Alister D Costa, Stefan Denkovski, Michal Malyska, Sae Young Moon,
  Brandon Rufino, Zhen Yang, Taylor Killian, Marzyeh Ghassemi",Multiple Sclerosis Severity Classification From Clinical Text,EMNLP 2020 Clinical NLP workshop,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Multiple Sclerosis (MS) is a chronic, inflammatory and degenerative
neurological disease, which is monitored by a specialist using the Expanded
Disability Status Scale (EDSS) and recorded in unstructured text in the form of
a neurology consult note. An EDSS measurement contains an overall ""EDSS"" score
and several functional subscores. Typically, expert knowledge is required to
interpret consult notes and generate these scores. Previous approaches used
limited context length Word2Vec embeddings and keyword searches to predict
scores given a consult note, but often failed when scores were not explicitly
stated. In this work, we present MS-BERT, the first publicly available
transformer model trained on real clinical data other than MIMIC. Next, we
present MSBC, a classifier that applies MS-BERT to generate embeddings and
predict EDSS and functional subscores. Lastly, we explore combining MSBC with
other models through the use of Snorkel to generate scores for unlabelled
consult notes. MSBC achieves state-of-the-art performance on all metrics and
prediction tasks and outperforms the models generated from the Snorkel
ensemble. We improve Macro-F1 by 0.12 (to 0.88) for predicting EDSS and on
average by 0.29 (to 0.63) for predicting functional subscores over previous
Word2Vec CNN and rule-based approaches.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 02:15:23 GMT'}]",2020-10-30,"[['Costa', 'Alister D', ''], ['Denkovski', 'Stefan', ''], ['Malyska', 'Michal', ''], ['Moon', 'Sae Young', ''], ['Rufino', 'Brandon', ''], ['Yang', 'Zhen', ''], ['Killian', 'Taylor', ''], ['Ghassemi', 'Marzyeh', '']]"
1265269,2004.00499,Shengbin Jia,Shengbin Jia,Unique Chinese Linguistic Phenomena,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Linguistics holds unique characteristics of generality, stability, and
nationality, which will affect the formulation of extraction strategies and
should be incorporated into the relation extraction. Chinese open relation
extraction is not well-established, because of the complexity of Chinese
linguistics makes it harder to operate, and the methods for English are not
compatible with that for Chinese. The diversities between Chinese and English
linguistics are mainly reflected in morphology and syntax.
","[{'version': 'v1', 'created': 'Sun, 23 Feb 2020 12:13:48 GMT'}, {'version': 'v2', 'created': 'Fri, 31 Jul 2020 10:00:08 GMT'}, {'version': 'v3', 'created': 'Thu, 29 Oct 2020 06:07:07 GMT'}]",2020-10-30,"[['Jia', 'Shengbin', '']]"
1150762,1907.06226,Jipeng Qiang,Jipeng Qiang and Yun Li and Yi Zhu and Yunhao Yuan and Xindong Wu,Lexical Simplification with Pretrained Encoders,,,,,cs.CL cs.AI cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Lexical simplification (LS) aims to replace complex words in a given sentence
with their simpler alternatives of equivalent meaning. Recently unsupervised
lexical simplification approaches only rely on the complex word itself
regardless of the given sentence to generate candidate substitutions, which
will inevitably produce a large number of spurious candidates. We present a
simple LS approach that makes use of the Bidirectional Encoder Representations
from Transformers (BERT) which can consider both the given sentence and the
complex word during generating candidate substitutions for the complex word.
Specifically, we mask the complex word of the original sentence for feeding
into the BERT to predict the masked token. The predicted results will be used
as candidate substitutions. Despite being entirely unsupervised, experimental
results show that our approach obtains obvious improvement compared with these
baselines leveraging linguistic databases and parallel corpus, outperforming
the state-of-the-art by more than 12 Accuracy points on three well-known
benchmarks.
","[{'version': 'v1', 'created': 'Sun, 14 Jul 2019 14:19:22 GMT'}, {'version': 'v2', 'created': 'Tue, 16 Jul 2019 14:36:41 GMT'}, {'version': 'v3', 'created': 'Tue, 30 Jul 2019 03:36:12 GMT'}, {'version': 'v4', 'created': 'Fri, 16 Aug 2019 01:48:46 GMT'}, {'version': 'v5', 'created': 'Thu, 29 Oct 2020 03:21:25 GMT'}]",2020-10-30,"[['Qiang', 'Jipeng', ''], ['Li', 'Yun', ''], ['Zhu', 'Yi', ''], ['Yuan', 'Yunhao', ''], ['Wu', 'Xindong', '']]"
1371643,2010.15313,Keen You,Keen You and Dan Goldwasser,"""where is this relationship going?"": Understanding Relationship
  Trajectories in Narrative Text",Accepted to *Sem 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We examine a new commonsense reasoning task: given a narrative describing a
social interaction that centers on two protagonists, systems make inferences
about the underlying relationship trajectory. Specifically, we propose two
evaluation tasks: Relationship Outlook Prediction MCQ and Resolution Prediction
MCQ. In Relationship Outlook Prediction, a system maps an interaction to a
relationship outlook that captures how the interaction is expected to change
the relationship. In Resolution Prediction, a system attributes a given
relationship outlook to a particular resolution that explains the outcome.
These two tasks parallel two real-life questions that people frequently ponder
upon as they navigate different social situations: ""where is this relationship
going?"" and ""how did we end up here?"". To facilitate the investigation of human
social relationships through these two tasks, we construct a new dataset,
Social Narrative Tree, which consists of 1250 stories documenting a variety of
daily social interactions. The narratives encode a multitude of social elements
that interweave to give rise to rich commonsense knowledge of how relationships
evolve with respect to social interactions. We establish baseline performances
using language models and the accuracies are significantly lower than human
performance. The results demonstrate that models need to look beyond syntactic
and semantic signals to comprehend complex human relationships.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 02:07:05 GMT'}]",2020-10-30,"[['You', 'Keen', ''], ['Goldwasser', 'Dan', '']]"
1371930,2010.15600,Ciro Garcia Mr,Ciro Ivan Garcia Lopez,Three computational models and its equivalence,,,,,cs.LO cs.CC cs.CL cs.GL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  The study of computability has its origin in Hilbert's conference of 1900,
where an adjacent question, to the ones he asked, is to give a precise
description of the notion of algorithm. In the search for a good definition
arose three independent theories: Turing and the Turing machines, G\""odel and
the recursive functions, Church and the Lambda Calculus.
  Later there were established by Kleene that the classic models of computation
are equivalent. This fact is widely accepted by many textbooks and the proof is
omitted since the proof is tedious and unreadable. We intend to fill this gap
presenting the proof in a modern way, without forgetting the mathematical
details.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 05:55:19 GMT'}]",2020-10-30,"[['Lopez', 'Ciro Ivan Garcia', '']]"
1371983,2010.15653,Niko Moritz,"Niko Moritz, Takaaki Hori, Jonathan Le Roux","Semi-Supervised Speech Recognition via Graph-based Temporal
  Classification",Submitted to ICASSP 2021,,,,cs.LG cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Semi-supervised learning has demonstrated promising results in automatic
speech recognition (ASR) by self-training using a seed ASR model with
pseudo-labels generated for unlabeled data. The effectiveness of this approach
largely relies on the pseudo-label accuracy, for which typically only the
1-best ASR hypothesis is used. However, alternative ASR hypotheses of an N-best
list can provide more accurate labels for an unlabeled speech utterance and
also reflect uncertainties of the seed ASR model. In this paper, we propose a
generalized form of the connectionist temporal classification (CTC) objective
that accepts a graph representation of the training targets. The newly proposed
graph-based temporal classification (GTC) objective is applied for
self-training with WFST-based supervision, which is generated from an N-best
list of pseudo-labels. In this setup, GTC is used to learn not only a temporal
alignment, similarly to CTC, but also a label alignment to obtain the optimal
pseudo-label sequence from the weighted graph. Results show that this approach
can effectively exploit an N-best list of pseudo-labels with associated scores,
outperforming standard pseudo-labeling by a large margin, with ASR results
close to an oracle experiment in which the best hypotheses of the N-best lists
are selected manually.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 14:56:56 GMT'}]",2020-10-30,"[['Moritz', 'Niko', ''], ['Hori', 'Takaaki', ''], ['Roux', 'Jonathan Le', '']]"
1358840,2010.02510,Lily Ou,"Sophie Groenwold, Lily Ou, Aesha Parekh, Samhita Honnavalli, Sharon
  Levy, Diba Mirza, William Yang Wang","Investigating African-American Vernacular English in Transformer-Based
  Text Generation","7 pages, EMNLP 2020",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The growth of social media has encouraged the written use of African American
Vernacular English (AAVE), which has traditionally been used only in oral
contexts. However, NLP models have historically been developed using dominant
English varieties, such as Standard American English (SAE), due to text corpora
availability. We investigate the performance of GPT-2 on AAVE text by creating
a dataset of intent-equivalent parallel AAVE/SAE tweet pairs, thereby isolating
syntactic structure and AAVE- or SAE-specific language for each pair. We
evaluate each sample and its GPT-2 generated text with pretrained sentiment
classifiers and find that while AAVE text results in more classifications of
negative sentiment than SAE, the use of GPT-2 generally increases occurrences
of positive sentiment for both. Additionally, we conduct human evaluation of
AAVE and SAE text generated with GPT-2 to compare contextual rigor and overall
quality.
","[{'version': 'v1', 'created': 'Tue, 6 Oct 2020 06:27:02 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 04:00:46 GMT'}]",2020-10-30,"[['Groenwold', 'Sophie', ''], ['Ou', 'Lily', ''], ['Parekh', 'Aesha', ''], ['Honnavalli', 'Samhita', ''], ['Levy', 'Sharon', ''], ['Mirza', 'Diba', ''], ['Wang', 'William Yang', '']]"
1367089,2010.10759,Yangyang Shi,"Yangyang Shi, Yongqiang Wang, Chunyang Wu, Ching-Feng Yeh, Julian
  Chan, Frank Zhang, Duc Le, Mike Seltzer","Emformer: Efficient Memory Transformer Based Acoustic Model For Low
  Latency Streaming Speech Recognition","5 pages, 2 figures, submitted to ICASSP 2021",,,,cs.SD cs.CL cs.LG eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper proposes an efficient memory transformer Emformer for low latency
streaming speech recognition. In Emformer, the long-range history context is
distilled into an augmented memory bank to reduce self-attention's computation
complexity. A cache mechanism saves the computation for the key and value in
self-attention for the left context. Emformer applies a parallelized block
processing in training to support low latency models. We carry out experiments
on benchmark LibriSpeech data. Under average latency of 960 ms, Emformer gets
WER $2.50\%$ on test-clean and $5.62\%$ on test-other. Comparing with a strong
baseline augmented memory transformer (AM-TRF), Emformer gets $4.6$ folds
training speedup and $18\%$ relative real-time factor (RTF) reduction in
decoding with relative WER reduction $17\%$ on test-clean and $9\%$ on
test-other. For a low latency scenario with an average latency of 80 ms,
Emformer achieves WER $3.01\%$ on test-clean and $7.09\%$ on test-other.
Comparing with the LSTM baseline with the same latency and model size, Emformer
gets relative WER reduction $9\%$ and $16\%$ on test-clean and test-other,
respectively.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 04:38:09 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 19:59:08 GMT'}, {'version': 'v3', 'created': 'Thu, 29 Oct 2020 14:55:59 GMT'}]",2020-10-30,"[['Shi', 'Yangyang', ''], ['Wang', 'Yongqiang', ''], ['Wu', 'Chunyang', ''], ['Yeh', 'Ching-Feng', ''], ['Chan', 'Julian', ''], ['Zhang', 'Frank', ''], ['Le', 'Duc', ''], ['Seltzer', 'Mike', '']]"
1371388,2010.15058,Tomek Korbak,Tomasz Korbak and Julian Zubek and Joanna R\k{a}czaszek-Leonardi,Measuring non-trivial compositionality in emergent communication,"4th Workshop on Emergent Communication, NeurIPS 2020",,,,cs.NE cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Compositionality is an important explanatory target in emergent communication
and language evolution. The vast majority of computational models of
communication account for the emergence of only a very basic form of
compositionality: trivial compositionality. A compositional protocol is
trivially compositional if the meaning of a complex signal (e.g. blue circle)
boils down to the intersection of meanings of its constituents (e.g. the
intersection of the set of blue objects and the set of circles). A protocol is
non-trivially compositional (NTC) if the meaning of a complex signal (e.g.
biggest apple) is a more complex function of the meanings of their
constituents. In this paper, we review several metrics of compositionality used
in emergent communication and experimentally show that most of them fail to
detect NTC - i.e. they treat non-trivial compositionality as a failure of
compositionality. The one exception is tree reconstruction error, a metric
motivated by formal accounts of compositionality. These results emphasise
important limitations of emergent communication research that could hamper
progress on modelling the emergence of NTC.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 16:11:07 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 16:22:44 GMT'}]",2020-10-30,"[['Korbak', 'Tomasz', ''], ['Zubek', 'Julian', ''], ['Rączaszek-Leonardi', 'Joanna', '']]"
1301728,2006.07214,Andre Martins,"Andr\'e F. T. Martins, Ant\'onio Farinhas, Marcos Treviso, Vlad
  Niculae, Pedro M. Q. Aguiar, M\'ario A. T. Figueiredo",Sparse and Continuous Attention Mechanisms,Accepted for spotlight presentation at NeurIPS 2020,,,,cs.LG cs.CL cs.CV stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Exponential families are widely used in machine learning; they include many
distributions in continuous and discrete domains (e.g., Gaussian, Dirichlet,
Poisson, and categorical distributions via the softmax transformation).
Distributions in each of these families have fixed support. In contrast, for
finite domains, there has been recent work on sparse alternatives to softmax
(e.g. sparsemax and alpha-entmax), which have varying support, being able to
assign zero probability to irrelevant categories. This paper expands that work
in two directions: first, we extend alpha-entmax to continuous domains,
revealing a link with Tsallis statistics and deformed exponential families.
Second, we introduce continuous-domain attention mechanisms, deriving efficient
gradient backpropagation algorithms for alpha in {1,2}. Experiments on
attention-based text classification, machine translation, and visual question
answering illustrate the use of continuous attention in 1D and 2D, showing that
it allows attending to time intervals and compact regions.
","[{'version': 'v1', 'created': 'Fri, 12 Jun 2020 14:16:48 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 22:22:38 GMT'}, {'version': 'v3', 'created': 'Thu, 29 Oct 2020 08:39:54 GMT'}]",2020-10-30,"[['Martins', 'André F. T.', ''], ['Farinhas', 'António', ''], ['Treviso', 'Marcos', ''], ['Niculae', 'Vlad', ''], ['Aguiar', 'Pedro M. Q.', ''], ['Figueiredo', 'Mário A. T.', '']]"
1324516,2007.13002,Siyuan Feng,"Siyuan Feng, Odette Scharenborg","Unsupervised Subword Modeling Using Autoregressive Pretraining and
  Cross-Lingual Phone-Aware Modeling","5 pages, 3 figures. Accepted for publication in INTERSPEECH 2020,
  Shanghai, China",,10.21437/Interspeech.2020-1170,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This study addresses unsupervised subword modeling, i.e., learning feature
representations that can distinguish subword units of a language. The proposed
approach adopts a two-stage bottleneck feature (BNF) learning framework,
consisting of autoregressive predictive coding (APC) as a front-end and a
DNN-BNF model as a back-end. APC pretrained features are set as input features
to a DNN-BNF model. A language-mismatched ASR system is used to provide
cross-lingual phone labels for DNN-BNF model training. Finally, BNFs are
extracted as the subword-discriminative feature representation. A second aim of
this work is to investigate the robustness of our approach's effectiveness to
different amounts of training data. The results on Libri-light and the
ZeroSpeech 2017 databases show that APC is effective in front-end feature
pretraining. Our whole system outperforms the state of the art on both
databases. Cross-lingual phone labels for English data by a Dutch ASR
outperform those by a Mandarin ASR, possibly linked to the larger similarity of
Dutch compared to Mandarin with English. Our system is less sensitive to
training data amount when the training data is over 50 hours. APC pretraining
leads to a reduction of needed training material from over 5,000 hours to
around 200 hours with little performance degradation.
","[{'version': 'v1', 'created': 'Sat, 25 Jul 2020 19:41:41 GMT'}, {'version': 'v2', 'created': 'Thu, 6 Aug 2020 19:15:48 GMT'}]",2020-10-30,"[['Feng', 'Siyuan', ''], ['Scharenborg', 'Odette', '']]"
1371596,2010.15266,Abhinav Singh,"Abhinav Singh, Patrick Xia, Guanghui Qin, Mahsa Yarmohammadi, Benjamin
  Van Durme","CopyNext: Explicit Span Copying and Alignment in Sequence to Sequence
  Models",4th Workshop on Structured Prediction for NLP (EMNLP 2020),,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Copy mechanisms are employed in sequence to sequence models (seq2seq) to
generate reproductions of words from the input to the output. These frameworks,
operating at the lexical type level, fail to provide an explicit alignment that
records where each token was copied from. Further, they require contiguous
token sequences from the input (spans) to be copied individually. We present a
model with an explicit token-level copy operation and extend it to copying
entire spans. Our model provides hard alignments between spans in the input and
output, allowing for nontraditional applications of seq2seq, like information
extraction. We demonstrate the approach on Nested Named Entity Recognition,
achieving near state-of-the-art accuracy with an order of magnitude increase in
decoding speed.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 22:45:16 GMT'}]",2020-10-30,"[['Singh', 'Abhinav', ''], ['Xia', 'Patrick', ''], ['Qin', 'Guanghui', ''], ['Yarmohammadi', 'Mahsa', ''], ['Van Durme', 'Benjamin', '']]"
1294236,2005.14441,Xiang Hao,"Xiang Hao, Xiangdong Su, Zhiyu Wang, Qiang Zhang, Huali Xu and
  Guanglai Gao",SNR-Based Teachers-Student Technique for Speech Enhancement,"Published in 2020 IEEE International Conference on Multimedia and
  Expo (ICME 2020)",,10.1109/ICME46284.2020.9102846,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  It is very challenging for speech enhancement methods to achieves robust
performance under both high signal-to-noise ratio (SNR) and low SNR
simultaneously. In this paper, we propose a method that integrates an SNR-based
teachers-student technique and time-domain U-Net to deal with this problem.
Specifically, this method consists of multiple teacher models and a student
model. We first train the teacher models under multiple small-range SNRs that
do not coincide with each other so that they can perform speech enhancement
well within the specific SNR range. Then, we choose different teacher models to
supervise the training of the student model according to the SNR of the
training data. Eventually, the student model can perform speech enhancement
under both high SNR and low SNR. To evaluate the proposed method, we
constructed a dataset with an SNR ranging from -20dB to 20dB based on the
public dataset. We experimentally analyzed the effectiveness of the SNR-based
teachers-student technique and compared the proposed method with several
state-of-the-art methods.
","[{'version': 'v1', 'created': 'Fri, 29 May 2020 08:13:01 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 12:12:20 GMT'}]",2020-10-30,"[['Hao', 'Xiang', ''], ['Su', 'Xiangdong', ''], ['Wang', 'Zhiyu', ''], ['Zhang', 'Qiang', ''], ['Xu', 'Huali', ''], ['Gao', 'Guanglai', '']]"
1294230,2005.14435,Xiang Hao,"Xiang Hao, Shixue Wen, Xiangdong Su, Yun Liu, Guanglai Gao and Xiaofei
  Li",Sub-Band Knowledge Distillation Framework for Speech Enhancement,Published in Interspeech 2020,,10.21437/Interspeech.2020-1539,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In single-channel speech enhancement, methods based on full-band spectral
features have been widely studied. However, only a few methods pay attention to
non-full-band spectral features. In this paper, we explore a knowledge
distillation framework based on sub-band spectral mapping for single-channel
speech enhancement. Specifically, we divide the full frequency band into
multiple sub-bands and pre-train an elite-level sub-band enhancement model
(teacher model) for each sub-band. These teacher models are dedicated to
processing their own sub-bands. Next, under the teacher models' guidance, we
train a general sub-band enhancement model (student model) that works for all
sub-bands. Without increasing the number of model parameters and computational
complexity, the student model's performance is further improved. To evaluate
our proposed method, we conducted a large number of experiments on an
open-source data set. The final experimental results show that the guidance
from the elite-level teacher models dramatically improves the student model's
performance, which exceeds the full-band model by employing fewer parameters.
","[{'version': 'v1', 'created': 'Fri, 29 May 2020 07:55:12 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 12:14:59 GMT'}]",2020-10-30,"[['Hao', 'Xiang', ''], ['Wen', 'Shixue', ''], ['Su', 'Xiangdong', ''], ['Liu', 'Yun', ''], ['Gao', 'Guanglai', ''], ['Li', 'Xiaofei', '']]"
1292684,2005.12889,Ruixiang Cui,"Ruixiang Cui, Daniel Hershcovich",Refining Implicit Argument Annotation for UCCA,DMR 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Predicate-argument structure analysis is a central component in meaning
representations of text. The fact that some arguments are not explicitly
mentioned in a sentence gives rise to ambiguity in language understanding, and
renders it difficult for machines to interpret text correctly. However, only
few resources represent implicit roles for NLU, and existing studies in NLP
only make coarse distinctions between categories of arguments omitted from
linguistic form. This paper proposes a typology for fine-grained implicit
argument annotation on top of Universal Conceptual Cognitive Annotation's
foundational layer. The proposed implicit argument categorisation is driven by
theories of implicit role interpretation and consists of six types: Deictic,
Generic, Genre-based, Type-identifiable, Non-specific, and Iterated-set. We
exemplify our design by revisiting part of the UCCA EWT corpus, providing a new
dataset annotated with the refinement layer, and making a comparative analysis
with other schemes.
","[{'version': 'v1', 'created': 'Tue, 26 May 2020 17:24:15 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 16:07:33 GMT'}]",2020-10-30,"[['Cui', 'Ruixiang', ''], ['Hershcovich', 'Daniel', '']]"
1358810,2010.02480,Cheng-Han Chiang,"Cheng-Han Chiang, Sung-Feng Huang and Hung-yi Lee",Pretrained Language Model Embryology: The Birth of ALBERT,"Accepted to EMNLP 2020, short paper",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While behaviors of pretrained language models (LMs) have been thoroughly
examined, what happened during pretraining is rarely studied. We thus
investigate the developmental process from a set of randomly initialized
parameters to a totipotent language model, which we refer to as the embryology
of a pretrained language model. Our results show that ALBERT learns to
reconstruct and predict tokens of different parts of speech (POS) in different
learning speeds during pretraining. We also find that linguistic knowledge and
world knowledge do not generally improve as pretraining proceeds, nor do
downstream tasks' performance. These findings suggest that knowledge of a
pretrained model varies during pretraining, and having more pretrain steps does
not necessarily provide a model with more comprehensive knowledge. We will
provide source codes and pretrained models to reproduce our results at
https://github.com/d223302/albert-embryology.
","[{'version': 'v1', 'created': 'Tue, 6 Oct 2020 05:15:39 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 00:07:43 GMT'}]",2020-10-30,"[['Chiang', 'Cheng-Han', ''], ['Huang', 'Sung-Feng', ''], ['Lee', 'Hung-yi', '']]"
1201305,1911.02711,Sen Yang,"Sen Yang, Leyang Cui, Jun Xie and Yue Zhang",Making the Best Use of Review Summary for Sentiment Analysis,To be published in COLING-2020,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Sentiment analysis provides a useful overview of customer review contents.
Many review websites allow a user to enter a summary in addition to a full
review. Intuitively, summary information may give additional benefit for review
sentiment analysis. In this paper, we conduct a study to exploit methods for
better use of summary information. We start by finding out that the sentimental
signal distribution of a review and that of its corresponding summary are in
fact complementary to each other. We thus explore various architectures to
better guide the interactions between the two and propose a
hierarchically-refined review-centric attention model. Empirical results show
that our review-centric model can make better use of user-written summaries for
review sentiment analysis, and is also more effective compared to existing
methods when the user summary is replaced with summary generated by an
automatic summarization system.
","[{'version': 'v1', 'created': 'Thu, 7 Nov 2019 01:46:54 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 07:15:01 GMT'}]",2020-10-30,"[['Yang', 'Sen', ''], ['Cui', 'Leyang', ''], ['Xie', 'Jun', ''], ['Zhang', 'Yue', '']]"
1202469,1911.03875,Khalil Mrini,"Khalil Mrini, Franck Dernoncourt, Quan Tran, Trung Bui, Walter Chang,
  Ndapa Nakashole",Rethinking Self-Attention: Towards Interpretability in Neural Parsing,EMNLP 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Attention mechanisms have improved the performance of NLP tasks while
allowing models to remain explainable. Self-attention is currently widely used,
however interpretability is difficult due to the numerous attention
distributions. Recent work has shown that model representations can benefit
from label-specific information, while facilitating interpretation of
predictions. We introduce the Label Attention Layer: a new form of
self-attention where attention heads represent labels. We test our novel layer
by running constituency and dependency parsing experiments and show our new
model obtains new state-of-the-art results for both tasks on both the Penn
Treebank (PTB) and Chinese Treebank. Additionally, our model requires fewer
self-attention layers compared to existing work. Finally, we find that the
Label Attention heads learn relations between syntactic categories and show
pathways to analyze errors.
","[{'version': 'v1', 'created': 'Sun, 10 Nov 2019 08:17:11 GMT'}, {'version': 'v2', 'created': 'Sat, 2 May 2020 04:34:52 GMT'}, {'version': 'v3', 'created': 'Thu, 29 Oct 2020 06:17:11 GMT'}]",2020-10-30,"[['Mrini', 'Khalil', ''], ['Dernoncourt', 'Franck', ''], ['Tran', 'Quan', ''], ['Bui', 'Trung', ''], ['Chang', 'Walter', ''], ['Nakashole', 'Ndapa', '']]"
1217216,1912.05320,Carlos S. Armendariz,"Carlos Santos Armendariz, Matthew Purver, Matej Ul\v{c}ar, Senja
  Pollak, Nikola Ljube\v{s}i\'c, Marko Robnik-\v{S}ikonja, Mark
  Granroth-Wilding, Kristiina Vaik",CoSimLex: A Resource for Evaluating Graded Word Similarity in Context,,"Proceedings of the 12th Language Resources and Evaluation
  Conference (2020) 5878-5886",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  State of the art natural language processing tools are built on
context-dependent word embeddings, but no direct method for evaluating these
representations currently exists. Standard tasks and datasets for intrinsic
evaluation of embeddings are based on judgements of similarity, but ignore
context; standard tasks for word sense disambiguation take account of context
but do not provide continuous measures of meaning similarity. This paper
describes an effort to build a new dataset, CoSimLex, intended to fill this
gap. Building on the standard pairwise similarity task of SimLex-999, it
provides context-dependent similarity measures; covers not only discrete
differences in word sense but more subtle, graded changes in meaning; and
covers not only a well-resourced language (English) but a number of
less-resourced languages. We define the task and evaluation metrics, outline
the dataset collection methodology, and describe the status of the dataset so
far.
","[{'version': 'v1', 'created': 'Wed, 11 Dec 2019 14:02:59 GMT'}, {'version': 'v2', 'created': 'Wed, 18 Dec 2019 10:33:05 GMT'}, {'version': 'v3', 'created': 'Thu, 29 Oct 2020 15:22:27 GMT'}]",2020-10-30,"[['Armendariz', 'Carlos Santos', ''], ['Purver', 'Matthew', ''], ['Ulčar', 'Matej', ''], ['Pollak', 'Senja', ''], ['Ljubešić', 'Nikola', ''], ['Robnik-Šikonja', 'Marko', ''], ['Granroth-Wilding', 'Mark', ''], ['Vaik', 'Kristiina', '']]"
1371555,2010.15225,Dylan Ebert,"Dylan Ebert, Ellie Pavlick",A Visuospatial Dataset for Naturalistic Verb Learning,"9 pages, 3 figures, starsem 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We introduce a new dataset for training and evaluating grounded language
models. Our data is collected within a virtual reality environment and is
designed to emulate the quality of language data to which a pre-verbal child is
likely to have access: That is, naturalistic, spontaneous speech paired with
richly grounded visuospatial context. We use the collected data to compare
several distributional semantics models for verb learning. We evaluate neural
models based on 2D (pixel) features as well as feature-engineered models based
on 3D (symbolic, spatial) features, and show that neither modeling approach
achieves satisfactory performance. Our results are consistent with evidence
from child language acquisition that emphasizes the difficulty of learning
verbs from naive distributional data. We discuss avenues for future work on
cognitively-inspired grounded language learning, and release our corpus with
the intent of facilitating research on the topic.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 20:47:13 GMT'}]",2020-10-30,"[['Ebert', 'Dylan', ''], ['Pavlick', 'Ellie', '']]"
1362681,2010.06351,Fuli Luo,"Fuli Luo, Pengcheng Yang, Shicheng Li, Xuancheng Ren, Xu Sun","CAPT: Contrastive Pre-Training for Learning Denoised Sequence
  Representations",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pre-trained self-supervised models such as BERT have achieved striking
success in learning sequence representations, especially for natural language
processing. These models typically corrupt the given sequences with certain
types of noise, such as masking, shuffling, or substitution, and then try to
recover the original input. However, such pre-training approaches are prone to
learning representations that are covariant with the noise, leading to the
discrepancy between the pre-training and fine-tuning stage. To remedy this, we
present ContrAstive Pre-Training (CAPT) to learn noise invariant sequence
representations. The proposed CAPT encourages the consistency between
representations of the original sequence and its corrupted version via
unsupervised instance-wise training signals. In this way, it not only
alleviates the pretrain-finetune discrepancy induced by the noise of
pre-training, but also aids the pre-trained model in better capturing global
semantics of the input via more effective sentence-level supervision. Different
from most prior work that focuses on a particular modality, comprehensive
empirical evidence on 11 natural language understanding and cross-modal tasks
illustrates that CAPT is applicable for both language and vision-language
tasks, and obtains surprisingly consistent improvement, including 0.6% absolute
gain on GLUE benchmarks and 0.8% absolute increment on NLVR.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 13:08:34 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 09:30:12 GMT'}, {'version': 'v3', 'created': 'Thu, 29 Oct 2020 06:41:07 GMT'}]",2020-10-30,"[['Luo', 'Fuli', ''], ['Yang', 'Pengcheng', ''], ['Li', 'Shicheng', ''], ['Ren', 'Xuancheng', ''], ['Sun', 'Xu', '']]"
1372108,2010.15778,Timo Denk,Timo I. Denk and Ana Peleteiro Ramallo,Contextual BERT: Conditioning the Language Model Using a Global State,"Accepted at the TextGraphs-14 workshop at COLING'2020 - The 28th
  International Conference on Computational Linguistics",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  BERT is a popular language model whose main pre-training task is to fill in
the blank, i.e., predicting a word that was masked out of a sentence, based on
the remaining words. In some applications, however, having an additional
context can help the model make the right prediction, e.g., by taking the
domain or the time of writing into account. This motivates us to advance the
BERT architecture by adding a global state for conditioning on a fixed-sized
context. We present our two novel approaches and apply them to an industry
use-case, where we complete fashion outfits with missing articles, conditioned
on a specific customer. An experimental comparison to other methods from the
literature shows that our methods improve personalization significantly.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 17:25:20 GMT'}]",2020-10-30,"[['Denk', 'Timo I.', ''], ['Ramallo', 'Ana Peleteiro', '']]"
1371581,2010.15251,Marimuthu Kalimuthu,"Marimuthu Kalimuthu, Aditya Mogadala, Marius Mosbach, Dietrich Klakow",Fusion Models for Improved Visual Captioning,"Under review at ""Multi-Modal Deep Learning: Challenges and
  Applications"", ICPR-2020",,,,cs.CV cs.AI cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Visual captioning aims to generate textual descriptions given images.
Traditionally, the captioning models are trained on human annotated datasets
such as Flickr30k and MS-COCO, which are limited in size and diversity. This
limitation hinders the generalization capabilities of these models while also
rendering them to often make mistakes. Language models can, however, be trained
on vast amounts of freely available unlabelled data and have recently emerged
as successful language encoders and coherent text generators. Meanwhile,
several unimodal and multimodal fusion techniques have been proven to work well
for natural language generation and automatic speech recognition. Building on
these recent developments, and with an aim of improving the quality of
generated captions, the contribution of our work in this paper is two-fold:
First, we propose a generic multimodal model fusion framework for caption
generation as well as emendation where we utilize different fusion strategies
to integrate a pretrained Auxiliary Language Model (AuxLM) within the
traditional encoder-decoder visual captioning frameworks. Next, we employ the
same fusion strategies to integrate a pretrained Masked Language Model (MLM),
namely BERT, with a visual captioning model, viz. Show, Attend, and Tell, for
emending both syntactic and semantic errors in captions. Our caption emendation
experiments on three benchmark image captioning datasets, viz. Flickr8k,
Flickr30k, and MSCOCO, show improvements over the baseline, indicating the
usefulness of our proposed multimodal fusion strategies. Further, we perform a
preliminary qualitative analysis on the emended captions and identify error
categories based on the type of corrections.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 21:55:25 GMT'}]",2020-10-30,"[['Kalimuthu', 'Marimuthu', ''], ['Mogadala', 'Aditya', ''], ['Mosbach', 'Marius', ''], ['Klakow', 'Dietrich', '']]"
1372058,2010.15728,Hang Dong,"Hang Dong, V\'ictor Su\'arez-Paniagua, William Whiteley, Honghan Wu","Explainable Automated Coding of Clinical Notes using Hierarchical
  Label-wise Attention Networks and Label Embedding Initialisation","Structured abstract in full text, 17 pages, 5 figures, 4
  supplementary materials (3 extra pages), submitted to Journal of Biomedical
  Informatics",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Diagnostic or procedural coding of clinical notes aims to derive a coded
summary of disease-related information about patients. Such coding is usually
done manually in hospitals but could potentially be automated to improve the
efficiency and accuracy of medical coding. Recent studies on deep learning for
automated medical coding achieved promising performances. However, the
explainability of these models is usually poor, preventing them to be used
confidently in supporting clinical practice. Another limitation is that these
models mostly assume independence among labels, ignoring the complex
correlation among medical codes which can potentially be exploited to improve
the performance. We propose a Hierarchical Label-wise Attention Network (HLAN),
which aimed to interpret the model by quantifying importance (as attention
weights) of words and sentences related to each of the labels. Secondly, we
propose to enhance the major deep learning models with a label embedding (LE)
initialisation approach, which learns a dense, continuous vector representation
and then injects the representation into the final layers and the label-wise
attention layers in the models. We evaluated the methods using three settings
on the MIMIC-III discharge summaries: full codes, top-50 codes, and the UK NHS
COVID-19 shielding codes. Experiments were conducted to compare HLAN and LE
initialisation to the state-of-the-art neural network based methods. HLAN
achieved the best Micro-level AUC and $F_1$ on the top-50 code prediction and
comparable results on the NHS COVID-19 shielding code prediction to other
models. By highlighting the most salient words and sentences for each label,
HLAN showed more meaningful and comprehensive model interpretation compared to
its downgraded baselines and the CNN-based models. LE initialisation
consistently boosted most deep learning models for automated medical coding.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 16:21:26 GMT'}]",2020-10-30,"[['Dong', 'Hang', ''], ['Suárez-Paniagua', 'Víctor', ''], ['Whiteley', 'William', ''], ['Wu', 'Honghan', '']]"
1371932,2010.15602,Junhua Liu,Nachamma Sockalingam and Junhua Liu,Designing learning experiences for online teaching and learning,,,,,cs.CY cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Teaching is about constantly innovating strategies, ways and means to engage
diverse students in active and meaningful learning. In line with this, SUTD
adopts various student-centric teaching and learning teaching methods and
approaches. This means that our graduate/undergraduate instructors have to be
ready to teach using these student student-centric teaching and learning
pedagogies. In this article, I share my experiences of redesigning this
teaching course that is typically conducted face-to-face to a synchronous
online course and also invite one of the participant in this course to reflect
on his experience as a student.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 07:03:49 GMT'}]",2020-10-30,"[['Sockalingam', 'Nachamma', ''], ['Liu', 'Junhua', '']]"
1371479,2010.15149,Yiwei Luo,"Yiwei Luo, Dallas Card, Dan Jurafsky",DeSMOG: Detecting Stance in Media On Global Warming,"9 pages, 6 figures (excluding references and appendices). To appear
  in Findings of EMNLP 2020",Findings of EMNLP 2020,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Citing opinions is a powerful yet understudied strategy in argumentation. For
example, an environmental activist might say, ""Leading scientists agree that
global warming is a serious concern,"" framing a clause which affirms their own
stance (""that global warming is serious"") as an opinion endorsed (""[scientists]
agree"") by a reputable source (""leading""). In contrast, a global warming denier
might frame the same clause as the opinion of an untrustworthy source with a
predicate connoting doubt: ""Mistaken scientists claim [...]."" Our work studies
opinion-framing in the global warming (GW) debate, an increasingly partisan
issue that has received little attention in NLP. We introduce DeSMOG, a dataset
of stance-labeled GW sentences, and train a BERT classifier to study novel
aspects of argumentation in how different sides of a debate represent their own
and each other's opinions. From 56K news articles, we find that similar
linguistic devices for self-affirming and opponent-doubting discourse are used
across GW-accepting and skeptic media, though GW-skeptical media shows more
opponent-doubt. We also find that authors often characterize sources as
hypocritical, by ascribing opinions expressing the author's own view to source
entities known to publicly endorse the opposing view. We release our stance
dataset, model, and lexicons of framing devices for future work on
opinion-framing and the automatic detection of GW stance.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 18:01:02 GMT'}]",2020-10-30,"[['Luo', 'Yiwei', ''], ['Card', 'Dallas', ''], ['Jurafsky', 'Dan', '']]"
1371630,2010.15300,Emaad Manzoor,"Emaad Manzoor, Nihar B. Shah",Uncovering Latent Biases in Text: Method and Application to Peer Review,,,,,cs.CL cs.CY cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Quantifying systematic disparities in numerical quantities such as employment
rates and wages between population subgroups provides compelling evidence for
the existence of societal biases. However, biases in the text written for
members of different subgroups (such as in recommendation letters for male and
non-male candidates), though widely reported anecdotally, remain challenging to
quantify. In this work, we introduce a novel framework to quantify bias in text
caused by the visibility of subgroup membership indicators. We develop a
nonparametric estimation and inference procedure to estimate this bias. We then
formalize an identification strategy to causally link the estimated bias to the
visibility of subgroup membership indicators, provided observations from time
periods both before and after an identity-hiding policy change. We identify an
application wherein ""ground truth"" bias can be inferred to evaluate our
framework, instead of relying on synthetic or secondary data. Specifically, we
apply our framework to quantify biases in the text of peer reviews from a
reputed machine learning conference before and after the conference adopted a
double-blind reviewing policy. We show evidence of biases in the review ratings
that serves as ""ground truth"", and show that our proposed framework accurately
detects these biases from the review text without having access to the review
ratings.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 01:24:19 GMT'}]",2020-10-30,"[['Manzoor', 'Emaad', ''], ['Shah', 'Nihar B.', '']]"
