,id,submitter,authors,title,comments,journal-ref,doi,report-no,categories,license,abstract,versions,update_date,authors_parsed
1361687,2010.05357,Jiahua Chen,Jiahua Chen and Shuai Wang and Sahisnu Mazumder and Bing Liu,"A Knowledge-Driven Approach to Classifying Object and Attribute
  Coreferences in Opinion Mining",Accepted to Proceedings of EMNLP 2020 (Findings),,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Classifying and resolving coreferences of objects (e.g., product names) and
attributes (e.g., product aspects) in opinionated reviews is crucial for
improving the opinion mining performance. However, the task is challenging as
one often needs to consider domain-specific knowledge (e.g., iPad is a tablet
and has aspect resolution) to identify coreferences in opinionated reviews.
Also, compiling a handcrafted and curated domain-specific knowledge base for
each domain is very time consuming and arduous. This paper proposes an approach
to automatically mine and leverage domain-specific knowledge for classifying
objects and attribute coreferences. The approach extracts domain-specific
knowledge from unlabeled review data and trains a knowledgeaware neural
coreference classification model to leverage (useful) domain knowledge together
with general commonsense knowledge for the task. Experimental evaluation on
realworld datasets involving five domains (product types) shows the
effectiveness of the approach.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 22:08:43 GMT'}]",2020-10-13,"[['Chen', 'Jiahua', ''], ['Wang', 'Shuai', ''], ['Mazumder', 'Sahisnu', ''], ['Liu', 'Bing', '']]"
1361331,2010.05001,Wanqing Cui,"Wanqing Cui, Yanyan Lan, Liang Pang, Jiafeng Guo, Xueqi Cheng",Beyond Language: Learning Commonsense from Images for Reasoning,Accepted to EMNLP'20 Findings,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper proposes a novel approach to learn commonsense from images,
instead of limited raw texts or costly constructed knowledge bases, for the
commonsense reasoning problem in NLP. Our motivation comes from the fact that
an image is worth a thousand words, where richer scene information could be
leveraged to help distill the commonsense knowledge, which is often hidden in
languages. Our approach, namely Loire, consists of two stages. In the first
stage, a bi-modal sequence-to-sequence approach is utilized to conduct the
scene layout generation task, based on a text representation model ViBERT. In
this way, the required visual scene knowledge, such as spatial relations, will
be encoded in ViBERT by the supervised learning process with some bi-modal data
like COCO. Then ViBERT is concatenated with a pre-trained language model to
perform the downstream commonsense reasoning tasks. Experimental results on two
commonsense reasoning problems, i.e. commonsense question answering and pronoun
resolution, demonstrate that Loire outperforms traditional language-based
methods. We also give some case studies to show what knowledge is learned from
images and explain how the generated scene layout helps the commonsense
reasoning process.
","[{'version': 'v1', 'created': 'Sat, 10 Oct 2020 13:47:13 GMT'}]",2020-10-13,"[['Cui', 'Wanqing', ''], ['Lan', 'Yanyan', ''], ['Pang', 'Liang', ''], ['Guo', 'Jiafeng', ''], ['Cheng', 'Xueqi', '']]"
1361319,2010.04989,Liang Ding,"Lei Zhou, Liang Ding and Koichi Takeda","Zero-Shot Translation Quality Estimation with Explicit Cross-Lingual
  Patterns",To appear in WMT2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper describes our submission of the WMT 2020 Shared Task on Sentence
Level Direct Assessment, Quality Estimation (QE). In this study, we empirically
reveal the \textit{mismatching issue} when directly adopting BERTScore to QE.
Specifically, there exist lots of mismatching errors between the source
sentence and translated candidate sentence with token pairwise similarity. In
response to this issue, we propose to expose explicit cross-lingual patterns,
\textit{e.g.} word alignments and generation score, to our proposed zero-shot
models. Experiments show that our proposed QE model with explicit cross-lingual
patterns could alleviate the mismatching issue, thereby improving the
performance. Encouragingly, our zero-shot QE method could achieve comparable
performance with supervised QE method, and even outperforms the supervised
counterpart on 2 out of 6 directions. We expect our work could shed light on
the zero-shot QE model improvement.
","[{'version': 'v1', 'created': 'Sat, 10 Oct 2020 13:11:41 GMT'}]",2020-10-13,"[['Zhou', 'Lei', ''], ['Ding', 'Liang', ''], ['Takeda', 'Koichi', '']]"
1361333,2010.05003,Xinyu Wang,"Xinyu Wang, Kewei Tu","Second-Order Neural Dependency Parsing with Message Passing and
  End-to-End Training",Accepted to AACL 2020. 7 pages,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we propose second-order graph-based neural dependency parsing
using message passing and end-to-end neural networks. We empirically show that
our approaches match the accuracy of very recent state-of-the-art second-order
graph-based neural dependency parsers and have significantly faster speed in
both training and testing. We also empirically show the advantage of
second-order parsing over first-order parsing and observe that the usefulness
of the head-selection structured constraint vanishes when using BERT embedding.
","[{'version': 'v1', 'created': 'Sat, 10 Oct 2020 13:49:46 GMT'}]",2020-10-13,"[['Wang', 'Xinyu', ''], ['Tu', 'Kewei', '']]"
1361532,2010.05202,Wangchunshu Zhou,Qifei Li and Wangchunshu Zhou,Connecting the Dots Between Fact Verification and Fake News Detection,Accepted to COLING 2020,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Fact verification models have enjoyed a fast advancement in the last two
years with the development of pre-trained language models like BERT and the
release of large scale datasets such as FEVER. However, the challenging problem
of fake news detection has not benefited from the improvement of fact
verification models, which is closely related to fake news detection. In this
paper, we propose a simple yet effective approach to connect the dots between
fact verification and fake news detection. Our approach first employs a text
summarization model pre-trained on news corpora to summarize the long news
article into a short claim. Then we use a fact verification model pre-trained
on the FEVER dataset to detect whether the input news article is real or fake.
Our approach makes use of the recent success of fact verification models and
enables zero-shot fake news detection, alleviating the need of large-scale
training data to train fake news detection models. Experimental results on
FakenewsNet, a benchmark dataset for fake news detection, demonstrate the
effectiveness of our proposed approach.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 09:28:52 GMT'}]",2020-10-13,"[['Li', 'Qifei', ''], ['Zhou', 'Wangchunshu', '']]"
1361553,2010.05223,Harshil Jain,"Harshil Jain, Akshat Agarwal, Kumar Shridhar, Denis Kleyko",End to End Binarized Neural Networks for Text Classification,"14 pages. Accepted at the SustaiNLP Workshop on Simple and Efficient
  Natural Language Processing at EMNLP 2020",,,,cs.LG cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Deep neural networks have demonstrated their superior performance in almost
every Natural Language Processing task, however, their increasing complexity
raises concerns. In particular, these networks require high expenses on
computational hardware, and training budget is a concern for many. Even for a
trained network, the inference phase can be too demanding for
resource-constrained devices, thus limiting its applicability. The
state-of-the-art transformer models are a vivid example. Simplifying the
computations performed by a network is one way of relaxing the complexity
requirements. In this paper, we propose an end to end binarized neural network
architecture for the intent classification task. In order to fully utilize the
potential of end to end binarization, both input representations (vector
embeddings of tokens statistics) and the classifier are binarized. We
demonstrate the efficiency of such architecture on the intent classification of
short texts over three datasets and for text classification with a larger
dataset. The proposed architecture achieves comparable to the state-of-the-art
results on standard intent classification datasets while utilizing ~ 20-40%
lesser memory and training time. Furthermore, the individual components of the
architecture, such as binarized vector embeddings of documents or binarized
classifiers, can be used separately with not necessarily fully binary
architectures.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 11:21:53 GMT'}]",2020-10-13,"[['Jain', 'Harshil', ''], ['Agarwal', 'Akshat', ''], ['Shridhar', 'Kumar', ''], ['Kleyko', 'Denis', '']]"
1361559,2010.05229,Tanya Schmah,Aditya Ohri and Tanya Schmah,Machine Translation of Mathematical Text,"14 pages, 2 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We have implemented a machine translation system, the PolyMath Translator,
for LaTeX documents containing mathematical text. The current implementation
translates English LaTeX to French LaTeX, attaining a BLEU score of 53.5 on a
held-out test corpus of mathematical sentences. It produces LaTeX documents
that can be compiled to PDF without further editing. The system first converts
the body of an input LaTeX document into English sentences containing math
tokens, using the pandoc universal document converter to parse LaTeX input. We
have trained a Transformer-based translator model, using OpenNMT, on a combined
corpus containing a small proportion of domain-specific sentences. Our full
system uses both this Transformer model and Google Translate, the latter being
used as a backup to better handle linguistic features that do not appear in our
training dataset. If the Transformer model does not have confidence in its
translation, as determined by a high perplexity score, then we use Google
Translate with a custom glossary. This backup was used 26% of the time on our
test corpus of mathematical sentences. The PolyMath Translator is available as
a web service at www.polymathtrans.ai.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 11:59:40 GMT'}]",2020-10-13,"[['Ohri', 'Aditya', ''], ['Schmah', 'Tanya', '']]"
1361560,2010.05230,Xinpeng Wang,"Feifei Xu, Xinpeng Wang, Yunpu Ma, Volker Tresp, Yuyi Wang, Shanlin
  Zhou and Haizhou Du",Controllable Multi-Character Psychology-Oriented Story Generation,Accepted by CIKM2020,,10.1145/1122445.1122456,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Story generation, which aims to generate a long and coherent story
automatically based on the title or an input sentence, is an important research
area in the field of natural language generation. There is relatively little
work on story generation with appointed emotions. Most existing works focus on
using only one specific emotion to control the generation of a whole story and
ignore the emotional changes in the characters in the course of the story. In
our work, we aim to design an emotional line for each character that considers
multiple emotions common in psychological theories, with the goal of generating
stories with richer emotional changes in the characters. To the best of our
knowledge, this work is first to focuses on characters' emotional lines in
story generation. We present a novel model-based attention mechanism that we
call SoCP (Storytelling of multi-Character Psychology). We show that the
proposed model can generate stories considering the changes in the
psychological state of different characters. To take into account the
particularity of the model, in addition to commonly used evaluation
indicators(BLEU, ROUGE, etc.), we introduce the accuracy rate of psychological
state control as a novel evaluation metric. The new indicator reflects the
effect of the model on the psychological state control of story characters.
Experiments show that with SoCP, the generated stories follow the psychological
state for each character according to both automatic and human evaluations.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 12:05:00 GMT'}]",2020-10-13,"[['Xu', 'Feifei', ''], ['Wang', 'Xinpeng', ''], ['Ma', 'Yunpu', ''], ['Tresp', 'Volker', ''], ['Wang', 'Yuyi', ''], ['Zhou', 'Shanlin', ''], ['Du', 'Haizhou', '']]"
1361573,2010.05243,Debaditya Pal,"Debaditya Pal, Harsh Sharma, Kaustubh Chaudhari",Data Agnostic RoBERTa-based Natural Language to SQL Query Generation,"8 Pages, 2 figures. Submitted to IEEE/ACM Transactions on Audio,
  Speech and Language Processing",,,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Relational databases are among the most widely used architectures to store
massive amounts of data in the modern world. However, there is a barrier
between these databases and the average user. The user often lacks the
knowledge of a query language such as SQL required to interact with the
database. The NL2SQL task aims at finding deep learning approaches to solve
this problem by converting natural language questions into valid SQL queries.
Given the sensitive nature of some databases and the growing need for data
privacy, we have presented an approach with data privacy at its core. We have
passed RoBERTa embeddings and data-agnostic knowledge vectors into LSTM based
submodels to predict the final query. Although we have not achieved state of
the art results, we have eliminated the need for the table data, right from the
training of the model, and have achieved a test set execution accuracy of
76.7%. By eliminating the table data dependency while training we have created
a model capable of zero shot learning based on the natural language question
and table schema alone.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 13:18:46 GMT'}]",2020-10-13,"[['Pal', 'Debaditya', ''], ['Sharma', 'Harsh', ''], ['Chaudhari', 'Kaustubh', '']]"
1361578,2010.05248,Qingqing Cao,"Qingqing Cao, Aruna Balasubramanian, Niranjan Balasubramanian",Towards Accurate and Reliable Energy Measurement of NLP Models,Accepted to SustaiNLP 2020 (co-located with EMNLP 2020),,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Accurate and reliable measurement of energy consumption is critical for
making well-informed design choices when choosing and training large scale NLP
models. In this work, we show that existing software-based energy measurements
are not accurate because they do not take into account hardware differences and
how resource utilization affects energy consumption. We conduct energy
measurement experiments with four different models for a question answering
task. We quantify the error of existing software-based energy measurements by
using a hardware power meter that provides highly accurate energy measurements.
Our key takeaway is the need for a more accurate energy estimation model that
takes into account hardware variabilities and the non-linear relationship
between resource utilization and energy consumption. We release the code and
data at https://github.com/csarron/sustainlp2020-energy.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 13:44:52 GMT'}]",2020-10-13,"[['Cao', 'Qingqing', ''], ['Balasubramanian', 'Aruna', ''], ['Balasubramanian', 'Niranjan', '']]"
1361586,2010.05256,Yutai Hou,"Yutai Hou, Yongkui Lai, Yushan Wu, Wanxiang Che, Ting Liu",Few-shot Learning for Multi-label Intent Detection,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we study the few-shot multi-label classification for user
intent detection. For multi-label intent detection, state-of-the-art work
estimates label-instance relevance scores and uses a threshold to select
multiple associated intent labels. To determine appropriate thresholds with
only a few examples, we first learn universal thresholding experience on
data-rich domains, and then adapt the thresholds to certain few-shot domains
with a calibration based on nonparametric learning. For better calculation of
label-instance relevance score, we introduce label name embedding as anchor
points in representation space, which refines representations of different
classes to be well-separated from each other. Experiments on two datasets show
that the proposed model significantly outperforms strong baselines in both
one-shot and five-shot settings.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 14:42:18 GMT'}]",2020-10-13,"[['Hou', 'Yutai', ''], ['Lai', 'Yongkui', ''], ['Wu', 'Yushan', ''], ['Che', 'Wanxiang', ''], ['Liu', 'Ting', '']]"
1361595,2010.05265,Shauli Ravfogel,"Shauli Ravfogel, Yanai Elazar, Jacob Goldberger, Yoav Goldberg","Unsupervised Distillation of Syntactic Information from Contextualized
  Word Representations",Accepted in BlackboxNLP@EMNLP2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Contextualized word representations, such as ELMo and BERT, were shown to
perform well on various semantic and syntactic tasks. In this work, we tackle
the task of unsupervised disentanglement between semantics and structure in
neural language representations: we aim to learn a transformation of the
contextualized vectors, that discards the lexical semantics, but keeps the
structural information. To this end, we automatically generate groups of
sentences which are structurally similar but semantically different, and use
metric-learning approach to learn a transformation that emphasizes the
structural component that is encoded in the vectors. We demonstrate that our
transformation clusters vectors in space by structural properties, rather than
by lexical semantics. Finally, we demonstrate the utility of our distilled
representations by showing that they outperform the original contextualized
representations in a few-shot parsing setting.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 15:13:18 GMT'}]",2020-10-13,"[['Ravfogel', 'Shauli', ''], ['Elazar', 'Yanai', ''], ['Goldberger', 'Jacob', ''], ['Goldberg', 'Yoav', '']]"
1361599,2010.05269,"Mika H\""am\""al\""ainen","Khalid Alnajjar, Mika H\""am\""al\""ainen, Niko Partanen, Jack Rueter",Automated Prediction of Medieval Arabic Diacritics,,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  This study uses a character level neural machine translation approach trained
on a long short-term memory-based bi-directional recurrent neural network
architecture for diacritization of Medieval Arabic. The results improve from
the online tool used as a baseline. A diacritization model have been published
openly through an easy to use Python package available on PyPi and Zenodo. We
have found that context size should be considered when optimizing a feasible
prediction model.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 15:21:01 GMT'}]",2020-10-13,"[['Alnajjar', 'Khalid', ''], ['Hämäläinen', 'Mika', ''], ['Partanen', 'Niko', ''], ['Rueter', 'Jack', '']]"
1361623,2010.05293,Jared Millson,Jared Millson,A Defeasible Calculus for Zetetic Agents,,,10.12775/LLP.2020.019,,cs.AI cs.CL math.LO,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  The study of defeasible reasoning unites epistemologists with those working
in AI, in part, because both are interested in epistemic rationality. While it
is traditionally thought to govern the formation and (with)holding of beliefs,
epistemic rationality may also apply to the interrogative attitudes associated
with our core epistemic practice of inquiry, such as wondering, investigating,
and curiosity. Since generally intelligent systems should be capable of
rational inquiry, AI researchers have a natural interest in the norms that
govern interrogative attitudes. Following its recent coinage, we use the term
""zetetic"" to refer to the properties and norms associated with the capacity to
inquire. In this paper, we argue that zetetic norms can be modeled via
defeasible inferences to and from questions---a.k.a erotetic inferences---in a
manner similar to the way norms of epistemic rationality are represented by
defeasible inference rules. We offer a sequent calculus that accommodates the
unique features of ""erotetic defeat"" and that exhibits the computational
properties needed to inform the design of zetetic agents. The calculus
presented here is an improved version of the one presented in Millson (2019),
extended to cover a new class of defeasible erotetic inferences.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 17:39:03 GMT'}]",2020-10-13,"[['Millson', 'Jared', '']]"
1361647,2010.05317,Sai Prabhakar Pandi Selvaraj,"Dhruvesh Patel, Sandeep Konam, Sai P. Selvaraj","Weakly Supervised Medication Regimen Extraction from Medical
  Conversations","To appear in the Proceedings of the Clinical Natural Language
  Processing Workshop, EMNLP, 2020",,,,cs.CL cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automated Medication Regimen (MR) extraction from medical conversations can
not only improve recall and help patients follow through with their care plan,
but also reduce the documentation burden for doctors. In this paper, we focus
on extracting spans for frequency, route and change, corresponding to
medications discussed in the conversation. We first describe a unique dataset
of annotated doctor-patient conversations and then present a weakly supervised
model architecture that can perform span extraction using noisy classification
data. The model utilizes an attention bottleneck inside a classification model
to perform the extraction. We experiment with several variants of attention
scoring and projection functions and propose a novel transformer-based
attention scoring function (TAScore). The proposed combination of TAScore and
Fusedmax projection achieves a 10 point increase in Longest Common Substring F1
compared to the baseline of additive scoring plus softmax projection.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 18:53:03 GMT'}]",2020-10-13,"[['Patel', 'Dhruvesh', ''], ['Konam', 'Sandeep', ''], ['Selvaraj', 'Sai P.', '']]"
1361648,2010.05318,Tharindu Ranasinghe Mr,"Tharindu Ranasinghe, Constantin Orasan, Ruslan Mitkov",TransQuest at WMT2020: Sentence-Level Direct Assessment,Accepted to WMT 2020,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  This paper presents the team TransQuest's participation in Sentence-Level
Direct Assessment shared task in WMT 2020. We introduce a simple QE framework
based on cross-lingual transformers, and we use it to implement and evaluate
two different neural architectures. The proposed methods achieve
state-of-the-art results surpassing the results obtained by OpenKiwi, the
baseline used in the shared task. We further fine tune the QE framework by
performing ensemble and data augmentation. Our approach is the winning solution
in all of the language pairs according to the WMT 2020 official results.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 18:53:05 GMT'}]",2020-10-13,"[['Ranasinghe', 'Tharindu', ''], ['Orasan', 'Constantin', ''], ['Mitkov', 'Ruslan', '']]"
1361654,2010.05324,Tharindu Ranasinghe Mr,"Tharindu Ranasinghe, Marcos Zampieri","Multilingual Offensive Language Identification with Cross-lingual
  Embeddings",Accepted to EMNLP 2020,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Offensive content is pervasive in social media and a reason for concern to
companies and government organizations. Several studies have been recently
published investigating methods to detect the various forms of such content
(e.g. hate speech, cyberbulling, and cyberaggression). The clear majority of
these studies deal with English partially because most annotated datasets
available contain English data. In this paper, we take advantage of English
data available by applying cross-lingual contextual word embeddings and
transfer learning to make predictions in languages with less resources. We
project predictions on comparable data in Bengali, Hindi, and Spanish and we
report results of 0.8415 F1 macro for Bengali, 0.8568 F1 macro for Hindi, and
0.7513 F1 macro for Spanish. Finally, we show that our approach compares
favorably to the best systems submitted to recent shared tasks on these three
languages, confirming the robustness of cross-lingual contextual embeddings and
transfer learning for this task.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 19:17:24 GMT'}]",2020-10-13,"[['Ranasinghe', 'Tharindu', ''], ['Zampieri', 'Marcos', '']]"
1361657,2010.05327,Tharindu Ranasinghe Mr,"Hansi Hettiarachchi, Tharindu Ranasinghe","InfoMiner at WNUT-2020 Task 2: Transformer-based Covid-19 Informative
  Tweet Extraction","Accepted to the 6th Workshop on Noisy User-generated Text (W-NUT) at
  EMNLP 2020",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Identifying informative tweets is an important step when building information
extraction systems based on social media. WNUT-2020 Task 2 was organised to
recognise informative tweets from noise tweets. In this paper, we present our
approach to tackle the task objective using transformers. Overall, our approach
achieves 10th place in the final rankings scoring 0.9004 F1 score for the test
set.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 19:31:18 GMT'}]",2020-10-13,"[['Hettiarachchi', 'Hansi', ''], ['Ranasinghe', 'Tharindu', '']]"
1361660,2010.05330,Brielen Madureira,Brielen Madureira and David Schlangen,"Incremental Processing in the Age of Non-Incremental Encoders: An
  Empirical Assessment of Bidirectional Models for Incremental NLU",Accepted to the EMNLP 2020 conference (long paper),,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  While humans process language incrementally, the best language encoders
currently used in NLP do not. Both bidirectional LSTMs and Transformers assume
that the sequence that is to be encoded is available in full, to be processed
either forwards and backwards (BiLSTMs) or as a whole (Transformers). We
investigate how they behave under incremental interfaces, when partial output
must be provided based on partial input seen up to a certain time step, which
may happen in interactive systems. We test five models on various NLU datasets
and compare their performance using three incremental evaluation metrics. The
results support the possibility of using bidirectional encoders in incremental
mode while retaining most of their non-incremental quality. The
""omni-directional"" BERT model, which achieves better non-incremental
performance, is impacted more by the incremental access. This can be alleviated
by adapting the training regime (truncated training), or the testing procedure,
by delaying the output until some right context is available or by
incorporating hypothetical right contexts generated by a language model like
GPT-2.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 19:51:21 GMT'}]",2020-10-13,"[['Madureira', 'Brielen', ''], ['Schlangen', 'David', '']]"
1361662,2010.05332,Danielle Saunders,Danielle Saunders and Rosie Sallis and Bill Byrne,"Neural Machine Translation Doesn't Translate Gender Coreference Right
  Unless You Make It","Workshop on Gender Bias in NLP, 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Neural Machine Translation (NMT) has been shown to struggle with grammatical
gender that is dependent on the gender of human referents, which can cause
gender bias effects. Many existing approaches to this problem seek to control
gender inflection in the target language by explicitly or implicitly adding a
gender feature to the source sentence, usually at the sentence level.
  In this paper we propose schemes for incorporating explicit word-level gender
inflection tags into NMT. We explore the potential of this gender-inflection
controlled translation when the gender feature can be determined from a human
reference, assessing on English-to-Spanish and English-to-German translation.
  We find that simple existing approaches can over-generalize a gender-feature
to multiple entities in a sentence, and suggest an effective alternative in the
form of tagged coreference adaptation data. We also propose an extension to
assess translations of gender-neutral entities from English given a
corresponding linguistic convention in the inflected target language.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 20:05:42 GMT'}]",2020-10-13,"[['Saunders', 'Danielle', ''], ['Sallis', 'Rosie', ''], ['Byrne', 'Bill', '']]"
1361663,2010.05333,Danielle Saunders,Danielle Saunders and Bill Byrne,"Addressing Exposure Bias With Document Minimum Risk Training: Cambridge
  at the WMT20 Biomedical Translation Task",WMT20 biomedical task,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The 2020 WMT Biomedical translation task evaluated Medline abstract
translations. This is a small-domain translation task, meaning limited relevant
training data with very distinct style and vocabulary. Models trained on such
data are susceptible to exposure bias effects, particularly when training
sentence pairs are imperfect translations of each other. This can result in
poor behaviour during inference if the model learns to neglect the source
sentence.
  The UNICAM entry addresses this problem during fine-tuning using a robust
variant on Minimum Risk Training. We contrast this approach with data-filtering
to remove `problem' training examples. Under MRT fine-tuning we obtain good
results for both directions of English-German and English-Spanish biomedical
translation. In particular we achieve the best English-to-Spanish translation
result and second-best Spanish-to-English result, despite using only single
models with no ensembling.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 20:09:43 GMT'}]",2020-10-13,"[['Saunders', 'Danielle', ''], ['Byrne', 'Bill', '']]"
1361668,2010.05338,Ramy Baly,"Ramy Baly, Giovanni Da San Martino, James Glass and Preslav Nakov","We Can Detect Your Bias: Predicting the Political Ideology of News
  Articles","Political bias, bias in news, neural networks bias, adversarial
  adaptation, triplet loss, transformers, recurrent neural networks",EMNLP-2020,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We explore the task of predicting the leading political ideology or bias of
news articles. First, we collect and release a large dataset of 34,737 articles
that were manually annotated for political ideology -left, center, or right-,
which is well-balanced across both topics and media. We further use a
challenging experimental setup where the test examples come from media that
were not seen during training, which prevents the model from learning to detect
the source of the target news article instead of predicting its political
ideology. From a modeling perspective, we propose an adversarial media
adaptation, as well as a specially adapted triplet loss. We further add
background information about the source, and we show that it is quite helpful
for improving article-level prediction. Our experimental results show very
sizable improvements over using state-of-the-art pre-trained Transformers in
this challenging setup.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 20:27:55 GMT'}]",2020-10-13,"[['Baly', 'Ramy', ''], ['Martino', 'Giovanni Da San', ''], ['Glass', 'James', ''], ['Nakov', 'Preslav', '']]"
1361675,2010.05345,Xikun Zhang,"Xikun Zhang, Deepak Ramachandran, Ian Tenney, Yanai Elazar, Dan Roth",Do Language Embeddings Capture Scales?,Accepted at EMNLP Findings 2020 and EMNLP BlackboxNLP workshop 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pretrained Language Models (LMs) have been shown to possess significant
linguistic, common sense, and factual knowledge. One form of knowledge that has
not been studied yet in this context is information about the scalar magnitudes
of objects. We show that pretrained language models capture a significant
amount of this information but are short of the capability required for general
common-sense reasoning. We identify contextual information in pre-training and
numeracy as two key factors affecting their performance and show that a simple
method of canonicalizing numbers can have a significant effect on the results.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 21:11:09 GMT'}]",2020-10-13,"[['Zhang', 'Xikun', ''], ['Ramachandran', 'Deepak', ''], ['Tenney', 'Ian', ''], ['Elazar', 'Yanai', ''], ['Roth', 'Dan', '']]"
1361524,2010.05194,Giannis Karamanolakis,"Ziyi Liu, Giannis Karamanolakis, Daniel Hsu, Luis Gravano","Detecting Foodborne Illness Complaints in Multiple Languages Using
  English Annotations Only","Accepted for the 11th International Workshop on Health Text Mining
  and Information Analysis (LOUHI@EMNLP 2020)",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Health departments have been deploying text classification systems for the
early detection of foodborne illness complaints in social media documents such
as Yelp restaurant reviews. Current systems have been successfully applied for
documents in English and, as a result, a promising direction is to increase
coverage and recall by considering documents in additional languages, such as
Spanish or Chinese. Training previous systems for more languages, however,
would be expensive, as it would require the manual annotation of many documents
for each new target language. To address this challenge, we consider
cross-lingual learning and train multilingual classifiers using only the
annotations for English-language reviews. Recent zero-shot approaches based on
pre-trained multi-lingual BERT (mBERT) have been shown to effectively align
languages for aspects such as sentiment. Interestingly, we show that those
approaches are less effective for capturing the nuances of foodborne illness,
our public health application of interest. To improve performance without extra
annotations, we create artificial training documents in the target language
through machine translation and train mBERT jointly for the source (English)
and target language. Furthermore, we show that translating labeled documents to
multiple languages leads to additional performance improvements for some target
languages. We demonstrate the benefits of our approach through extensive
experiments with Yelp restaurant reviews in seven languages. Our classifiers
identify foodborne illness complaints in multilingual reviews from the Yelp
Challenge dataset, which highlights the potential of our general approach for
deployment in health departments.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 08:46:17 GMT'}]",2020-10-13,"[['Liu', 'Ziyi', ''], ['Karamanolakis', 'Giannis', ''], ['Hsu', 'Daniel', ''], ['Gravano', 'Luis', '']]"
1361332,2010.05002,Prafull Prakash,"Prafull Prakash, Saurabh Kumar Shashidhar, Wenlong Zhao, Subendhu
  Rongali, Haidar Khan, Michael Kayser","Compressing Transformer-Based Semantic Parsing Models using
  Compositional Code Embeddings",Accepted at EMNLP 2020 (Findings); 7 Pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The current state-of-the-art task-oriented semantic parsing models use BERT
or RoBERTa as pretrained encoders; these models have huge memory footprints.
This poses a challenge to their deployment for voice assistants such as Amazon
Alexa and Google Assistant on edge devices with limited memory budgets. We
propose to learn compositional code embeddings to greatly reduce the sizes of
BERT-base and RoBERTa-base. We also apply the technique to DistilBERT,
ALBERT-base, and ALBERT-large, three already compressed BERT variants which
attain similar state-of-the-art performances on semantic parsing with much
smaller model sizes. We observe 95.15% ~ 98.46% embedding compression rates and
20.47% ~ 34.22% encoder compression rates, while preserving greater than 97.5%
semantic parsing performances. We provide the recipe for training and analyze
the trade-off between code embedding sizes and downstream performances.
","[{'version': 'v1', 'created': 'Sat, 10 Oct 2020 13:47:55 GMT'}]",2020-10-13,"[['Prakash', 'Prafull', ''], ['Shashidhar', 'Saurabh Kumar', ''], ['Zhao', 'Wenlong', ''], ['Rongali', 'Subendhu', ''], ['Khan', 'Haidar', ''], ['Kayser', 'Michael', '']]"
1361523,2010.05193,Chenhui Chu,"Vipul Mishra, Chenhui Chu and Yuki Arase",Lexically Cohesive Neural Machine Translation with Copy Mechanism,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Lexically cohesive translations preserve consistency in word choices in
document-level translation. We employ a copy mechanism into a context-aware
neural machine translation model to allow copying words from previous
translation outputs. Different from previous context-aware neural machine
translation models that handle all the discourse phenomena implicitly, our
model explicitly addresses the lexical cohesion problem by boosting the
probabilities to output words consistently. We conduct experiments on Japanese
to English translation using an evaluation dataset for discourse translation.
The results showed that the proposed model significantly improved lexical
cohesion compared to previous context-aware models.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 08:39:02 GMT'}]",2020-10-13,"[['Mishra', 'Vipul', ''], ['Chu', 'Chenhui', ''], ['Arase', 'Yuki', '']]"
1361515,2010.05185,Chenhui Chu,"Chenhui Chu, Yuto Takebayashi, Mishra Vipul, Yuta Nakashima",Constructing a Visual Relationship Authenticity Dataset,,,,,cs.CV cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A visual relationship denotes a relationship between two objects in an image,
which can be represented as a triplet of (subject; predicate; object). Visual
relationship detection is crucial for scene understanding in images. Existing
visual relationship detection datasets only contain true relationships that
correctly describe the content in an image. However, distinguishing false
visual relationships from true ones is also crucial for image understanding and
grounded natural language processing. In this paper, we construct a visual
relationship authenticity dataset, where both true and false relationships
among all objects appeared in the captions in the Flickr30k entities image
caption dataset are annotated. The dataset is available at
https://github.com/codecreator2053/VR_ClassifiedDataset. We hope that this
dataset can promote the study on both vision and language understanding.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 07:38:33 GMT'}]",2020-10-13,"[['Chu', 'Chenhui', ''], ['Takebayashi', 'Yuto', ''], ['Vipul', 'Mishra', ''], ['Nakashima', 'Yuta', '']]"
1361336,2010.05006,Xinyu Wang,"Xinyu Wang, Yong Jiang, Nguyen Bach, Tao Wang, Zhongqiang Huang, Fei
  Huang, Kewei Tu",Automated Concatenation of Embeddings for Structured Prediction,"We propose ACE, which achieves new SOTA for 6 NLP tasks over 23
  datasets. Under review as a conference paper at ICLR 2021. 19 pages",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pretrained contextualized embeddings are powerful word representations for
structured prediction tasks. Recent work found that better word representations
can be obtained by concatenating different types of embeddings. However, the
selection of embeddings to form the best concatenated representation usually
varies depending on the task and the collection of candidate embeddings, and
the ever-increasing number of embedding types makes it a more difficult
problem. In this paper, we propose Automated Concatenation of Embeddings (ACE)
to automate the process of finding better concatenations of embeddings for
structured prediction tasks, based on a formulation inspired by recent progress
on neural architecture search. Specifically, a controller alternately samples a
concatenation of embeddings, according to its current belief of the
effectiveness of individual embedding types in consideration for a task, and
updates the belief based on a reward. We follow strategies in reinforcement
learning to optimize the parameters of the controller and compute the reward
based on the accuracy of a task model, which is fed with the sampled
concatenation as input and trained on a task dataset. Empirical results on 6
tasks and 23 datasets show that our approach outperforms strong baselines and
achieves state-of-the-art performance with fine-tuned embeddings in the vast
majority of evaluations.
","[{'version': 'v1', 'created': 'Sat, 10 Oct 2020 14:03:20 GMT'}]",2020-10-13,"[['Wang', 'Xinyu', ''], ['Jiang', 'Yong', ''], ['Bach', 'Nguyen', ''], ['Wang', 'Tao', ''], ['Huang', 'Zhongqiang', ''], ['Huang', 'Fei', ''], ['Tu', 'Kewei', '']]"
1361340,2010.05010,Xinyu Wang,"Xinyu Wang, Yong Jiang, Zhaohui Yan, Zixia Jia, Nguyen Bach, Tao Wang,
  Zhongqiang Huang, Fei Huang, Kewei Tu",Structural Knowledge Distillation,Under review as a conference paper of ICLR 2021. 15 pages,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Knowledge distillation is a critical technique to transfer knowledge between
models, typically from a large model (the teacher) to a smaller one (the
student). The objective function of knowledge distillation is typically the
cross-entropy between the teacher and the student's output distributions.
However, for structured prediction problems, the output space is exponential in
size; therefore, the cross-entropy objective becomes intractable to compute and
optimize directly. In this paper, we derive a factorized form of the knowledge
distillation objective for structured prediction, which is tractable for many
typical choices of the teacher and student models. In particular, we show the
tractability and empirical effectiveness of structural knowledge distillation
between sequence labeling and dependency parsing models under four different
scenarios: 1) the teacher and student share the same factorization form of the
output structure scoring function; 2) the student factorization produces
smaller substructures than the teacher factorization; 3) the teacher
factorization produces smaller substructures than the student factorization; 4)
the factorization forms from the teacher and the student are incompatible.
","[{'version': 'v1', 'created': 'Sat, 10 Oct 2020 14:19:25 GMT'}]",2020-10-13,"[['Wang', 'Xinyu', ''], ['Jiang', 'Yong', ''], ['Yan', 'Zhaohui', ''], ['Jia', 'Zixia', ''], ['Bach', 'Nguyen', ''], ['Wang', 'Tao', ''], ['Huang', 'Zhongqiang', ''], ['Huang', 'Fei', ''], ['Tu', 'Kewei', '']]"
1361420,2010.05090,Kunal Chawla,"Kunal Chawla, Diyi Yang","Semi-supervised Formality Style Transfer using Language Model
  Discriminator and Mutual Information Maximization",EMNLP 2020 Findings,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Formality style transfer is the task of converting informal sentences to
grammatically-correct formal sentences, which can be used to improve
performance of many downstream NLP tasks. In this work, we propose a
semi-supervised formality style transfer model that utilizes a language
model-based discriminator to maximize the likelihood of the output sentence
being formal, which allows us to use maximization of token-level conditional
probabilities for training. We further propose to maximize mutual information
between source and target styles as our training objective instead of
maximizing the regular likelihood that often leads to repetitive and trivial
generated responses. Experiments showed that our model outperformed previous
state-of-the-art baselines significantly in terms of both automated metrics and
human judgement. We further generalized our model to unsupervised text style
transfer task, and achieved significant improvements on two benchmark sentiment
style transfer datasets.
","[{'version': 'v1', 'created': 'Sat, 10 Oct 2020 21:05:56 GMT'}]",2020-10-13,"[['Chawla', 'Kunal', ''], ['Yang', 'Diyi', '']]"
1361426,2010.05096,Surabhi Datta,Surabhi Datta and Shekhar Khanpara and Roy F. Riascos and Kirk Roberts,"Leveraging Spatial Information in Radiology Reports for Ischemic Stroke
  Phenotyping",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Classifying fine-grained ischemic stroke phenotypes relies on identifying
important clinical information. Radiology reports provide relevant information
with context to determine such phenotype information. We focus on stroke
phenotypes with location-specific information: brain region affected,
laterality, stroke stage, and lacunarity. We use an existing fine-grained
spatial information extraction system--Rad-SpatialNet--to identify clinically
important information and apply simple domain rules on the extracted
information to classify phenotypes. The performance of our proposed approach is
promising (recall of 89.62% for classifying brain region and 74.11% for
classifying brain region, side, and stroke stage together). Our work
demonstrates that an information extraction system based on a fine-grained
schema can be utilized to determine complex phenotypes with the inclusion of
simple domain rules. These phenotypes have the potential to facilitate stroke
research focusing on post-stroke outcome and treatment planning based on the
stroke location.
","[{'version': 'v1', 'created': 'Sat, 10 Oct 2020 21:35:42 GMT'}]",2020-10-13,"[['Datta', 'Surabhi', ''], ['Khanpara', 'Shekhar', ''], ['Riascos', 'Roy F.', ''], ['Roberts', 'Kirk', '']]"
1361433,2010.05103,Stephen Mussmann,"Stephen Mussmann, Robin Jia, Percy Liang","On the Importance of Adaptive Data Collection for Extremely Imbalanced
  Pairwise Tasks",In Findings of EMNLP 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Many pairwise classification tasks, such as paraphrase detection and
open-domain question answering, naturally have extreme label imbalance (e.g.,
$99.99\%$ of examples are negatives). In contrast, many recent datasets
heuristically choose examples to ensure label balance. We show that these
heuristics lead to trained models that generalize poorly: State-of-the art
models trained on QQP and WikiQA each have only $2.4\%$ average precision when
evaluated on realistically imbalanced test data. We instead collect training
data with active learning, using a BERT-based embedding model to efficiently
retrieve uncertain points from a very large pool of unlabeled utterance pairs.
By creating balanced training data with more informative negative examples,
active learning greatly improves average precision to $32.5\%$ on QQP and
$20.1\%$ on WikiQA.
","[{'version': 'v1', 'created': 'Sat, 10 Oct 2020 21:56:27 GMT'}]",2020-10-13,"[['Mussmann', 'Stephen', ''], ['Jia', 'Robin', ''], ['Liang', 'Percy', '']]"
1361436,2010.05106,Mehrad Moradshahi,"Mehrad Moradshahi, Giovanni Campagna, Sina J. Semnani, Silei Xu,
  Monica S. Lam","Localizing Open-Ontology QA Semantic Parsers in a Day Using Machine
  Translation",Published in EMNLP 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose Semantic Parser Localizer (SPL), a toolkit that leverages Neural
Machine Translation (NMT) systems to localize a semantic parser for a new
language. Our methodology is to (1) generate training data automatically in the
target language by augmenting machine-translated datasets with local entities
scraped from public websites, (2) add a few-shot boost of human-translated
sentences and train a novel XLMR-LSTM semantic parser, and (3) test the model
on natural utterances curated using human translators.
  We assess the effectiveness of our approach by extending the current
capabilities of Schema2QA, a system for English Question Answering (QA) on the
open web, to 10 new languages for the restaurants and hotels domains. Our
models achieve an overall test accuracy ranging between 61% and 69% for the
hotels domain and between 64% and 78% for restaurants domain, which compares
favorably to 69% and 80% obtained for English parser trained on gold English
data and a few examples from validation set. We show our approach outperforms
the previous state-of-the-art methodology by more than 30% for hotels and 40%
for restaurants with localized ontologies for the subset of languages tested.
  Our methodology enables any software developer to add a new language
capability to a QA system for a new domain, leveraging machine translation, in
less than 24 hours.
","[{'version': 'v1', 'created': 'Sat, 10 Oct 2020 22:03:58 GMT'}]",2020-10-13,"[['Moradshahi', 'Mehrad', ''], ['Campagna', 'Giovanni', ''], ['Semnani', 'Sina J.', ''], ['Xu', 'Silei', ''], ['Lam', 'Monica S.', '']]"
1361441,2010.05111,Shyam Subramanian,"Shyam Subramanian, Kyumin Lee","Hierarchical Evidence Set Modeling for Automated Fact Extraction and
  Verification","12 pages, 7 figures. Accepted to EMNLP 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automated fact extraction and verification is a challenging task that
involves finding relevant evidence sentences from a reliable corpus to verify
the truthfulness of a claim. Existing models either (i) concatenate all the
evidence sentences, leading to the inclusion of redundant and noisy
information; or (ii) process each claim-evidence sentence pair separately and
aggregate all of them later, missing the early combination of related sentences
for more accurate claim verification. Unlike the prior works, in this paper, we
propose Hierarchical Evidence Set Modeling (HESM), a framework to extract
evidence sets (each of which may contain multiple evidence sentences), and
verify a claim to be supported, refuted or not enough info, by encoding and
attending the claim and evidence sets at different levels of hierarchy. Our
experimental results show that HESM outperforms 7 state-of-the-art methods for
fact extraction and claim verification. Our source code is available at
https://github.com/ShyamSubramanian/HESM.
","[{'version': 'v1', 'created': 'Sat, 10 Oct 2020 22:27:17 GMT'}]",2020-10-13,"[['Subramanian', 'Shyam', ''], ['Lee', 'Kyumin', '']]"
1361520,2010.05190,Siddharth Karamcheti,"Siddharth Karamcheti, Dorsa Sadigh, Percy Liang",Learning Adaptive Language Interfaces through Decomposition,"Accepted at the 1st Workshop for Interactive and Executable Semantic
  Parsing (IntEx-SemPar) @ EMNLP 2020. 11 pages, 5 figures",,,,cs.CL cs.AI cs.LG cs.RO,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Our goal is to create an interactive natural language interface that
efficiently and reliably learns from users to complete tasks in simulated
robotics settings. We introduce a neural semantic parsing system that learns
new high-level abstractions through decomposition: users interactively teach
the system by breaking down high-level utterances describing novel behavior
into low-level steps that it can understand. Unfortunately, existing methods
either rely on grammars which parse sentences with limited flexibility, or
neural sequence-to-sequence models that do not learn efficiently or reliably
from individual examples. Our approach bridges this gap, demonstrating the
flexibility of modern neural systems, as well as the one-shot reliable
generalization of grammar-based methods. Our crowdsourced interactive
experiments suggest that over time, users complete complex tasks more
efficiently while using our system by leveraging what they just taught. At the
same time, getting users to trust the system enough to be incentivized to teach
high-level utterances is still an ongoing challenge. We end with a discussion
of some of the obstacles we need to overcome to fully realize the potential of
the interactive paradigm.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 08:27:07 GMT'}]",2020-10-13,"[['Karamcheti', 'Siddharth', ''], ['Sadigh', 'Dorsa', ''], ['Liang', 'Percy', '']]"
1361969,2010.05639,Qiao Jin,"Qiao Jin, Chuanqi Tan, Mosha Chen, Xiaozhong Liu, Songfang Huang",Predicting Clinical Trial Results by Implicit Evidence Integration,EMNLP 2020 long paper,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Clinical trials provide essential guidance for practicing Evidence-Based
Medicine, though often accompanying with unendurable costs and risks. To
optimize the design of clinical trials, we introduce a novel Clinical Trial
Result Prediction (CTRP) task. In the CTRP framework, a model takes a
PICO-formatted clinical trial proposal with its background as input and
predicts the result, i.e. how the Intervention group compares with the
Comparison group in terms of the measured Outcome in the studied Population.
While structured clinical evidence is prohibitively expensive for manual
collection, we exploit large-scale unstructured sentences from medical
literature that implicitly contain PICOs and results as evidence. Specifically,
we pre-train a model to predict the disentangled results from such implicit
evidence and fine-tune the model with limited data on the downstream datasets.
Experiments on the benchmark Evidence Integration dataset show that the
proposed model outperforms the baselines by large margins, e.g., with a 10.7%
relative gain over BioBERT in macro-F1. Moreover, the performance improvement
is also validated on another dataset composed of clinical trials related to
COVID-19.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 12:25:41 GMT'}]",2020-10-13,"[['Jin', 'Qiao', ''], ['Tan', 'Chuanqi', ''], ['Chen', 'Mosha', ''], ['Liu', 'Xiaozhong', ''], ['Huang', 'Songfang', '']]"
1361459,2010.05129,Dongyeop Kang,"Dongyeop Kang, Andrew Head, Risham Sidhu, Kyle Lo, Daniel S. Weld,
  Marti A. Hearst","Document-Level Definition Detection in Scholarly Documents: Existing
  Models, Error Analyses, and Future Directions","Workshop on Scholarly Document Processing (SDP), EMNLP 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The task of definition detection is important for scholarly papers, because
papers often make use of technical terminology that may be unfamiliar to
readers. Despite prior work on definition detection, current approaches are far
from being accurate enough to use in real-world applications. In this paper, we
first perform in-depth error analysis of the current best performing definition
detection system and discover major causes of errors. Based on this analysis,
we develop a new definition detection system, HEDDEx, that utilizes syntactic
features, transformer encoders, and heuristic filters, and evaluate it on a
standard sentence-level benchmark. Because current benchmarks evaluate randomly
sampled sentences, we propose an alternative evaluation that assesses every
sentence within a document. This allows for evaluating recall in addition to
precision. HEDDEx outperforms the leading system on both the sentence-level and
the document-level tasks, by 12.7 F1 points and 14.4 F1 points, respectively.
We note that performance on the high-recall document-level task is much lower
than in the standard evaluation approach, due to the necessity of incorporation
of document structure as features. We discuss remaining challenges in
document-level definition detection, ideas for improvements, and potential
issues for the development of reading aid applications.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 01:16:10 GMT'}]",2020-10-13,"[['Kang', 'Dongyeop', ''], ['Head', 'Andrew', ''], ['Sidhu', 'Risham', ''], ['Lo', 'Kyle', ''], ['Weld', 'Daniel S.', ''], ['Hearst', 'Marti A.', '']]"
1361471,2010.05141,Dongyeop Kang,"Dongyeop Kang, Eduard Hovy",Plan ahead: Self-Supervised Text Planning for Paragraph Completion Task,EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite the recent success of contextualized language models on various NLP
tasks, language model itself cannot capture textual coherence of a long,
multi-sentence document (e.g., a paragraph). Humans often make structural
decisions on what and how to say about before making utterances. Guiding
surface realization with such high-level decisions and structuring text in a
coherent way is essentially called a planning process. Where can the model
learn such high-level coherence? A paragraph itself contains various forms of
inductive coherence signals called self-supervision in this work, such as
sentence orders, topical keywords, rhetorical structures, and so on. Motivated
by that, this work proposes a new paragraph completion task PARCOM; predicting
masked sentences in a paragraph. However, the task suffers from predicting and
selecting appropriate topical content with respect to the given context. To
address that, we propose a self-supervised text planner SSPlanner that predicts
what to say first (content prediction), then guides the pretrained language
model (surface realization) using the predicted content. SSPlanner outperforms
the baseline generation models on the paragraph completion task in both
automatic and human evaluation. We also find that a combination of noun and
verb types of keywords is the most effective for content selection. As more
number of content keywords are provided, overall generation quality also
increases.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 02:38:21 GMT'}]",2020-10-13,"[['Kang', 'Dongyeop', ''], ['Hovy', 'Eduard', '']]"
1361473,2010.05143,Xiang Yue,Xiang Yue and Shuang Zhou,"PHICON: Improving Generalization of Clinical Text De-identification
  Models via Data Augmentation",Accepted by The 3rd ClinicalNLP Workshop at EMNLP'20,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  De-identification is the task of identifying protected health information
(PHI) in the clinical text. Existing neural de-identification models often fail
to generalize to a new dataset. We propose a simple yet effective data
augmentation method PHICON to alleviate the generalization issue. PHICON
consists of PHI augmentation and Context augmentation, which creates augmented
training corpora by replacing PHI entities with named-entities sampled from
external sources, and by changing background context with synonym replacement
or random word insertion, respectively. Experimental results on the i2b2 2006
and 2014 de-identification challenge datasets show that PHICON can help three
selected de-identification models boost F1-score (by at most 8.6%) on
cross-dataset test setting. We also discuss how much augmentation to use and
how each augmentation method influences the performance.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 02:57:11 GMT'}]",2020-10-13,"[['Yue', 'Xiang', ''], ['Zhou', 'Shuang', '']]"
1361480,2010.05150,Tsung-Yen Yang,"Tsung-Yen Yang and Michael Hu and Yinlam Chow and Peter J. Ramadge and
  Karthik Narasimhan",Safe Reinforcement Learning with Natural Language Constraints,The first two authors contributed equally,,,,cs.CL cs.AI cs.LG cs.RO,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we tackle the problem of learning control policies for tasks
when provided with constraints in natural language. In contrast to instruction
following, language here is used not to specify goals, but rather to describe
situations that an agent must avoid during its exploration of the environment.
Specifying constraints in natural language also differs from the predominant
paradigm in safe reinforcement learning, where safety criteria are enforced by
hand-defined cost functions. While natural language allows for easy and
flexible specification of safety constraints and budget limitations, its
ambiguous nature presents a challenge when mapping these specifications into
representations that can be used by techniques for safe reinforcement learning.
To address this, we develop a model that contains two components: (1) a
constraint interpreter to encode natural language constraints into vector
representations capturing spatial and temporal information on forbidden states,
and (2) a policy network that uses these representations to output a policy
with minimal constraint violations. Our model is end-to-end differentiable and
we train it using a recently proposed algorithm for constrained policy
optimization. To empirically demonstrate the effectiveness of our approach, we
create a new benchmark task for autonomous navigation with crowd-sourced
free-form text specifying three different types of constraints. Our method
outperforms several baselines by achieving 6-7 times higher returns and 76%
fewer constraint violations on average. Dataset and code to reproduce our
experiments are available at https://sites.google.com/view/polco-hazard-world/.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 03:41:56 GMT'}]",2020-10-13,"[['Yang', 'Tsung-Yen', ''], ['Hu', 'Michael', ''], ['Chow', 'Yinlam', ''], ['Ramadge', 'Peter J.', ''], ['Narasimhan', 'Karthik', '']]"
1361494,2010.05164,Laurence Clarfeld,"Laurence A. Clarfeld, Robert Gramling, Donna M. Rizzo, Margaret J.
  Eppstein","A General Model of Conversational Dynamics and an Example Application in
  Serious Illness Communication","34 pages, 20 figures, submitted to PLOS One (in review)",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Conversation has been a primary means for the exchange of information since
ancient times. Understanding patterns of information flow in conversations is a
critical step in assessing and improving communication quality. In this paper,
we describe COnversational DYnamics Model (CODYM) analysis, a novel approach
for studying patterns of information flow in conversations. CODYMs are Markov
Models that capture sequential dependencies in the lengths of speaker turns.
The proposed method is automated and scalable, and preserves the privacy of the
conversational participants. The primary function of CODYM analysis is to
quantify and visualize patterns of information flow, concisely summarized over
sequential turns from one or more conversations. Our approach is general and
complements existing methods, providing a new tool for use in the analysis of
any type of conversation. As an important first application, we demonstrate the
model on transcribed conversations between palliative care clinicians and
seriously ill patients. These conversations are dynamic and complex, taking
place amidst heavy emotions, and include difficult topics such as end-of-life
preferences and patient values. We perform a versatile set of CODYM analyses
that (a) establish the validity of the model by confirming known patterns of
conversational turn-taking and word usage, (b) identify normative patterns of
information flow in serious illness conversations, and (c) show how these
patterns vary across narrative time and differ under expressions of anger, fear
and sadness. Potential applications of CODYMs range from assessment and
training of effective healthcare communication to comparing conversational
dynamics across language and culture, with the prospect of identifying
universal similarities and unique ""fingerprints"" of information flow.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 04:33:03 GMT'}]",2020-10-13,"[['Clarfeld', 'Laurence A.', ''], ['Gramling', 'Robert', ''], ['Rizzo', 'Donna M.', ''], ['Eppstein', 'Margaret J.', '']]"
1361501,2010.05171,Changhan Wang,"Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Dmytro Okhonko, Juan Pino",fairseq S2T: Fast Speech-to-Text Modeling with fairseq,Accepted to AACL 2020 Demo,,,,cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We introduce fairseq S2T, a fairseq extension for speech-to-text (S2T)
modeling tasks such as end-to-end speech recognition and speech-to-text
translation. It follows fairseq's careful design for scalability and
extensibility. We provide end-to-end workflows from data pre-processing, model
training to offline (online) inference. We implement state-of-the-art RNN-based
as well as Transformer-based models and open-source detailed training recipes.
Fairseq's machine translation models and language models can be seamlessly
integrated into S2T workflows for multi-task learning or transfer learning.
Fairseq S2T documentation and examples are available at
https://github.com/pytorch/fairseq/tree/master/examples/speech_to_text.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 05:36:54 GMT'}]",2020-10-13,"[['Wang', 'Changhan', ''], ['Tang', 'Yun', ''], ['Ma', 'Xutai', ''], ['Wu', 'Anne', ''], ['Okhonko', 'Dmytro', ''], ['Pino', 'Juan', '']]"
1361452,2010.05122,Zuchao Li,"Zuchao Li, Hai Zhao, Rui Wang, Kehai Chen, Masao Utiyama, Eiichiro
  Sumita","SJTU-NICT's Supervised and Unsupervised Neural Machine Translation
  Systems for the WMT20 News Translation Task",WMT20,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we introduced our joint team SJTU-NICT 's participation in the
WMT 2020 machine translation shared task. In this shared task, we participated
in four translation directions of three language pairs: English-Chinese,
English-Polish on supervised machine translation track, German-Upper Sorbian on
low-resource and unsupervised machine translation tracks. Based on different
conditions of language pairs, we have experimented with diverse neural machine
translation (NMT) techniques: document-enhanced NMT, XLM pre-trained language
model enhanced NMT, bidirectional translation as a pre-training, reference
language based UNMT, data-dependent gaussian prior objective, and BT-BLEU
collaborative filtering self-training. We also used the TF-IDF algorithm to
filter the training set to obtain a domain more similar set with the test set
for finetuning. In our submissions, the primary systems won the first place on
English to Chinese, Polish to English, and German to Upper Sorbian translation
directions.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 00:40:05 GMT'}]",2020-10-13,"[['Li', 'Zuchao', ''], ['Zhao', 'Hai', ''], ['Wang', 'Rui', ''], ['Chen', 'Kehai', ''], ['Utiyama', 'Masao', ''], ['Sumita', 'Eiichiro', '']]"
1278618,2004.13848,Honglei Liu,"Honglei Liu, Yan Xu, Zhiqiang Zhang, Ni Wang, Yanqun Huang, Yanjun Hu,
  Zhenghan Yang, Rui Jiang, Hui Chen","A Natural Language Processing Pipeline of Chinese Free-text Radiology
  Reports for Liver Cancer Diagnosis",,,10.1109/ACCESS.2020.3020138,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite the rapid development of natural language processing (NLP)
implementation in electronic medical records (EMRs), Chinese EMRs processing
remains challenging due to the limited corpus and specific grammatical
characteristics, especially for radiology reports. In this study, we designed
an NLP pipeline for the direct extraction of clinically relevant features from
Chinese radiology reports, which is the first key step in computer-aided
radiologic diagnosis. The pipeline was comprised of named entity recognition,
synonyms normalization, and relationship extraction to finally derive the
radiological features composed of one or more terms. In named entity
recognition, we incorporated lexicon into deep learning model bidirectional
long short-term memory-conditional random field (BiLSTM-CRF), and the model
finally achieved an F1 score of 93.00%. With the extracted radiological
features, least absolute shrinkage and selection operator and machine learning
methods (support vector machine, random forest, decision tree, and logistic
regression) were used to build the classifiers for liver cancer prediction. For
liver cancer diagnosis, random forest had the highest predictive performance in
liver cancer diagnosis (F1 score 86.97%, precision 87.71%, and recall 86.25%).
This work was a comprehensive NLP study focusing on Chinese radiology reports
and the application of NLP in cancer risk prediction. The proposed NLP pipeline
for the radiological feature extraction could be easily implemented in other
kinds of Chinese clinical texts and other disease predictive tasks.
","[{'version': 'v1', 'created': 'Fri, 10 Apr 2020 09:32:07 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Oct 2020 12:51:42 GMT'}]",2020-10-14,"[['Liu', 'Honglei', ''], ['Xu', 'Yan', ''], ['Zhang', 'Zhiqiang', ''], ['Wang', 'Ni', ''], ['Huang', 'Yanqun', ''], ['Hu', 'Yanjun', ''], ['Yang', 'Zhenghan', ''], ['Jiang', 'Rui', ''], ['Chen', 'Hui', '']]"
1277496,2004.12726,Kawin Ethayarajh,Kawin Ethayarajh and Dorsa Sadigh,BLEU Neighbors: A Reference-less Approach to Automatic Evaluation,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Evaluation is a bottleneck in the development of natural language generation
(NLG) models. Automatic metrics such as BLEU rely on references, but for tasks
such as open-ended generation, there are no references to draw upon. Although
language diversity can be estimated using statistical measures such as
perplexity, measuring language quality requires human evaluation. However,
because human evaluation at scale is slow and expensive, it is used sparingly;
it cannot be used to rapidly iterate on NLG models, in the way BLEU is used for
machine translation. To this end, we propose BLEU Neighbors, a nearest
neighbors model for estimating language quality by using the BLEU score as a
kernel function. On existing datasets for chitchat dialogue and open-ended
sentence generation, we find that -- on average -- the quality estimation from
a BLEU Neighbors model has a lower mean squared error and higher Spearman
correlation with the ground truth than individual human annotators. Despite its
simplicity, BLEU Neighbors even outperforms state-of-the-art models on
automatically grading essays, including models that have access to a
gold-standard reference essay.
","[{'version': 'v1', 'created': 'Mon, 27 Apr 2020 11:51:28 GMT'}, {'version': 'v2', 'created': 'Wed, 29 Apr 2020 04:54:12 GMT'}, {'version': 'v3', 'created': 'Mon, 12 Oct 2020 21:20:37 GMT'}]",2020-10-14,"[['Ethayarajh', 'Kawin', ''], ['Sadigh', 'Dorsa', '']]"
1291881,2005.12086,Joosung Lee,Joosung Lee,"Stable Style Transformer: Delete and Generate Approach with
  Encoder-Decoder for Text Style Transfer","10 pages, 3 figures, INLG 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Text style transfer is the task that generates a sentence by preserving the
content of the input sentence and transferring the style. Most existing studies
are progressing on non-parallel datasets because parallel datasets are limited
and hard to construct. In this work, we introduce a method that follows two
stages in non-parallel datasets. The first stage is to delete attribute markers
of a sentence directly through a classifier. The second stage is to generate a
transferred sentence by combining the content tokens and the target style. We
experiment on two benchmark datasets and evaluate context, style, fluency, and
semantic. It is difficult to select the best system using only these automatic
metrics, but it is possible to select stable systems. We consider only robust
systems in all automatic evaluation metrics to be the minimum conditions that
can be used in real applications. Many previous systems are difficult to use in
certain situations because performance is significantly lower in several
evaluation metrics. However, our system is stable in all automatic evaluation
metrics and has results comparable to other models. Also, we compare the
performance results of our system and the unstable system through human
evaluation. Our code and data are available at the
link~\footnote{https://github.com/rungjoo/Stable-Style-Transformer}.
","[{'version': 'v1', 'created': 'Mon, 25 May 2020 13:04:54 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Oct 2020 08:04:13 GMT'}]",2020-10-14,"[['Lee', 'Joosung', '']]"
1297004,2006.02490,Juan Pino,"Juan Pino and Qiantong Xu and Xutai Ma and Mohammad Javad Dousti and
  Yun Tang",Self-Training for End-to-End Speech Translation,INTERSPEECH 2020,,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  One of the main challenges for end-to-end speech translation is data
scarcity. We leverage pseudo-labels generated from unlabeled audio by a cascade
and an end-to-end speech translation model. This provides 8.3 and 5.7 BLEU
gains over a strong semi-supervised baseline on the MuST-C English-French and
English-German datasets, reaching state-of-the art performance. The effect of
the quality of the pseudo-labels is investigated. Our approach is shown to be
more effective than simply pre-training the encoder on the speech recognition
task. Finally, we demonstrate the effectiveness of self-training by directly
generating pseudo-labels with an end-to-end model instead of a cascade model.
","[{'version': 'v1', 'created': 'Wed, 3 Jun 2020 19:28:36 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Oct 2020 05:25:01 GMT'}]",2020-10-14,"[['Pino', 'Juan', ''], ['Xu', 'Qiantong', ''], ['Ma', 'Xutai', ''], ['Dousti', 'Mohammad Javad', ''], ['Tang', 'Yun', '']]"
1302946,2006.08432,Gencer Sumbul,"Gencer Sumbul, Sonali Nayak, Beg\""um Demir",SD-RSIC: Summarization Driven Deep Remote Sensing Image Captioning,"Accepted in the IEEE Transactions on Geoscience and Remote Sensing.
  For code visit: https://gitlab.tubit.tu-berlin.de/rsim/SD-RSIC",,10.1109/TGRS.2020.3031111,,cs.CV cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Deep neural networks (DNNs) have been recently found popular for image
captioning problems in remote sensing (RS). Existing DNN based approaches rely
on the availability of a training set made up of a high number of RS images
with their captions. However, captions of training images may contain redundant
information (they can be repetitive or semantically similar to each other),
resulting in information deficiency while learning a mapping from the image
domain to the language domain. To overcome this limitation, in this paper, we
present a novel Summarization Driven Remote Sensing Image Captioning (SD-RSIC)
approach. The proposed approach consists of three main steps. The first step
obtains the standard image captions by jointly exploiting convolutional neural
networks (CNNs) with long short-term memory (LSTM) networks. The second step,
unlike the existing RS image captioning methods, summarizes the ground-truth
captions of each training image into a single caption by exploiting sequence to
sequence neural networks and eliminates the redundancy present in the training
set. The third step automatically defines the adaptive weights associated to
each RS image to combine the standard captions with the summarized captions
based on the semantic content of the image. This is achieved by a novel
adaptive weighting strategy defined in the context of LSTM networks.
Experimental results obtained on the RSCID, UCM-Captions and Sydney-Captions
datasets show the effectiveness of the proposed approach compared to the
state-of-the-art RS image captioning approaches. The code of the proposed
approach is publicly available at
https://gitlab.tubit.tu-berlin.de/rsim/SD-RSIC.
","[{'version': 'v1', 'created': 'Mon, 15 Jun 2020 14:29:12 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Oct 2020 10:09:15 GMT'}]",2020-10-14,"[['Sumbul', 'Gencer', ''], ['Nayak', 'Sonali', ''], ['Demir', 'Begüm', '']]"
1290980,2005.11185,Danni Liu,"Danni Liu, Gerasimos Spanakis, Jan Niehues","Low-Latency Sequence-to-Sequence Speech Recognition and Translation by
  Partial Hypothesis Selection",Interspeech 2020,,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Encoder-decoder models provide a generic architecture for
sequence-to-sequence tasks such as speech recognition and translation. While
offline systems are often evaluated on quality metrics like word error rates
(WER) and BLEU, latency is also a crucial factor in many practical use-cases.
We propose three latency reduction techniques for chunk-based incremental
inference and evaluate their efficiency in terms of accuracy-latency trade-off.
On the 300-hour How2 dataset, we reduce latency by 83% to 0.8 second by
sacrificing 1% WER (6% rel.) compared to offline transcription. Although our
experiments use the Transformer, the hypothesis selection strategies are
applicable to other encoder-decoder models. To avoid expensive re-computation,
we use a unidirectionally-attending encoder. After an adaptation procedure to
partial sequences, the unidirectional model performs on-par with the original
model. We further show that our approach is also applicable to low-latency
speech translation. On How2 English-Portuguese speech translation, we reduce
latency to 0.7 second (-84% rel.) while incurring a loss of 2.4 BLEU points (5%
rel.) compared to the offline system.
","[{'version': 'v1', 'created': 'Fri, 22 May 2020 13:42:54 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Oct 2020 16:18:44 GMT'}]",2020-10-14,"[['Liu', 'Danni', ''], ['Spanakis', 'Gerasimos', ''], ['Niehues', 'Jan', '']]"
1362599,2010.06269,Tharindu Ranasinghe Mr,"Hansi Hettiarachchi, Tharindu Ranasinghe","BRUMS at SemEval-2020 Task 3: Contextualised Embeddings forPredicting
  the (Graded) Effect of Context in Word Similarity","Accepted to SemEval-2020 (International Workshop on Semantic
  Evaluation) at COLING 2020",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  This paper presents the team BRUMS submission to SemEval-2020 Task 3: Graded
Word Similarity in Context. The system utilises state-of-the-art contextualised
word embeddings, which have some task-specific adaptations, including stacked
embeddings and average embeddings. Overall, the approach achieves good
evaluation scores across all the languages, while maintaining simplicity.
Following the final rankings, our approach is ranked within the top 5 solutions
of each language while preserving the 1st position of Finnish subtask 2.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 10:25:18 GMT'}]",2020-10-14,"[['Hettiarachchi', 'Hansi', ''], ['Ranasinghe', 'Tharindu', '']]"
1362377,2010.06047,Saturnino Luz,"Sofia de la Fuente Garcia, Craig Ritchie and Saturnino Luz","Artificial Intelligence, speech and language processing approaches to
  monitoring Alzheimer's Disease: a systematic review",Pre-print submitted to the Journal of Alzheimer's Disease,,,,cs.AI cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language is a valuable source of clinical information in Alzheimer's Disease,
as it declines concurrently with neurodegeneration. Consequently, speech and
language data have been extensively studied in connection with its diagnosis.
This paper summarises current findings on the use of artificial intelligence,
speech and language processing to predict cognitive decline in the context of
Alzheimer's Disease, detailing current research procedures, highlighting their
limitations and suggesting strategies to address them. We conducted a
systematic review of original research between 2000 and 2019, registered in
PROSPERO (reference CRD42018116606). An interdisciplinary search covered six
databases on engineering (ACM and IEEE), psychology (PsycINFO), medicine
(PubMed and Embase) and Web of Science. Bibliographies of relevant papers were
screened until December 2019. From 3,654 search results 51 articles were
selected against the eligibility criteria. Four tables summarise their
findings: study details (aim, population, interventions, comparisons, methods
and outcomes), data details (size, type, modalities, annotation, balance,
availability and language of study), methodology (pre-processing, feature
generation, machine learning, evaluation and results) and clinical
applicability (research implications, clinical potential, risk of bias and
strengths/limitations). While promising results are reported across nearly all
51 studies, very few have been implemented in clinical research or practice. We
concluded that the main limitations of the field are poor standardisation,
limited comparability of results, and a degree of disconnect between study aims
and clinical applications. Attempts to close these gaps should support
translation of future research into clinical practice.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 21:43:04 GMT'}]",2020-10-14,"[['Garcia', 'Sofia de la Fuente', ''], ['Ritchie', 'Craig', ''], ['Luz', 'Saturnino', '']]"
1362371,2010.06041,Sina Ahmadi,"Sina Ahmadi, Mariam Masoud",Towards Machine Translation for the Kurdish Language,"12 pages - under review in the ACM Transactions on Asian and
  Low-Resource Language Information Processing (TALLIP)",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Machine translation is the task of translating texts from one language to
another using computers. It has been one of the major tasks in natural language
processing and computational linguistics and has been motivating to facilitate
human communication. Kurdish, an Indo-European language, has received little
attention in this realm due to the language being less-resourced. Therefore, in
this paper, we are addressing the main issues in creating a machine translation
system for the Kurdish language, with a focus on the Sorani dialect. We
describe the available scarce parallel data suitable for training a neural
machine translation model for Sorani Kurdish-English translation. We also
discuss some of the major challenges in Kurdish language translation and
demonstrate how fundamental text processing tasks, such as tokenization, can
improve translation performance.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 21:28:57 GMT'}]",2020-10-14,"[['Ahmadi', 'Sina', ''], ['Masoud', 'Mariam', '']]"
1362902,2010.06572,Jack Hessel,Jack Hessel and Lillian Lee,"Does my multimodal model learn cross-modal interactions? It's harder to
  tell than you might think!",,Published in EMNLP 2020,,,cs.CL cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Modeling expressive cross-modal interactions seems crucial in multimodal
tasks, such as visual question answering. However, sometimes high-performing
black-box algorithms turn out to be mostly exploiting unimodal signals in the
data. We propose a new diagnostic tool, empirical multimodally-additive
function projection (EMAP), for isolating whether or not cross-modal
interactions improve performance for a given model on a given task. This
function projection modifies model predictions so that cross-modal interactions
are eliminated, isolating the additive, unimodal structure. For seven
image+text classification tasks (on each of which we set new state-of-the-art
benchmarks), we find that, in many cases, removing cross-modal interactions
results in little to no performance degradation. Surprisingly, this holds even
when expressive models, with capacity to consider interactions, otherwise
outperform less expressive models; thus, performance improvements, even when
present, often cannot be attributed to consideration of cross-modal feature
interactions. We hence recommend that researchers in multimodal machine
learning report the performance not only of unimodal baselines, but also the
EMAP of their best-performing model.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 17:45:28 GMT'}]",2020-10-14,"[['Hessel', 'Jack', ''], ['Lee', 'Lillian', '']]"
1362362,2010.06032,Kellie Webster,"Kellie Webster and Xuezhi Wang and Ian Tenney and Alex Beutel and
  Emily Pitler and Ellie Pavlick and Jilin Chen and Slav Petrov",Measuring and Reducing Gendered Correlations in Pre-trained Models,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pre-trained models have revolutionized natural language understanding.
However, researchers have found they can encode artifacts undesired in many
applications, such as professions correlating with one gender more than
another. We explore such gendered correlations as a case study for how to
address unintended correlations in pre-trained models. We define metrics and
reveal that it is possible for models with similar accuracy to encode
correlations at very different rates. We show how measured correlations can be
reduced with general-purpose techniques, and highlight the trade offs different
strategies have. With these results, we make recommendations for training
robust models: (1) carefully evaluate unintended correlations, (2) be mindful
of seemingly innocuous configuration differences, and (3) focus on general
mitigations.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 21:15:29 GMT'}]",2020-10-14,"[['Webster', 'Kellie', ''], ['Wang', 'Xuezhi', ''], ['Tenney', 'Ian', ''], ['Beutel', 'Alex', ''], ['Pitler', 'Emily', ''], ['Pavlick', 'Ellie', ''], ['Chen', 'Jilin', ''], ['Petrov', 'Slav', '']]"
1362360,2010.06030,Jiahui Yu,"Jiahui Yu, Wei Han, Anmol Gulati, Chung-Cheng Chiu, Bo Li, Tara N.
  Sainath, Yonghui Wu, Ruoming Pang","Universal ASR: Unify and Improve Streaming ASR with Full-context
  Modeling",tech report,,,,cs.CL cs.AI cs.LG cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Streaming automatic speech recognition (ASR) aims to emit each hypothesized
word as quickly and accurately as possible, while full-context ASR waits for
the completion of a full speech utterance before emitting completed hypotheses.
In this work, we propose a unified framework, Universal ASR, to train a single
end-to-end ASR model with shared weights for both streaming and full-context
speech recognition. We show that the latency and accuracy of streaming ASR
significantly benefit from weight sharing and joint training of full-context
ASR, especially with inplace knowledge distillation. The Universal ASR
framework can be applied to recent state-of-the-art convolution-based and
transformer-based ASR networks. We present extensive experiments with two
state-of-the-art ASR networks, ContextNet and Conformer, on two datasets, a
widely used public dataset LibriSpeech and an internal large-scale dataset
MultiDomain. Experiments and ablation studies demonstrate that Universal ASR
not only simplifies the workflow of training and deploying streaming and
full-context ASR models, but also significantly improves both emission latency
and recognition accuracy of streaming ASR. With Universal ASR, we achieve new
state-of-the-art streaming ASR results on both LibriSpeech and MultiDomain in
terms of accuracy and latency.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 21:12:56 GMT'}]",2020-10-14,"[['Yu', 'Jiahui', ''], ['Han', 'Wei', ''], ['Gulati', 'Anmol', ''], ['Chiu', 'Chung-Cheng', ''], ['Li', 'Bo', ''], ['Sainath', 'Tara N.', ''], ['Wu', 'Yonghui', ''], ['Pang', 'Ruoming', '']]"
1362358,2010.06028,Cicero Nogueira Dos Santos,"Siamak Shakeri, Cicero Nogueira dos Santos, Henry Zhu, Patrick Ng,
  Feng Nan, Zhiguo Wang, Ramesh Nallapati, Bing Xiang","End-to-End Synthetic Data Generation for Domain Adaptation of Question
  Answering Systems",EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose an end-to-end approach for synthetic QA data generation. Our model
comprises a single transformer-based encoder-decoder network that is trained
end-to-end to generate both answers and questions. In a nutshell, we feed a
passage to the encoder and ask the decoder to generate a question and an answer
token-by-token. The likelihood produced in the generation process is used as a
filtering score, which avoids the need for a separate filtering model. Our
generator is trained by fine-tuning a pretrained LM using maximum likelihood
estimation. The experimental results indicate significant improvements in the
domain adaptation of QA models outperforming current state-of-the-art methods.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 21:10:18 GMT'}]",2020-10-14,"[['Shakeri', 'Siamak', ''], ['Santos', 'Cicero Nogueira dos', ''], ['Zhu', 'Henry', ''], ['Ng', 'Patrick', ''], ['Nan', 'Feng', ''], ['Wang', 'Zhiguo', ''], ['Nallapati', 'Ramesh', ''], ['Xiang', 'Bing', '']]"
1362348,2010.06018,Tom Kocmi,"Tom Kocmi, Tomasz Limisiewicz, Gabriel Stanovsky",Gender Coreference and Bias Evaluation at WMT 2020,Accepted WMT20,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Gender bias in machine translation can manifest when choosing gender
inflections based on spurious gender correlations. For example, always
translating doctors as men and nurses as women. This can be particularly
harmful as models become more popular and deployed within commercial systems.
Our work presents the largest evidence for the phenomenon in more than 19
systems submitted to the WMT over four diverse target languages: Czech, German,
Polish, and Russian. To achieve this, we use WinoMT, a recent automatic test
suite which examines gender coreference and bias when translating from English
to languages with grammatical gender. We extend WinoMT to handle two new
languages tested in WMT: Polish and Czech. We find that all systems
consistently use spurious correlations in the data rather than meaningful
contextual information.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 20:42:21 GMT'}]",2020-10-14,"[['Kocmi', 'Tom', ''], ['Limisiewicz', 'Tomasz', ''], ['Stanovsky', 'Gabriel', '']]"
1362330,2010.06000,Sanjay Subramanian,"Sanjay Subramanian, Lucy Lu Wang, Sachin Mehta, Ben Bogin, Madeleine
  van Zuylen, Sravanthi Parasa, Sameer Singh, Matt Gardner, Hannaneh Hajishirzi","MedICaT: A Dataset of Medical Images, Captions, and Textual References",EMNLP-Findings 2020,,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Understanding the relationship between figures and text is key to scientific
document understanding. Medical figures in particular are quite complex, often
consisting of several subfigures (75% of figures in our dataset), with detailed
text describing their content. Previous work studying figures in scientific
papers focused on classifying figure content rather than understanding how
images relate to the text. To address challenges in figure retrieval and
figure-to-text alignment, we introduce MedICaT, a dataset of medical images in
context. MedICaT consists of 217K images from 131K open access biomedical
papers, and includes captions, inline references for 74% of figures, and
manually annotated subfigures and subcaptions for a subset of figures. Using
MedICaT, we introduce the task of subfigure to subcaption alignment in compound
figures and demonstrate the utility of inline references in image-text
matching. Our data and code can be accessed at
https://github.com/allenai/medicat.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 19:56:08 GMT'}]",2020-10-14,"[['Subramanian', 'Sanjay', ''], ['Wang', 'Lucy Lu', ''], ['Mehta', 'Sachin', ''], ['Bogin', 'Ben', ''], ['van Zuylen', 'Madeleine', ''], ['Parasa', 'Sravanthi', ''], ['Singh', 'Sameer', ''], ['Gardner', 'Matt', ''], ['Hajishirzi', 'Hannaneh', '']]"
1362327,2010.05997,Xing Jie Zhong,"Xing Jie Zhong, and David Chiang","Look It Up: Bilingual and Monolingual Dictionaries Improve Neural
  Machine Translation",Accepted for publication in Proceedings of WMT 2020,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite advances in neural machine translation (NMT) quality, rare words
continue to be problematic. For humans, the solution to the rare-word problem
has long been dictionaries, but dictionaries cannot be straightforwardly
incorporated into NMT. In this paper, we describe a new method for ""attaching""
dictionary definitions to rare words so that the network can learn the best way
to use them. We demonstrate improvements of up to 3.1 BLEU using bilingual
dictionaries and up to 0.7 BLEU using monolingual source-language dictionaries.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 19:53:08 GMT'}]",2020-10-14,"[['Zhong', 'Xing Jie', ''], ['Chiang', 'David', '']]"
1362324,2010.05994,Jianqiao Li,"Guoyin Wang, Chunyuan Li, Jianqiao Li, Hao Fu, Yuh-Chen Lin, Liqun
  Chen, Yizhe Zhang, Chenyang Tao, Ruiyi Zhang, Wenlin Wang, Dinghan Shen, Qian
  Yang and Lawrence Carin",Improving Text Generation with Student-Forcing Optimal Transport,To appear at EMNLP 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Neural language models are often trained with maximum likelihood estimation
(MLE), where the next word is generated conditioned on the ground-truth word
tokens. During testing, however, the model is instead conditioned on previously
generated tokens, resulting in what is termed exposure bias. To reduce this gap
between training and testing, we propose using optimal transport (OT) to match
the sequences generated in these two modes. An extension is further proposed to
improve the OT learning, based on the structural and contextual information of
the text sequences. The effectiveness of the proposed method is validated on
machine translation, text summarization, and text generation tasks.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 19:42:25 GMT'}]",2020-10-14,"[['Wang', 'Guoyin', ''], ['Li', 'Chunyuan', ''], ['Li', 'Jianqiao', ''], ['Fu', 'Hao', ''], ['Lin', 'Yuh-Chen', ''], ['Chen', 'Liqun', ''], ['Zhang', 'Yizhe', ''], ['Tao', 'Chenyang', ''], ['Zhang', 'Ruiyi', ''], ['Wang', 'Wenlin', ''], ['Shen', 'Dinghan', ''], ['Yang', 'Qian', ''], ['Carin', 'Lawrence', '']]"
1362323,2010.05993,Andrea Zugarini,Andrea Zugarini and Matteo Tiezzi and Marco Maggini,"Vulgaris: Analysis of a Corpus for Middle-Age Varieties of Italian
  Language",,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Italian is a Romance language that has its roots in Vulgar Latin. The birth
of the modern Italian started in Tuscany around the 14th century, and it is
mainly attributed to the works of Dante Alighieri, Francesco Petrarca and
Giovanni Boccaccio, who are among the most acclaimed authors of the medieval
age in Tuscany. However, Italy has been characterized by a high variety of
dialects, which are often loosely related to each other, due to the past
fragmentation of the territory. Italian has absorbed influences from many of
these dialects, as also from other languages due to dominion of portions of the
country by other nations, such as Spain and France. In this work we present
Vulgaris, a project aimed at studying a corpus of Italian textual resources
from authors of different regions, ranging in a time period between 1200 and
1600. Each composition is associated to its author, and authors are also
grouped in families, i.e. sharing similar stylistic/chronological
characteristics. Hence, the dataset is not only a valuable resource for
studying the diachronic evolution of Italian and the differences between its
dialects, but it is also useful to investigate stylistic aspects between single
authors. We provide a detailed statistical analysis of the data, and a
corpus-driven study in dialectology and diachronic varieties.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 19:42:22 GMT'}]",2020-10-14,"[['Zugarini', 'Andrea', ''], ['Tiezzi', 'Matteo', ''], ['Maggini', 'Marco', '']]"
1362909,2010.06579,Jekaterina Novikova Dr.,"Benjamin Eyre, Aparna Balagopalan, Jekaterina Novikova","Fantastic Features and Where to Find Them: Detecting Cognitive
  Impairment with a Subsequence Classification Guided Approach",EMNLP Workshop on Noisy User-generated Text (W-NUT 2020),,,,cs.LG cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite the widely reported success of embedding-based machine learning
methods on natural language processing tasks, the use of more easily
interpreted engineered features remains common in fields such as cognitive
impairment (CI) detection. Manually engineering features from noisy text is
time and resource consuming, and can potentially result in features that do not
enhance model performance. To combat this, we describe a new approach to
feature engineering that leverages sequential machine learning models and
domain knowledge to predict which features help enhance performance. We provide
a concrete example of this method on a standard data set of CI speech and
demonstrate that CI classification accuracy improves by 2.3% over a strong
baseline when using features produced by this method. This demonstration
provides an ex-ample of how this method can be used to assist classification in
fields where interpretability is important, such as health care.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 17:57:18 GMT'}]",2020-10-14,"[['Eyre', 'Benjamin', ''], ['Balagopalan', 'Aparna', ''], ['Novikova', 'Jekaterina', '']]"
1362317,2010.05987,Sean MacAvaney,"Sean MacAvaney, Arman Cohan, Nazli Goharian",SLEDGE-Z: A Zero-Shot Baseline for COVID-19 Literature Search,EMNLP 2020. This article draws heavily from arXiv:2005.02365,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  With worldwide concerns surrounding the Severe Acute Respiratory Syndrome
Coronavirus 2 (SARS-CoV-2), there is a rapidly growing body of scientific
literature on the virus. Clinicians, researchers, and policy-makers need to be
able to search these articles effectively. In this work, we present a zero-shot
ranking algorithm that adapts to COVID-related scientific literature. Our
approach filters training data from another collection down to medical-related
queries, uses a neural re-ranking model pre-trained on scientific text
(SciBERT), and filters the target document collection. This approach ranks top
among zero-shot methods on the TREC COVID Round 1 leaderboard, and exhibits a
P@5 of 0.80 and an nDCG@10 of 0.68 when evaluated on both Round 1 and 2
judgments. Despite not relying on TREC-COVID data, our method outperforms
models that do. As one of the first search methods to thoroughly evaluate
COVID-19 search, we hope that this serves as a strong baseline and helps in the
global crisis.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 19:28:29 GMT'}]",2020-10-14,"[['MacAvaney', 'Sean', ''], ['Cohan', 'Arman', ''], ['Goharian', 'Nazli', '']]"
1362315,2010.05985,Alexander Gutkin,Alexander Gutkin and Richard Sproat,"NEMO: Frequentist Inference Approach to Constrained Linguistic Typology
  Feature Prediction in SIGTYP 2020 Shared Task","To appear in Second Workshop on Computational Research in Linguistic
  Typology (SIGTYP 2020) at 2020 Conference on Empirical Methods in Natural
  Language Processing (EMNLP)",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  This paper describes the NEMO submission to SIGTYP 2020 shared task which
deals with prediction of linguistic typological features for multiple languages
using the data derived from World Atlas of Language Structures (WALS). We
employ frequentist inference to represent correlations between typological
features and use this representation to train simple multi-class estimators
that predict individual features. We describe two submitted ridge
regression-based configurations which ranked second and third overall in the
constrained task. Our best configuration achieved the micro-averaged accuracy
score of 0.66 on 149 test languages.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 19:25:43 GMT'}]",2020-10-14,"[['Gutkin', 'Alexander', ''], ['Sproat', 'Richard', '']]"
1362301,2010.05971,Yanai Elazar,"Yanai Elazar, Victoria Basmov, Shauli Ravfogel, Yoav Goldberg, Reut
  Tsarfaty",The Extraordinary Failure of Complement Coercion Crowdsourcing,"Workshop on Insights from Negative Results in NLP, co-located with
  EMNLP 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Crowdsourcing has eased and scaled up the collection of linguistic annotation
in recent years. In this work, we follow known methodologies of collecting
labeled data for the complement coercion phenomenon. These are constructions
with an implied action -- e.g., ""I started a new book I bought last week"",
where the implied action is reading. We aim to collect annotated data for this
phenomenon by reducing it to either of two known tasks: Explicit Completion and
Natural Language Inference. However, in both cases, crowdsourcing resulted in
low agreement scores, even though we followed the same methodologies as in
previous work. Why does the same process fail to yield high agreement scores?
We specify our modeling schemes, highlight the differences with previous work
and provide some insights about the task and possible explanations for the
failure. We conclude that specific phenomena require tailored solutions, not
only in specialized algorithms, but also in data collection methods.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 19:04:04 GMT'}]",2020-10-14,"[['Elazar', 'Yanai', ''], ['Basmov', 'Victoria', ''], ['Ravfogel', 'Shauli', ''], ['Goldberg', 'Yoav', ''], ['Tsarfaty', 'Reut', '']]"
1362297,2010.05967,Ewan Dunbar,"Ewan Dunbar and Julien Karadayi and Mathieu Bernard and Xuan-Nga Cao
  and Robin Algayres and Lucas Ondel and Laurent Besacier and Sakriani Sakti
  and Emmanuel Dupoux","The Zero Resource Speech Challenge 2020: Discovering discrete subword
  and word units",,Proceedings of Interspeech 2020,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present the Zero Resource Speech Challenge 2020, which aims at learning
speech representations from raw audio signals without any labels. It combines
the data sets and metrics from two previous benchmarks (2017 and 2019) and
features two tasks which tap into two levels of speech representation. The
first task is to discover low bit-rate subword representations that optimize
the quality of speech synthesis; the second one is to discover word-like units
from unsegmented raw speech. We present the results of the twenty submitted
models and discuss the implications of the main findings for unsupervised
speech learning.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 18:56:48 GMT'}]",2020-10-14,"[['Dunbar', 'Ewan', ''], ['Karadayi', 'Julien', ''], ['Bernard', 'Mathieu', ''], ['Cao', 'Xuan-Nga', ''], ['Algayres', 'Robin', ''], ['Ondel', 'Lucas', ''], ['Besacier', 'Laurent', ''], ['Sakti', 'Sakriani', ''], ['Dupoux', 'Emmanuel', '']]"
1362291,2010.05961,Ewan Dunbar,Juliette Millet and Ewan Dunbar,"Perceptimatic: A human speech perception benchmark for unsupervised
  subword modelling",,Proceedings of Interspeech 2020,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we present a data set and methods to compare speech processing
models and human behaviour on a phone discrimination task. We provide
Perceptimatic, an open data set which consists of French and English speech
stimuli, as well as the results of 91 English- and 93 French-speaking
listeners. The stimuli test a wide range of French and English contrasts, and
are extracted directly from corpora of natural running read speech, used for
the 2017 Zero Resource Speech Challenge. We provide a method to compare humans'
perceptual space with models' representational space, and we apply it to models
previously submitted to the Challenge. We show that, unlike unsupervised models
and supervised multilingual models, a standard supervised monolingual HMM-GMM
phone recognition system, while good at discriminating phones, yields a
representational space very different from that of human native listeners.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 18:40:08 GMT'}]",2020-10-14,"[['Millet', 'Juliette', ''], ['Dunbar', 'Ewan', '']]"
1362289,2010.05959,Alexander Gutkin,Alexander Gutkin and Martin Jansche and Lucy Skidmore,Towards Induction of Structured Phoneme Inventories,"To appear in the Second Workshop on Computational Research in
  Linguistic Typology (SIGTYP 2020) at EMNLP 2020",,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  This extended abstract surveying the work on phonological typology was
prepared for ""SIGTYP 2020: The Second Workshop on Computational Research in
Linguistic Typology"" to be held at EMNLP 2020.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 18:39:07 GMT'}]",2020-10-14,"[['Gutkin', 'Alexander', ''], ['Jansche', 'Martin', ''], ['Skidmore', 'Lucy', '']]"
1362283,2010.05953,Jena Hwang,"Jena D. Hwang, Chandra Bhagavatula, Ronan Le Bras, Jeff Da, Keisuke
  Sakaguchi, Antoine Bosselut, Yejin Choi",COMET-ATOMIC 2020: On Symbolic and Neural Commonsense Knowledge Graphs,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent years have brought about a renewed interest in commonsense
representation and reasoning in the field of natural language understanding.
The development of new commonsense knowledge graphs (CSKG) has been central to
these advances as their diverse facts can be used and referenced by machine
learning models for tackling new and challenging tasks. At the same time, there
remain questions about the quality and coverage of these resources due to the
massive scale required to comprehensively encompass general commonsense
knowledge.
  In this work, we posit that manually constructed CSKGs will never achieve the
coverage necessary to be applicable in all situations encountered by NLP
agents. Therefore, we propose a new evaluation framework for testing the
utility of KGs based on how effectively implicit knowledge representations can
be learned from them.
  With this new goal, we propose ATOMIC 2020, a new CSKG of general-purpose
commonsense knowledge containing knowledge that is not readily available in
pretrained language models. We evaluate its properties in comparison with other
leading CSKGs, performing the first large-scale pairwise study of commonsense
knowledge resources. Next, we show that ATOMIC 2020 is better suited for
training knowledge models that can generate accurate, representative knowledge
for new, unseen entities and events. Finally, through human evaluation, we show
that the few-shot performance of GPT-3 (175B parameters), while impressive,
remains ~12 absolute points lower than a BART-based knowledge model trained on
ATOMIC 2020 despite using over 430x fewer parameters.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 18:27:05 GMT'}]",2020-10-14,"[['Hwang', 'Jena D.', ''], ['Bhagavatula', 'Chandra', ''], ['Bras', 'Ronan Le', ''], ['Da', 'Jeff', ''], ['Sakaguchi', 'Keisuke', ''], ['Bosselut', 'Antoine', ''], ['Choi', 'Yejin', '']]"
1279294,2004.14524,Huda Khayrallah,"Huda Khayrallah, Brian Thompson, Matt Post, Philipp Koehn","Simulated Multiple Reference Training Improves Low-Resource Machine
  Translation",EMNLP 2020 camera ready,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Many valid translations exist for a given sentence, yet machine translation
(MT) is trained with a single reference translation, exacerbating data sparsity
in low-resource settings. We introduce Simulated Multiple Reference Training
(SMRT), a novel MT training method that approximates the full space of possible
translations by sampling a paraphrase of the reference sentence from a
paraphraser and training the MT model to predict the paraphraser's distribution
over possible tokens. We demonstrate the effectiveness of SMRT in low-resource
settings when translating to English, with improvements of 1.2 to 7.0 BLEU. We
also find SMRT is complementary to back-translation.
","[{'version': 'v1', 'created': 'Thu, 30 Apr 2020 00:11:53 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Oct 2020 15:43:57 GMT'}]",2020-10-14,"[['Khayrallah', 'Huda', ''], ['Thompson', 'Brian', ''], ['Post', 'Matt', ''], ['Koehn', 'Philipp', '']]"
1361853,2010.05523,Xiangru Tang,"Xiangru Tang, Alan Aw","FILM: A Fast, Interpretable, and Low-rank Metric Learning Approach for
  Sentence Matching",,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Detection of semantic similarity plays a vital role in sentence matching. It
requires to learn discriminative representations of natural language. Recently,
owing to more and more sophisticated model architecture, impressive progress
has been made, along with a time-consuming training process and
not-interpretable inference. To alleviate this problem, we explore a metric
learning approach, named FILM (Fast, Interpretable, and Low-rank Metric
learning) to efficiently find a high discriminative projection of the
high-dimensional data. We construct this metric learning problem as a manifold
optimization problem and solve it with the Cayley transformation method with
the Barzilai-Borwein step size. In experiments, we apply FILM with triplet loss
minimization objective to the Quora Challenge and Semantic Textual Similarity
(STS) Task. The results demonstrate that the FILM method achieves superior
performance as well as the fastest computation speed, which is consistent with
our theoretical analysis of time complexity.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 08:24:41 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Oct 2020 01:14:14 GMT'}]",2020-10-14,"[['Tang', 'Xiangru', ''], ['Aw', 'Alan', '']]"
1360835,2010.04505,Yu Wan,"Yu Wan, Baosong Yang, Derek F. Wong, Yikai Zhou, Lidia S. Chao, Haibo
  Zhang, Boxing Chen",Self-Paced Learning for Neural Machine Translation,Accepted by EMNLP2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent studies have proven that the training of neural machine translation
(NMT) can be facilitated by mimicking the learning process of humans.
Nevertheless, achievements of such kind of curriculum learning rely on the
quality of artificial schedule drawn up with the handcrafted features, e.g.
sentence length or word rarity. We ameliorate this procedure with a more
flexible manner by proposing self-paced learning, where NMT model is allowed to
1) automatically quantify the learning confidence over training examples; and
2) flexibly govern its learning via regulating the loss in each iteration step.
Experimental results over multiple translation tasks demonstrate that the
proposed model yields better performance than strong baselines and those models
trained with human-designed curricula on both translation quality and
convergence speed.
","[{'version': 'v1', 'created': 'Fri, 9 Oct 2020 11:33:16 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Oct 2020 09:02:09 GMT'}]",2020-10-14,"[['Wan', 'Yu', ''], ['Yang', 'Baosong', ''], ['Wong', 'Derek F.', ''], ['Zhou', 'Yikai', ''], ['Chao', 'Lidia S.', ''], ['Zhang', 'Haibo', ''], ['Chen', 'Boxing', '']]"
1360185,2010.03855,Dong-Jin Kim,"Dong-Jin Kim, Tae-Hyun Oh, Jinsoo Choi, In So Kweon",Dense Relational Image Captioning via Multi-task Triple-Stream Networks,"Journal extension of our CVPR 2019 paper ( arXiv:1903.05942 ). Source
  code : https://github.com/Dong-JinKim/DenseRelationalCaptioning",,,,cs.CV cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We introduce dense relational captioning, a novel image captioning task which
aims to generate multiple captions with respect to relational information
between objects in a visual scene. Relational captioning provides explicit
descriptions of each relationship between object combinations. This framework
is advantageous in both diversity and amount of information, leading to a
comprehensive image understanding based on relationships, e.g., relational
proposal generation. For relational understanding between objects, the
part-of-speech (POS, i.e., subject-object-predicate categories) can be a
valuable prior information to guide the causal sequence of words in a caption.
We enforce our framework to not only learn to generate captions but also
predict the POS of each word. To this end, we propose the multi-task
triple-stream network (MTTSNet) which consists of three recurrent units
responsible for each POS which is trained by jointly predicting the correct
captions and POS for each word. In addition, we found that the performance of
MTTSNet can be improved by modulating the object embeddings with an explicit
relational module. We demonstrate that our proposed model can generate more
diverse and richer captions, via extensive experimental analysis on large scale
datasets and several metrics. We additionally extend analysis to an ablation
study, applications on holistic image captioning, scene graph generation, and
retrieval tasks.
","[{'version': 'v1', 'created': 'Thu, 8 Oct 2020 09:17:55 GMT'}, {'version': 'v2', 'created': 'Mon, 12 Oct 2020 18:14:14 GMT'}]",2020-10-14,"[['Kim', 'Dong-Jin', ''], ['Oh', 'Tae-Hyun', ''], ['Choi', 'Jinsoo', ''], ['Kweon', 'In So', '']]"
1362383,2010.06053,Zhao Song,"Yangsibo Huang, Zhao Song, Danqi Chen, Kai Li, Sanjeev Arora",TextHide: Tackling Data Privacy in Language Understanding Tasks,Findings of EMNLP 2020,,,,cs.CL cs.CR cs.DS cs.LG stat.ML,http://creativecommons.org/licenses/by-sa/4.0/,"  An unsolved challenge in distributed or federated learning is to effectively
mitigate privacy risks without slowing down training or reducing accuracy. In
this paper, we propose TextHide aiming at addressing this challenge for natural
language understanding tasks. It requires all participants to add a simple
encryption step to prevent an eavesdropping attacker from recovering private
text data. Such an encryption step is efficient and only affects the task
performance slightly. In addition, TextHide fits well with the popular
framework of fine-tuning pre-trained language models (e.g., BERT) for any
sentence or sentence-pair task. We evaluate TextHide on the GLUE benchmark, and
our experiments show that TextHide can effectively defend attacks on shared
gradients or representations and the averaged accuracy reduction is only
$1.9\%$. We also present an analysis of the security of TextHide using a
conjecture about the computational intractability of a mathematical problem.
  Our code is available at https://github.com/Hazelsuko07/TextHide
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 22:22:15 GMT'}]",2020-10-14,"[['Huang', 'Yangsibo', ''], ['Song', 'Zhao', ''], ['Chen', 'Danqi', ''], ['Li', 'Kai', ''], ['Arora', 'Sanjeev', '']]"
1220338,1912.08442,Xinting Huang,"Xinting Huang, Jianzhong Qi, Yu Sun, Rui Zhang",MALA: Cross-Domain Dialogue Generation with Action Learning,Update: Accepted to Proceedings of AAAI 2020,,10.1609/aaai.v34i05.6306,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Response generation for task-oriented dialogues involves two basic
components: dialogue planning and surface realization. These two components,
however, have a discrepancy in their objectives, i.e., task completion and
language quality. To deal with such discrepancy, conditioned response
generation has been introduced where the generation process is factorized into
action decision and language generation via explicit action representations. To
obtain action representations, recent studies learn latent actions in an
unsupervised manner based on the utterance lexical similarity. Such an action
learning approach is prone to diversities of language surfaces, which may
impinge task completion and language quality. To address this issue, we propose
multi-stage adaptive latent action learning (MALA) that learns semantic latent
actions by distinguishing the effects of utterances on dialogue progress. We
model the utterance effect using the transition of dialogue states caused by
the utterance and develop a semantic similarity measurement that estimates
whether utterances have similar effects. For learning semantic actions on
domains without dialogue states, MsALA extends the semantic similarity
measurement across domains progressively, i.e., from aligning shared actions to
learning domain-specific actions. Experiments using multi-domain datasets, SMD
and MultiWOZ, show that our proposed model achieves consistent improvements
over the baselines models in terms of both task completion and language
quality.
","[{'version': 'v1', 'created': 'Wed, 18 Dec 2019 08:14:10 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Oct 2020 13:33:38 GMT'}]",2020-10-14,"[['Huang', 'Xinting', ''], ['Qi', 'Jianzhong', ''], ['Sun', 'Yu', ''], ['Zhang', 'Rui', '']]"
1362395,2010.06065,Zonghai Yao,"Zonghai Yao, Liangliang Cao and Huapu Pan",Zero-shot Entity Linking with Efficient Long Range Sequence Modeling,"6 pages, 6 figures, Findings of EMNLP2020",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper considers the problem of zero-shot entity linking, in which a link
in the test time may not present in training. Following the prevailing
BERT-based research efforts, we find a simple yet effective way is to expand
the long-range sequence modeling. Unlike many previous methods, our method does
not require expensive pre-training of BERT with long position embedding.
Instead, we propose an efficient position embeddings initialization method
called Embedding-repeat, which initializes larger position embeddings based on
BERT-Base. On Wikia's zero-shot EL dataset, our method improves the SOTA from
76.06% to 79.08%, and for its long data, the corresponding improvement is from
74.57% to 82.14%. Our experiments suggest the effectiveness of long-range
sequence modeling without retraining the BERT model.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 22:59:18 GMT'}]",2020-10-14,"[['Yao', 'Zonghai', ''], ['Cao', 'Liangliang', ''], ['Pan', 'Huapu', '']]"
1362445,2010.06115,Yuanhe Tian,"Yuanhe Tian, Yan Song, Fei Xia","Supertagging Combinatory Categorial Grammar with Attentive Graph
  Convolutional Networks","Natural Language Processing. 8 pages, 4 figures. EMNLP-2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Supertagging is conventionally regarded as an important task for combinatory
categorial grammar (CCG) parsing, where effective modeling of contextual
information is highly important to this task. However, existing studies have
made limited efforts to leverage contextual features except for applying
powerful encoders (e.g., bi-LSTM). In this paper, we propose attentive graph
convolutional networks to enhance neural CCG supertagging through a novel
solution of leveraging contextual information. Specifically, we build the graph
from chunks (n-grams) extracted from a lexicon and apply attention over the
graph, so that different word pairs from the contexts within and across chunks
are weighted in the model and facilitate the supertagging accordingly. The
experiments performed on the CCGbank demonstrate that our approach outperforms
all previous studies in terms of both supertagging and parsing. Further
analyses illustrate the effectiveness of each component in our approach to
discriminatively learn from word pairs to enhance CCG supertagging.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 01:58:29 GMT'}]",2020-10-14,"[['Tian', 'Yuanhe', ''], ['Song', 'Yan', ''], ['Xia', 'Fei', '']]"
1362762,2010.06432,Matan Orbach,"Orith Toledo-Ronen, Matan Orbach, Yonatan Bilu, Artem Spector, Noam
  Slonim",Multilingual Argument Mining: Datasets and Analysis,"Accepted to Findings of EMNLP 2020 (Long Paper). For the associated
  multilingual arguments and evidence corpus, see
  https://www.research.ibm.com/haifa/dept/vst/debating_data.shtml#Multilingual%20Argument%20Mining",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The growing interest in argument mining and computational argumentation
brings with it a plethora of Natural Language Understanding (NLU) tasks and
corresponding datasets. However, as with many other NLU tasks, the dominant
language is English, with resources in other languages being few and far
between. In this work, we explore the potential of transfer learning using the
multilingual BERT model to address argument mining tasks in non-English
languages, based on English datasets and the use of machine translation. We
show that such methods are well suited for classifying the stance of arguments
and detecting evidence, but less so for assessing the quality of arguments,
presumably because quality is harder to preserve under translation. In
addition, focusing on the translate-train approach, we show how the choice of
languages for translation, and the relations among them, affect the accuracy of
the resultant model. Finally, to facilitate evaluation of transfer learning on
argument mining tasks, we provide a human-generated dataset with more than 10k
arguments in multiple languages, as well as machine translation of the English
datasets.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 14:49:10 GMT'}]",2020-10-14,"[['Toledo-Ronen', 'Orith', ''], ['Orbach', 'Matan', ''], ['Bilu', 'Yonatan', ''], ['Spector', 'Artem', ''], ['Slonim', 'Noam', '']]"
1362684,2010.06354,"J\""org Tiedemann","J\""org Tiedemann","The Tatoeba Translation Challenge -- Realistic Data Sets for Low
  Resource and Multilingual MT",to be appear at the 5th Conference on Machine Translation (WMT20),,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  This paper describes the development of a new benchmark for machine
translation that provides training and test data for thousands of language
pairs covering over 500 languages and tools for creating state-of-the-art
translation models from that collection. The main goal is to trigger the
development of open translation tools and models with a much broader coverage
of the World's languages. Using the package it is possible to work on realistic
low-resource scenarios avoiding artificially reduced setups that are common
when demonstrating zero-shot or few-shot learning. For the first time, this
package provides a comprehensive collection of diverse data sets in hundreds of
languages with systematic language and script annotation and data splits to
extend the narrow coverage of existing benchmarks. Together with the data
release, we also provide a growing number of pre-trained baseline models for
individual language pairs and selected language groups.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 13:12:21 GMT'}]",2020-10-14,"[['Tiedemann', 'Jörg', '']]"
1362655,2010.06325,Guillaume Salha,"Elena V. Epure and Guillaume Salha and Manuel Moussallam and Romain
  Hennequin",Modeling the Music Genre Perception across Language-Bound Cultures,"2020 Conference on Empirical Methods in Natural Language Processing
  (EMNLP 2020)",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The music genre perception expressed through human annotations of artists or
albums varies significantly across language-bound cultures. These variations
cannot be modeled as mere translations since we also need to account for
cultural differences in the music genre perception. In this work, we study the
feasibility of obtaining relevant cross-lingual, culture-specific music genre
annotations based only on language-specific semantic representations, namely
distributed concept embeddings and ontologies. Our study, focused on six
languages, shows that unsupervised cross-lingual music genre annotation is
feasible with high accuracy, especially when combining both types of
representations. This approach of studying music genres is the most extensive
to date and has many implications in musicology and music information
retrieval. Besides, we introduce a new, domain-dependent cross-lingual corpus
to benchmark state of the art multilingual pre-trained embedding models.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 12:20:32 GMT'}]",2020-10-14,"[['Epure', 'Elena V.', ''], ['Salha', 'Guillaume', ''], ['Moussallam', 'Manuel', ''], ['Hennequin', 'Romain', '']]"
1362766,2010.06436,Andrey Kutuzov,"Julia Rodina, Andrey Kutuzov",RuSemShift: a dataset of historical lexical semantic change in Russian,Accepted to COLING 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present RuSemShift, a large-scale manually annotated test set for the task
of semantic change modeling in Russian for two long-term time period pairs:
from the pre-Soviet through the Soviet times and from the Soviet through the
post-Soviet times. Target words were annotated by multiple crowd-source
workers. The annotation process was organized following the DURel framework and
was based on sentence contexts extracted from the Russian National Corpus.
Additionally, we report the performance of several distributional approaches on
RuSemShift, achieving promising results, which at the same time leave room for
other researchers to improve.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 14:54:05 GMT'}]",2020-10-14,"[['Rodina', 'Julia', ''], ['Kutuzov', 'Andrey', '']]"
1362774,2010.06444,Thiago H. Silva,"Frances Santos, Thiago H Silva, Antonio A F Loureiro, Leandro Villas","Automatic Extraction of Urban Outdoor Perception from Geolocated
  Free-Texts",Paper accepted - to be published,,,,cs.SI cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The automatic extraction of urban perception shared by people on
location-based social networks (LBSNs) is an important multidisciplinary
research goal. One of the reasons is because it facilitates the understanding
of the intrinsic characteristics of urban areas in a scalable way, helping to
leverage new services. However, content shared on LBSNs is diverse,
encompassing several topics, such as politics, sports, culture, religion, and
urban perceptions, making the task of content extraction regarding a particular
topic very challenging. Considering free-text messages shared on LBSNs, we
propose an automatic and generic approach to extract people's perceptions. For
that, our approach explores opinions that are spatial-temporal and semantically
similar. We exemplify our approach in the context of urban outdoor areas in
Chicago, New York City and London. Studying those areas, we found evidence that
LBSN data brings valuable information about urban regions. To analyze and
validate our outcomes, we conducted a temporal analysis to measure the results'
robustness over time. We show that our approach can be helpful to better
understand urban areas considering different perspectives. We also conducted a
comparative analysis based on a public dataset, which contains volunteers'
perceptions regarding urban areas expressed in a controlled experiment. We
observe that both results yield a very similar level of agreement.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 14:59:46 GMT'}]",2020-10-14,"[['Santos', 'Frances', ''], ['Silva', 'Thiago H', ''], ['Loureiro', 'Antonio A F', ''], ['Villas', 'Leandro', '']]"
1362624,2010.06294,Li Liang,"Li Liang, Zheng Zhao and Bonnie Webber",Extending Implicit Discourse Relation Recognition to the PDTB-3,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The PDTB-3 contains many more Implicit discourse relations than the previous
PDTB-2. This is in part because implicit relations have now been annotated
within sentences as well as between them. In addition, some now co-occur with
explicit discourse relations, instead of standing on their own. Here we show
that while this can complicate the problem of identifying the location of
implicit discourse relations, it can in turn simplify the problem of
identifying their senses. We present data to support this claim, as well as
methods that can serve as a non-trivial baseline for future state-of-the-art
recognizers for implicit discourse relations.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 11:19:42 GMT'}]",2020-10-14,"[['Liang', 'Li', ''], ['Zhao', 'Zheng', ''], ['Webber', 'Bonnie', '']]"
1362613,2010.06283,Hendrik Schuff,"Hendrik Schuff, Heike Adel, Ngoc Thang Vu","F1 is Not Enough! Models and Evaluation Towards User-Centered
  Explainable Question Answering",EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Explainable question answering systems predict an answer together with an
explanation showing why the answer has been selected. The goal is to enable
users to assess the correctness of the system and understand its reasoning
process. However, we show that current models and evaluation settings have
shortcomings regarding the coupling of answer and explanation which might cause
serious issues in user experience. As a remedy, we propose a hierarchical model
and a new regularization term to strengthen the answer-explanation coupling as
well as two evaluation scores to quantify the coupling. We conduct experiments
on the HOTPOTQA benchmark data set and perform a user study. The user study
shows that our models increase the ability of the users to judge the
correctness of the system and that scores like F1 are not enough to estimate
the usefulness of a model in a practical setting with human users. Our scores
are better aligned with user experience, making them promising candidates for
model selection.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 10:53:20 GMT'}]",2020-10-14,"[['Schuff', 'Hendrik', ''], ['Adel', 'Heike', ''], ['Vu', 'Ngoc Thang', '']]"
1362611,2010.06281,Tharindu Ranasinghe Mr,"Tharindu Ranasinghe, Alistair Plum, Constantin Orasan, Ruslan Mitkov",RGCL at SemEval-2020 Task 6: Neural Approaches to Definition Extraction,"Accepted to SemEval-2020 (International Workshop on Semantic
  Evaluation) at COLING 2020",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  This paper presents the RGCL team submission to SemEval 2020 Task 6:
DeftEval, subtasks 1 and 2. The system classifies definitions at the sentence
and token levels. It utilises state-of-the-art neural network architectures,
which have some task-specific adaptations, including an automatically extended
training set. Overall, the approach achieves acceptable evaluation scores,
while maintaining flexibility in architecture selection.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 10:48:15 GMT'}]",2020-10-14,"[['Ranasinghe', 'Tharindu', ''], ['Plum', 'Alistair', ''], ['Orasan', 'Constantin', ''], ['Mitkov', 'Ruslan', '']]"
1362608,2010.06278,Tharindu Ranasinghe Mr,"Tharindu Ranasinghe, Hansi Hettiarachchi","BRUMS at SemEval-2020 Task 12 : Transformer based Multilingual Offensive
  Language Identification in Social Media","Accepted to SemEval-2020 (International Workshop on Semantic
  Evaluation) at COLING 2020",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we describe the team \textit{BRUMS} entry to OffensEval 2:
Multilingual Offensive Language Identification in Social Media in SemEval-2020.
The OffensEval organizers provided participants with annotated datasets
containing posts from social media in Arabic, Danish, English, Greek and
Turkish. We present a multilingual deep learning model to identify offensive
language in social media. Overall, the approach achieves acceptable evaluation
scores, while maintaining flexibility between languages.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 10:39:14 GMT'}]",2020-10-14,"[['Ranasinghe', 'Tharindu', ''], ['Hettiarachchi', 'Hansi', '']]"
1362797,2010.06467,Jimmy Lin,"Jimmy Lin, Rodrigo Nogueira, and Andrew Yates",Pretrained Transformers for Text Ranking: BERT and Beyond,,,,,cs.IR cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The goal of text ranking is to generate an ordered list of texts retrieved
from a corpus in response to a query. Although the most common formulation of
text ranking is search, instances of the task can also be found in many natural
language processing applications. This survey provides an overview of text
ranking with neural network architectures known as transformers, of which BERT
is the best-known example. The combination of transformers and self-supervised
pretraining has, without exaggeration, revolutionized the fields of natural
language processing (NLP), information retrieval (IR), and beyond. In this
survey, we provide a synthesis of existing work as a single point of entry for
practitioners who wish to gain a better understanding of how to apply
transformers to text ranking problems and researchers who wish to pursue work
in this area. We cover a wide range of modern techniques, grouped into two
high-level categories: transformer models that perform reranking in multi-stage
ranking architectures and learned dense representations that attempt to perform
ranking directly. There are two themes that pervade our survey: techniques for
handling long documents, beyond the typical sentence-by-sentence processing
approaches used in NLP, and techniques for addressing the tradeoff between
effectiveness (result quality) and efficiency (query latency). Although
transformer architectures and pretraining techniques are recent innovations,
many aspects of how they are applied to text ranking are relatively well
understood and represent mature techniques. However, there remain many open
research questions, and thus in addition to laying out the foundations of
pretrained transformers for text ranking, this survey also attempts to
prognosticate where the field is heading.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 15:20:32 GMT'}]",2020-10-14,"[['Lin', 'Jimmy', ''], ['Nogueira', 'Rodrigo', ''], ['Yates', 'Andrew', '']]"
1362583,2010.06253,Peng Cui,"Peng Cui, Le Hu, and Yuanchao Liu","Enhancing Extractive Text Summarization with Topic-Aware Graph Neural
  Networks",Accepted by COLING(2020),,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Text summarization aims to compress a textual document to a short summary
while keeping salient information. Extractive approaches are widely used in
text summarization because of their fluency and efficiency. However, most of
existing extractive models hardly capture inter-sentence relationships,
particularly in long documents. They also often ignore the effect of topical
information on capturing important contents. To address these issues, this
paper proposes a graph neural network (GNN)-based extractive summarization
model, enabling to capture inter-sentence relationships efficiently via
graph-structured document representation. Moreover, our model integrates a
joint neural topic model (NTM) to discover latent topics, which can provide
document-level features for sentence selection. The experimental results
demonstrate that our model not only substantially achieves state-of-the-art
results on CNN/DM and NYT datasets but also considerably outperforms existing
approaches on scientific paper datasets consisting of much longer documents,
indicating its better robustness in document genres and lengths. Further
discussions show that topical information can help the model preselect salient
contents from an entire document, which interprets its effectiveness in long
document summarization.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 09:30:04 GMT'}]",2020-10-14,"[['Cui', 'Peng', ''], ['Hu', 'Le', ''], ['Liu', 'Yuanchao', '']]"
1362802,2010.06472,Aaron Mueller,"Aaron Mueller, Zach Wood-Doughty, Silvio Amir, Mark Dredze, Alicia L.
  Nobles","Demographic Representation and Collective Storytelling in the Me Too
  Twitter Hashtag Activism Movement",27 pages (incl. 5 for references). Submitted to CSCW 2021,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The #MeToo movement on Twitter has drawn attention to the pervasive nature of
sexual harassment and violence. While #MeToo has been praised for providing
support for self-disclosures of harassment or violence and shifting societal
response, it has also been criticized for exemplifying how women of color have
been discounted for their historical contributions to and excluded from
feminist movements. Through an analysis of over 600,000 tweets from over
256,000 unique users, we examine online #MeToo conversations across gender and
racial/ethnic identities and the topics that each demographic emphasized. We
found that tweets authored by white women were overrepresented in the movement
compared to other demographics, aligning with criticism of unequal
representation. We found that intersected identities contributed differing
narratives to frame the movement, co-opted the movement to raise visibility in
parallel ongoing movements, employed the same hashtags both critically and
supportively, and revived and created new hashtags in response to pivotal
moments. Notably, tweets authored by black women often expressed emotional
support and were critical about differential treatment in the justice system
and by police. In comparison, tweets authored by white women and men often
highlighted sexual harassment and violence by public figures and weaved in more
general political discussions. We discuss the implications of work for digital
activism research and design including suggestions to raise visibility by those
who were under-represented in this hashtag activism movement. Content warning:
this article discusses issues of sexual harassment and violence.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 15:25:33 GMT'}]",2020-10-14,"[['Mueller', 'Aaron', ''], ['Wood-Doughty', 'Zach', ''], ['Amir', 'Silvio', ''], ['Dredze', 'Mark', ''], ['Nobles', 'Alicia L.', '']]"
1362543,2010.06213,Maxime Peyrard,"Maxime Peyrard, Robert West",KLearn: Background Knowledge Inference from Summarization Data,Accepted at Findings of EMNLP 2020,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  The goal of text summarization is to compress documents to the relevant
information while excluding background information already known to the
receiver. So far, summarization researchers have given considerably more
attention to relevance than to background knowledge. In contrast, this work
puts background knowledge in the foreground. Building on the realization that
the choices made by human summarizers and annotators contain implicit
information about their background knowledge, we develop and compare techniques
for inferring background knowledge from summarization data. Based on this
framework, we define summary scoring functions that explicitly model background
knowledge, and show that these scoring functions fit human judgments
significantly better than baselines. We illustrate some of the many potential
applications of our framework. First, we provide insights into human
information importance priors. Second, we demonstrate that averaging the
background knowledge of multiple, potentially biased annotators or corpora
greatly improves summary-scoring performance. Finally, we discuss potential
applications of our framework beyond summarization.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 07:42:25 GMT'}]",2020-10-14,"[['Peyrard', 'Maxime', ''], ['West', 'Robert', '']]"
1362808,2010.06478,Tommaso Pasini,"Alessandro Raganato, Tommaso Pasini, Jose Camacho-Collados, Mohammad
  Taher Pilehvar","XL-WiC: A Multilingual Benchmark for Evaluating Semantic
  Contextualization",EMNLP2020,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The ability to correctly model distinct meanings of a word is crucial for the
effectiveness of semantic representation techniques. However, most existing
evaluation benchmarks for assessing this criterion are tied to sense
inventories (usually WordNet), restricting their usage to a small subset of
knowledge-based representation techniques. The Word-in-Context dataset (WiC)
addresses the dependence on sense inventories by reformulating the standard
disambiguation task as a binary classification problem; but, it is limited to
the English language. We put forward a large multilingual benchmark, XL-WiC,
featuring gold standards in 12 new languages from varied language families and
with different degrees of resource availability, opening room for evaluation
scenarios such as zero-shot cross-lingual transfer. We perform a series of
experiments to determine the reliability of the datasets and to set performance
baselines for several recent contextualized multilingual models. Experimental
results show that even when no tagged instances are available for a target
language, models trained solely on the English data can attain competitive
performance in the task of distinguishing different meanings of a word, even
for distant languages. XL-WiC is available at
https://pilehvar.github.io/xlwic/.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 15:32:00 GMT'}]",2020-10-14,"[['Raganato', 'Alessandro', ''], ['Pasini', 'Tommaso', ''], ['Camacho-Collados', 'Jose', ''], ['Pilehvar', 'Mohammad Taher', '']]"
1362526,2010.06196,Zitao Liu,"Tianqiao Liu, Qian Fang, Wenbiao Ding, Zhongqin Wu, Zitao Liu","Mathematical Word Problem Generation from Commonsense Knowledge Graph
  and Equations",,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  There is an increasing interest in the use of automatic mathematical word
problem (MWP) generation in educational assessment. Different from standard
natural question generation, MWP generation needs to maintain the underlying
mathematical operations between quantities and variables, while at the same
time ensuring the relevance between the output and the given topic. To address
above problem we develop an end-to-end neural model to generate personalized
and diverse MWPs in real-world scenarios from commonsense knowledge graph and
equations. The proposed model (1) learns both representations from
edge-enhanced Levi graphs of symbolic equations and commonsense knowledge; (2)
automatically fuses equation and commonsense knowledge information via a
self-planning module when generating the MWPs. Experiments on an educational
gold-standard set and a large-scale generated MWP set show that our approach is
superior on the MWP generation task, and it outperforms the state-of-the-art
models in terms of both automatic evaluation metrics, i.e., BLEU-4, ROUGE-L,
Self-BLEU, and human evaluation metrics, i.e, equation relevance, topic
relevance, and language coherence.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 06:31:53 GMT'}]",2020-10-14,"[['Liu', 'Tianqiao', ''], ['Fang', 'Qian', ''], ['Ding', 'Wenbiao', ''], ['Wu', 'Zhongqin', ''], ['Liu', 'Zitao', '']]"
1362515,2010.06185,Avishai Gretz,"Shai Gretz, Yonatan Bilu, Edo Cohen-Karlik and Noam Slonim","The workweek is the best time to start a family -- A Study of GPT-2
  Based Claim Generation",Accepted to Findings of EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Argument generation is a challenging task whose research is timely
considering its potential impact on social media and the dissemination of
information. Here we suggest a pipeline based on GPT-2 for generating coherent
claims, and explore the types of claims that it produces, and their veracity,
using an array of manual and automatic assessments. In addition, we explore the
interplay between this task and the task of Claim Retrieval, showing how they
can complement one another.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 05:22:30 GMT'}]",2020-10-14,"[['Gretz', 'Shai', ''], ['Bilu', 'Yonatan', ''], ['Cohen-Karlik', 'Edo', ''], ['Slonim', 'Noam', '']]"
1362480,2010.06150,Nan Ding,"Xi Chen, Nan Ding, Tomer Levinboim, Radu Soricut","Improving Text Generation Evaluation with Batch Centering and Tempered
  Word Mover Distance",EMNLP 2020 Eval4NLP Workshop,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent advances in automatic evaluation metrics for text have shown that deep
contextualized word representations, such as those generated by BERT encoders,
are helpful for designing metrics that correlate well with human judgements. At
the same time, it has been argued that contextualized word representations
exhibit sub-optimal statistical properties for encoding the true similarity
between words or sentences. In this paper, we present two techniques for
improving encoding representations for similarity metrics: a batch-mean
centering strategy that improves statistical properties; and a computationally
efficient tempered Word Mover Distance, for better fusion of the information in
the contextualized word representations. We conduct numerical experiments that
demonstrate the robustness of our techniques, reporting results over various
BERT-backbone learned metrics and achieving state of the art correlation with
human ratings on several benchmarks.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 03:46:25 GMT'}]",2020-10-14,"[['Chen', 'Xi', ''], ['Ding', 'Nan', ''], ['Levinboim', 'Tomer', ''], ['Soricut', 'Radu', '']]"
1362468,2010.06138,Junliang Guo,"Junliang Guo, Zhirui Zhang, Linli Xu, Hao-Ran Wei, Boxing Chen, Enhong
  Chen",Incorporating BERT into Parallel Sequence Decoding with Adapters,NeurIPS 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While large scale pre-trained language models such as BERT have achieved
great success on various natural language understanding tasks, how to
efficiently and effectively incorporate them into sequence-to-sequence models
and the corresponding text generation tasks remains a non-trivial problem. In
this paper, we propose to address this problem by taking two different BERT
models as the encoder and decoder respectively, and fine-tuning them by
introducing simple and lightweight adapter modules, which are inserted between
BERT layers and tuned on the task-specific dataset. In this way, we obtain a
flexible and efficient model which is able to jointly leverage the information
contained in the source-side and target-side BERT models, while bypassing the
catastrophic forgetting problem. Each component in the framework can be
considered as a plug-in unit, making the framework flexible and task agnostic.
Our framework is based on a parallel sequence decoding algorithm named
Mask-Predict considering the bi-directional and conditional independent nature
of BERT, and can be adapted to traditional autoregressive decoding easily. We
conduct extensive experiments on neural machine translation tasks where the
proposed method consistently outperforms autoregressive baselines while
reducing the inference latency by half, and achieves $36.49$/$33.57$ BLEU
scores on IWSLT14 German-English/WMT14 German-English translation. When adapted
to autoregressive decoding, the proposed method achieves $30.60$/$43.56$ BLEU
scores on WMT14 English-German/English-French translation, on par with the
state-of-the-art baseline models.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 03:25:15 GMT'}]",2020-10-14,"[['Guo', 'Junliang', ''], ['Zhang', 'Zhirui', ''], ['Xu', 'Linli', ''], ['Wei', 'Hao-Ran', ''], ['Chen', 'Boxing', ''], ['Chen', 'Enhong', '']]"
1362467,2010.06137,Farjana Sultana Mim,"Farjana Sultana Mim, Naoya Inoue, Paul Reisert, Hiroki Ouchi and
  Kentaro Inui","Corruption Is Not All Bad: Incorporating Discourse Structure into
  Pre-training via Corruption for Essay Scoring",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Existing approaches for automated essay scoring and document representation
learning typically rely on discourse parsers to incorporate discourse structure
into text representation. However, the performance of parsers is not always
adequate, especially when they are used on noisy texts, such as student essays.
In this paper, we propose an unsupervised pre-training approach to capture
discourse structure of essays in terms of coherence and cohesion that does not
require any discourse parser or annotation. We introduce several types of
token, sentence and paragraph-level corruption techniques for our proposed
pre-training approach and augment masked language modeling pre-training with
our pre-training method to leverage both contextualized and discourse
information. Our proposed unsupervised approach achieves new state-of-the-art
result on essay Organization scoring task.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 03:17:34 GMT'}]",2020-10-14,"[['Mim', 'Farjana Sultana', ''], ['Inoue', 'Naoya', ''], ['Reisert', 'Paul', ''], ['Ouchi', 'Hiroki', ''], ['Inui', 'Kentaro', '']]"
1362463,2010.06133,XiaoKang Liu,"Jianquan Li, Xiaokang Liu, Honghong Zhao, Ruifeng Xu, Min Yang and
  Yaohong Jin","BERT-EMD: Many-to-Many Layer Mapping for BERT Compression with Earth
  Mover's Distance",EMNLP 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pre-trained language models (e.g., BERT) have achieved significant success in
various natural language processing (NLP) tasks. However, high storage and
computational costs obstruct pre-trained language models to be effectively
deployed on resource-constrained devices. In this paper, we propose a novel
BERT distillation method based on many-to-many layer mapping, which allows each
intermediate student layer to learn from any intermediate teacher layers. In
this way, our model can learn from different teacher layers adaptively for
various NLP tasks. %motivated by the intuition that different NLP tasks require
different levels of linguistic knowledge contained in the intermediate layers
of BERT. In addition, we leverage Earth Mover's Distance (EMD) to compute the
minimum cumulative cost that must be paid to transform knowledge from teacher
network to student network. EMD enables the effective matching for many-to-many
layer mapping. %EMD can be applied to network layers with different sizes and
effectively measures semantic distance between the teacher network and student
network. Furthermore, we propose a cost attention mechanism to learn the layer
weights used in EMD automatically, which is supposed to further improve the
model's performance and accelerate convergence time. Extensive experiments on
GLUE benchmark demonstrate that our model achieves competitive performance
compared to strong competitors in terms of both accuracy and model compression.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 02:53:52 GMT'}]",2020-10-14,"[['Li', 'Jianquan', ''], ['Liu', 'Xiaokang', ''], ['Zhao', 'Honghong', ''], ['Xu', 'Ruifeng', ''], ['Yang', 'Min', ''], ['Jin', 'Yaohong', '']]"
1362457,2010.06127,Yang Chen,Yang Chen and Alan Ritter,"Model Selection for Cross-Lingual Transfer using a Learned Scoring
  Function",,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Transformers that are pre-trained on multilingual text corpora, such as,
mBERT and XLM-RoBERTa, have achieved impressive cross-lingual transfer learning
results. In the zero-shot cross-lingual transfer setting, only English training
data is assumed, and the fine-tuned model is evaluated on another target
language. No target-language validation data is assumed in this setting,
however substantial variance has been observed in target language performance
between different fine-tuning runs. Prior work has relied on English
validation/development data to select among models that are fine-tuned with
different learning rates, number of steps and other hyperparameters, often
resulting in suboptimal choices. To address this challenge, we propose a
meta-learning approach to model selection that uses the fine-tuned model's own
internal representations to predict its cross-lingual capabilities. In
extensive experiments we find that our approach consistently selects better
models than English validation data across five languages and five well-studied
NLP tasks, achieving results that are comparable to small amounts of target
language development data.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 02:36:48 GMT'}]",2020-10-14,"[['Chen', 'Yang', ''], ['Ritter', 'Alan', '']]"
1362452,2010.06122,Clara Vania,"Clara Vania, Ruijie Chen, Samuel R. Bowman","Asking Crowdworkers to Write Entailment Examples: The Best of Bad
  Options",AACL 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large-scale natural language inference (NLI) datasets such as SNLI or MNLI
have been created by asking crowdworkers to read a premise and write three new
hypotheses, one for each possible semantic relationships (entailment,
contradiction, and neutral). While this protocol has been used to create useful
benchmark data, it remains unclear whether the writing-based annotation
protocol is optimal for any purpose, since it has not been evaluated directly.
Furthermore, there is ample evidence that crowdworker writing can introduce
artifacts in the data. We investigate two alternative protocols which
automatically create candidate (premise, hypothesis) pairs for annotators to
label. Using these protocols and a writing-based baseline, we collect several
new English NLI datasets of over 3k examples each, each using a fixed amount of
annotator time, but a varying number of examples to fit that time budget. Our
experiments on NLI and transfer learning show negative results: None of the
alternative protocols outperforms the baseline in evaluations of generalization
within NLI or on transfer to outside target tasks. We conclude that crowdworker
writing still the best known option for entailment data, highlighting the need
for further data collection work to focus on improving writing-based annotation
processes.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 02:27:05 GMT'}]",2020-10-14,"[['Vania', 'Clara', ''], ['Chen', 'Ruijie', ''], ['Bowman', 'Samuel R.', '']]"
1362449,2010.06119,Qingyun Wang,"Qingyun Wang, Qi Zeng, Lifu Huang, Kevin Knight, Heng Ji, Nazneen
  Fatema Rajani","ReviewRobot: Explainable Paper Review Generation based on Knowledge
  Synthesis",11 pages. Accepted by INLG 2020,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  To assist human review process, we build a novel ReviewRobot to automatically
assign a review score and write comments for multiple categories. A good review
needs to be knowledgeable, namely that the comments should be constructive and
informative to help improve the paper; and explainable by providing detailed
evidence. ReviewRobot achieves these goals via three steps: (1) We perform
domain-specific Information Extraction to construct a knowledge graph (KG) from
the target paper under review, a related work KG from the papers cited by the
target paper, and a background KG from a large collection of previous papers in
the domain. (2) By comparing these three KGs we predict a review score and
detailed structured knowledge as evidence for each review category. (3) We
carefully select and generalize human review sentences into templates, and
apply these templates to transform the review scores and evidence into natural
language comments. Experimental results show that our review score predictor
reaches 71.4-100% accuracy. Human assessment by domain experts shows that
41.7%-70.5% of the comments generated by ReviewRobot are valid and
constructive, and better than human-written ones 20% of the time. Thus,
ReviewRobot can serve as an assistant for paper reviewers, program chairs and
authors.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 02:17:58 GMT'}]",2020-10-14,"[['Wang', 'Qingyun', ''], ['Zeng', 'Qi', ''], ['Huang', 'Lifu', ''], ['Knight', 'Kevin', ''], ['Ji', 'Heng', ''], ['Rajani', 'Nazneen Fatema', '']]"
1362851,2010.06521,Michael Kruse,"Michael Kruse, Hal Finkel, Xingfu Wu",Autotuning Search Space for Loop Transformations,LLVM-in-HPC 2020 preprint,,,,cs.DC cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  One of the challenges for optimizing compilers is to predict whether applying
an optimization will improve its execution speed. Programmers may override the
compiler's profitability heuristic using optimization directives such as
pragmas in the source code. Machine learning in the form of autotuning can
assist users in finding the best optimizations for each platform.
  In this paper we propose a loop transformation search space that takes the
form of a tree, in contrast to previous approaches that usually use vector
spaces to represent loop optimization configurations. We implemented a simple
autotuner exploring the search space and applied it to a selected set of
PolyBench kernels. While the autotuner is capable of representing every
possible sequence of loop transformations and their relations, the results
motivate the use of better search strategies such as Monte Carlo tree search to
find sophisticated loop transformations such as multilevel tiling.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 16:26:57 GMT'}]",2020-10-14,"[['Kruse', 'Michael', ''], ['Finkel', 'Hal', ''], ['Wu', 'Xingfu', '']]"
1359519,2010.03189,BalaSundaraRaman Lakshmanan,BalaSundaraRaman Lakshmanan and Sanjeeth Kumar Ravindranath,"Theedhum Nandrum@Dravidian-CodeMix-FIRE2020: A Sentiment Polarity
  Classifier for YouTube Comments with Code-switching between Tamil, Malayalam
  and English","FIRE 2020, December 16-20, 2020, Hyderabad, India",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Theedhum Nandrum is a sentiment polarity detection system using two
approaches--a Stochastic Gradient Descent (SGD) based classifier and a Long
Short-term Memory (LSTM) based Classifier. Our approach utilises language
features like use of emoji, choice of scripts and code mixing which appeared
quite marked in the datasets specified for the Dravidian Codemix - FIRE 2020
task. The hyperparameters for the SGD were tuned using GridSearchCV. Our system
was ranked 4th in Tamil-English with a weighted average F1 score of 0.62 and
9th in Malayalam-English with a score of 0.65. We achieved a weighted average
F1 score of 0.77 for Tamil-English using a Logistic Regression based model
after the task deadline. This performance betters the top ranked classifier on
this dataset by a wide margin. Our use of language-specific Soundex to
harmonise the spelling variants in code-mixed data appears to be a novel
application of Soundex. Our complete code is published in github at
https://github.com/oligoglot/theedhum-nandrum.
","[{'version': 'v1', 'created': 'Wed, 7 Oct 2020 05:40:25 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Oct 2020 09:27:35 GMT'}]",2020-10-14,"[['Lakshmanan', 'BalaSundaraRaman', ''], ['Ravindranath', 'Sanjeeth Kumar', '']]"
1362725,2010.06395,Malte Ostendorff,"Malte Ostendorff, Terry Ruas, Till Blume, Bela Gipp, Georg Rehm",Aspect-based Document Similarity for Research Papers,Accepted for publication at COLING 2020,,,,cs.CL cs.IR,http://creativecommons.org/licenses/by/4.0/,"  Traditional document similarity measures provide a coarse-grained distinction
between similar and dissimilar documents. Typically, they do not consider in
what aspects two documents are similar. This limits the granularity of
applications like recommender systems that rely on document similarity. In this
paper, we extend similarity with aspect information by performing a pairwise
document classification task. We evaluate our aspect-based document similarity
for research papers. Paper citations indicate the aspect-based similarity,
i.e., the section title in which a citation occurs acts as a label for the pair
of citing and cited paper. We apply a series of Transformer models such as
RoBERTa, ELECTRA, XLNet, and BERT variations and compare them to an LSTM
baseline. We perform our experiments on two newly constructed datasets of
172,073 research paper pairs from the ACL Anthology and CORD-19 corpus. Our
results show SciBERT as the best performing system. A qualitative examination
validates our quantitative results. Our findings motivate future research of
aspect-based document similarity and the development of a recommender system
based on the evaluated techniques. We make our datasets, code, and trained
models publicly available.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 13:51:21 GMT'}]",2020-10-14,"[['Ostendorff', 'Malte', ''], ['Ruas', 'Terry', ''], ['Blume', 'Till', ''], ['Gipp', 'Bela', ''], ['Rehm', 'Georg', '']]"
1349618,2009.08115,Yichi Zhang,"Yichi Zhang, Zhijian Ou, Huixin Wang, Junlan Feng","A Probabilistic End-To-End Task-Oriented Dialog Model with Latent Belief
  States towards Semi-Supervised Learning",Accepted by EMNLP 2020,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Structured belief states are crucial for user goal tracking and database
query in task-oriented dialog systems. However, training belief trackers often
requires expensive turn-level annotations of every user utterance. In this
paper we aim at alleviating the reliance on belief state labels in building
end-to-end dialog systems, by leveraging unlabeled dialog data towards
semi-supervised learning. We propose a probabilistic dialog model, called the
LAtent BElief State (LABES) model, where belief states are represented as
discrete latent variables and jointly modeled with system responses given user
inputs. Such latent variable modeling enables us to develop semi-supervised
learning under the principled variational learning framework. Furthermore, we
introduce LABES-S2S, which is a copy-augmented Seq2Seq model instantiation of
LABES. In supervised experiments, LABES-S2S obtains strong results on three
benchmark datasets of different scales. In utilizing unlabeled dialog data,
semi-supervised LABES-S2S significantly outperforms both supervised-only and
semi-supervised baselines. Remarkably, we can reduce the annotation demands to
50% without performance loss on MultiWOZ.
","[{'version': 'v1', 'created': 'Thu, 17 Sep 2020 07:26:37 GMT'}, {'version': 'v2', 'created': 'Wed, 7 Oct 2020 06:43:09 GMT'}, {'version': 'v3', 'created': 'Tue, 13 Oct 2020 14:18:09 GMT'}]",2020-10-14,"[['Zhang', 'Yichi', ''], ['Ou', 'Zhijian', ''], ['Wang', 'Huixin', ''], ['Feng', 'Junlan', '']]"
1354773,2009.13270,Rajiv Movva,"Rajiv Movva, Jason Y. Zhao","Dissecting Lottery Ticket Transformers: Structural and Behavioral Study
  of Sparse Neural Machine Translation",Camera-ready for BlackboxNLP @ EMNLP 2020,,,,cs.CL cs.LG stat.ML,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Recent work on the lottery ticket hypothesis has produced highly sparse
Transformers for NMT while maintaining BLEU. However, it is unclear how such
pruning techniques affect a model's learned representations. By probing
Transformers with more and more low-magnitude weights pruned away, we find that
complex semantic information is first to be degraded. Analysis of internal
activations reveals that higher layers diverge most over the course of pruning,
gradually becoming less complex than their dense counterparts. Meanwhile, early
layers of sparse models begin to perform more encoding. Attention mechanisms
remain remarkably consistent as sparsity increases.
","[{'version': 'v1', 'created': 'Thu, 17 Sep 2020 02:08:45 GMT'}, {'version': 'v2', 'created': 'Mon, 12 Oct 2020 18:55:22 GMT'}]",2020-10-14,"[['Movva', 'Rajiv', ''], ['Zhao', 'Jason Y.', '']]"
1346268,2009.04765,Damian Pascual,"Nicolas Affolter, Beni Egressy, Damian Pascual, Roger Wattenhofer",Brain2Word: Decoding Brain Activity for Language Generation,,,,,cs.CL cs.LG q-bio.NC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Brain decoding, understood as the process of mapping brain activities to the
stimuli that generated them, has been an active research area in the last
years. In the case of language stimuli, recent studies have shown that it is
possible to decode fMRI scans into an embedding of the word a subject is
reading. However, such word embeddings are designed for natural language
processing tasks rather than for brain decoding. Therefore, they limit our
ability to recover the precise stimulus. In this work, we propose to directly
classify an fMRI scan, mapping it to the corresponding word within a fixed
vocabulary. Unlike existing work, we evaluate on scans from previously unseen
subjects. We argue that this is a more realistic setup and we present a model
that can decode fMRI data from unseen subjects. Our model achieves 5.22% Top-1
and 13.59% Top-5 accuracy in this challenging task, significantly outperforming
all the considered competitive baselines. Furthermore, we use the decoded words
to guide language generation with the GPT-2 model. This way, we advance the
quest for a system that translates brain activities into coherent text.
","[{'version': 'v1', 'created': 'Thu, 10 Sep 2020 10:47:36 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Oct 2020 08:05:08 GMT'}]",2020-10-14,"[['Affolter', 'Nicolas', ''], ['Egressy', 'Beni', ''], ['Pascual', 'Damian', ''], ['Wattenhofer', 'Roger', '']]"
1267191,2004.02421,Deng Cai,"Zibo Lin, Deng Cai, Yan Wang, Xiaojiang Liu, Hai-Tao Zheng, Shuming
  Shi","The World is Not Binary: Learning to Rank with Grayscale Data for
  Dialogue Response Selection",EMNLP2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Response selection plays a vital role in building retrieval-based
conversation systems. Despite that response selection is naturally a
learning-to-rank problem, most prior works take a point-wise view and train
binary classifiers for this task: each response candidate is labeled either
relevant (one) or irrelevant (zero). On the one hand, this formalization can be
sub-optimal due to its ignorance of the diversity of response quality. On the
other hand, annotating grayscale data for learning-to-rank can be prohibitively
expensive and challenging. In this work, we show that grayscale data can be
automatically constructed without human effort. Our method employs
off-the-shelf response retrieval models and response generation models as
automatic grayscale data generators. With the constructed grayscale data, we
propose multi-level ranking objectives for training, which can (1) teach a
matching model to capture more fine-grained context-response relevance
difference and (2) reduce the train-test discrepancy in terms of distractor
strength. Our method is simple, effective, and universal. Experiments on three
benchmark datasets and four state-of-the-art matching models show that the
proposed approach brings significant and consistent performance improvements.
","[{'version': 'v1', 'created': 'Mon, 6 Apr 2020 06:34:54 GMT'}, {'version': 'v2', 'created': 'Tue, 28 Apr 2020 02:39:39 GMT'}, {'version': 'v3', 'created': 'Wed, 16 Sep 2020 14:08:23 GMT'}, {'version': 'v4', 'created': 'Tue, 13 Oct 2020 07:08:07 GMT'}]",2020-10-14,"[['Lin', 'Zibo', ''], ['Cai', 'Deng', ''], ['Wang', 'Yan', ''], ['Liu', 'Xiaojiang', ''], ['Zheng', 'Hai-Tao', ''], ['Shi', 'Shuming', '']]"
1141880,1906.09694,Frank Z. Xing,Haodong Bai and Frank Z. Xing and Erik Cambria and Win-Bin Huang,"Business Taxonomy Construction Using Concept-Level Hierarchical
  Clustering","Accepted to The First Workshop on Financial Technology and Natural
  Language Processing (FinNLP@IJCAI-19)",,,,cs.CL q-fin.PM,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Business taxonomies are indispensable tools for investors to do equity
research and make professional decisions. However, to identify the structure of
industry sectors in an emerging market is challenging for two reasons. First,
existing taxonomies are designed for mature markets, which may not be the
appropriate classification for small companies with innovative business models.
Second, emerging markets are fast-developing, thus the static business
taxonomies cannot promptly reflect the new features. In this article, we
propose a new method to construct business taxonomies automatically from the
content of corporate annual reports. Extracted concepts are hierarchically
clustered using greedy affinity propagation. Our method requires less
supervision and is able to discover new terms. Experiments and evaluation on
the Chinese National Equities Exchange and Quotations (NEEQ) market show
several advantages of the business taxonomy we build. Our results provide an
effective tool for understanding and investing in the new growth companies.
","[{'version': 'v1', 'created': 'Mon, 24 Jun 2019 02:59:22 GMT'}]",2020-10-14,"[['Bai', 'Haodong', ''], ['Xing', 'Frank Z.', ''], ['Cambria', 'Erik', ''], ['Huang', 'Win-Bin', '']]"
1268260,2004.03490,Priyanka Sen,Priyanka Sen and Amir Saffari,What do Models Learn from Question Answering Datasets?,Accepted at EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While models have reached superhuman performance on popular question
answering (QA) datasets such as SQuAD, they have yet to outperform humans on
the task of question answering itself. In this paper, we investigate if models
are learning reading comprehension from QA datasets by evaluating BERT-based
models across five datasets. We evaluate models on their generalizability to
out-of-domain examples, responses to missing or incorrect data, and ability to
handle question variations. We find that no single dataset is robust to all of
our experiments and identify shortcomings in both datasets and evaluation
methods. Following our analysis, we make recommendations for building future QA
datasets that better evaluate the task of question answering through reading
comprehension. We also release code to convert QA datasets to a shared format
for easier experimentation at
https://github.com/amazon-research/qa-dataset-converter.
","[{'version': 'v1', 'created': 'Tue, 7 Apr 2020 15:41:55 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Oct 2020 13:02:44 GMT'}]",2020-10-14,"[['Sen', 'Priyanka', ''], ['Saffari', 'Amir', '']]"
1268429,2004.03659,Elena Tutubalina Dr.,"Elena Tutubalina, Ilseyar Alimova, Zulfat Miftahutdinov, Andrey
  Sakhovskiy, Valentin Malykh and Sergey Nikolenko","The Russian Drug Reaction Corpus and Neural Models for Drug Reactions
  and Effectiveness Detection in User Reviews","9 pages, 9 tables, 4 figures","Bioinformatics, 2020",10.1093/bioinformatics/btaa675,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The Russian Drug Reaction Corpus (RuDReC) is a new partially annotated corpus
of consumer reviews in Russian about pharmaceutical products for the detection
of health-related named entities and the effectiveness of pharmaceutical
products. The corpus itself consists of two parts, the raw one and the labelled
one. The raw part includes 1.4 million health-related user-generated texts
collected from various Internet sources, including social media. The labelled
part contains 500 consumer reviews about drug therapy with drug- and
disease-related information. Labels for sentences include health-related issues
or their absence. The sentences with one are additionally labelled at the
expression level for identification of fine-grained subtypes such as drug
classes and drug forms, drug indications, and drug reactions. Further, we
present a baseline model for named entity recognition (NER) and multi-label
sentence classification tasks on this corpus. The macro F1 score of 74.85% in
the NER task was achieved by our RuDR-BERT model. For the sentence
classification task, our model achieves the macro F1 score of 68.82% gaining
7.47% over the score of BERT model trained on Russian data. We make the RuDReC
corpus and pretrained weights of domain-specific BERT models freely available
at https://github.com/cimm-kzn/RuDReC
","[{'version': 'v1', 'created': 'Tue, 7 Apr 2020 19:26:13 GMT'}]",2020-10-14,"[['Tutubalina', 'Elena', ''], ['Alimova', 'Ilseyar', ''], ['Miftahutdinov', 'Zulfat', ''], ['Sakhovskiy', 'Andrey', ''], ['Malykh', 'Valentin', ''], ['Nikolenko', 'Sergey', '']]"
1268638,2004.03868,Dieuwke Hupkes,"Diana Rodr\'iguez Luna, Edoardo Maria Ponti, Dieuwke Hupkes, Elia
  Bruni","Internal and external pressures on language emergence: least effort,
  object constancy and frequency",Accepted for EMNLP-findings,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In previous work, artificial agents were shown to achieve almost perfect
accuracy in referential games where they have to communicate to identify
images. Nevertheless, the resulting communication protocols rarely display
salient features of natural languages, such as compositionality. In this paper,
we propose some realistic sources of pressure on communication that avert this
outcome. More specifically, we formalise the principle of least effort through
an auxiliary objective. Moreover, we explore several game variants, inspired by
the principle of object constancy, in which we alter the frequency, position,
and luminosity of the objects in the images. We perform an extensive analysis
on their effect through compositionality metrics, diagnostic classifiers, and
zero-shot evaluation. Our findings reveal that the proposed sources of pressure
result in emerging languages with less redundancy, more focus on high-level
conceptual information, and better abilities of generalisation. Overall, our
contributions reduce the gap between emergent and natural languages.
","[{'version': 'v1', 'created': 'Wed, 8 Apr 2020 08:12:41 GMT'}, {'version': 'v2', 'created': 'Fri, 24 Jul 2020 17:48:06 GMT'}, {'version': 'v3', 'created': 'Tue, 13 Oct 2020 09:29:44 GMT'}]",2020-10-14,"[['Luna', 'Diana Rodríguez', ''], ['Ponti', 'Edoardo Maria', ''], ['Hupkes', 'Dieuwke', ''], ['Bruni', 'Elia', '']]"
1280561,2005.00766,Nora Kassner,"Nora Kassner and Hinrich Sch\""utze","BERT-kNN: Adding a kNN Search Component to Pretrained Language Models
  for Better QA",to appear in EMNLP Findings,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Khandelwal et al. (2020) use a k-nearest-neighbor (kNN) component to improve
language model performance. We show that this idea is beneficial for
open-domain question answering (QA). To improve the recall of facts encountered
during training, we combine BERT (Devlin et al., 2019) with a traditional
information retrieval step (IR) and a kNN search over a large datastore of an
embedded text collection. Our contributions are as follows: i) BERT-kNN
outperforms BERT on cloze-style QA by large margins without any further
training. ii) We show that BERT often identifies the correct response category
(e.g., US city), but only kNN recovers the factually correct answer (e.g.,
""Miami""). iii) Compared to BERT, BERT-kNN excels for rare facts. iv) BERT-kNN
can easily handle facts not covered by BERT's training set, e.g., recent
events.
","[{'version': 'v1', 'created': 'Sat, 2 May 2020 09:34:42 GMT'}, {'version': 'v2', 'created': 'Mon, 12 Oct 2020 18:44:05 GMT'}]",2020-10-14,"[['Kassner', 'Nora', ''], ['Schütze', 'Hinrich', '']]"
1279942,2005.00147,Yasumasa Onoe,Yasumasa Onoe and Greg Durrett,Interpretable Entity Representations through Large-Scale Typing,Findings of EMNLP 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In standard methodology for natural language processing, entities in text are
typically embedded in dense vector spaces with pre-trained models. The
embeddings produced this way are effective when fed into downstream models, but
they require end-task fine-tuning and are fundamentally difficult to interpret.
In this paper, we present an approach to creating entity representations that
are human readable and achieve high performance on entity-related tasks out of
the box. Our representations are vectors whose values correspond to posterior
probabilities over fine-grained entity types, indicating the confidence of a
typing model's decision that the entity belongs to the corresponding type. We
obtain these representations using a fine-grained entity typing model, trained
either on supervised ultra-fine entity typing data (Choi et al. 2018) or
distantly-supervised examples from Wikipedia. On entity probing tasks involving
recognizing entity identity, our embeddings used in parameter-free downstream
models achieve competitive performance with ELMo- and BERT-based embeddings in
trained models. We also show that it is possible to reduce the size of our type
set in a learning-based way for particular domains. Finally, we show that these
embeddings can be post-hoc modified through a small number of rules to
incorporate domain knowledge and improve performance.
","[{'version': 'v1', 'created': 'Thu, 30 Apr 2020 23:58:03 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Oct 2020 01:18:13 GMT'}]",2020-10-14,"[['Onoe', 'Yasumasa', ''], ['Durrett', 'Greg', '']]"
1347871,2009.06368,Yanjun  Qi Dr.,"Jin Yong Yoo, John X. Morris, Eli Lifland, Yanjun Qi","Searching for a Search Method: Benchmarking Search Algorithms for
  Generating NLP Adversarial Examples","14 pages, 5 figures, 4 tables; Accepted by EMNLP BlackBox NLP
  Workshop 2020 @ https://blackboxnlp.github.io/cfp.html",,,,cs.CL cs.AI cs.CR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We study the behavior of several black-box search algorithms used for
generating adversarial examples for natural language processing (NLP) tasks. We
perform a fine-grained analysis of three elements relevant to search: search
algorithm, search space, and search budget. When new search algorithms are
proposed in past work, the attack search space is often modified alongside the
search algorithm. Without ablation studies benchmarking the search algorithm
change with the search space held constant, one cannot tell if an increase in
attack success rate is a result of an improved search algorithm or a less
restrictive search space. Additionally, many previous studies fail to properly
consider the search algorithms' run-time cost, which is essential for
downstream tasks like adversarial training. Our experiments provide a
reproducible benchmark of search algorithms across a variety of search spaces
and query budgets to guide future research in adversarial NLP. Based on our
experiments, we recommend greedy attacks with word importance ranking when
under a time constraint or attacking long inputs, and either beam search or
particle swarm optimization otherwise. Code implementation shared via
https://github.com/QData/TextAttack-Search-Benchmark
","[{'version': 'v1', 'created': 'Wed, 9 Sep 2020 17:04:42 GMT'}, {'version': 'v2', 'created': 'Mon, 12 Oct 2020 19:46:36 GMT'}]",2020-10-14,"[['Yoo', 'Jin Yong', ''], ['Morris', 'John X.', ''], ['Lifland', 'Eli', ''], ['Qi', 'Yanjun', '']]"
1348813,2009.07310,Ozan Caglayan,"Ozan Caglayan, Julia Ive, Veneta Haralampieva, Pranava Madhyastha,
  Lo\""ic Barrault and Lucia Specia",Simultaneous Machine Translation with Visual Context,"Long paper accepted to EMNLP 2020, Camera-ready version",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Simultaneous machine translation (SiMT) aims to translate a continuous input
text stream into another language with the lowest latency and highest quality
possible. The translation thus has to start with an incomplete source text,
which is read progressively, creating the need for anticipation. In this paper,
we seek to understand whether the addition of visual information can compensate
for the missing source context. To this end, we analyse the impact of different
multimodal approaches and visual features on state-of-the-art SiMT frameworks.
Our results show that visual context is helpful and that visually-grounded
models based on explicit object region information are much better than
commonly used global features, reaching up to 3 BLEU points improvement under
low latency scenarios. Our qualitative analysis illustrates cases where only
the multimodal systems are able to translate correctly from English into
gender-marked languages, as well as deal with differences in word order, such
as adjective-noun placement between English and French.
","[{'version': 'v1', 'created': 'Tue, 15 Sep 2020 18:19:11 GMT'}, {'version': 'v2', 'created': 'Wed, 23 Sep 2020 10:27:15 GMT'}, {'version': 'v3', 'created': 'Tue, 13 Oct 2020 10:45:18 GMT'}]",2020-10-14,"[['Caglayan', 'Ozan', ''], ['Ive', 'Julia', ''], ['Haralampieva', 'Veneta', ''], ['Madhyastha', 'Pranava', ''], ['Barrault', 'Loïc', ''], ['Specia', 'Lucia', '']]"
1082699,1902.01615,Prakhar Ganesh,"Prakhar Ganesh, Saket Dingliwal","Restructuring Conversations using Discourse Relations for Zero-shot
  Abstractive Dialogue Summarization",4 pages + supplementary,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Dialogue summarization is a challenging problem due to the informal and
unstructured nature of conversational data. Recent advances in abstractive
summarization have been focused on data-hungry neural models and adapting these
models to a new domain requires the availability of domain-specific manually
annotated corpus created by linguistic experts. We propose a zero-shot
abstractive dialogue summarization method that uses discourse relations to
provide structure to conversations, and then uses an out-of-the-box document
summarization model to create final summaries. Experiments on the AMI and ICSI
meeting corpus, with document summarization models like PGN and BART, shows
that our method improves the ROGUE score by up to 3 points, and even performs
competitively against other state-of-the-art methods.
","[{'version': 'v1', 'created': 'Tue, 5 Feb 2019 09:50:47 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Oct 2020 07:04:22 GMT'}]",2020-10-14,"[['Ganesh', 'Prakhar', ''], ['Dingliwal', 'Saket', '']]"
1348956,2009.07453,Se Jung Kwon,"Insoo Chung, Byeongwook Kim, Yoonjung Choi, Se Jung Kwon, Yongkweon
  Jeon, Baeseong Park, Sangha Kim and Dongsoo Lee","Extremely Low Bit Transformer Quantization for On-Device Neural Machine
  Translation",Findings of EMNLP 2020,,,,cs.LG cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The deployment of widely used Transformer architecture is challenging because
of heavy computation load and memory overhead during inference, especially when
the target device is limited in computational resources such as mobile or edge
devices. Quantization is an effective technique to address such challenges. Our
analysis shows that for a given number of quantization bits, each block of
Transformer contributes to translation quality and inference computations in
different manners. Moreover, even inside an embedding block, each word presents
vastly different contributions. Correspondingly, we propose a mixed precision
quantization strategy to represent Transformer weights by an extremely low
number of bits (e.g., under 3 bits). For example, for each word in an embedding
block, we assign different quantization bits based on statistical property. Our
quantized Transformer model achieves 11.8$\times$ smaller model size than the
baseline model, with less than -0.5 BLEU. We achieve 8.3$\times$ reduction in
run-time memory footprints and 3.5$\times$ speed up (Galaxy N10+) such that our
proposed compression strategy enables efficient implementation for on-device
NMT.
","[{'version': 'v1', 'created': 'Wed, 16 Sep 2020 03:58:01 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Oct 2020 05:23:31 GMT'}]",2020-10-14,"[['Chung', 'Insoo', ''], ['Kim', 'Byeongwook', ''], ['Choi', 'Yoonjung', ''], ['Kwon', 'Se Jung', ''], ['Jeon', 'Yongkweon', ''], ['Park', 'Baeseong', ''], ['Kim', 'Sangha', ''], ['Lee', 'Dongsoo', '']]"
1349046,2009.07543,Hengyi Cai,"Hengyi Cai, Hongshen Chen, Yonghao Song, Zhuoye Ding, Yongjun Bao,
  Weipeng Yan, Xiaofang Zhao",Group-wise Contrastive Learning for Neural Dialogue Generation,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Neural dialogue response generation has gained much popularity in recent
years. Maximum Likelihood Estimation (MLE) objective is widely adopted in
existing dialogue model learning. However, models trained with MLE objective
function are plagued by the low-diversity issue when it comes to the
open-domain conversational setting. Inspired by the observation that humans not
only learn from the positive signals but also benefit from correcting behaviors
of undesirable actions, in this work, we introduce contrastive learning into
dialogue generation, where the model explicitly perceives the difference
between the well-chosen positive and negative utterances. Specifically, we
employ a pretrained baseline model as a reference. During contrastive learning,
the target dialogue model is trained to give higher conditional probabilities
for the positive samples, and lower conditional probabilities for those
negative samples, compared to the reference model. To manage the multi-mapping
relations prevailed in human conversation, we augment contrastive dialogue
learning with group-wise dual sampling. Extensive experimental results show
that the proposed group-wise contrastive learning framework is suited for
training a wide range of neural dialogue generation models with very favorable
performance over the baseline training approaches.
","[{'version': 'v1', 'created': 'Wed, 16 Sep 2020 08:28:30 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Oct 2020 04:12:07 GMT'}]",2020-10-14,"[['Cai', 'Hengyi', ''], ['Chen', 'Hongshen', ''], ['Song', 'Yonghao', ''], ['Ding', 'Zhuoye', ''], ['Bao', 'Yongjun', ''], ['Yan', 'Weipeng', ''], ['Zhao', 'Xiaofang', '']]"
1201947,1911.03353,Tan Yan,"Tan Yan, Heyan Huang, Xian-Ling Mao","SEPT: Improving Scientific Named Entity Recognition with Span
  Representation",This work is outdated. The result should not be trusted,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We introduce a new scientific named entity recognizer called SEPT, which
stands for Span Extractor with Pre-trained Transformers. In recent papers, span
extractors have been demonstrated to be a powerful model compared with sequence
labeling models. However, we discover that with the development of pre-trained
language models, the performance of span extractors appears to become similar
to sequence labeling models. To keep the advantages of span representation, we
modified the model by under-sampling to balance the positive and negative
samples and reduce the search space. Furthermore, we simplify the origin
network architecture to combine the span extractor with BERT. Experiments
demonstrate that even simplified architecture achieves the same performance and
SEPT achieves a new state of the art result in scientific named entity
recognition even without relation information involved.
","[{'version': 'v1', 'created': 'Fri, 8 Nov 2019 16:19:26 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Oct 2020 04:25:25 GMT'}]",2020-10-14,"[['Yan', 'Tan', ''], ['Huang', 'Heyan', ''], ['Mao', 'Xian-Ling', '']]"
1286820,2005.07025,Kun Zhou,"Kun Zhou, Berrak Sisman, Mingyang Zhang and Haizhou Li","Converting Anyone's Emotion: Towards Speaker-Independent Emotional Voice
  Conversion",Accepted by Interspeech 2020,,,,cs.SD cs.AI cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Emotional voice conversion aims to convert the emotion of speech from one
state to another while preserving the linguistic content and speaker identity.
The prior studies on emotional voice conversion are mostly carried out under
the assumption that emotion is speaker-dependent. We consider that there is a
common code between speakers for emotional expression in a spoken language,
therefore, a speaker-independent mapping between emotional states is possible.
In this paper, we propose a speaker-independent emotional voice conversion
framework, that can convert anyone's emotion without the need for parallel
data. We propose a VAW-GAN based encoder-decoder structure to learn the
spectrum and prosody mapping. We perform prosody conversion by using continuous
wavelet transform (CWT) to model the temporal dependencies. We also investigate
the use of F0 as an additional input to the decoder to improve emotion
conversion performance. Experiments show that the proposed speaker-independent
framework achieves competitive results for both seen and unseen speakers.
","[{'version': 'v1', 'created': 'Wed, 13 May 2020 13:36:34 GMT'}, {'version': 'v2', 'created': 'Fri, 7 Aug 2020 13:37:48 GMT'}, {'version': 'v3', 'created': 'Tue, 13 Oct 2020 06:07:16 GMT'}]",2020-10-14,"[['Zhou', 'Kun', ''], ['Sisman', 'Berrak', ''], ['Zhang', 'Mingyang', ''], ['Li', 'Haizhou', '']]"
1328678,2008.00956,Paul Tarau,Paul Tarau and Eduardo Blanco,Interactive Text Graph Mining with a Prolog-based Dialog Engine,"Under consideration in Theory and Practice of Logic Programming
  (TPLP). arXiv admin note: substantial text overlap with arXiv:1909.09742",,10.1017/S1471068420000137,,cs.CL cs.LO,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  On top of a neural network-based dependency parser and a graph-based natural
language processing module we design a Prolog-based dialog engine that explores
interactively a ranked fact database extracted from a text document.
  We reorganize dependency graphs to focus on the most relevant content
elements of a sentence and integrate sentence identifiers as graph nodes.
  Additionally, after ranking the graph we take advantage of the implicit
semantic information that dependency links and WordNet bring in the form of
subject-verb-object, is-a and part-of relations.
  Working on the Prolog facts and their inferred consequences, the dialog
engine specializes the text graph with respect to a query and reveals
interactively the document's most relevant content elements.
  The open-source code of the integrated system is available at
https://github.com/ptarau/DeepRank .
  Under consideration in Theory and Practice of Logic Programming (TPLP).
","[{'version': 'v1', 'created': 'Fri, 31 Jul 2020 03:29:49 GMT'}]",2020-10-14,"[['Tarau', 'Paul', ''], ['Blanco', 'Eduardo', '']]"
1277067,2004.12297,Liu Yang,"Liu Yang, Mingyang Zhang, Cheng Li, Michael Bendersky, Marc Najork","Beyond 512 Tokens: Siamese Multi-depth Transformer-based Hierarchical
  Encoder for Long-Form Document Matching",Accepted as a full paper in CIKM 2020,,,,cs.IR cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Many natural language processing and information retrieval problems can be
formalized as the task of semantic matching. Existing work in this area has
been largely focused on matching between short texts (e.g., question
answering), or between a short and a long text (e.g., ad-hoc retrieval).
Semantic matching between long-form documents, which has many important
applications like news recommendation, related article recommendation and
document clustering, is relatively less explored and needs more research
effort. In recent years, self-attention based models like Transformers and BERT
have achieved state-of-the-art performance in the task of text matching. These
models, however, are still limited to short text like a few sentences or one
paragraph due to the quadratic computational complexity of self-attention with
respect to input text length. In this paper, we address the issue by proposing
the Siamese Multi-depth Transformer-based Hierarchical (SMITH) Encoder for
long-form document matching. Our model contains several innovations to adapt
self-attention models for longer text input. In order to better capture
sentence level semantic relations within a document, we pre-train the model
with a novel masked sentence block language modeling task in addition to the
masked word language modeling task used by BERT. Our experimental results on
several benchmark datasets for long-form document matching show that our
proposed SMITH model outperforms the previous state-of-the-art models including
hierarchical attention, multi-depth attention-based hierarchical recurrent
neural network, and BERT. Comparing to BERT based baselines, our model is able
to increase maximum input text length from 512 to 2048. We will open source a
Wikipedia based benchmark dataset, code and a pre-trained checkpoint to
accelerate future research on long-form document matching.
","[{'version': 'v1', 'created': 'Sun, 26 Apr 2020 07:04:08 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Oct 2020 01:48:52 GMT'}]",2020-10-14,"[['Yang', 'Liu', ''], ['Zhang', 'Mingyang', ''], ['Li', 'Cheng', ''], ['Bendersky', 'Michael', ''], ['Najork', 'Marc', '']]"
1208490,1911.09896,Robert Hawkins,"Robert D. Hawkins, Minae Kwon, Dorsa Sadigh, Noah D. Goodman",Continual adaptation for efficient machine communication,Accepted at CoNLL,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  To communicate with new partners in new contexts, humans rapidly form new
linguistic conventions. Recent neural language models are able to comprehend
and produce the existing conventions present in their training data, but are
not able to flexibly and interactively adapt those conventions on the fly as
humans do. We introduce an interactive repeated reference task as a benchmark
for models of adaptation in communication and propose a regularized continual
learning framework that allows an artificial agent initialized with a generic
language model to more accurately and efficiently communicate with a partner
over time. We evaluate this framework through simulations on COCO and in
real-time reference game experiments with human partners.
","[{'version': 'v1', 'created': 'Fri, 22 Nov 2019 07:26:40 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Oct 2020 09:39:21 GMT'}]",2020-10-14,"[['Hawkins', 'Robert D.', ''], ['Kwon', 'Minae', ''], ['Sadigh', 'Dorsa', ''], ['Goodman', 'Noah D.', '']]"
1353806,2009.12303,Prasetya Ajie Utama,"Prasetya Ajie Utama, Nafise Sadat Moosavi, Iryna Gurevych",Towards Debiasing NLU Models from Unknown Biases,Accepted at EMNLP 2020,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  NLU models often exploit biases to achieve high dataset-specific performance
without properly learning the intended task. Recently proposed debiasing
methods are shown to be effective in mitigating this tendency. However, these
methods rely on a major assumption that the types of bias should be known
a-priori, which limits their application to many NLU tasks and datasets. In
this work, we present the first step to bridge this gap by introducing a
self-debiasing framework that prevents models from mainly utilizing biases
without knowing them in advance. The proposed framework is general and
complementary to the existing debiasing methods. We show that it allows these
existing methods to retain the improvement on the challenge datasets (i.e.,
sets of examples designed to expose models' reliance on biases) without
specifically targeting certain biases. Furthermore, the evaluation suggests
that applying the framework results in improved overall robustness.
","[{'version': 'v1', 'created': 'Fri, 25 Sep 2020 15:49:39 GMT'}, {'version': 'v2', 'created': 'Thu, 8 Oct 2020 11:00:39 GMT'}, {'version': 'v3', 'created': 'Mon, 12 Oct 2020 11:52:22 GMT'}, {'version': 'v4', 'created': 'Tue, 13 Oct 2020 12:37:27 GMT'}]",2020-10-14,"[['Utama', 'Prasetya Ajie', ''], ['Moosavi', 'Nafise Sadat', ''], ['Gurevych', 'Iryna', '']]"
1363188,2010.06858,Paul O'Leary McCann,Paul McCann,"fugashi, a Tool for Tokenizing Japanese in Python",Accepted at EMNLP2020's NLP-OSS workshop,,,,cs.CL,http://creativecommons.org/publicdomain/zero/1.0/,"  Recent years have seen an increase in the number of large-scale multilingual
NLP projects. However, even in such projects, languages with special processing
requirements are often excluded. One such language is Japanese. Japanese is
written without spaces, tokenization is non-trivial, and while high quality
open source tokenizers exist they can be hard to use and lack English
documentation. This paper introduces fugashi, a MeCab wrapper for Python, and
gives an introduction to tokenizing Japanese.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 07:52:47 GMT'}]",2020-10-15,"[['McCann', 'Paul', '']]"
1363221,2010.06891,Qingyang Wu,"Qingyang Wu, Zhenzhong Lan, Jing Gu, Zhou Yu",Memformer: The Memory-Augmented Transformer,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Transformer models have obtained remarkable accomplishments in various NLP
tasks. However, these models have efficiency issues on long sequences, as the
complexity of their self-attention module scales quadratically with the
sequence length. To remedy the limitation, we present Memformer, a novel
language model that utilizes a single unified memory to encode and retrieve
past information. It includes a new optimization scheme, Memory Replay
Back-Propagation, which promotes long-range back-propagation through time with
a significantly reduced memory requirement. Memformer achieves $\mathcal{O}(n)$
time complexity and $\mathcal{O}(1)$ space complexity in processing long
sequences, meaning that the model can handle an infinite length sequence during
inference. Our model is also compatible with other self-supervised tasks to
further improve the performance on language modeling. Experimental results show
that Memformer outperforms the previous long-range sequence models on
WikiText-103, including Transformer-XL and compressive Transformer.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 09:03:36 GMT'}]",2020-10-15,"[['Wu', 'Qingyang', ''], ['Lan', 'Zhenzhong', ''], ['Gu', 'Jing', ''], ['Yu', 'Zhou', '']]"
1363045,2010.06715,Liam Fowl,"Liam Fowl, Micah Goldblum, Arjun Gupta, Amr Sharaf, Tom Goldstein","Random Network Distillation as a Diversity Metric for Both Image and
  Text Generation",,,,,cs.LG cs.CL cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Generative models are increasingly able to produce remarkably high quality
images and text. The community has developed numerous evaluation metrics for
comparing generative models. However, these metrics do not effectively quantify
data diversity. We develop a new diversity metric that can readily be applied
to data, both synthetic and natural, of any type. Our method employs random
network distillation, a technique introduced in reinforcement learning. We
validate and deploy this metric on both images and text. We further explore
diversity in few-shot image generation, a setting which was previously
difficult to evaluate.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 22:03:52 GMT'}]",2020-10-15,"[['Fowl', 'Liam', ''], ['Goldblum', 'Micah', ''], ['Gupta', 'Arjun', ''], ['Sharaf', 'Amr', ''], ['Goldstein', 'Tom', '']]"
1363165,2010.06835,Zhucheng Tu,"Svitlana Vakulenko, Shayne Longpre, Zhucheng Tu, Raviteja Anantha","A Wrong Answer or a Wrong Question? An Intricate Relationship between
  Question Reformulation and Answer Selection in Conversational Question
  Answering","Accepted at the Workshop on Search-Oriented Conversational AI (SCAI)
  2020. arXiv admin note: text overlap with arXiv:2004.14652",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The dependency between an adequate question formulation and correct answer
selection is a very intriguing but still underexplored area. In this paper, we
show that question rewriting (QR) of the conversational context allows to shed
more light on this phenomenon and also use it to evaluate robustness of
different answer selection approaches. We introduce a simple framework that
enables an automated analysis of the conversational question answering (QA)
performance using question rewrites, and present the results of this analysis
on the TREC CAsT and QuAC (CANARD) datasets. Our experiments uncover
sensitivity to question formulation of the popular state-of-the-art models for
reading comprehension and passage ranking. Our results demonstrate that the
reading comprehension model is insensitive to question formulation, while the
passage ranking changes dramatically with a little variation in the input
question. The benefit of QR is that it allows us to pinpoint and group such
cases automatically. We show how to use this methodology to verify whether QA
models are really learning the task or just finding shortcuts in the dataset,
and better understand the frequent types of error they make.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 06:29:51 GMT'}]",2020-10-15,"[['Vakulenko', 'Svitlana', ''], ['Longpre', 'Shayne', ''], ['Tu', 'Zhucheng', ''], ['Anantha', 'Raviteja', '']]"
1363153,2010.06823,JingHui Qin,"Jinghui Qin, Lihui Lin, Xiaodan Liang, Rumin Zhang, Liang Lin","Semantically-Aligned Universal Tree-Structured Solver for Math Word
  Problems",EMNLP2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A practical automatic textual math word problems (MWPs) solver should be able
to solve various textual MWPs while most existing works only focused on
one-unknown linear MWPs. Herein, we propose a simple but efficient method
called Universal Expression Tree (UET) to make the first attempt to represent
the equations of various MWPs uniformly. Then a semantically-aligned universal
tree-structured solver (SAU-Solver) based on an encoder-decoder framework is
proposed to resolve multiple types of MWPs in a unified model, benefiting from
our UET representation. Our SAU-Solver generates a universal expression tree
explicitly by deciding which symbol to generate according to the generated
symbols' semantic meanings like human solving MWPs. Besides, our SAU-Solver
also includes a novel subtree-level semanticallyaligned regularization to
further enforce the semantic constraints and rationality of the generated
expression tree by aligning with the contextual information. Finally, to
validate the universality of our solver and extend the research boundary of
MWPs, we introduce a new challenging Hybrid Math Word Problems dataset (HMWP),
consisting of three types of MWPs. Experimental results on several MWPs
datasets show that our model can solve universal types of MWPs and outperforms
several state-of-the-art models.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 06:27:07 GMT'}]",2020-10-15,"[['Qin', 'Jinghui', ''], ['Lin', 'Lihui', ''], ['Liang', 'Xiaodan', ''], ['Zhang', 'Rumin', ''], ['Lin', 'Liang', '']]"
1363134,2010.06804,Ankur Goswami,"Ankur Goswami, Akshata Bhat, Hadar Ohana, Theodoros Rekatsinas","Unsupervised Relation Extraction from Language Models using Constrained
  Cloze Completion","14 pages, 5 figures, Accepted to Findings of EMNLP 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We show that state-of-the-art self-supervised language models can be readily
used to extract relations from a corpus without the need to train a fine-tuned
extractive head. We introduce RE-Flex, a simple framework that performs
constrained cloze completion over pretrained language models to perform
unsupervised relation extraction. RE-Flex uses contextual matching to ensure
that language model predictions matches supporting evidence from the input
corpus that is relevant to a target relation. We perform an extensive
experimental study over multiple relation extraction benchmarks and demonstrate
that RE-Flex outperforms competing unsupervised relation extraction methods
based on pretrained language models by up to 27.8 $F_1$ points compared to the
next-best method. Our results show that constrained inference queries against a
language model can enable accurate unsupervised relation extraction.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 04:21:57 GMT'}]",2020-10-15,"[['Goswami', 'Ankur', ''], ['Bhat', 'Akshata', ''], ['Ohana', 'Hadar', ''], ['Rekatsinas', 'Theodoros', '']]"
1362777,2010.06447,Dan John Velasco,Dan John Velasco,"Pagsusuri ng RNN-based Transfer Learning Technique sa Low-Resource
  Language","5 pages, 3 tables, 1 figure. in Filipino language; typos corrected,
  rephrased sentences, thoughts and results unchanged",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Low-resource languages such as Filipino suffer from data scarcity which makes
it challenging to develop NLP applications for Filipino language. The use of
Transfer Learning (TL) techniques alleviates this problem in low-resource
setting. In recent years, transformer-based models are proven to be effective
in low-resource tasks but faces challenges in accessibility due to its high
compute and memory requirements. For this reason, there's a need for a cheaper
but effective alternative. This paper has three contributions. First, release a
pre-trained AWD-LSTM language model for Filipino language. Second, benchmark
AWD-LSTM in the Hate Speech classification task and show that it performs on
par with transformer-based models. Third, analyze the the performance of
AWD-LSTM in low-resource setting using degradation test and compare it with
transformer-based models.
  -----
  Ang mga low-resource languages tulad ng Filipino ay gipit sa accessible na
datos kaya't mahirap gumawa ng mga applications sa wikang ito. Ang mga Transfer
Learning (TL) techniques ay malaking tulong para sa low-resource setting o mga
pagkakataong gipit sa datos. Sa mga nagdaang taon, nanaig ang mga
transformer-based TL techniques pagdating sa low-resource tasks ngunit ito ay
mataas na compute and memory requirements kaya nangangailangan ng mas mura pero
epektibong alternatibo. Ang papel na ito ay may tatlong kontribusyon. Una,
maglabas ng pre-trained AWD-LSTM language model sa wikang Filipino upang maging
tuntungan sa pagbuo ng mga NLP applications sa wikang Filipino. Pangalawa, mag
benchmark ng AWD-LSTM sa Hate Speech classification task at ipakita na kayang
nitong makipagsabayan sa mga transformer-based models. Pangatlo, suriin ang
performance ng AWD-LSTM sa low-resource setting gamit ang degradation test at
ikumpara ito sa mga transformer-based models.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 15:06:07 GMT'}, {'version': 'v2', 'created': 'Wed, 14 Oct 2020 04:50:06 GMT'}]",2020-10-15,"[['Velasco', 'Dan John', '']]"
1363131,2010.06801,Ming Gong,"Xingyao Zhang, Linjun Shou, Jian Pei, Ming Gong, Lijie Wen, Daxin
  Jiang","A Graph Representation of Semi-structured Data for Web Question
  Answering",Accepted as long paper in COLING 2020,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The abundant semi-structured data on the Web, such as HTML-based tables and
lists, provide commercial search engines a rich information source for question
answering (QA). Different from plain text passages in Web documents, Web tables
and lists have inherent structures, which carry semantic correlations among
various elements in tables and lists. Many existing studies treat tables and
lists as flat documents with pieces of text and do not make good use of
semantic information hidden in structures. In this paper, we propose a novel
graph representation of Web tables and lists based on a systematic
categorization of the components in semi-structured data as well as their
relations. We also develop pre-training and reasoning techniques on the graph
model for the QA task. Extensive experiments on several real datasets collected
from a commercial engine verify the effectiveness of our approach. Our method
improves F1 score by 3.90 points over the state-of-the-art baselines.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 04:01:54 GMT'}]",2020-10-15,"[['Zhang', 'Xingyao', ''], ['Shou', 'Linjun', ''], ['Pei', 'Jian', ''], ['Gong', 'Ming', ''], ['Wen', 'Lijie', ''], ['Jiang', 'Daxin', '']]"
1363054,2010.06724,Muhao Chen,"Muhao Chen, Hongming Zhang, Haoyu Wang, Dan Roth","""What Are You Trying to Do?"" Semantic Typing of Event Processes",CoNLL 2020,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper studies a new cognitively motivated semantic typing task,
multi-axis event process typing, that, given an event process, attempts to
infer free-form type labels describing (i) the type of action made by the
process and (ii) the type of object the process seeks to affect. This task is
inspired by computational and cognitive studies of event understanding, which
suggest that understanding processes of events is often directed by recognizing
the goals, plans or intentions of the protagonist(s). We develop a large
dataset containing over 60k event processes, featuring ultra fine-grained
typing on both the action and object type axes with very large ($10^3\sim
10^4$) label vocabularies. We then propose a hybrid learning framework, P2GT,
which addresses the challenging typing problem with indirect supervision from
glosses1and a joint learning-to-rank framework. As our experiments indicate,
P2GT supports identifying the intent of processes, as well as the fine semantic
type of the affected object. It also demonstrates the capability of handling
few-shot cases, and strong generalizability on out-of-domain event processes.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 22:37:29 GMT'}]",2020-10-15,"[['Chen', 'Muhao', ''], ['Zhang', 'Hongming', ''], ['Wang', 'Haoyu', ''], ['Roth', 'Dan', '']]"
1363116,2010.06786,Fereshteh Jafariakinabad,"Fereshteh Jafariakinabad, Kien A. Hua","A Self-supervised Representation Learning of Sentence Structure for
  Authorship Attribution",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Syntactic structure of sentences in a document substantially informs about
its authorial writing style. Sentence representation learning has been widely
explored in recent years and it has been shown that it improves the
generalization of different downstream tasks across many domains. Even though
utilizing probing methods in several studies suggests that these learned
contextual representations implicitly encode some amount of syntax, explicit
syntactic information further improves the performance of deep neural models in
the domain of authorship attribution. These observations have motivated us to
investigate the explicit representation learning of syntactic structure of
sentences. In this paper, we propose a self-supervised framework for learning
structural representations of sentences. The self-supervised network contains
two components; a lexical sub-network and a syntactic sub-network which take
the sequence of words and their corresponding structural labels as the input,
respectively. Due to the n-to-1 mapping of words to their structural labels,
each word will be embedded into a vector representation which mainly carries
structural information. We evaluate the learned structural representations of
sentences using different probing tasks, and subsequently utilize them in the
authorship attribution task. Our experimental results indicate that the
structural embeddings significantly improve the classification tasks when
concatenated with the existing pre-trained word embeddings.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 02:57:10 GMT'}]",2020-10-15,"[['Jafariakinabad', 'Fereshteh', ''], ['Hua', 'Kien A.', '']]"
1363108,2010.06778,Alexander Gutkin,"Alena Butryna and Shan-Hui Cathy Chu and Isin Demirsahin and Alexander
  Gutkin and Linne Ha and Fei He and Martin Jansche and Cibu Johny and Anna
  Katanova and Oddur Kjartansson and Chenfang Li and Tatiana Merkulova and Yin
  May Oo and Knot Pipatsrisawat and Clara Rivera and Supheakmungkol Sarin and
  Pasindu de Silva and Keshan Sodimana and Richard Sproat and Theeraphol
  Wattanavekin and Jaka Aris Eko Wibawa","Google Crowdsourced Speech Corpora and Related Open-Source Resources for
  Low-Resource Languages and Dialects: An Overview","Appeared in 2019 UNESCO International Conference Language
  Technologies for All (LT4All): Enabling Linguistic Diversity and
  Multilingualism Worldwide, 4-6 December, Paris, France",,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  This paper presents an overview of a program designed to address the growing
need for developing freely available speech resources for under-represented
languages. At present we have released 38 datasets for building text-to-speech
and automatic speech recognition applications for languages and dialects of
South and Southeast Asia, Africa, Europe and South America. The paper describes
the methodology used for developing such corpora and presents some of our
findings that could benefit under-represented language communities.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 02:24:04 GMT'}]",2020-10-15,"[['Butryna', 'Alena', ''], ['Chu', 'Shan-Hui Cathy', ''], ['Demirsahin', 'Isin', ''], ['Gutkin', 'Alexander', ''], ['Ha', 'Linne', ''], ['He', 'Fei', ''], ['Jansche', 'Martin', ''], ['Johny', 'Cibu', ''], ['Katanova', 'Anna', ''], ['Kjartansson', 'Oddur', ''], ['Li', 'Chenfang', ''], ['Merkulova', 'Tatiana', ''], ['Oo', 'Yin May', ''], ['Pipatsrisawat', 'Knot', ''], ['Rivera', 'Clara', ''], ['Sarin', 'Supheakmungkol', ''], ['de Silva', 'Pasindu', ''], ['Sodimana', 'Keshan', ''], ['Sproat', 'Richard', ''], ['Wattanavekin', 'Theeraphol', ''], ['Wibawa', 'Jaka Aris Eko', '']]"
1363051,2010.06721,Steven Reich,"Steven Reich, David Mueller, Nicholas Andrews","Ensemble Distillation for Structured Prediction: Calibrated, Accurate,
  Fast---Choose Three",EMNLP 2020,,,,cs.LG cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Modern neural networks do not always produce well-calibrated predictions,
even when trained with a proper scoring function such as cross-entropy. In
classification settings, simple methods such as isotonic regression or
temperature scaling may be used in conjunction with a held-out dataset to
calibrate model outputs. However, extending these methods to structured
prediction is not always straightforward or effective; furthermore, a held-out
calibration set may not always be available. In this paper, we study ensemble
distillation as a general framework for producing well-calibrated structured
prediction models while avoiding the prohibitive inference-time cost of
ensembles. We validate this framework on two tasks: named-entity recognition
and machine translation. We find that, across both tasks, ensemble distillation
produces models which retain much of, and occasionally improve upon, the
performance and calibration benefits of ensembles, while only requiring a
single model during test-time.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 22:30:06 GMT'}]",2020-10-15,"[['Reich', 'Steven', ''], ['Mueller', 'David', ''], ['Andrews', 'Nicholas', '']]"
1363187,2010.06857,Hatem Haddad,"Abir Messaoudi and Hatem Haddad and Moez Ben HajHmida and Chayma
  Fourati and Abderrazak Ben Hamida",Learning Word Representations for Tunisian Sentiment Analysis,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Tunisians on social media tend to express themselves in their local dialect
using Latin script (TUNIZI). This raises an additional challenge to the process
of exploring and recognizing online opinions. To date, very little work has
addressed TUNIZI sentiment analysis due to scarce resources for training an
automated system. In this paper, we focus on the Tunisian dialect sentiment
analysis used on social media. Most of the previous work used machine learning
techniques combined with handcrafted features. More recently, Deep Neural
Networks were widely used for this task, especially for the English language.
In this paper, we explore the importance of various unsupervised word
representations (word2vec, BERT) and we investigate the use of Convolutional
Neural Networks and Bidirectional Long Short-Term Memory. Without using any
kind of handcrafted features, our experimental results on two publicly
available datasets showed comparable performances to other languages.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 07:47:33 GMT'}]",2020-10-15,"[['Messaoudi', 'Abir', ''], ['Haddad', 'Hatem', ''], ['HajHmida', 'Moez Ben', ''], ['Fourati', 'Chayma', ''], ['Hamida', 'Abderrazak Ben', '']]"
1363236,2010.06906,Debanjana Kar,"Debanjana Kar, Mohit Bhardwaj, Suranjana Samanta, Amar Prakash Azad","No Rumours Please! A Multi-Indic-Lingual Approach for COVID Fake-Tweet
  Detection","6 pages, 4 figures",,,,cs.CL cs.LG cs.SI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The sudden widespread menace created by the present global pandemic COVID-19
has had an unprecedented effect on our lives. Man-kind is going through
humongous fear and dependence on social media like never before. Fear
inevitably leads to panic, speculations, and the spread of misinformation. Many
governments have taken measures to curb the spread of such misinformation for
public well being. Besides global measures, to have effective outreach, systems
for demographically local languages have an important role to play in this
effort. Towards this, we propose an approach to detect fake news about COVID-19
early on from social media, such as tweets, for multiple Indic-Languages
besides English. In addition, we also create an annotated dataset of Hindi and
Bengali tweet for fake news detection. We propose a BERT based model augmented
with additional relevant features extracted from Twitter to identify fake
tweets. To expand our approach to multiple Indic languages, we resort to mBERT
based model which is fine-tuned over created dataset in Hindi and Bengali. We
also propose a zero-shot learning approach to alleviate the data scarcity issue
for such low resource languages. Through rigorous experiments, we show that our
approach reaches around 89% F-Score in fake tweet detection which supercedes
the state-of-the-art (SOTA) results. Moreover, we establish the first benchmark
for two Indic-Languages, Hindi and Bengali. Using our annotated data, our model
achieves about 79% F-Score in Hindi and 81% F-Score for Bengali Tweets. Our
zero-shot model achieves about 81% F-Score in Hindi and 78% F-Score for Bengali
Tweets without any annotated data, which clearly indicates the efficacy of our
approach.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 09:37:51 GMT'}]",2020-10-15,"[['Kar', 'Debanjana', ''], ['Bhardwaj', 'Mohit', ''], ['Samanta', 'Suranjana', ''], ['Azad', 'Amar Prakash', '']]"
1363046,2010.06716,Oleg Vasilyev,"Oleg Vasilyev, Vedant Dharnidharka, Nicholas Egan, Charlene Chambliss,
  John Bohannon",Sensitivity of BLANC to human-scored qualities of text summaries,"6 pages, 3 figures, 2 tables",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We explore the sensitivity of a document summary quality estimator, BLANC, to
human assessment of qualities for the same summaries. In our human evaluations,
we distinguish five summary qualities, defined by how fluent, understandable,
informative, compact, and factually correct the summary is. We make the case
for optimal BLANC parameters, at which the BLANC sensitivity to almost all of
summary qualities is about as good as the sensitivity of a human annotator.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 22:08:11 GMT'}]",2020-10-15,"[['Vasilyev', 'Oleg', ''], ['Dharnidharka', 'Vedant', ''], ['Egan', 'Nicholas', ''], ['Chambliss', 'Charlene', ''], ['Bohannon', 'John', '']]"
1363044,2010.06714,Jiaxin Huang,"Jiaxin Huang, Yiqing Xie, Yu Meng, Yunyi Zhang, Jiawei Han","CoRel: Seed-Guided Topical Taxonomy Construction by Concept Learning and
  Relation Transferring",KDD 2020 Research Track,,10.1145/3394486.3403244,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Taxonomy is not only a fundamental form of knowledge representation, but also
crucial to vast knowledge-rich applications, such as question answering and web
search. Most existing taxonomy construction methods extract hypernym-hyponym
entity pairs to organize a ""universal"" taxonomy. However, these generic
taxonomies cannot satisfy user's specific interest in certain areas and
relations. Moreover, the nature of instance taxonomy treats each node as a
single word, which has low semantic coverage. In this paper, we propose a
method for seed-guided topical taxonomy construction, which takes a corpus and
a seed taxonomy described by concept names as input, and constructs a more
complete taxonomy based on user's interest, wherein each node is represented by
a cluster of coherent terms. Our framework, CoRel, has two modules to fulfill
this goal. A relation transferring module learns and transfers the user's
interested relation along multiple paths to expand the seed taxonomy structure
in width and depth. A concept learning module enriches the semantics of each
concept node by jointly embedding the taxonomy and text. Comprehensive
experiments conducted on real-world datasets show that Corel generates
high-quality topical taxonomies and outperforms all the baselines
significantly.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 22:00:31 GMT'}]",2020-10-15,"[['Huang', 'Jiaxin', ''], ['Xie', 'Yiqing', ''], ['Meng', 'Yu', ''], ['Zhang', 'Yunyi', ''], ['Han', 'Jiawei', '']]"
1363609,2010.07279,Khyathi Raghavi Chandu,Khyathi Raghavi Chandu and Alan W Black,Dissecting the components and factors of Neural Text Generation,15 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Neural text generation metamorphosed into several critical natural language
applications ranging from text completion to free form narrative generation.
Generating natural language has fundamentally been a human attribute and the
advent of ubiquitous NLP applications and virtual agents marks the need to
impart this skill to machines. There has been a colossal research effort in
various frontiers of neural text generation including machine translation,
summarization, image captioning, storytelling etc., We believe that this is an
excellent juncture to retrospect on the directions of the field. Specifically,
this paper surveys the fundamental factors and components relaying task
agnostic impacts across various generation tasks such as storytelling,
summarization, translation etc., In specific, we present an abstraction of the
imperative techniques with respect to learning paradigms, pretraining, modeling
approaches, decoding and the key challenges. Thereby, we hope to deliver a
one-stop destination for researchers in the field to facilitate a perspective
on where to situate their work and how it impacts other closely related tasks.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 17:54:42 GMT'}]",2020-10-15,"[['Chandu', 'Khyathi Raghavi', ''], ['Black', 'Alan W', '']]"
1363040,2010.06710,Diego Amancio,Jorge A. V. Tohalino and Diego R. Amancio,Language Networks: a Practical Approach,,,,,cs.CL cs.SI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This manuscript provides a short and practical introduction to the topic of
language networks. This text aims at assisting researchers with no practical
experience in text and/or network analysis. We provide a practical tutorial on
how to model and characterize texts using network-based features. In this
tutorial, we also include examples of pre-processing and network
representations. A brief description of the main tasks allying network science
and text analysis is also provided. A further development of this text shall
include a practical description of network classification via machine learning
methods.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 21:51:14 GMT'}]",2020-10-15,"[['Tohalino', 'Jorge A. V.', ''], ['Amancio', 'Diego R.', '']]"
1363575,2010.07245,Yu Meng,"Yu Meng, Yunyi Zhang, Jiaxin Huang, Chenyan Xiong, Heng Ji, Chao
  Zhang, Jiawei Han","Text Classification Using Label Names Only: A Language Model
  Self-Training Approach",EMNLP 2020. (Code: https://github.com/yumeng5/LOTClass),,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Current text classification methods typically require a good number of
human-labeled documents as training data, which can be costly and difficult to
obtain in real applications. Humans can perform classification without seeing
any labeled examples but only based on a small set of words describing the
categories to be classified. In this paper, we explore the potential of only
using the label name of each class to train classification models on unlabeled
data, without using any labeled documents. We use pre-trained neural language
models both as general linguistic knowledge sources for category understanding
and as representation learning models for document classification. Our method
(1) associates semantically related words with the label names, (2) finds
category-indicative words and trains the model to predict their implied
categories, and (3) generalizes the model via self-training. We show that our
model achieves around 90% accuracy on four benchmark datasets including topic
and sentiment classification without using any labeled documents but learning
from unlabeled data supervised by at most 3 words (1 in most cases) per class
as the label name.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 17:06:41 GMT'}]",2020-10-15,"[['Meng', 'Yu', ''], ['Zhang', 'Yunyi', ''], ['Huang', 'Jiaxin', ''], ['Xiong', 'Chenyan', ''], ['Ji', 'Heng', ''], ['Zhang', 'Chao', ''], ['Han', 'Jiawei', '']]"
1363542,2010.07212,Debajyoti Datta,"Debajyoti Datta, Shashwat Kumar, Laura Barnes, Tom Fletcher",Geometry matters: Exploring language examples at the decision boundary,Preprint: Under Review,,,,cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A growing body of recent evidence has highlighted the limitations of natural
language processing (NLP) datasets and classifiers. These include the presence
of annotation artifacts in datasets, classifiers relying on shallow features
like a single word (e.g., if a movie review has the word ""romantic"", the review
tends to be positive), or unnecessary words (e.g., learning a proper noun to
classify a movie as positive or negative). The presence of such artifacts has
subsequently led to the development of challenging datasets to force the model
to generalize better. While a variety of heuristic strategies, such as
counterfactual examples and contrast sets, have been proposed, the theoretical
justification about what makes these examples difficult is often lacking or
unclear. In this paper, using tools from information geometry, we propose a
theoretical way to quantify the difficulty of an example in NLP. Using our
approach, we explore difficult examples for two popular NLP architectures. We
discover that both BERT and CNN are susceptible to single word substitutions in
high difficulty examples. Consequently, examples with low difficulty scores
tend to be robust to multiple word substitutions. Our analysis shows that
perturbations like contrast sets and counterfactual examples are not
necessarily difficult for the model, and they may not be accomplishing the
intended goal. Our approach is simple, architecture agnostic, and easily
extendable to other datasets. All the code used will be made publicly
available, including a tool to explore the difficult examples for other
datasets.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 16:26:13 GMT'}]",2020-10-15,"[['Datta', 'Debajyoti', ''], ['Kumar', 'Shashwat', ''], ['Barnes', 'Laura', ''], ['Fletcher', 'Tom', '']]"
1363001,2010.06671,Pedram Hosseini,"Lily Li, Or Levi, Pedram Hosseini, David A. Broniatowski",A Multi-Modal Method for Satire Detection using Textual and Visual Cues,"Accepted to the Third Workshop on NLP for Internet Freedom (NLP4IF):
  Censorship, Disinformation, and Propaganda. Co-located with COLING 2020",,,,cs.CL cs.AI cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Satire is a form of humorous critique, but it is sometimes misinterpreted by
readers as legitimate news, which can lead to harmful consequences. We observe
that the images used in satirical news articles often contain absurd or
ridiculous content and that image manipulation is used to create fictional
scenarios. While previous work have studied text-based methods, in this work we
propose a multi-modal approach based on state-of-the-art visiolinguistic model
ViLBERT. To this end, we create a new dataset consisting of images and
headlines of regular and satirical news for the task of satire detection. We
fine-tune ViLBERT on the dataset and train a convolutional neural network that
uses an image forensics technique. Evaluation on the dataset shows that our
proposed multi-modal approach outperforms image-only, text-only, and simple
fusion baselines.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 20:08:29 GMT'}]",2020-10-15,"[['Li', 'Lily', ''], ['Levi', 'Or', ''], ['Hosseini', 'Pedram', ''], ['Broniatowski', 'David A.', '']]"
1362996,2010.06666,Devin Johnson,"Devin Johnson, Denise Mak, Drew Barker, Lexi Loessberg-Zahl","Probing for Multilingual Numerical Understanding in Transformer-Based
  Language Models",BlackboxNLP (EMNLP 2020),,,,cs.CL,http://creativecommons.org/publicdomain/zero/1.0/,"  Natural language numbers are an example of compositional structures, where
larger numbers are composed of operations on smaller numbers. Given that
compositional reasoning is a key to natural language understanding, we propose
novel multilingual probing tasks tested on DistilBERT, XLM, and BERT to
investigate for evidence of compositional reasoning over numerical data in
various natural language number systems. By using both grammaticality judgment
and value comparison classification tasks in English, Japanese, Danish, and
French, we find evidence that the information encoded in these pretrained
models' embeddings is sufficient for grammaticality judgments but generally not
for value comparisons. We analyze possible reasons for this and discuss how our
tasks could be extended in further studies.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 19:56:02 GMT'}]",2020-10-15,"[['Johnson', 'Devin', ''], ['Mak', 'Denise', ''], ['Barker', 'Drew', ''], ['Loessberg-Zahl', 'Lexi', '']]"
1363504,2010.07174,Benjamin Newman,"Benjamin Newman, John Hewitt, Percy Liang, Christopher D. Manning",The EOS Decision and Length Extrapolation,"16 page, 7 Figures, 9 Tables, Blackbox NLP Workshop at EMNLP 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Extrapolation to unseen sequence lengths is a challenge for neural generative
models of language. In this work, we characterize the effect on length
extrapolation of a modeling decision often overlooked: predicting the end of
the generative process through the use of a special end-of-sequence (EOS)
vocabulary item. We study an oracle setting - forcing models to generate to the
correct sequence length at test time - to compare the length-extrapolative
behavior of networks trained to predict EOS (+EOS) with networks not trained to
(-EOS). We find that -EOS substantially outperforms +EOS, for example
extrapolating well to lengths 10 times longer than those seen at training time
in a bracket closing task, as well as achieving a 40% improvement over +EOS in
the difficult SCAN dataset length generalization task. By comparing the hidden
states and dynamics of -EOS and +EOS models, we observe that +EOS models fail
to generalize because they (1) unnecessarily stratify their hidden states by
their linear position is a sequence (structures we call length manifolds) or
(2) get stuck in clusters (which we refer to as length attractors) once the EOS
token is the highest-probability prediction.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 15:46:17 GMT'}]",2020-10-15,"[['Newman', 'Benjamin', ''], ['Hewitt', 'John', ''], ['Liang', 'Percy', ''], ['Manning', 'Christopher D.', '']]"
1362987,2010.06657,Hancheng Cao,"Hancheng Cao, Mengjie Cheng, Zhepeng Cen, Daniel A. McFarland, Xiang
  Ren","Will This Idea Spread Beyond Academia? Understanding Knowledge Transfer
  of Scientific Concepts across Text Corpora",EMNLP 2020 Findings,,,,cs.CY cs.CL cs.DL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  What kind of basic research ideas are more likely to get applied in practice?
There is a long line of research investigating patterns of knowledge transfer,
but it generally focuses on documents as the unit of analysis and follow their
transfer into practice for a specific scientific domain. Here we study
translational research at the level of scientific concepts for all scientific
fields. We do this through text mining and predictive modeling using three
corpora: 38.6 million paper abstracts, 4 million patent documents, and 0.28
million clinical trials. We extract scientific concepts (i.e., phrases) from
corpora as instantiations of ""research ideas"", create concept-level features as
motivated by literature, and then follow the trajectories of over 450,000 new
concepts (emerged from 1995-2014) to identify factors that lead only a small
proportion of these ideas to be used in inventions and drug trials. Results
from our analysis suggest several mechanisms that distinguish which scientific
concept will be adopted in practice, and which will not. We also demonstrate
that our derived features can be used to explain and predict knowledge transfer
with high accuracy. Our work provides greater understanding of knowledge
transfer for researchers, practitioners, and government agencies interested in
encouraging translational research.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 19:46:59 GMT'}]",2020-10-15,"[['Cao', 'Hancheng', ''], ['Cheng', 'Mengjie', ''], ['Cen', 'Zhepeng', ''], ['McFarland', 'Daniel A.', ''], ['Ren', 'Xiang', '']]"
1363460,2010.07130,Pradeep R,"Pradeep Rangan, Sundeep Teki, and Hemant Misra","Exploiting Spectral Augmentation for Code-Switched Spoken Language
  Identification","5 pages, 3 figures, Accepted for INTERSPEECH-2020 - ""First Workshop
  on Speech Technologies for Code-switching in Multilingual Communities 2020""",,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Spoken language Identification (LID) systems are needed to identify the
language(s) present in a given audio sample, and typically could be the first
step in many speech processing related tasks such as automatic speech
recognition (ASR). Automatic identification of the languages present in a
speech signal is not only scientifically interesting, but also of practical
importance in a multilingual country such as India. In many of the Indian
cities, when people interact with each other, as many as three languages may
get mixed. These may include the official language of that province, Hindi and
English (at times the languages of the neighboring provinces may also get mixed
during these interactions). This makes the spoken LID task extremely
challenging in Indian context. While quite a few LID systems in the context of
Indian languages have been implemented, most such systems have used small scale
speech data collected internally within an organization. In the current work,
we perform spoken LID on three Indian languages (Gujarati, Telugu, and Tamil)
code-mixed with English. This task was organized by the Microsoft research team
as a spoken LID challenge. In our work, we modify the usual spectral
augmentation approach and propose a language mask that discriminates the
language ID pairs, which leads to a noise robust spoken LID system. The
proposed method gives a relative improvement of approximately 3-5% in the LID
accuracy over a baseline system proposed by Microsoft on the three language
pairs for two shared tasks suggested in the challenge.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 14:37:03 GMT'}]",2020-10-15,"[['Rangan', 'Pradeep', ''], ['Teki', 'Sundeep', ''], ['Misra', 'Hemant', '']]"
1363439,2010.07109,Zihan Zhao,"Zihan Zhao, Yuncong Liu, Lu Chen, Qi Liu, Rao Ma and Kai Yu","An Investigation on Different Underlying Quantization Schemes for
  Pre-trained Language Models",Accepted to NLPCC 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, pre-trained language models like BERT have shown promising
performance on multiple natural language processing tasks. However, the
application of these models has been limited due to their huge size. To reduce
its size, a popular and efficient way is quantization. Nevertheless, most of
the works focusing on BERT quantization adapted primary linear clustering as
the quantization scheme, and few works try to upgrade it. That limits the
performance of quantization significantly. In this paper, we implement k-means
quantization and compare its performance on the fix-precision quantization of
BERT with linear quantization. Through the comparison, we verify that the
effect of the underlying quantization scheme upgrading is underestimated and
there is a huge development potential of k-means quantization. Besides, we also
compare the two quantization schemes on ALBERT models to explore the robustness
differences between different pre-trained models.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 14:05:06 GMT'}]",2020-10-15,"[['Zhao', 'Zihan', ''], ['Liu', 'Yuncong', ''], ['Chen', 'Lu', ''], ['Liu', 'Qi', ''], ['Ma', 'Rao', ''], ['Yu', 'Kai', '']]"
1362925,2010.06595,Dallas Card,"Dallas Card and Peter Henderson and Urvashi Khandelwal and Robin Jia
  and Kyle Mahowald and Dan Jurafsky",With Little Power Comes Great Responsibility,To appear at EMNLP 2020,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite its importance to experimental design, statistical power (the
probability that, given a real effect, an experiment will reject the null
hypothesis) has largely been ignored by the NLP community. Underpowered
experiments make it more difficult to discern the difference between
statistical noise and meaningful model improvements, and increase the chances
of exaggerated findings. By meta-analyzing a set of existing NLP papers and
datasets, we characterize typical power for a variety of settings and conclude
that underpowered experiments are common in the NLP literature. In particular,
for several tasks in the popular GLUE benchmark, small test sets mean that most
attempted comparisons to state of the art models will not be adequately
powered. Similarly, based on reasonable assumptions, we find that the most
typical experimental design for human rating studies will be underpowered to
detect small model differences, of the sort that are frequently studied. For
machine translation, we find that typical test sets of 2000 sentences have
approximately 75% power to detect differences of 1 BLEU point. To improve the
situation going forward, we give an overview of best practices for power
analysis in NLP and release a series of notebooks to assist with future power
analyses.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 18:00:02 GMT'}]",2020-10-15,"[['Card', 'Dallas', ''], ['Henderson', 'Peter', ''], ['Khandelwal', 'Urvashi', ''], ['Jia', 'Robin', ''], ['Mahowald', 'Kyle', ''], ['Jurafsky', 'Dan', '']]"
1363431,2010.07101,Xu Zhao,"Xu Zhao, Zihao Wang, Hao Wu, Yong Zhang",Semi-Supervised Bilingual Lexicon Induction with Two-way Interaction,"12 pages, 2 figures, 6 tables, accepted as long paper by EMNLP2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Semi-supervision is a promising paradigm for Bilingual Lexicon Induction
(BLI) with limited annotations. However, previous semisupervised methods do not
fully utilize the knowledge hidden in annotated and nonannotated data, which
hinders further improvement of their performance. In this paper, we propose a
new semi-supervised BLI framework to encourage the interaction between the
supervised signal and unsupervised alignment. We design two message-passing
mechanisms to transfer knowledge between annotated and non-annotated data,
named prior optimal transport and bi-directional lexicon update respectively.
Then, we perform semi-supervised learning based on a cyclic or a parallel
parameter feeding routine to update our models. Our framework is a general
framework that can incorporate any supervised and unsupervised BLI methods
based on optimal transport. Experimental results on MUSE and VecMap datasets
show significant improvement of our models. Ablation study also proves that the
two-way interaction between the supervised signal and unsupervised alignment
accounts for the gain of the overall performance. Results on distant language
pairs further illustrate the advantage and robustness of our proposed method.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 13:59:07 GMT'}]",2020-10-15,"[['Zhao', 'Xu', ''], ['Wang', 'Zihao', ''], ['Wu', 'Hao', ''], ['Zhang', 'Yong', '']]"
1363430,2010.07100,Manik Bhandari,"Manik Bhandari, Pranav Gour, Atabak Ashfaq, Pengfei Liu and Graham
  Neubig",Re-evaluating Evaluation in Text Summarization,Accepted at EMNLP 2020,,,,cs.CL cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automated evaluation metrics as a stand-in for manual evaluation are an
essential part of the development of text-generation tasks such as text
summarization. However, while the field has progressed, our standard metrics
have not -- for nearly 20 years ROUGE has been the standard evaluation in most
summarization papers. In this paper, we make an attempt to re-evaluate the
evaluation method for text summarization: assessing the reliability of
automatic metrics using top-scoring system outputs, both abstractive and
extractive, on recently popular datasets for both system-level and
summary-level evaluation settings. We find that conclusions about evaluation
metrics on older datasets do not necessarily hold on modern datasets and
systems.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 13:58:53 GMT'}]",2020-10-15,"[['Bhandari', 'Manik', ''], ['Gour', 'Pranav', ''], ['Ashfaq', 'Atabak', ''], ['Liu', 'Pengfei', ''], ['Neubig', 'Graham', '']]"
1363425,2010.07095,Xu Zhao,"Xu Zhao, Zihao Wang, Hao Wu, Yong Zhang",A Relaxed Matching Procedure for Unsupervised BLI,"6 pages,1 figures, accepted as short paper by ACL2020",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently unsupervised Bilingual Lexicon Induction (BLI) without any parallel
corpus has attracted much research interest. One of the crucial parts in
methods for the BLI task is the matching procedure. Previous works impose a too
strong constraint on the matching and lead to many counterintuitive translation
pairings. Thus, We propose a relaxed matching procedure to find a more precise
matching between two languages. We also find that aligning source and target
language embedding space bidirectionally will bring significant improvement. We
follow the previous iterative framework to conduct experiments. Results on
standard benchmark demonstrate the effectiveness of our proposed method, which
substantially outperforms previous unsupervised methods.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 13:53:08 GMT'}]",2020-10-15,"[['Zhao', 'Xu', ''], ['Wang', 'Zihao', ''], ['Wu', 'Hao', ''], ['Zhang', 'Yong', '']]"
1363405,2010.07075,Yujing Wang,"Yiren Chen, Yaming Yang, Hong Sun, Yujing Wang, Yu Xu, Wei Shen, Rong
  Zhou, Yunhai Tong, Jing Bai, Ruofei Zhang",AutoADR: Automatic Model Design for Ad Relevance,CIKM 2020,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large-scale pre-trained models have attracted extensive attention in the
research community and shown promising results on various tasks of natural
language processing. However, these pre-trained models are memory and
computation intensive, hindering their deployment into industrial online
systems like Ad Relevance. Meanwhile, how to design an effective yet efficient
model architecture is another challenging problem in online Ad Relevance.
Recently, AutoML shed new lights on architecture design, but how to integrate
it with pre-trained language models remains unsettled. In this paper, we
propose AutoADR (Automatic model design for AD Relevance) -- a novel end-to-end
framework to address this challenge, and share our experience to ship these
cutting-edge techniques into online Ad Relevance system at Microsoft Bing.
Specifically, AutoADR leverages a one-shot neural architecture search algorithm
to find a tailored network architecture for Ad Relevance. The search process is
simultaneously guided by knowledge distillation from a large pre-trained
teacher model (e.g. BERT), while taking the online serving constraints (e.g.
memory and latency) into consideration. We add the model designed by AutoADR as
a sub-model into the production Ad Relevance model. This additional sub-model
improves the Precision-Recall AUC (PR AUC) on top of the original Ad Relevance
model by 2.65X of the normalized shipping bar. More importantly, adding this
automatically designed sub-model leads to a statistically significant 4.6%
Bad-Ad ratio reduction in online A/B testing. This model has been shipped into
Microsoft Bing Ad Relevance Production model.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 13:24:43 GMT'}]",2020-10-15,"[['Chen', 'Yiren', ''], ['Yang', 'Yaming', ''], ['Sun', 'Hong', ''], ['Wang', 'Yujing', ''], ['Xu', 'Yu', ''], ['Shen', 'Wei', ''], ['Zhou', 'Rong', ''], ['Tong', 'Yunhai', ''], ['Bai', 'Jing', ''], ['Zhang', 'Ruofei', '']]"
1363404,2010.07074,Jiwei Li,"Xiaofei Sun, Chun Fan, Zijun Sun, Yuxian Meng, Fei Wu and Jiwei Li","Summarize, Outline, and Elaborate: Long-Text Generation via Hierarchical
  Supervision from Extractive Summaries",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Long-text generation remains a challenge. The difficulty of generating
coherent long texts lies in the fact that existing models overwhelmingly focus
on the tasks of local word prediction, and cannot make high level plans on what
to generate or capture the high-level discourse dependencies between chunks of
texts. Inspired by how humans write, where a list of bullet points or a catalog
is first outlined, and then each bullet point is expanded to form the whole
article, we propose {\it SOE}, a pipelined system that involves of summarizing,
outlining and elaborating for long text generation: the model first outlines
the summaries for different segments of long texts, and then elaborates on each
bullet point to generate the corresponding segment. To avoid the
labor-intensive process of summary soliciting, we propose the {\it
reconstruction} strategy, which extracts segment summaries in an unsupervised
manner by selecting its most informative part to reconstruct the segment.The
proposed generation system comes with the following merits: (1) the summary
provides high-level guidances for text generation and avoids the local minimum
of individual word predictions; (2) the high-level discourse dependencies are
captured in the conditional dependencies between summaries and are preserved
during the summary expansion process and (3) additionally, we are able to
consider significantly more contexts by representing contexts as concise
summaries. Extensive experiments demonstrate that SOE produces long texts with
significantly better quality, along with faster convergence speed.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 13:22:20 GMT'}]",2020-10-15,"[['Sun', 'Xiaofei', ''], ['Fan', 'Chun', ''], ['Sun', 'Zijun', ''], ['Meng', 'Yuxian', ''], ['Wu', 'Fei', ''], ['Li', 'Jiwei', '']]"
1363378,2010.07048,Jipeng Qiang,"Jipeng Qiang and Xinyu Lu and Yun Li and Yunhao Yuan and Yang Shi and
  Xindong Wu",Chinese Lexical Simplification,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Lexical simplification has attracted much attention in many languages, which
is the process of replacing complex words in a given sentence with simpler
alternatives of equivalent meaning. Although the richness of vocabulary in
Chinese makes the text very difficult to read for children and non-native
speakers, there is no research work for Chinese lexical simplification (CLS)
task. To circumvent difficulties in acquiring annotations, we manually create
the first benchmark dataset for CLS, which can be used for evaluating the
lexical simplification systems automatically. In order to acquire more thorough
comparison, we present five different types of methods as baselines to generate
substitute candidates for the complex word that include synonym-based approach,
word embedding-based approach, pretrained language model-based approach,
sememe-based approach, and a hybrid approach. Finally, we design the
experimental evaluation of these baselines and discuss their advantages and
disadvantages. To our best knowledge, this is the first study for CLS task.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 12:55:36 GMT'}]",2020-10-15,"[['Qiang', 'Jipeng', ''], ['Lu', 'Xinyu', ''], ['Li', 'Yun', ''], ['Yuan', 'Yunhao', ''], ['Shi', 'Yang', ''], ['Wu', 'Xindong', '']]"
1363347,2010.07017,Christopher Wild,"Wesley Burr, Fanny Chevalier, Christopher Collins, Alison L Gibbs,
  Raymond Ng, Chris Wild",Computational Skills by Stealth in Secondary School Data Science,"38 pages, 8 figures",,,,cs.CY cs.CL stat.OT,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The unprecedented growth in the availability of data of all types and
qualities and the emergence of the field of data science has provided an
impetus to finally realizing the implementation of the full breadth of the
Nolan and Temple Lang proposed integration of computing concepts into
statistics curricula at all levels in statistics and new data science programs
and courses. Moreover, data science, implemented carefully, opens accessible
pathways to stem for students for whom neither mathematics nor computer science
are natural affinities, and who would traditionally be excluded. We discuss a
proposal for the stealth development of computational skills in students' first
exposure to data science through careful, scaffolded exposure to computation
and its power. The intent of this approach is to support students, regardless
of interest and self-efficacy in coding, in becoming data-driven learners, who
are capable of asking complex questions about the world around them, and then
answering those questions through the use of data-driven inquiry. This
discussion is presented in the context of the International Data Science in
Schools Project which recently published computer science and statistics
consensus curriculum frameworks for a two-year secondary school data science
program, designed to make data science accessible to all.
","[{'version': 'v1', 'created': 'Thu, 8 Oct 2020 09:11:51 GMT'}]",2020-10-15,"[['Burr', 'Wesley', ''], ['Chevalier', 'Fanny', ''], ['Collins', 'Christopher', ''], ['Gibbs', 'Alison L', ''], ['Ng', 'Raymond', ''], ['Wild', 'Chris', '']]"
1363333,2010.07003,Gyuwan Kim,Gyuwan Kim and Kyunghyun Cho,"Length-Adaptive Transformer: Train Once with Length Drop, Use Anytime
  with Search","11 pages, 4 figures",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Although transformers have achieved impressive accuracies in various tasks in
natural language processing, they often come with a prohibitive computational
cost, that prevents their use in scenarios with limited computational resources
for inference. This need for computational efficiency in inference has been
addressed by for instance PoWER-BERT (Goyal et al., 2020) which gradually
decreases the length of a sequence as it is passed through layers. These
approaches however often assume that the target computational complexity is
known in advance at the time of training. This implies that a separate model
must be trained for each inference scenario with its distinct computational
budget. In this paper, we extend PoWER-BERT to address this issue of
inefficiency and redundancy. The proposed extension enables us to train a
large-scale transformer, called Length-Adaptive Transformer, once and uses it
for various inference scenarios without re-training it. To do so, we train a
transformer with LengthDrop, a structural variant of dropout, which
stochastically determines the length of a sequence at each layer. We then use a
multi-objective evolutionary search to find a length configuration that
maximizes the accuracy and minimizes the computational complexity under any
given computational budget. Additionally, we significantly extend the
applicability of PoWER-BERT beyond sequence-level classification into
token-level classification such as span-based question-answering, by
introducing the idea of Drop-and-Restore. With Drop-and-Restore, word-vectors
are dropped temporarily in intermediate layers and restored at the last layer
if necessary. We empirically verify the utility of the proposed approach by
demonstrating the superior accuracy-efficiency trade-off under various setups,
including SQuAD 1.1, MNLI-m, and SST-2. Code is available at
https://github.com/clovaai/length-adaptive-transformer.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 12:28:08 GMT'}]",2020-10-15,"[['Kim', 'Gyuwan', ''], ['Cho', 'Kyunghyun', '']]"
1363323,2010.06993,Pavel Kalaidin,Artem Chumachenko and Daniil Gavrilov and Pavel Kalaidin,Weight Squeezing: Reparameterization for Compression and Fast Inference,,,,,cs.LG cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this work, we present a novel approach for simultaneous knowledge transfer
and model compression called Weight Squeezing. With this method, we perform
knowledge transfer from a pre-trained teacher model by learning the mapping
from its weights to smaller student model weights, without significant loss of
model accuracy.
  We applied Weight Squeezing combined with Knowledge Distillation to a
pre-trained text classification model, and compared it to various knowledge
transfer and model compression methods on several downstream text
classification tasks. We observed that our approach produces better results
than Knowledge Distillation methods without any loss in inference speed. We
also compared Weight Squeezing with Low Rank Factorization methods and observed
that our method is significantly faster at inference while being competitive in
terms of accuracy.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 12:13:28 GMT'}]",2020-10-15,"[['Chumachenko', 'Artem', ''], ['Gavrilov', 'Daniil', ''], ['Kalaidin', 'Pavel', '']]"
1363305,2010.06975,Shaoxiong Ji,Shaoxiong Ji and Shirui Pan and Pekka Marttinen,Medical Code Assignment with Gated Convolution and Note-Code Interaction,,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Medical code assignment from clinical text is a fundamental task in clinical
information system management. As medical notes are typically lengthy and the
medical coding system's code space is large, this task is a long-standing
challenge. Recent work applies deep neural network models to encode the medical
notes and assign medical codes to clinical documents. However, these methods
are still ineffective as they do not fully encode and capture the lengthy and
rich semantic information of medical notes nor explicitly exploit the
interactions between the notes and codes. We propose a novel method, gated
convolutional neural networks, and a note-code interaction (GatedCNN-NCI), for
automatic medical code assignment to overcome these challenges. Our methods
capture the rich semantic information of the lengthy clinical text for better
representation by utilizing embedding injection and gated information
propagation in the medical note encoding module. With a novel note-code
interaction design and a graph message passing mechanism, we explicitly capture
the underlying dependency between notes and codes, enabling effective code
prediction. A weight sharing scheme is further designed to decrease the number
of trainable parameters. Empirical experiments on real-world clinical datasets
show that our proposed model outperforms state-of-the-art models in most cases,
and our model size is on par with light-weighted baselines.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 11:37:24 GMT'}]",2020-10-15,"[['Ji', 'Shaoxiong', ''], ['Pan', 'Shirui', ''], ['Marttinen', 'Pekka', '']]"
1363303,2010.06973,James Thorne,"James Thorne, Majid Yazdani, Marzieh Saeidi, Fabrizio Silvestri,
  Sebastian Riedel, Alon Halevy",Neural Databases,Submitted to PVLDB vol 14,,,,cs.CL cs.DB cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In recent years, neural networks have shown impressive performance gains on
long-standing AI problems, and in particular, answering queries from natural
language text. These advances raise the question of whether they can be
extended to a point where we can relax the fundamental assumption of database
management, namely, that our data is represented as fields of a pre-defined
schema.
  This paper presents a first step in answering that question. We describe
NeuralDB, a database system with no pre-defined schema, in which updates and
queries are given in natural language. We develop query processing techniques
that build on the primitives offered by the state of the art Natural Language
Processing methods.
  We begin by demonstrating that at the core, recent NLP transformers, powered
by pre-trained language models, can answer select-project-join queries if they
are given the exact set of relevant facts. However, they cannot scale to
non-trivial databases and cannot perform aggregation queries. Based on these
findings, we describe a NeuralDB architecture that runs multiple Neural SPJ
operators in parallel, each with a set of database sentences that can produce
one of the answers to the query. The result of these operators is fed to an
aggregation operator if needed. We describe an algorithm that learns how to
create the appropriate sets of facts to be fed into each of the Neural SPJ
operators. Importantly, this algorithm can be trained by the Neural SPJ
operator itself. We experimentally validate the accuracy of NeuralDB and its
components, showing that we can answer queries over thousands of sentences with
very high accuracy.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 11:31:53 GMT'}]",2020-10-15,"[['Thorne', 'James', ''], ['Yazdani', 'Majid', ''], ['Saeidi', 'Marzieh', ''], ['Silvestri', 'Fabrizio', ''], ['Riedel', 'Sebastian', ''], ['Halevy', 'Alon', '']]"
1363273,2010.06943,Jiwei Li,"Yuxian Meng, Chun Fan, Zijun Sun, Eduard Hovy, Fei Wu and Jiwei Li","Pair the Dots: Jointly Examining Training History and Test Stimuli for
  Model Interpretability",,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Any prediction from a model is made by a combination of learning history and
test stimuli. This provides significant insights for improving model
interpretability: {\it because of which part(s) of which training example(s),
the model attends to which part(s) of a test example}. Unfortunately, existing
methods to interpret a model's predictions are only able to capture a single
aspect of either test stimuli or learning history, and evidences from both are
never combined or integrated. In this paper, we propose an efficient and
differentiable approach to make it feasible to interpret a model's prediction
by jointly examining training history and test stimuli. Test stimuli is first
identified by gradient-based methods, signifying {\it the part of a test
example that the model attends to}. The gradient-based saliency scores are then
propagated to training examples using influence functions to identify {\it
which part(s) of which training example(s)} make the model attends to the test
stimuli. The system is differentiable and time efficient: the adoption of
saliency scores from gradient-based methods allows us to efficiently trace a
model's prediction through test stimuli, and then back to training examples
through influence functions. We demonstrate that the proposed methodology
offers clear explanations about neural model decisions, along with being useful
for performing error analysis, crafting adversarial examples and fixing
erroneously classified examples.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 10:45:01 GMT'}]",2020-10-15,"[['Meng', 'Yuxian', ''], ['Fan', 'Chun', ''], ['Sun', 'Zijun', ''], ['Hovy', 'Eduard', ''], ['Wu', 'Fei', ''], ['Li', 'Jiwei', '']]"
1363255,2010.06925,Chuhan Wu,"Chuhan Wu, Fangzhao Wu, Yongfeng Huang",DA-Transformer: Distance-aware Transformer,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Transformer has achieved great success in the NLP field by composing various
advanced models like BERT and GPT. However, Transformer and its existing
variants may not be optimal in capturing token distances because the position
or distance embeddings used by these methods usually cannot keep the precise
information of real distances, which may not be beneficial for modeling the
orders and relations of contexts. In this paper, we propose DA-Transformer,
which is a distance-aware Transformer that can exploit the real distance. We
propose to incorporate the real distances between tokens to re-scale the raw
self-attention weights, which are computed by the relevance between attention
query and key. Concretely, in different self-attention heads the relative
distance between each pair of tokens is weighted by different learnable
parameters, which control the different preferences on long- or short-term
information of these heads. Since the raw weighted real distances may not be
optimal for adjusting self-attention weights, we propose a learnable sigmoid
function to map them into re-scaled coefficients that have proper ranges. We
first clip the raw self-attention weights via the ReLU function to keep
non-negativity and introduce sparsity, and then multiply them with the
re-scaled coefficients to encode real distance information into self-attention.
Extensive experiments on five benchmark datasets show that DA-Transformer can
effectively improve the performance of many tasks and outperform the vanilla
Transformer and its several variants.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 10:09:01 GMT'}]",2020-10-15,"[['Wu', 'Chuhan', ''], ['Wu', 'Fangzhao', ''], ['Huang', 'Yongfeng', '']]"
1362879,2010.06549,Ghazi Felhi,"Ghazi Felhi, Joseph Leroux, Djam\'e Seddah","Controlling the Interaction Between Generation and Inference in
  Semi-Supervised Variational Autoencoders Using Importance Weighting",,,,,cs.LG cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Even though Variational Autoencoders (VAEs) are widely used for
semi-supervised learning, the reason why they work remains unclear. In fact,
the addition of the unsupervised objective is most often vaguely described as a
regularization. The strength of this regularization is controlled by
down-weighting the objective on the unlabeled part of the training set. Through
an analysis of the objective of semi-supervised VAEs, we observe that they use
the posterior of the learned generative model to guide the inference model in
learning the partially observed latent variable. We show that given this
observation, it is possible to gain finer control on the effect of the
unsupervised objective on the training procedure. Using importance weighting,
we derive two novel objectives that prioritize either one of the partially
observed latent variable, or the unobserved latent variable. Experiments on the
IMDB english sentiment analysis dataset and on the AG News topic classification
dataset show the improvements brought by our prioritization mechanism and
exhibit a behavior that is inline with our description of the inner working of
Semi-Supervised VAEs.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 17:01:40 GMT'}, {'version': 'v2', 'created': 'Wed, 14 Oct 2020 13:04:47 GMT'}]",2020-10-15,"[['Felhi', 'Ghazi', ''], ['Leroux', 'Joseph', ''], ['Seddah', 'Djamé', '']]"
1363035,2010.06705,Jiaxin Huang,"Jiaxin Huang, Yu Meng, Fang Guo, Heng Ji, Jiawei Han","Weakly-Supervised Aspect-Based Sentiment Analysis via Joint
  Aspect-Sentiment Topic Embedding",accepted to EMNLP 2020,,,,cs.CL cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Aspect-based sentiment analysis of review texts is of great value for
understanding user feedback in a fine-grained manner. It has in general two
sub-tasks: (i) extracting aspects from each review, and (ii) classifying
aspect-based reviews by sentiment polarity. In this paper, we propose a
weakly-supervised approach for aspect-based sentiment analysis, which uses only
a few keywords describing each aspect/sentiment without using any labeled
examples. Existing methods are either designed only for one of the sub-tasks,
neglecting the benefit of coupling both, or are based on topic models that may
contain overlapping concepts. We propose to first learn <sentiment, aspect>
joint topic embeddings in the word embedding space by imposing regularizations
to encourage topic distinctiveness, and then use neural models to generalize
the word-level discriminative information by pre-training the classifiers with
embedding-based predictions and self-training them on unlabeled data. Our
comprehensive performance analysis shows that our method generates quality
joint topics and outperforms the baselines significantly (7.4% and 5.1%
F1-score gain on average for aspect and sentiment classification respectively)
on benchmark datasets. Our code and data are available at
https://github.com/teapot123/JASen.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 21:33:24 GMT'}]",2020-10-15,"[['Huang', 'Jiaxin', ''], ['Meng', 'Yu', ''], ['Guo', 'Fang', ''], ['Ji', 'Heng', ''], ['Han', 'Jiawei', '']]"
1363057,2010.06727,Muhao Chen,"Haoyu Wang, Muhao Chen, Hongming Zhang, Dan Roth",Joint Constrained Learning for Event-Event Relation Extraction,EMNLP 2020,,,,cs.CL cs.AI cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Understanding natural language involves recognizing how multiple event
mentions structurally and temporally interact with each other. In this process,
one can induce event complexes that organize multi-granular events with
temporal order and membership relations interweaving among them. Due to the
lack of jointly labeled data for these relational phenomena and the restriction
on the structures they articulate, we propose a joint constrained learning
framework for modeling event-event relations. Specifically, the framework
enforces logical constraints within and across multiple temporal and subevent
relations by converting these constraints into differentiable learning
objectives. We show that our joint constrained learning approach effectively
compensates for the lack of jointly labeled data, and outperforms SOTA methods
on benchmarks for both temporal relation extraction and event hierarchy
construction, replacing a commonly used but more expensive global inference
process. We also present a promising case study showing the effectiveness of
our approach in inducing event complexes on an external corpus.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 22:45:28 GMT'}]",2020-10-15,"[['Wang', 'Haoyu', ''], ['Chen', 'Muhao', ''], ['Zhang', 'Hongming', ''], ['Roth', 'Dan', '']]"
1106724,1904.01684,Jekaterina Novikova Dr.,"Aparna Balagopalan, Ksenia Shkaruta, Jekaterina Novikova","Impact of ASR on Alzheimer's Disease Detection: All Errors are Equal,
  but Deletions are More Equal than Others",EMNLP Workshop on Noisy User-generated Text (W-NUT 2020),,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automatic Speech Recognition (ASR) is a critical component of any
fully-automated speech-based dementia detection model. However, despite years
of speech recognition research, little is known about the impact of ASR
accuracy on dementia detection. In this paper, we experiment with controlled
amounts of artificially generated ASR errors and investigate their influence on
dementia detection. We find that deletion errors affect detection performance
the most, due to their impact on the features of syntactic complexity and
discourse representation in speech. We show the trend to be generalisable
across two different datasets for cognitive impairment detection. As a
conclusion, we propose optimising the ASR to reflect a higher penalty for
deletion errors in order to improve dementia detection performance.
","[{'version': 'v1', 'created': 'Tue, 2 Apr 2019 21:59:35 GMT'}, {'version': 'v2', 'created': 'Mon, 8 Apr 2019 00:44:41 GMT'}, {'version': 'v3', 'created': 'Tue, 13 Oct 2020 18:08:35 GMT'}]",2020-10-15,"[['Balagopalan', 'Aparna', ''], ['Shkaruta', 'Ksenia', ''], ['Novikova', 'Jekaterina', '']]"
1358659,2010.02329,Boxin Wang,"Boxin Wang, Shuohang Wang, Yu Cheng, Zhe Gan, Ruoxi Jia, Bo Li,
  Jingjing Liu","InfoBERT: Improving Robustness of Language Models from An Information
  Theoretic Perspective","20 pages, 8 tables, 2 figures",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large-scale language models such as BERT have achieved state-of-the-art
performance across a wide range of NLP tasks. Recent studies, however, show
that such BERT-based models are vulnerable facing the threats of textual
adversarial attacks. We aim to address this problem from an
information-theoretic perspective, and propose InfoBERT, a novel learning
framework for robust fine-tuning of pre-trained language models. InfoBERT
contains two mutual-information-based regularizers for model training: (i) an
Information Bottleneck regularizer, which suppresses noisy mutual information
between the input and the feature representation; and (ii) a Robust Feature
regularizer, which increases the mutual information between local robust
features and global features. We provide a principled way to theoretically
analyze and improve the robustness of representation learning for language
models in both standard and adversarial training. Extensive experiments
demonstrate that InfoBERT achieves state-of-the-art robust accuracy over
several adversarial datasets on Natural Language Inference (NLI) and Question
Answering (QA) tasks.
","[{'version': 'v1', 'created': 'Mon, 5 Oct 2020 20:49:26 GMT'}, {'version': 'v2', 'created': 'Wed, 14 Oct 2020 13:24:03 GMT'}]",2020-10-15,"[['Wang', 'Boxin', ''], ['Wang', 'Shuohang', ''], ['Cheng', 'Yu', ''], ['Gan', 'Zhe', ''], ['Jia', 'Ruoxi', ''], ['Li', 'Bo', ''], ['Liu', 'Jingjing', '']]"
1359414,2010.03084,Xiaoyu Yang,"Xiaoyu Yang, Feng Nie, Yufei Feng, Quan Liu, Zhigang Chen, Xiaodan Zhu","Program Enhanced Fact Verification with Verbalization and Graph
  Attention Network",16 pages (EMNLP 2019),,,,cs.AI cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Performing fact verification based on structured data is important for many
real-life applications and is a challenging research problem, particularly when
it involves both symbolic operations and informal inference based on language
understanding. In this paper, we present a Program-enhanced Verbalization and
Graph Attention Network (ProgVGAT) to integrate programs and execution into
textual inference models. Specifically, a verbalization with program execution
model is proposed to accumulate evidences that are embedded in operations over
the tables. Built on that, we construct the graph attention verification
networks, which are designed to fuse different sources of evidences from
verbalized program execution, program structures, and the original statements
and tables, to make the final verification decision. To support the above
framework, we propose a program selection module optimized with a new training
strategy based on margin loss, to produce more accurate programs, which is
shown to be effective in enhancing the final verification results. Experimental
results show that the proposed framework achieves the new state-of-the-art
performance, a 74.4% accuracy, on the benchmark dataset TABFACT.
","[{'version': 'v1', 'created': 'Tue, 6 Oct 2020 23:29:08 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Oct 2020 16:43:38 GMT'}, {'version': 'v3', 'created': 'Wed, 14 Oct 2020 00:49:15 GMT'}]",2020-10-15,"[['Yang', 'Xiaoyu', ''], ['Nie', 'Feng', ''], ['Feng', 'Yufei', ''], ['Liu', 'Quan', ''], ['Chen', 'Zhigang', ''], ['Zhu', 'Xiaodan', '']]"
1358759,2010.02429,Heeyoung Kwon,"Heeyoung Kwon, Mahnaz Koupaee, Pratyush Singh, Gargi Sawhney, Anmol
  Shukla, Keerthi Kumar Kallur, Nathanael Chambers and Niranjan Balasubramanian",Modeling Preconditions in Text with a Crowd-sourced Dataset,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Preconditions provide a form of logical connection between events that
explains why some events occur together and information that is complementary
to the more widely studied relations such as causation, temporal ordering,
entailment, and discourse relations. Modeling preconditions in text has been
hampered in part due to the lack of large scale labeled data grounded in text.
This paper introduces PeKo, a crowd-sourced annotation of preconditions between
event pairs in newswire, an order of magnitude larger than prior text
annotations. To complement this new corpus, we also introduce two challenge
tasks aimed at modeling preconditions: (i) Precondition Identification -- a
standard classification task defined over pairs of event mentions, and (ii)
Precondition Generation -- a generative task aimed at testing a more general
ability to reason about a given event. Evaluation on both tasks shows that
modeling preconditions is challenging even for today's large language models
(LM). This suggests that precondition knowledge is not easily accessible in
LM-derived representations alone. Our generation results show that fine-tuning
an LM on PeKo yields better conditional relations than when trained on raw text
or temporally-ordered corpora.
","[{'version': 'v1', 'created': 'Tue, 6 Oct 2020 01:52:34 GMT'}, {'version': 'v2', 'created': 'Wed, 7 Oct 2020 02:20:14 GMT'}, {'version': 'v3', 'created': 'Wed, 14 Oct 2020 17:56:03 GMT'}]",2020-10-15,"[['Kwon', 'Heeyoung', ''], ['Koupaee', 'Mahnaz', ''], ['Singh', 'Pratyush', ''], ['Sawhney', 'Gargi', ''], ['Shukla', 'Anmol', ''], ['Kallur', 'Keerthi Kumar', ''], ['Chambers', 'Nathanael', ''], ['Balasubramanian', 'Niranjan', '']]"
1280601,2005.00806,Qinyuan Ye,"Qinyuan Ye, Xiao Huang, Elizabeth Boschee, Xiang Ren",Teaching Machine Comprehension with Compositional Explanations,"Accepted to EMNLP 2020 Findings. Camera-ready version. Project page:
  http://inklab.usc.edu/mrc-explanation-project/",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Advances in machine reading comprehension (MRC) rely heavily on the
collection of large scale human-annotated examples in the form of (question,
paragraph, answer) triples. In contrast, humans are typically able to
generalize with only a few examples, relying on deeper underlying world
knowledge, linguistic sophistication, and/or simply superior deductive powers.
In this paper, we focus on ""teaching"" machines reading comprehension, using a
small number of semi-structured explanations that explicitly inform machines
why answer spans are correct. We extract structured variables and rules from
explanations and compose neural module teachers that annotate instances for
training downstream MRC models. We use learnable neural modules and soft logic
to handle linguistic variation and overcome sparse coverage; the modules are
jointly optimized with the MRC model to improve final performance. On the SQuAD
dataset, our proposed method achieves 70.14% F1 score with supervision from 26
explanations, comparable to plain supervised learning using 1,100 labeled
instances, yielding a 12x speed up.
","[{'version': 'v1', 'created': 'Sat, 2 May 2020 11:54:34 GMT'}, {'version': 'v2', 'created': 'Mon, 21 Sep 2020 20:13:10 GMT'}, {'version': 'v3', 'created': 'Tue, 13 Oct 2020 19:28:50 GMT'}]",2020-10-15,"[['Ye', 'Qinyuan', ''], ['Huang', 'Xiao', ''], ['Boschee', 'Elizabeth', ''], ['Ren', 'Xiang', '']]"
1293058,2005.13263,Tanner Bohn,"Tanner Bohn, Charles X. Ling",Catching Attention with Automatic Pull Quote Selection,"Accepted to COLING-2020. 15 pages (~9 for content + refs + appendix),
  6 figures, 5 tables (+ 5 appendix tables)",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  To advance understanding on how to engage readers, we advocate the novel task
of automatic pull quote selection. Pull quotes are a component of articles
specifically designed to catch the attention of readers with spans of text
selected from the article and given more salient presentation. This task
differs from related tasks such as summarization and clickbait identification
by several aspects. We establish a spectrum of baseline approaches to the task,
ranging from handcrafted features to a neural mixture-of-experts to cross-task
models. By examining the contributions of individual features and embedding
dimensions from these models, we uncover unexpected properties of pull quotes
to help answer the important question of what engages readers. Human evaluation
also supports the uniqueness of this task and the suitability of our selection
models. The benefits of exploring this problem further are clear: pull quotes
increase enjoyment and readability, shape reader perceptions, and facilitate
learning. Code to reproduce this work is available at
https://github.com/tannerbohn/AutomaticPullQuoteSelection.
","[{'version': 'v1', 'created': 'Wed, 27 May 2020 09:59:34 GMT'}, {'version': 'v2', 'created': 'Wed, 14 Oct 2020 02:49:35 GMT'}]",2020-10-15,"[['Bohn', 'Tanner', ''], ['Ling', 'Charles X.', '']]"
1360093,2010.03763,Lang Yu,Lang Yu and Allyson Ettinger,Assessing Phrasal Representation and Composition in Transformers,Accepted at EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Deep transformer models have pushed performance on NLP tasks to new limits,
suggesting sophisticated treatment of complex linguistic inputs, such as
phrases. However, we have limited understanding of how these models handle
representation of phrases, and whether this reflects sophisticated composition
of phrase meaning like that done by humans. In this paper, we present
systematic analysis of phrasal representations in state-of-the-art pre-trained
transformers. We use tests leveraging human judgments of phrase similarity and
meaning shift, and compare results before and after control of word overlap, to
tease apart lexical effects versus composition effects. We find that phrase
representation in these models relies heavily on word content, with little
evidence of nuanced composition. We also identify variations in phrase
representation quality across models, layers, and representation types, and
make corresponding recommendations for usage of representations from these
models.
","[{'version': 'v1', 'created': 'Thu, 8 Oct 2020 04:59:39 GMT'}, {'version': 'v2', 'created': 'Wed, 14 Oct 2020 02:25:52 GMT'}]",2020-10-15,"[['Yu', 'Lang', ''], ['Ettinger', 'Allyson', '']]"
1164139,1908.05969,Ruotian Ma,"Ruotian Ma, Minlong Peng, Qi Zhang, Xuanjing Huang",Simplify the Usage of Lexicon in Chinese NER,ACL 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, many works have tried to augment the performance of Chinese named
entity recognition (NER) using word lexicons. As a representative, Lattice-LSTM
(Zhang and Yang, 2018) has achieved new benchmark results on several public
Chinese NER datasets. However, Lattice-LSTM has a complex model architecture.
This limits its application in many industrial areas where real-time NER
responses are needed.
  In this work, we propose a simple but effective method for incorporating the
word lexicon into the character representations. This method avoids designing a
complicated sequence modeling architecture, and for any neural NER model, it
requires only subtle adjustment of the character representation layer to
introduce the lexicon information. Experimental studies on four benchmark
Chinese NER datasets show that our method achieves an inference speed up to
6.15 times faster than those of state-ofthe-art methods, along with a better
performance. The experimental results also show that the proposed method can be
easily incorporated with pre-trained models like BERT.
","[{'version': 'v1', 'created': 'Fri, 16 Aug 2019 13:35:24 GMT'}, {'version': 'v2', 'created': 'Wed, 14 Oct 2020 08:06:12 GMT'}]",2020-10-15,"[['Ma', 'Ruotian', ''], ['Peng', 'Minlong', ''], ['Zhang', 'Qi', ''], ['Huang', 'Xuanjing', '']]"
1333236,2008.05514,Roger Hsiao,"Roger Hsiao, Dogan Can, Tim Ng, Ruchir Travadi and Arnab Ghoshal","Online Automatic Speech Recognition with Listen, Attend and Spell Model","5 pages, 4 figures, this version is submitted to IEEE Signal
  Processing Letters",,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The Listen, Attend and Spell (LAS) model and other attention-based automatic
speech recognition (ASR) models have known limitations when operated in a fully
online mode. In this paper, we analyze the online operation of LAS models to
demonstrate that these limitations stem from the handling of silence regions
and the reliability of online attention mechanism at the edge of input buffers.
We propose a novel and simple technique that can achieve fully online
recognition while meeting accuracy and latency targets. For the Mandarin
dictation task, our proposed approach can achieve a character error rate in
online operation that is within 4% relative to an offline LAS model. The
proposed online LAS model operates at 12% lower latency relative to a
conventional neural network hidden Markov model hybrid of comparable accuracy.
We have validated the proposed method through a production scale deployment,
which, to the best of our knowledge, is the first such deployment of a fully
online LAS model.
","[{'version': 'v1', 'created': 'Wed, 12 Aug 2020 18:18:54 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Oct 2020 18:40:28 GMT'}]",2020-10-15,"[['Hsiao', 'Roger', ''], ['Can', 'Dogan', ''], ['Ng', 'Tim', ''], ['Travadi', 'Ruchir', ''], ['Ghoshal', 'Arnab', '']]"
1362370,2010.06040,Dinghan Shen,"Mingzhi Zheng, Dinghan Shen, Yelong Shen, Weizhu Chen, Lin Xiao","Improving Self-supervised Pre-training via a Fully-Explored Masked
  Language Model",,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Masked Language Model (MLM) framework has been widely adopted for
self-supervised language pre-training. In this paper, we argue that randomly
sampled masks in MLM would lead to undesirably large gradient variance. Thus,
we theoretically quantify the gradient variance via correlating the gradient
covariance with the Hamming distance between two different masks (given a
certain text sequence). To reduce the variance due to the sampling of masks, we
propose a fully-explored masking strategy, where a text sequence is divided
into a certain number of non-overlapping segments. Thereafter, the tokens
within one segment are masked for training. We prove, from a theoretical
perspective, that the gradients derived from this new masking schema have a
smaller variance and can lead to more efficient self-supervised training. We
conduct extensive experiments on both continual pre-training and general
pre-training from scratch. Empirical results confirm that this new masking
strategy can consistently outperform standard random masking. Detailed
efficiency analysis and ablation studies further validate the advantages of our
fully-explored masking strategy under the MLM framework.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 21:28:14 GMT'}, {'version': 'v2', 'created': 'Wed, 14 Oct 2020 04:45:59 GMT'}]",2020-10-15,"[['Zheng', 'Mingzhi', ''], ['Shen', 'Dinghan', ''], ['Shen', 'Yelong', ''], ['Chen', 'Weizhu', ''], ['Xiao', 'Lin', '']]"
1343222,2009.01719,Felix Hill Mr,"Felix Hill, Olivier Tieleman, Tamara von Glehn, Nathaniel Wong, Hamza
  Merzic, Stephen Clark",Grounded Language Learning Fast and Slow,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent work has shown that large text-based neural language models, trained
with conventional supervised learning objectives, acquire a surprising
propensity for few- and one-shot learning. Here, we show that an embodied agent
situated in a simulated 3D world, and endowed with a novel dual-coding external
memory, can exhibit similar one-shot word learning when trained with
conventional reinforcement learning algorithms. After a single introduction to
a novel object via continuous visual perception and a language prompt (""This is
a dax""), the agent can re-identify the object and manipulate it as instructed
(""Put the dax on the bed""). In doing so, it seamlessly integrates short-term,
within-episode knowledge of the appropriate referent for the word ""dax"" with
long-term lexical and motor knowledge acquired across episodes (i.e. ""bed"" and
""putting""). We find that, under certain training conditions and with a
particular memory writing mechanism, the agent's one-shot word-object binding
generalizes to novel exemplars within the same ShapeNet category, and is
effective in settings with unfamiliar numbers of objects. We further show how
dual-coding memory can be exploited as a signal for intrinsic motivation,
stimulating the agent to seek names for objects that may be useful for later
executing instructions. Together, the results demonstrate that deep neural
networks can exploit meta-learning, episodic memory and an explicitly
multi-modal environment to account for 'fast-mapping', a fundamental pillar of
human cognitive development and a potentially transformative capacity for
agents that interact with human users.
","[{'version': 'v1', 'created': 'Thu, 3 Sep 2020 14:52:03 GMT'}, {'version': 'v2', 'created': 'Mon, 7 Sep 2020 13:25:12 GMT'}, {'version': 'v3', 'created': 'Tue, 15 Sep 2020 10:56:08 GMT'}, {'version': 'v4', 'created': 'Wed, 14 Oct 2020 14:38:58 GMT'}]",2020-10-15,"[['Hill', 'Felix', ''], ['Tieleman', 'Olivier', ''], ['von Glehn', 'Tamara', ''], ['Wong', 'Nathaniel', ''], ['Merzic', 'Hamza', ''], ['Clark', 'Stephen', '']]"
1362399,2010.06069,Shiran Dudy,Shiran Dudy and Steven Bedrick,Are Some Words Worth More than Others?,EMNLP 2020 Eval4NLP Workshop,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Current evaluation metrics for language modeling and generation rely heavily
on the accuracy of predicted (or generated) words as compared to a reference
ground truth. While important, token-level accuracy only captures one aspect of
a language model's behavior, and ignores linguistic properties of words that
may allow some mis-predicted tokens to be useful in practice. Furthermore,
statistics directly tied to prediction accuracy (including perplexity) may be
confounded by the Zipfian nature of written language, as the majority of the
prediction attempts will occur with frequently-occurring types. A model's
performance may vary greatly between high- and low-frequency words, which in
practice could lead to failure modes such as repetitive and dull generated text
being produced by a downstream consumer of a language model. To address this,
we propose two new intrinsic evaluation measures within the framework of a
simple word prediction task that are designed to give a more holistic picture
of a language model's performance. We evaluate several commonly-used large
English language models using our proposed metrics, and demonstrate that our
approach reveals functional differences in performance between the models that
are obscured by more traditional metrics.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 23:12:11 GMT'}, {'version': 'v2', 'created': 'Wed, 14 Oct 2020 03:39:59 GMT'}]",2020-10-15,"[['Dudy', 'Shiran', ''], ['Bedrick', 'Steven', '']]"
1327754,2008.00032,Cristina Zuheros,"Cristina Zuheros, Eugenio Mart\'inez-C\'amara, Enrique Herrera-Viedma,
  and Francisco Herrera","Sentiment Analysis based Multi-person Multi-criteria Decision Making
  Methodology using Natural Language Processing and Deep Learning for Smarter
  Decision Aid. Case study of restaurant choice using TripAdvisor reviews",,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Decision making models are constrained by taking the expert evaluations with
pre-defined numerical or linguistic terms. We claim that the use of sentiment
analysis will allow decision making models to consider expert evaluations in
natural language. Accordingly, we propose the Sentiment Analysis based
Multi-person Multi-criteria Decision Making (SA-MpMcDM) methodology for smarter
decision aid, which builds the expert evaluations from their natural language
reviews, and even from their numerical ratings if they are available. The
SA-MpMcDM methodology incorporates an end-to-end multi-task deep learning model
for aspect based sentiment analysis, named DOC-ABSADeepL model, able to
identify the aspect categories mentioned in an expert review, and to distill
their opinions and criteria. The individual evaluations are aggregated via the
procedure named criteria weighting through the attention of the experts. We
evaluate the methodology in a case study of restaurant choice using TripAdvisor
reviews, hence we build, manually annotate, and release the TripR-2020 dataset
of restaurant reviews. We analyze the SA-MpMcDM methodology in different
scenarios using and not using natural language and numerical evaluations. The
analysis shows that the combination of both sources of information results in a
higher quality preference vector.
","[{'version': 'v1', 'created': 'Fri, 31 Jul 2020 18:45:52 GMT'}, {'version': 'v2', 'created': 'Wed, 14 Oct 2020 14:18:41 GMT'}]",2020-10-15,"[['Zuheros', 'Cristina', ''], ['Martínez-Cámara', 'Eugenio', ''], ['Herrera-Viedma', 'Enrique', ''], ['Herrera', 'Francisco', '']]"
1362640,2010.06310,Yue Wang,"Yue Wang, Zhuo Xu, Lu Bai, Yao Wan, Lixin Cui, Qian Zhao, Edwin R.
  Hancock, Philip S. Yu","Cross-Supervised Joint-Event-Extraction with Heterogeneous Information
  Networks",Accepted by ICPR 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Joint-event-extraction, which extracts structural information (i.e., entities
or triggers of events) from unstructured real-world corpora, has attracted more
and more research attention in natural language processing. Most existing works
do not fully address the sparse co-occurrence relationships between entities
and triggers, which loses this important information and thus deteriorates the
extraction performance. To mitigate this issue, we first define the
joint-event-extraction as a sequence-to-sequence labeling task with a tag set
composed of tags of triggers and entities. Then, to incorporate the missing
information in the aforementioned co-occurrence relationships, we propose a
Cross-Supervised Mechanism (CSM) to alternately supervise the extraction of
either triggers or entities based on the type distribution of each other.
Moreover, since the connected entities and triggers naturally form a
heterogeneous information network (HIN), we leverage the latent pattern along
meta-paths for a given corpus to further improve the performance of our
proposed method. To verify the effectiveness of our proposed method, we conduct
extensive experiments on four real-world datasets as well as compare our method
with state-of-the-art methods. Empirical results and analysis show that our
approach outperforms the state-of-the-art methods in both entity and trigger
extraction.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 11:51:17 GMT'}, {'version': 'v2', 'created': 'Wed, 14 Oct 2020 02:11:09 GMT'}]",2020-10-15,"[['Wang', 'Yue', ''], ['Xu', 'Zhuo', ''], ['Bai', 'Lu', ''], ['Wan', 'Yao', ''], ['Cui', 'Lixin', ''], ['Zhao', 'Qian', ''], ['Hancock', 'Edwin R.', ''], ['Yu', 'Philip S.', '']]"
1302856,2006.08342,Lukas Muttenthaler,Lukas Muttenthaler,"Subjective Question Answering: Deciphering the inner workings of
  Transformers in the realm of subjectivity","80 pages, Master's thesis in Computer Science (CS)",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Understanding subjectivity demands reasoning skills beyond the realm of
common knowledge. It requires a machine learning model to process sentiment and
to perform opinion mining. In this work, I've exploited a recently released
dataset for span-selection Question Answering, namely SubjQA. SubjQA is the
first QA dataset that contains questions that ask for subjective opinions
corresponding to review paragraphs from six different domains. Hence, to answer
these subjective questions, a learner must extract opinions and process
sentiment for various domains, and additionally, align the knowledge extracted
from a paragraph with the natural language utterances in the corresponding
question, which together enhance the difficulty of a QA task. The primary goal
of this thesis was to investigate the inner workings (i.e., latent
representations) of a Transformer-based architecture to contribute to a better
understanding of these not yet well understood ""black-box"" models.
Transformer's hidden representations, concerning the true answer span, are
clustered more closely in vector space than those representations corresponding
to erroneous predictions. This observation holds across the top three
Transformer layers for both objective and subjective questions and generally
increases as a function of layer dimensions. Moreover, the probability to
achieve a high cosine similarity among hidden representations in latent space
concerning the true answer span tokens is significantly higher for correct
compared to incorrect answer span predictions. These results have decisive
implications for down-stream applications, where it is crucial to know about
why a neural network made mistakes, and in which point, in space and time the
mistake has happened (e.g., to automatically predict correctness of an answer
span prediction without the necessity of labeled data).
","[{'version': 'v1', 'created': 'Tue, 2 Jun 2020 13:48:14 GMT'}, {'version': 'v2', 'created': 'Wed, 14 Oct 2020 07:47:52 GMT'}]",2020-10-15,"[['Muttenthaler', 'Lukas', '']]"
1362390,2010.06060,Hoo Chang Shin,"Hoo-Chang Shin, Yang Zhang, Evelina Bakhturina, Raul Puri, Mostofa
  Patwary, Mohammad Shoeybi, Raghav Mani",BioMegatron: Larger Biomedical Domain Language Model,Accepted for publication at EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  There has been an influx of biomedical domain-specific language models,
showing language models pre-trained on biomedical text perform better on
biomedical domain benchmarks than those trained on general domain text corpora
such as Wikipedia and Books. Yet, most works do not study the factors affecting
each domain language application deeply. Additionally, the study of model size
on domain-specific models has been mostly missing. We empirically study and
evaluate several factors that can affect performance on domain language
applications, such as the sub-word vocabulary set, model size, pre-training
corpus, and domain transfer. We show consistent improvements on benchmarks with
our larger BioMegatron model trained on a larger domain corpus, contributing to
our understanding of domain language model applications. We demonstrate
noticeable improvements over the previous state-of-the-art (SOTA) on standard
biomedical NLP benchmarks of named entity recognition, relation extraction, and
question answering. Model checkpoints and code are available at
[https://ngc.nvidia.com] and [https://github.com/NVIDIA/NeMo].
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 22:46:10 GMT'}, {'version': 'v2', 'created': 'Wed, 14 Oct 2020 02:02:55 GMT'}]",2020-10-15,"[['Shin', 'Hoo-Chang', ''], ['Zhang', 'Yang', ''], ['Bakhturina', 'Evelina', ''], ['Puri', 'Raul', ''], ['Patwary', 'Mostofa', ''], ['Shoeybi', 'Mohammad', ''], ['Mani', 'Raghav', '']]"
1363105,2010.06775,Hao Tan,"Hao Tan, Mohit Bansal","Vokenization: Improving Language Understanding with Contextualized,
  Visual-Grounded Supervision",EMNLP 2020 (15 pages),,,,cs.CL cs.AI cs.CV cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Humans learn language by listening, speaking, writing, reading, and also, via
interaction with the multimodal real world. Existing language pre-training
frameworks show the effectiveness of text-only self-supervision while we
explore the idea of a visually-supervised language model in this paper. We find
that the main reason hindering this exploration is the large divergence in
magnitude and distributions between the visually-grounded language datasets and
pure-language corpora. Therefore, we develop a technique named ""vokenization""
that extrapolates multimodal alignments to language-only data by contextually
mapping language tokens to their related images (which we call ""vokens""). The
""vokenizer"" is trained on relatively small image captioning datasets and we
then apply it to generate vokens for large language corpora. Trained with these
contextually generated vokens, our visually-supervised language models show
consistent improvements over self-supervised alternatives on multiple
pure-language tasks such as GLUE, SQuAD, and SWAG. Code and pre-trained models
publicly available at https://github.com/airsplay/vokenization
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 02:11:51 GMT'}]",2020-10-15,"[['Tan', 'Hao', ''], ['Bansal', 'Mohit', '']]"
1302033,2006.07519,Kyle Dent,Kyle Dent and Kalai Ramea,Conversational User Interfaces for Blind Knowledge Workers: A Case Study,,,,,cs.HC cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Modern trends in interface design for office equipment using controls on
touch surfaces create greater obstacles for blind and visually impaired users
and contribute to an environment of dependency in work settings. We believe
that \textit{conversational user interfaces} (CUIs) offer a reasonable
alternative to touchscreen interactions enabling more access and most
importantly greater independence for blind knowledge workers. We present a case
study of our work to develop a conversational user interface for accessibility
for multifunction printers. We also describe our approach to conversational
interfaces in general, which emphasizes task-based collaborative interactions
between people and intelligent agents, and we detail the specifics of the
solution we created for multifunction printers. To guide our design, we worked
with a group of blind and visually impaired individuals starting with focus
group sessions to ascertain the challenges our target users face in their
professional lives. We followed our technology development with a user study to
assess the solution and direct our future efforts. We present our findings and
conclusions from the study.
","[{'version': 'v1', 'created': 'Sat, 13 Jun 2020 00:27:14 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Oct 2020 21:06:00 GMT'}]",2020-10-15,"[['Dent', 'Kyle', ''], ['Ramea', 'Kalai', '']]"
1362581,2010.06251,Mariana Neves,Mariana Neves and Jurica Seva,Annotationsaurus: A Searchable Directory of Annotation Tools,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Manual annotation of textual documents is a necessary task when constructing
benchmark corpora for training and evaluating machine learning algorithms. We
created a comprehensive directory of annotation tools that currently includes
93 tools. We analyzed the tools over a set of 31 features and implemented
simple scripts and a Web application that filters the tools based on chosen
criteria. We present two use cases using the directory and propose ideas for
its maintenance. The directory, source codes for scripts, and link to the Web
application are available at: https://github.com/mariananeves/annotation-tools
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 09:22:48 GMT'}, {'version': 'v2', 'created': 'Wed, 14 Oct 2020 06:41:06 GMT'}]",2020-10-15,"[['Neves', 'Mariana', ''], ['Seva', 'Jurica', '']]"
1358160,2010.01830,Mark Anderson,Mark Anderson and Carlos G\'omez-Rodr\'iguez,On the Frailty of Universal POS Tags for Neural UD Parsers,"To be published in proceedings of the 24th SIGNLL Conference on
  Computational Natural Language Learning (CoNLL). Be aware of long appendix:
  please don't print all 28 pages",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present an analysis on the effect UPOS accuracy has on parsing
performance. Results suggest that leveraging UPOS tags as features for neural
parsers requires a prohibitively high tagging accuracy and that the use of gold
tags offers a non-linear increase in performance, suggesting some sort of
exceptionality. We also investigate what aspects of predicted UPOS tags impact
parsing accuracy the most, highlighting some potentially meaningful linguistic
facets of the problem.
","[{'version': 'v1', 'created': 'Mon, 5 Oct 2020 07:40:35 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Oct 2020 07:42:54 GMT'}, {'version': 'v3', 'created': 'Wed, 14 Oct 2020 05:47:29 GMT'}]",2020-10-15,"[['Anderson', 'Mark', ''], ['Gómez-Rodríguez', 'Carlos', '']]"
1363765,2010.07435,Maryam Hashemzadeh,"Maryam Hashemzadeh, Greta Kaufeld, Martha White, Andrea E. Martin,
  Alona Fyshe","From Language to Language-ish: How Brain-Like is an LSTM's
  Representation of Nonsensical Language Stimuli?",12 pages,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The representations generated by many models of language (word embeddings,
recurrent neural networks and transformers) correlate to brain activity
recorded while people read. However, these decoding results are usually based
on the brain's reaction to syntactically and semantically sound language
stimuli. In this study, we asked: how does an LSTM (long short term memory)
language model, trained (by and large) on semantically and syntactically intact
language, represent a language sample with degraded semantic or syntactic
information? Does the LSTM representation still resemble the brain's reaction?
We found that, even for some kinds of nonsensical language, there is a
statistically significant relationship between the brain's activity and the
representations of an LSTM. This indicates that, at least in some instances,
LSTMs and the human brain handle nonsensical data similarly.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 23:26:28 GMT'}]",2020-10-16,"[['Hashemzadeh', 'Maryam', ''], ['Kaufeld', 'Greta', ''], ['White', 'Martha', ''], ['Martin', 'Andrea E.', ''], ['Fyshe', 'Alona', '']]"
1363762,2010.07432,Alex Tamkin,"Alex Tamkin, Mike Wu, Noah Goodman","Viewmaker Networks: Learning Views for Unsupervised Representation
  Learning",,,,,cs.LG cs.CL cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Many recent methods for unsupervised representation learning involve training
models to be invariant to different ""views,"" or transformed versions of an
input. However, designing these views requires considerable human expertise and
experimentation, hindering widespread adoption of unsupervised representation
learning methods across domains and modalities. To address this, we propose
viewmaker networks: generative models that learn to produce input-dependent
views for contrastive learning. We train this network jointly with an encoder
network to produce adversarial $\ell_p$ perturbations for an input, which
yields challenging yet useful views without extensive human tuning. Our learned
views, when applied to CIFAR-10, enable comparable transfer accuracy to the the
well-studied augmentations used for the SimCLR model. Our views significantly
outperforming baseline augmentations in speech (+9% absolute) and wearable
sensor (+17% absolute) domains. We also show how viewmaker views can be
combined with handcrafted views to improve robustness to common image
corruptions. Our method demonstrates that learned views are a promising way to
reduce the amount of expertise and effort needed for unsupervised learning,
potentially extending its benefits to a much wider set of domains.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 23:03:31 GMT'}]",2020-10-16,"[['Tamkin', 'Alex', ''], ['Wu', 'Mike', ''], ['Goodman', 'Noah', '']]"
1363744,2010.07414,Isar Nejadgholi,Isar Nejadgholi and Svetlana Kiritchenko,On Cross-Dataset Generalization in Automatic Detection of Online Abuse,"13 pages, 3 figures, accepted to WOAH-2020 (The 4th Workshop on
  Online Abuse and Harms)",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  NLP research has attained high performances in abusive language detection as
a supervised classification task. While in research settings, training and test
datasets are usually obtained from similar data samples, in practice systems
are often applied on data that are different from the training set in topic and
class distributions. Also, the ambiguity in class definitions inherited in this
task aggravates the discrepancies between source and target datasets. We
explore the topic bias and the task formulation bias in cross-dataset
generalization. We show that the benign examples in the Wikipedia Detox dataset
are biased towards platform-specific topics. We identify these examples using
unsupervised topic modeling and manual inspection of topics' keywords. Removing
these topics increases cross-dataset generalization, without reducing in-domain
classification performance. For a robust dataset design, we suggest applying
inexpensive unsupervised methods to inspect the collected data and downsize the
non-generalizable content before manually annotating for class labels.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 21:47:03 GMT'}]",2020-10-16,"[['Nejadgholi', 'Isar', ''], ['Kiritchenko', 'Svetlana', '']]"
1363770,2010.07440,Elena Del Olmo Su\'arez,"Elena del Olmo Su\'arez and Ana Mar\'ia Fern\'andez-Pampill\'on
  Cesteros","A new approach for extracting the conceptual schema of texts based on
  the linguistic Thematic Progression theory",,"Del Olmo, E.; Fern\'andez-Pampill\'on, A. A new approach for
  extracting the conceptual schema of texts based on the linguistic Thematic
  Progression theory. Proceedings of the Workshop on Hybrid Intelligence for
  NLP Tasks (ECAI-2020), 23-27",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The purpose of this article is to present a new approach for the discovery
and labelling of the implicit conceptual schema of texts through the
application of the Thematic Progression theory. The underlying conceptual
schema is the core component for the generation of summaries that are genuinely
consistent with the semantics of the text.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 23:50:25 GMT'}]",2020-10-16,"[['Suárez', 'Elena del Olmo', ''], ['Cesteros', 'Ana María Fernández-Pampillón', '']]"
1358472,2010.02142,Anshul Wadhawan,"Janvijay Singh, Anshul Wadhawan","PublishInCovid19 at WNUT 2020 Shared Task-1: Entity Recognition in Wet
  Lab Protocols using Structured Learning Ensemble and Contextualised
  Embeddings",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we describe the approach that we employed to address the task
of Entity Recognition over Wet Lab Protocols -- a shared task in EMNLP
WNUT-2020 Workshop. Our approach is composed of two phases. In the first phase,
we experiment with various contextualised word embeddings (like Flair,
BERT-based) and a BiLSTM-CRF model to arrive at the best-performing
architecture. In the second phase, we create an ensemble composed of eleven
BiLSTM-CRF models. The individual models are trained on random train-validation
splits of the complete dataset. Here, we also experiment with different output
merging schemes, including Majority Voting and Structured Learning Ensembling
(SLE). Our final submission achieved a micro F1-score of 0.8175 and 0.7757 for
the partial and exact match of the entity spans, respectively. We were ranked
first and second, in terms of partial and exact match, respectively.
","[{'version': 'v1', 'created': 'Mon, 5 Oct 2020 16:45:30 GMT'}, {'version': 'v2', 'created': 'Thu, 15 Oct 2020 08:33:45 GMT'}]",2020-10-16,"[['Singh', 'Janvijay', ''], ['Wadhawan', 'Anshul', '']]"
1363740,2010.07410,Ilan Price,"Ilan Price, Jordan Gifford-Moore, Jory Flemming, Saul Musker, Maayan
  Roichman, Guillaume Sylvain, Nithum Thain, Lucas Dixon, Jeffrey Sorensen",Six Attributes of Unhealthy Conversation,Appearing in the 4th Workshop on Online Abuse and Harms (2020),,,,cs.CL cs.SI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  We present a new dataset of approximately 44000 comments labeled by
crowdworkers. Each comment is labelled as either 'healthy' or 'unhealthy', in
addition to binary labels for the presence of six potentially 'unhealthy'
sub-attributes: (1) hostile; (2) antagonistic, insulting, provocative or
trolling; (3) dismissive; (4) condescending or patronising; (5) sarcastic;
and/or (6) an unfair generalisation. Each label also has an associated
confidence score. We argue that there is a need for datasets which enable
research based on a broad notion of 'unhealthy online conversation'. We build
this typology to encompass a substantial proportion of the individual comments
which contribute to unhealthy online conversation. For some of these
attributes, this is the first publicly available dataset of this scale. We
explore the quality of the dataset, present some summary statistics and initial
models to illustrate the utility of this data, and highlight limitations and
directions for further research.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 21:28:06 GMT'}]",2020-10-16,"[['Price', 'Ilan', ''], ['Gifford-Moore', 'Jordan', ''], ['Flemming', 'Jory', ''], ['Musker', 'Saul', ''], ['Roichman', 'Maayan', ''], ['Sylvain', 'Guillaume', ''], ['Thain', 'Nithum', ''], ['Dixon', 'Lucas', ''], ['Sorensen', 'Jeffrey', '']]"
1363796,2010.07466,Hoang Nguyen Hung Van,"Hoang Van, Ahmad Musa, Mihai Surdeanu and Stephen Kobourov","The Language of Food during the Pandemic: Hints about the Dietary
  Effects of Covid-19","9 page of main contents plus 1 page of references. 4 figures and 9
  tables",,,,cs.CL cs.SI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We study the language of food on Twitter during the pandemic lockdown in the
United States, focusing on the two month period of March 15 to May 15, 2020.
Specifically, we analyze over770,000 tweets published during the lockdown and
the equivalent period in the five previous years and highlight several worrying
trends. First, we observe that during the lockdown there was a notable shift
from mentions of healthy foods to unhealthy foods. Second, we show an increased
pointwise mutual information of depression hashtags with food-related tweets
posted during the lockdown and an increased association between depression
hashtags and unhealthy foods, tobacco, and alcohol during the lockdown.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 01:33:05 GMT'}]",2020-10-16,"[['Van', 'Hoang', ''], ['Musa', 'Ahmad', ''], ['Surdeanu', 'Mihai', ''], ['Kobourov', 'Stephen', '']]"
1363622,2010.07292,Hancheng Cao,"Hancheng Cao, Vivian Yang, Victor Chen, Yu Jin Lee, Lydia Stone,
  N'godjigui Junior Diarrassouba, Mark E. Whiting, Michael S. Bernstein","My Team Will Go On: Differentiating High and Low Viability Teams through
  Team Interaction",CSCW 2020 Honorable Mention Award,,,,cs.CY cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Understanding team viability -- a team's capacity for sustained and future
success -- is essential for building effective teams. In this study, we
aggregate features drawn from the organizational behavior literature to train a
viability classification model over a dataset of 669 10-minute text
conversations of online teams. We train classifiers to identify teams at the
top decile (most viable teams), 50th percentile (above a median split), and
bottom decile (least viable teams), then characterize the attributes of teams
at each of these viability levels. We find that a lasso regression model
achieves an accuracy of .74--.92 AUC ROC under different thresholds of
classifying viability scores. From these models, we identify the use of
exclusive language such as `but' and `except', and the use of second person
pronouns, as the most predictive features for detecting the most viable teams,
suggesting that active engagement with others' ideas is a crucial signal of a
viable team. Only a small fraction of the 10-minute discussion, as little as 70
seconds, is required for predicting the viability of team interaction. This
work suggests opportunities for teams to assess, track, and visualize their own
viability in real time as they collaborate.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 21:33:36 GMT'}]",2020-10-16,"[['Cao', 'Hancheng', ''], ['Yang', 'Vivian', ''], ['Chen', 'Victor', ''], ['Lee', 'Yu Jin', ''], ['Stone', 'Lydia', ''], ['Diarrassouba', ""N'godjigui Junior"", ''], ['Whiting', 'Mark E.', ''], ['Bernstein', 'Michael S.', '']]"
1363591,2010.07261,Makesh Narsimhan Sreedhar,"Makesh Narsimhan Sreedhar, Kun Ni, Siva Reddy","Learning Improvised Chatbots from Adversarial Modifications of Natural
  Language Feedback",Accepted for publication at Findings of EMNLP 2020,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The ubiquitous nature of chatbots and their interaction with users generate
an enormous amount of data. Can we improve chatbots using this data? A
self-feeding chatbot improves itself by asking natural language feedback when a
user is dissatisfied with its response and uses this feedback as an additional
training sample. However, user feedback in most cases contains extraneous
sequences hindering their usefulness as a training sample. In this work, we
propose a generative adversarial model that converts noisy feedback into a
plausible natural response in a conversation. The generator's goal is to
convert the feedback into a response that answers the user's previous utterance
and to fool the discriminator which distinguishes feedback from natural
responses. We show that augmenting original training data with these modified
feedback responses improves the original chatbot performance from 69.94% to
75.96% in ranking correct responses on the Personachat dataset, a large
improvement given that the original model is already trained on 131k samples.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 17:33:37 GMT'}, {'version': 'v2', 'created': 'Thu, 15 Oct 2020 02:19:13 GMT'}]",2020-10-16,"[['Sreedhar', 'Makesh Narsimhan', ''], ['Ni', 'Kun', ''], ['Reddy', 'Siva', '']]"
1363777,2010.07447,Michal Lukasik,"Michal Lukasik, Himanshu Jain, Aditya Krishna Menon, Seungyeon Kim,
  Srinadh Bhojanapalli, Felix Yu, Sanjiv Kumar",Semantic Label Smoothing for Sequence to Sequence Problems,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Label smoothing has been shown to be an effective regularization strategy in
classification, that prevents overfitting and helps in label de-noising.
However, extending such methods directly to seq2seq settings, such as Machine
Translation, is challenging: the large target output space of such problems
makes it intractable to apply label smoothing over all possible outputs. Most
existing approaches for seq2seq settings either do token level smoothing, or
smooth over sequences generated by randomly substituting tokens in the target
sequence. Unlike these works, in this paper, we propose a technique that
smooths over \emph{well formed} relevant sequences that not only have
sufficient n-gram overlap with the target sequence, but are also
\emph{semantically similar}. Our method shows a consistent and significant
improvement over the state-of-the-art techniques on different datasets.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 00:31:15 GMT'}]",2020-10-16,"[['Lukasik', 'Michal', ''], ['Jain', 'Himanshu', ''], ['Menon', 'Aditya Krishna', ''], ['Kim', 'Seungyeon', ''], ['Bhojanapalli', 'Srinadh', ''], ['Yu', 'Felix', ''], ['Kumar', 'Sanjiv', '']]"
1279976,2005.00181,Yi Luan,"Yi Luan, Jacob Eisenstein, Kristina Toutanova, Michael Collins","Sparse, Dense, and Attentional Representations for Text Retrieval","To appear in TACL 2020. The arXiv version is a pre-MIT Press
  publication version",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Dual encoders perform retrieval by encoding documents and queries into dense
lowdimensional vectors, scoring each document by its inner product with the
query. We investigate the capacity of this architecture relative to sparse
bag-of-words models and attentional neural networks. Using both theoretical and
empirical analysis, we establish connections between the encoding dimension,
the margin between gold and lower-ranked documents, and the document length,
suggesting limitations in the capacity of fixed-length encodings to support
precise retrieval of long documents. Building on these insights, we propose a
simple neural model that combines the efficiency of dual encoders with some of
the expressiveness of more costly attentional architectures, and explore
sparse-dense hybrids to capitalize on the precision of sparse retrieval. These
models outperform strong alternatives in large-scale retrieval.
","[{'version': 'v1', 'created': 'Fri, 1 May 2020 02:21:17 GMT'}, {'version': 'v2', 'created': 'Wed, 14 Oct 2020 19:12:42 GMT'}]",2020-10-16,"[['Luan', 'Yi', ''], ['Eisenstein', 'Jacob', ''], ['Toutanova', 'Kristina', ''], ['Collins', 'Michael', '']]"
1356624,2010.00294,Anshul Wadhawan,Anshul Wadhawan,"Phonemer at WNUT-2020 Task 2: Sequence Classification Using COVID
  Twitter BERT and Bagging Ensemble Technique based on Plurality Voting",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents the approach that we employed to tackle the EMNLP
WNUT-2020 Shared Task 2 : Identification of informative COVID-19 English
Tweets. The task is to develop a system that automatically identifies whether
an English Tweet related to the novel coronavirus (COVID-19) is informative or
not. We solve the task in three stages. The first stage involves pre-processing
the dataset by filtering only relevant information. This is followed by
experimenting with multiple deep learning models like CNNs, RNNs and
Transformer based models. In the last stage, we propose an ensemble of the best
model trained on different subsets of the provided dataset. Our final approach
achieved an F1-score of 0.9037 and we were ranked sixth overall with F1-score
as the evaluation criteria.
","[{'version': 'v1', 'created': 'Thu, 1 Oct 2020 10:54:54 GMT'}, {'version': 'v2', 'created': 'Fri, 9 Oct 2020 09:43:34 GMT'}, {'version': 'v3', 'created': 'Thu, 15 Oct 2020 08:35:00 GMT'}]",2020-10-16,"[['Wadhawan', 'Anshul', '']]"
1356283,2009.14780,Yevgeni Berzak,"Jonathan Malmaud, Roger Levy, Yevgeni Berzak","Bridging Information-Seeking Human Gaze and Machine Reading
  Comprehension",CoNLL 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this work, we analyze how human gaze during reading comprehension is
conditioned on the given reading comprehension question, and whether this
signal can be beneficial for machine reading comprehension. To this end, we
collect a new eye-tracking dataset with a large number of participants engaging
in a multiple choice reading comprehension task. Our analysis of this data
reveals increased fixation times over parts of the text that are most relevant
for answering the question. Motivated by this finding, we propose making
automated reading comprehension more human-like by mimicking human
information-seeking reading behavior during reading comprehension. We
demonstrate that this approach leads to performance gains on multiple choice
question answering in English for a state-of-the-art reading comprehension
model.
","[{'version': 'v1', 'created': 'Wed, 30 Sep 2020 16:34:27 GMT'}, {'version': 'v2', 'created': 'Thu, 15 Oct 2020 16:08:02 GMT'}]",2020-10-16,"[['Malmaud', 'Jonathan', ''], ['Levy', 'Roger', ''], ['Berzak', 'Yevgeni', '']]"
1279393,2004.14623,Christopher Potts,"Atticus Geiger, Kyle Richardson, and Christopher Potts","Neural Natural Language Inference Models Partially Embed Theories of
  Lexical Entailment and Negation",To appear in Proceedings of BlackBoxNLP 2020,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We address whether neural models for Natural Language Inference (NLI) can
learn the compositional interactions between lexical entailment and negation,
using four methods: the behavioral evaluation methods of (1) challenge test
sets and (2) systematic generalization tasks, and the structural evaluation
methods of (3) probes and (4) interventions. To facilitate this holistic
evaluation, we present Monotonicity NLI (MoNLI), a new naturalistic dataset
focused on lexical entailment and negation. In our behavioral evaluations, we
find that models trained on general-purpose NLI datasets fail systematically on
MoNLI examples containing negation, but that MoNLI fine-tuning addresses this
failure. In our structural evaluations, we look for evidence that our
top-performing BERT-based model has learned to implement the monotonicity
algorithm behind MoNLI. Probes yield evidence consistent with this conclusion,
and our intervention experiments bolster this, showing that the causal dynamics
of the model mirror the causal dynamics of this algorithm on subsets of MoNLI.
This suggests that the BERT model at least partially embeds a theory of lexical
entailment and negation at an algorithmic level.
","[{'version': 'v1', 'created': 'Thu, 30 Apr 2020 07:53:20 GMT'}, {'version': 'v2', 'created': 'Tue, 14 Jul 2020 20:51:04 GMT'}, {'version': 'v3', 'created': 'Thu, 15 Oct 2020 17:04:12 GMT'}]",2020-10-16,"[['Geiger', 'Atticus', ''], ['Richardson', 'Kyle', ''], ['Potts', 'Christopher', '']]"
1355391,2009.13888,Kawin Ethayarajh,"Kawin Ethayarajh, Dan Jurafsky",Utility is in the Eye of the User: A Critique of NLP Leaderboards,EMNLP 2020,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Benchmarks such as GLUE have helped drive advances in NLP by incentivizing
the creation of more accurate models. While this leaderboard paradigm has been
remarkably successful, a historical focus on performance-based evaluation has
been at the expense of other qualities that the NLP community values in models,
such as compactness, fairness, and energy efficiency. In this opinion paper, we
study the divergence between what is incentivized by leaderboards and what is
useful in practice through the lens of microeconomic theory. We frame both the
leaderboard and NLP practitioners as consumers and the benefit they get from a
model as its utility to them. With this framing, we formalize how leaderboards
-- in their current form -- can be poor proxies for the NLP community at large.
For example, a highly inefficient model would provide less utility to
practitioners but not to a leaderboard, since it is a cost that only the former
must bear. To allow practitioners to better estimate a model's utility to them,
we advocate for more transparency on leaderboards, such as the reporting of
statistics that are of practical concern (e.g., model size, energy efficiency,
and inference latency).
","[{'version': 'v1', 'created': 'Tue, 29 Sep 2020 09:25:31 GMT'}, {'version': 'v2', 'created': 'Sun, 4 Oct 2020 23:04:29 GMT'}, {'version': 'v3', 'created': 'Thu, 15 Oct 2020 00:40:13 GMT'}]",2020-10-16,"[['Ethayarajh', 'Kawin', ''], ['Jurafsky', 'Dan', '']]"
1278835,2004.14065,Hila Gonen,Hila Gonen and Kellie Webster,"Automatically Identifying Gender Issues in Machine Translation using
  Perturbations",Findings of EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The successful application of neural methods to machine translation has
realized huge quality advances for the community. With these improvements, many
have noted outstanding challenges, including the modeling and treatment of
gendered language. While previous studies have identified issues using
synthetic examples, we develop a novel technique to mine examples from real
world data to explore challenges for deployed systems. We use our method to
compile an evaluation benchmark spanning examples for four languages from three
language families, which we publicly release to facilitate research. The
examples in our benchmark expose where model representations are gendered, and
the unintended consequences these gendered representations can have in
downstream application.
","[{'version': 'v1', 'created': 'Wed, 29 Apr 2020 10:38:09 GMT'}, {'version': 'v2', 'created': 'Wed, 14 Oct 2020 19:01:59 GMT'}]",2020-10-16,"[['Gonen', 'Hila', ''], ['Webster', 'Kellie', '']]"
1363805,2010.07475,Wanjun Zhong,"Wanjun Zhong, Duyu Tang, Zenan Xu, Ruize Wang, Nan Duan, Ming Zhou,
  Jiahai Wang, Jian Yin",Neural Deepfake Detection with Factual Structure of Text,EMNLP2020;10 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Deepfake detection, the task of automatically discriminating
machine-generated text, is increasingly critical with recent advances in
natural language generative models. Existing approaches to deepfake detection
typically represent documents with coarse-grained representations. However,
they struggle to capture factual structures of documents, which is a
discriminative factor between machine-generated and human-written text
according to our statistical analysis. To address this, we propose a
graph-based model that utilizes the factual structure of a document for
deepfake detection of text. Our approach represents the factual structure of a
given document as an entity graph, which is further utilized to learn sentence
representations with a graph neural network. Sentence representations are then
composed to a document representation for making predictions, where consistent
relations between neighboring sentences are sequentially modeled. Results of
experiments on two public deepfake datasets show that our approach
significantly improves strong base models built with RoBERTa. Model analysis
further indicates that our model can distinguish the difference in the factual
structure between machine-generated text and human-written text.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 02:35:31 GMT'}]",2020-10-16,"[['Zhong', 'Wanjun', ''], ['Tang', 'Duyu', ''], ['Xu', 'Zenan', ''], ['Wang', 'Ruize', ''], ['Duan', 'Nan', ''], ['Zhou', 'Ming', ''], ['Wang', 'Jiahai', ''], ['Yin', 'Jian', '']]"
1352298,2009.10795,Swabha Swayamdipta,"Swabha Swayamdipta, Roy Schwartz, Nicholas Lourie, Yizhong Wang,
  Hannaneh Hajishirzi, Noah A. Smith, Yejin Choi","Dataset Cartography: Mapping and Diagnosing Datasets with Training
  Dynamics",Proceedings of EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large datasets have become commonplace in NLP research. However, the
increased emphasis on data quantity has made it challenging to assess the
quality of data. We introduce Data Maps---a model-based tool to characterize
and diagnose datasets. We leverage a largely ignored source of information: the
behavior of the model on individual instances during training (training
dynamics) for building data maps. This yields two intuitive measures for each
example---the model's confidence in the true class, and the variability of this
confidence across epochs---obtained in a single run of training. Experiments
across four datasets show that these model-dependent measures reveal three
distinct regions in the data map, each with pronounced characteristics. First,
our data maps show the presence of ""ambiguous"" regions with respect to the
model, which contribute the most towards out-of-distribution generalization.
Second, the most populous regions in the data are ""easy to learn"" for the
model, and play an important role in model optimization. Finally, data maps
uncover a region with instances that the model finds ""hard to learn""; these
often correspond to labeling errors. Our results indicate that a shift in focus
from quantity to quality of data could lead to robust models and improved
out-of-distribution generalization.
","[{'version': 'v1', 'created': 'Tue, 22 Sep 2020 20:19:41 GMT'}, {'version': 'v2', 'created': 'Thu, 15 Oct 2020 05:53:46 GMT'}]",2020-10-16,"[['Swayamdipta', 'Swabha', ''], ['Schwartz', 'Roy', ''], ['Lourie', 'Nicholas', ''], ['Wang', 'Yizhong', ''], ['Hajishirzi', 'Hannaneh', ''], ['Smith', 'Noah A.', ''], ['Choi', 'Yejin', '']]"
1287604,2005.07809,Zhuohao Chen,"Zhuohao Chen, Nikolaos Flemotomos, Victor Ardulov, Torrey A. Creed,
  Zac E. Imel, David C. Atkins, Shrikanth Narayanan","Feature Fusion Strategies for End-to-End Evaluation of Cognitive
  Behavior Therapy Sessions",,,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Cognitive Behavioral Therapy (CBT) is a goal-oriented psychotherapy for
mental health concerns implemented in a conversational setting with broad
empirical support for its effectiveness across a range of presenting problems
and client populations. The quality of a CBT session is typically assessed by
trained human raters who manually assign pre-defined session-level behavioral
codes. In this paper, we develop an end-to-end pipeline that converts speech
audio to diarized and transcribed text and extracts linguistic features to code
the CBT sessions automatically. We investigate both word-level and
utterance-level features and propose feature fusion strategies to combine them.
The utterance level features include dialog act tags as well as behavioral
codes drawn from another well-known talk psychotherapy called Motivational
Interviewing (MI). We propose a novel method to augment the word-based features
with the utterance level tags for subsequent CBT code estimation. Experiments
show that our new fusion strategy outperforms all the studied features, both
when used individually and when fused by direct concatenation. We also find
that incorporating a sentence segmentation module can further improve the
overall system given the preponderance of multi-utterance conversational turns
in CBT sessions.
","[{'version': 'v1', 'created': 'Fri, 15 May 2020 22:26:58 GMT'}, {'version': 'v2', 'created': 'Wed, 14 Oct 2020 20:53:36 GMT'}]",2020-10-16,"[['Chen', 'Zhuohao', ''], ['Flemotomos', 'Nikolaos', ''], ['Ardulov', 'Victor', ''], ['Creed', 'Torrey A.', ''], ['Imel', 'Zac E.', ''], ['Atkins', 'David C.', ''], ['Narayanan', 'Shrikanth', '']]"
1258247,2003.07892,Shrey Desai,Shrey Desai and Greg Durrett,Calibration of Pre-trained Transformers,Accepted to EMNLP 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pre-trained Transformers are now ubiquitous in natural language processing,
but despite their high end-task performance, little is known empirically about
whether they are calibrated. Specifically, do these models' posterior
probabilities provide an accurate empirical measure of how likely the model is
to be correct on a given example? We focus on BERT and RoBERTa in this work,
and analyze their calibration across three tasks: natural language inference,
paraphrase detection, and commonsense reasoning. For each task, we consider
in-domain as well as challenging out-of-domain settings, where models face more
examples they should be uncertain about. We show that: (1) when used
out-of-the-box, pre-trained models are calibrated in-domain, and compared to
baselines, their calibration error out-of-domain can be as much as 3.5x lower;
(2) temperature scaling is effective at further reducing calibration error
in-domain, and using label smoothing to deliberately increase empirical
uncertainty helps calibrate posteriors out-of-domain.
","[{'version': 'v1', 'created': 'Tue, 17 Mar 2020 18:58:44 GMT'}, {'version': 'v2', 'created': 'Fri, 20 Mar 2020 21:35:54 GMT'}, {'version': 'v3', 'created': 'Thu, 15 Oct 2020 17:04:21 GMT'}]",2020-10-16,"[['Desai', 'Shrey', ''], ['Durrett', 'Greg', '']]"
1258552,2003.08197,Paul Pu Liang,"Paul Pu Liang, Manzil Zaheer, Yuan Wang, Amr Ahmed",Anchor & Transform: Learning Sparse Embeddings for Large Vocabularies,,,,,cs.LG cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Learning continuous representations of discrete objects such as text, users,
movies, and URLs lies at the heart of many applications including language and
user modeling. When using discrete objects as input to neural networks, we
often ignore the underlying structures (e.g. natural groupings and
similarities) and embed the objects independently into individual vectors. As a
result, existing methods do not scale to large vocabulary sizes. In this paper,
we design a simple and efficient embedding algorithm that learns a small set of
anchor embeddings and a sparse transformation matrix. We call our method Anchor
& Transform (ANT) as the embeddings of discrete objects are a sparse linear
combination of the anchors, weighted according to the transformation matrix.
ANT is scalable, flexible, and end-to-end trainable. We further provide a
statistical interpretation of our algorithm as a Bayesian nonparametric prior
for embeddings that encourages sparsity and leverages natural groupings among
objects. By deriving an approximate inference algorithm based on Small Variance
Asymptotics, we obtain a natural extension that automatically learns the
optimal number of anchors instead of having to tune it as a hyperparameter. On
text classification, language modeling, and movie recommendation benchmarks, we
show that ANT is particularly suitable for large vocabulary sizes and
demonstrates stronger performance with fewer parameters (up to 40x compression)
as compared to existing compression baselines.
","[{'version': 'v1', 'created': 'Wed, 18 Mar 2020 13:07:51 GMT'}, {'version': 'v2', 'created': 'Thu, 16 Jul 2020 03:51:17 GMT'}, {'version': 'v3', 'created': 'Thu, 15 Oct 2020 04:43:51 GMT'}]",2020-10-16,"[['Liang', 'Paul Pu', ''], ['Zaheer', 'Manzil', ''], ['Wang', 'Yuan', ''], ['Ahmed', 'Amr', '']]"
1335494,2008.07772,Xiaodong Liu,"Xiaodong Liu, Kevin Duh, Liyuan Liu and Jianfeng Gao",Very Deep Transformers for Neural Machine Translation,"6 pages, 3 figures and 4 tables. V2 includes the back-translation
  results",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We explore the application of very deep Transformer models for Neural Machine
Translation (NMT). Using a simple yet effective initialization technique that
stabilizes training, we show that it is feasible to build standard
Transformer-based models with up to 60 encoder layers and 12 decoder layers.
These deep models outperform their baseline 6-layer counterparts by as much as
2.5 BLEU, and achieve new state-of-the-art benchmark results on WMT14
English-French (43.8 BLEU and 46.4 BLEU with back-translation) and WMT14
English-German (30.1 BLEU).The code and trained models will be publicly
available at: https://github.com/namisan/exdeep-nmt.
","[{'version': 'v1', 'created': 'Tue, 18 Aug 2020 07:14:54 GMT'}, {'version': 'v2', 'created': 'Wed, 14 Oct 2020 22:56:32 GMT'}]",2020-10-16,"[['Liu', 'Xiaodong', ''], ['Duh', 'Kevin', ''], ['Liu', 'Liyuan', ''], ['Gao', 'Jianfeng', '']]"
1339371,2008.11649,Masataro Asai,"Masataro Asai, Zilu Tang",Discrete Word Embedding for Logical Natural Language Understanding,equal contribution,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose an unsupervised neural model for learning a discrete embedding of
words. Unlike existing discrete embeddings, our binary embedding supports
vector arithmetic operations similar to continuous embeddings. Our embedding
represents each word as a set of propositional statements describing a
transition rule in classical/STRIPS planning formalism. This makes the
embedding directly compatible with symbolic, state of the art classical
planning solvers.
","[{'version': 'v1', 'created': 'Wed, 26 Aug 2020 16:15:18 GMT'}, {'version': 'v2', 'created': 'Thu, 15 Oct 2020 14:37:59 GMT'}]",2020-10-16,"[['Asai', 'Masataro', ''], ['Tang', 'Zilu', '']]"
1356640,2010.00310,Anshul Wadhawan,"Akshita Aggarwal, Anshul Wadhawan, Anshima Chaudhary, Kavita Maurya","""Did you really mean what you said?"" : Sarcasm Detection in
  Hindi-English Code-Mixed Data using Bilingual Word Embeddings",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  With the increased use of social media platforms by people across the world,
many new interesting NLP problems have come into existence. One such being the
detection of sarcasm in the social media texts. We present a corpus of tweets
for training custom word embeddings and a Hinglish dataset labelled for sarcasm
detection. We propose a deep learning based approach to address the issue of
sarcasm detection in Hindi-English code mixed tweets using bilingual word
embeddings derived from FastText and Word2Vec approaches. We experimented with
various deep learning models, including CNNs, LSTMs, Bi-directional LSTMs (with
and without attention). We were able to outperform all state-of-the-art
performances with our deep learning models, with attention based Bi-directional
LSTMs giving the best performance exhibiting an accuracy of 78.49%.
","[{'version': 'v1', 'created': 'Thu, 1 Oct 2020 11:41:44 GMT'}, {'version': 'v2', 'created': 'Sun, 11 Oct 2020 08:32:33 GMT'}, {'version': 'v3', 'created': 'Thu, 15 Oct 2020 08:32:09 GMT'}]",2020-10-16,"[['Aggarwal', 'Akshita', ''], ['Wadhawan', 'Anshul', ''], ['Chaudhary', 'Anshima', ''], ['Maurya', 'Kavita', '']]"
1304103,2006.09589,Zijian Wang,"Elisa Kreiss, Zijian Wang, Christopher Potts",Modeling Subjective Assessments of Guilt in Newspaper Crime Narratives,CoNLL 2020,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Crime reporting is a prevalent form of journalism with the power to shape
public perceptions and social policies. How does the language of these reports
act on readers? We seek to address this question with the SuspectGuilt Corpus
of annotated crime stories from English-language newspapers in the U.S. For
SuspectGuilt, annotators read short crime articles and provided text-level
ratings concerning the guilt of the main suspect as well as span-level
annotations indicating which parts of the story they felt most influenced their
ratings. SuspectGuilt thus provides a rich picture of how linguistic choices
affect subjective guilt judgments. In addition, we use SuspectGuilt to train
and assess predictive models, and show that these models benefit from genre
pretraining and joint supervision from the text-level ratings and span-level
annotations. Such models might be used as tools for understanding the societal
effects of crime reporting.
","[{'version': 'v1', 'created': 'Wed, 17 Jun 2020 01:21:19 GMT'}, {'version': 'v2', 'created': 'Wed, 14 Oct 2020 22:38:44 GMT'}]",2020-10-16,"[['Kreiss', 'Elisa', ''], ['Wang', 'Zijian', ''], ['Potts', 'Christopher', '']]"
1363827,2010.07497,Jianheng Tang,"Wenge Liu, Jianheng Tang, Jinghui Qin, Lin Xu, Zhen Li, Xiaodan Liang","MedDG: A Large-scale Medical Consultation Dataset for Building Medical
  Dialogue System",Data and code are available at https://github.com/lwgkzl/MedDG,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Developing conversational agents to interact with patients and provide
primary clinical advice has attracted increasing attention due to its huge
application potential, especially in the time of COVID-19 Pandemic. However,
the training of end-to-end neural-based medical dialogue system is restricted
by an insufficient quantity of medical dialogue corpus. In this work, we make
the first attempt to build and release a large-scale high-quality Medical
Dialogue dataset related to 12 types of common Gastrointestinal diseases named
MedDG, with more than 17K conversations collected from the online health
consultation community. Five different categories of entities, including
diseases, symptoms, attributes, tests, and medicines, are annotated in each
conversation of MedDG as additional labels. To push forward the future research
on building expert-sensitive medical dialogue system, we proposes two kinds of
medical dialogue tasks based on MedDG dataset. One is the next entity
prediction and the other is the doctor response generation. To acquire a clear
comprehension on these two medical dialogue tasks, we implement several
state-of-the-art benchmarks, as well as design two dialogue models with a
further consideration on the predicted entities. Experimental results show that
the pre-train language models and other baselines struggle on both tasks with
poor performance in our dataset, and the response quality can be enhanced with
the help of auxiliary entity information. From human evaluation, the simple
retrieval model outperforms several state-of-the-art generative models,
indicating that there still remains a large room for improvement on generating
medically meaningful responses.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 03:34:33 GMT'}]",2020-10-16,"[['Liu', 'Wenge', ''], ['Tang', 'Jianheng', ''], ['Qin', 'Jinghui', ''], ['Xu', 'Lin', ''], ['Li', 'Zhen', ''], ['Liang', 'Xiaodan', '']]"
1363845,2010.07515,John Hewitt,"John Hewitt, Michael Hahn, Surya Ganguli, Percy Liang, Christopher D.
  Manning",RNNs can generate bounded hierarchical languages with optimal memory,EMNLP2020 + appendix typo fixes,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recurrent neural networks empirically generate natural language with high
syntactic fidelity. However, their success is not well-understood
theoretically. We provide theoretical insight into this success, proving in a
finite-precision setting that RNNs can efficiently generate bounded
hierarchical languages that reflect the scaffolding of natural language syntax.
We introduce Dyck-($k$,$m$), the language of well-nested brackets (of $k$
types) and $m$-bounded nesting depth, reflecting the bounded memory needs and
long-distance dependencies of natural language syntax. The best known results
use $O(k^{\frac{m}{2}})$ memory (hidden units) to generate these languages. We
prove that an RNN with $O(m \log k)$ hidden units suffices, an exponential
reduction in memory, by an explicit construction. Finally, we show that no
algorithm, even with unbounded computation, can suffice with $o(m \log k)$
hidden units.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 04:42:29 GMT'}]",2020-10-16,"[['Hewitt', 'John', ''], ['Hahn', 'Michael', ''], ['Ganguli', 'Surya', ''], ['Liang', 'Percy', ''], ['Manning', 'Christopher D.', '']]"
1364103,2010.07773,Shubhanker Banerjee,"Shubhanker Banerjee, Arun Jayapal and Sajeetha Thavareesan","NUIG-Shubhanker@Dravidian-CodeMix-FIRE2020: Sentiment Analysis of
  Code-Mixed Dravidian text using XLNet",7 pages,,,,cs.CL cs.AI cs.LG cs.NE,http://creativecommons.org/publicdomain/zero/1.0/,"  Social media has penetrated into multilingual societies, however most of them
use English to be a preferred language for communication. So it looks natural
for them to mix their cultural language with English during conversations
resulting in abundance of multilingual data, call this code-mixed data,
available in todays' world.Downstream NLP tasks using such data is challenging
due to the semantic nature of it being spread across multiple languages.One
such Natural Language Processing task is sentiment analysis, for this we use an
auto-regressive XLNet model to perform sentiment analysis on code-mixed
Tamil-English and Malayalam-English datasets.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 14:09:02 GMT'}]",2020-10-16,"[['Banerjee', 'Shubhanker', ''], ['Jayapal', 'Arun', ''], ['Thavareesan', 'Sajeetha', '']]"
1363833,2010.07503,Sho Takase,Sho Takase and Naoaki Okazaki,Multi-Task Learning for Cross-Lingual Abstractive Summarization,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present a multi-task learning framework for cross-lingual abstractive
summarization to augment training data. Recent studies constructed pseudo
cross-lingual abstractive summarization data to train their neural
encoder-decoders. Meanwhile, we introduce existing genuine data such as
translation pairs and monolingual abstractive summarization data into training.
Our proposed method, Transum, attaches a special token to the beginning of the
input sentence to indicate the target task. The special token enables us to
incorporate the genuine data into the training data easily. The experimental
results show that Transum achieves better performance than the model trained
with only pseudo cross-lingual summarization data. In addition, we achieve the
top ROUGE score on Chinese-English and Arabic-English abstractive
summarization. Moreover, Transum also has a positive effect on machine
translation. Experimental results indicate that Transum improves the
performance from the strong baseline, Transformer, in Chinese-English,
Arabic-English, and English-Japanese translation datasets.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 04:03:00 GMT'}]",2020-10-16,"[['Takase', 'Sho', ''], ['Okazaki', 'Naoaki', '']]"
1364115,2010.07785,Weishi Wang,"Weishi Wang, Shafiq Joty, Steven C.H. Hoi","Response Selection for Multi-Party Conversations with Dynamic Topic
  Tracking","9 pages, EMNLP2020",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While participants in a multi-party multi-turn conversation simultaneously
engage in multiple conversation topics, existing response selection methods are
developed mainly focusing on a two-party single-conversation scenario. Hence,
the prolongation and transition of conversation topics are ignored by current
methods. In this work, we frame response selection as a dynamic topic tracking
task to match the topic between the response and relevant conversation context.
With this new formulation, we propose a novel multi-task learning framework
that supports efficient encoding through large pretrained models with only two
utterances at once to perform dynamic topic disentanglement and response
selection. We also propose Topic-BERT an essential pretraining step to embed
topic information into BERT with self-supervised learning. Experimental results
on the DSTC-8 Ubuntu IRC dataset show state-of-the-art results in response
selection and topic disentanglement tasks outperforming existing methods by a
good margin.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 14:21:38 GMT'}]",2020-10-16,"[['Wang', 'Weishi', ''], ['Joty', 'Shafiq', ''], ['Hoi', 'Steven C. H.', '']]"
1364122,2010.07792,Yinuo Guo,"Yinuo Guo, Zeqi Lin, Jian-Guang Lou, Dongmei Zhang",Hierarchical Poset Decoding for Compositional Generalization in Language,Accepted by Neurips 2020,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We formalize human language understanding as a structured prediction task
where the output is a partially ordered set (poset). Current encoder-decoder
architectures do not take the poset structure of semantics into account
properly, thus suffering from poor compositional generalization ability. In
this paper, we propose a novel hierarchical poset decoding paradigm for
compositional generalization in language. Intuitively: (1) the proposed
paradigm enforces partial permutation invariance in semantics, thus avoiding
overfitting to bias ordering information; (2) the hierarchical mechanism allows
to capture high-level structures of posets. We evaluate our proposed decoder on
Compositional Freebase Questions (CFQ), a large and realistic natural language
question answering dataset that is specifically designed to measure
compositional generalization. Results show that it outperforms current
decoders.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 14:34:26 GMT'}]",2020-10-16,"[['Guo', 'Yinuo', ''], ['Lin', 'Zeqi', ''], ['Lou', 'Jian-Guang', ''], ['Zhang', 'Dongmei', '']]"
1364146,2010.07816,Georgios MIchalopoulos,"George Michalopoulos, Helen Chen, Alexander Wong","Where's the Question? A Multi-channel Deep Convolutional Neural Network
  for Question Identification in Textual Data","12 pages, 4 figures, to be published in The 3rd Clinical Natural
  Language Processing Workshop",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In most clinical practice settings, there is no rigorous reviewing of the
clinical documentation, resulting in inaccurate information captured in the
patient medical records. The gold standard in clinical data capturing is
achieved via ""expert-review"", where clinicians can have a dialogue with a
domain expert (reviewers) and ask them questions about data entry rules.
Automatically identifying ""real questions"" in these dialogues could uncover
ambiguities or common problems in data capturing in a given clinical setting.
  In this study, we proposed a novel multi-channel deep convolutional neural
network architecture, namely Quest-CNN, for the purpose of separating real
questions that expect an answer (information or help) about an issue from
sentences that are not questions, as well as from questions referring to an
issue mentioned in a nearby sentence (e.g., can you clarify this?), which we
will refer as ""c-questions"". We conducted a comprehensive performance
comparison analysis of the proposed multi-channel deep convolutional neural
network against other deep neural networks. Furthermore, we evaluated the
performance of traditional rule-based and learning-based methods for detecting
question sentences. The proposed Quest-CNN achieved the best F1 score both on a
dataset of data entry-review dialogue in a dialysis care setting, and on a
general domain dataset.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 15:11:22 GMT'}]",2020-10-16,"[['Michalopoulos', 'George', ''], ['Chen', 'Helen', ''], ['Wong', 'Alexander', '']]"
1364195,2010.07865,Vladislav Lyalin,"Vladislav Lialin, Rahul Goel, Andrey Simanovsky, Anna Rumshisky,
  Rushin Shah",Continual Learning for Neural Semantic Parsing,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A semantic parsing model is crucial to natural language processing
applications such as goal-oriented dialogue systems. Such models can have
hundreds of classes with a highly non-uniform distribution. In this work, we
show how to efficiently (in terms of computational budget) improve model
performance given a new portion of labeled data for a specific low-resource
class or a set of classes. We demonstrate that a simple approach with a
specific fine-tuning procedure for the old model can reduce the computational
costs by ~90% compared to the training of a new model. The resulting
performance is on-par with a model trained from scratch on a full dataset. We
showcase the efficacy of our approach on two popular semantic parsing datasets,
Facebook TOP, and SNIPS.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 16:37:41 GMT'}]",2020-10-16,"[['Lialin', 'Vladislav', ''], ['Goel', 'Rahul', ''], ['Simanovsky', 'Andrey', ''], ['Rumshisky', 'Anna', ''], ['Shah', 'Rushin', '']]"
1364091,2010.07761,Phillip Keung,"Phillip Keung, Julian Salazar, Yichao Lu, Noah A. Smith","Unsupervised Bitext Mining and Translation via Self-trained Contextual
  Embeddings","To appear in the Transactions of the Association for Computational
  Linguistics",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We describe an unsupervised method to create pseudo-parallel corpora for
machine translation (MT) from unaligned text. We use multilingual BERT to
create source and target sentence embeddings for nearest-neighbor search and
adapt the model via self-training. We validate our technique by extracting
parallel sentence pairs on the BUCC 2017 bitext mining task and observe up to a
24.5 point increase (absolute) in F1 scores over previous unsupervised methods.
We then improve an XLM-based unsupervised neural MT system pre-trained on
Wikipedia by supplementing it with pseudo-parallel text mined from the same
corpus, boosting unsupervised translation performance by up to 3.5 BLEU on the
WMT'14 French-English and WMT'16 German-English tasks and outperforming the
previous state-of-the-art. Finally, we enrich the IWSLT'15 English-Vietnamese
corpus with pseudo-parallel Wikipedia sentence pairs, yielding a 1.2 BLEU
improvement on the low-resource MT task. We demonstrate that unsupervised
bitext mining is an effective way of augmenting MT datasets and complements
existing techniques like initializing with pre-trained contextual embeddings.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 14:04:03 GMT'}]",2020-10-16,"[['Keung', 'Phillip', ''], ['Salazar', 'Julian', ''], ['Lu', 'Yichao', ''], ['Smith', 'Noah A.', '']]"
1364204,2010.07874,Peter Belc\'ak,Peter Belcak,The LL(finite) strategy for optimal LL(k) parsing,,,,,cs.PL cs.CL cs.FL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The LL(finite) parsing strategy for parsing of LL(k) grammars where k needs
not to be known is presented. The strategy parses input in linear time, uses
arbitrary but always minimal lookahead necessary to disambiguate between
alternatives of nonterminals, and it is optimal in the number of lookahead
terminal scans performed. Modifications to the algorithm are shown that allow
for resolution of grammar ambiguities by precedence -- effectively interpreting
the input as a parsing expression grammar -- as well as for the use of
predicates, and a proof of concept, the open-source parser generator Astir,
employs the LL(finite) strategy in the output it generates.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 16:52:29 GMT'}]",2020-10-16,"[['Belcak', 'Peter', '']]"
1364212,2010.07882,Jiacheng Xu,"Jiacheng Xu, Shrey Desai, Greg Durrett",Understanding Neural Abstractive Summarization Models via Uncertainty,"To appear in EMNLP 2020; code available at
  https://github.com/jiacheng-xu/text-sum-uncertainty",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  An advantage of seq2seq abstractive summarization models is that they
generate text in a free-form manner, but this flexibility makes it difficult to
interpret model behavior. In this work, we analyze summarization decoders in
both blackbox and whitebox ways by studying on the entropy, or uncertainty, of
the model's token-level predictions. For two strong pre-trained models, PEGASUS
and BART on two summarization datasets, we find a strong correlation between
low prediction entropy and where the model copies tokens rather than generating
novel text. The decoder's uncertainty also connects to factors like sentence
position and syntactic distance between adjacent pairs of tokens, giving a
sense of what factors make a context particularly selective for the model's
next output token. Finally, we study the relationship of decoder uncertainty
and attention behavior to understand how attention gives rise to these observed
effects in the model. We show that uncertainty is a useful perspective for
analyzing summarization and text generation models more broadly.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 16:57:27 GMT'}]",2020-10-16,"[['Xu', 'Jiacheng', ''], ['Desai', 'Shrey', ''], ['Durrett', 'Greg', '']]"
1364216,2010.07886,Shrey Desai,Shrey Desai and Jiacheng Xu and Greg Durrett,Compressive Summarization with Plausibility and Salience Modeling,Accepted to EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Compressive summarization systems typically rely on a crafted set of
syntactic rules to determine what spans of possible summary sentences can be
deleted, then learn a model of what to actually delete by optimizing for
content selection (ROUGE). In this work, we propose to relax the rigid
syntactic constraints on candidate spans and instead leave compression
decisions to two data-driven criteria: plausibility and salience. Deleting a
span is plausible if removing it maintains the grammaticality and factuality of
a sentence, and spans are salient if they contain important information from
the summary. Each of these is judged by a pre-trained Transformer model, and
only deletions that are both plausible and not salient can be applied. When
integrated into a simple extraction-compression pipeline, our method achieves
strong in-domain results on benchmark summarization datasets, and human
evaluation shows that the plausibility model generally selects for grammatical
and factual deletions. Furthermore, the flexibility of our approach allows it
to generalize cross-domain: our system fine-tuned on only 500 samples from a
new domain can match or exceed an in-domain extractive model trained on much
more data.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 17:07:10 GMT'}]",2020-10-16,"[['Desai', 'Shrey', ''], ['Xu', 'Jiacheng', ''], ['Durrett', 'Greg', '']]"
1360576,2010.04246,Shang-Yu Su,"Shang-Yu Su, Yung-Sung Chuang, Yun-Nung Chen",Dual Inference for Improving Language Understanding and Generation,"Published in Findings of EMNLP 2020. The first two authors
  contributed to this paper equally",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Natural language understanding (NLU) and Natural language generation (NLG)
tasks hold a strong dual relationship, where NLU aims at predicting semantic
labels based on natural language utterances and NLG does the opposite. The
prior work mainly focused on exploiting the duality in model training in order
to obtain the models with better performance. However, regarding the
fast-growing scale of models in the current NLP area, sometimes we may have
difficulty retraining whole NLU and NLG models. To better address the issue,
this paper proposes to leverage the duality in the inference stage without the
need of retraining. The experiments on three benchmark datasets demonstrate the
effectiveness of the proposed method in both NLU and NLG, providing the great
potential of practical usage.
","[{'version': 'v1', 'created': 'Thu, 8 Oct 2020 20:14:41 GMT'}, {'version': 'v2', 'created': 'Thu, 15 Oct 2020 02:10:48 GMT'}]",2020-10-16,"[['Su', 'Shang-Yu', ''], ['Chuang', 'Yung-Sung', ''], ['Chen', 'Yun-Nung', '']]"
1361252,2010.04922,Zhengxuan Wu,"Zhengxuan Wu, Thanh-Son Nguyen, Desmond C. Ong",Structured Self-Attention Weights Encode Semantics in Sentiment Analysis,10 pages,BlackBoxNLP Workshop at EMNLP 2020,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Neural attention, especially the self-attention made popular by the
Transformer, has become the workhorse of state-of-the-art natural language
processing (NLP) models. Very recent work suggests that the self-attention in
the Transformer encodes syntactic information; Here, we show that
self-attention scores encode semantics by considering sentiment analysis tasks.
In contrast to gradient-based feature attribution methods, we propose a simple
and effective Layer-wise Attention Tracing (LAT) method to analyze structured
attention weights. We apply our method to Transformer models trained on two
tasks that have surface dissimilarities, but share common semantics---sentiment
analysis of movie reviews and time-series valence prediction in life story
narratives. Across both tasks, words with high aggregated attention weights
were rich in emotional semantics, as quantitatively validated by an emotion
lexicon labeled by human annotators. Our results show that structured attention
weights encode rich semantics in sentiment analysis, and match human
interpretations of semantics.
","[{'version': 'v1', 'created': 'Sat, 10 Oct 2020 06:49:25 GMT'}]",2020-10-16,"[['Wu', 'Zhengxuan', ''], ['Nguyen', 'Thanh-Son', ''], ['Ong', 'Desmond C.', '']]"
1040351,1810.09164,Alberto Cetoli,"Alberto Cetoli, Mohammad Akbari, Stefano Bragaglia, Andrew D.
  O'Harney, Marc Sloan",Named Entity Disambiguation using Deep Learning on Graphs,,,10.1007/978-3-030-15719-7_10,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We tackle \ac{NED} by comparing entities in short sentences with \wikidata{}
graphs. Creating a context vector from graphs through deep learning is a
challenging problem that has never been applied to \ac{NED}. Our main
contribution is to present an experimental study of recent neural techniques,
as well as a discussion about which graph features are most important for the
disambiguation task. In addition, a new dataset (\wikidatadisamb{}) is created
to allow a clean and scalable evaluation of \ac{NED} with \wikidata{} entries,
and to be used as a reference in future research. In the end our results show
that a \ac{Bi-LSTM} encoding of the graph triplets performs best, improving
upon the baseline models and scoring an \rm{F1} value of $91.6\%$ on the
\wikidatadisamb{} test set
","[{'version': 'v1', 'created': 'Mon, 22 Oct 2018 10:16:07 GMT'}]",2020-10-16,"[['Cetoli', 'Alberto', ''], ['Akbari', 'Mohammad', ''], ['Bragaglia', 'Stefano', ''], [""O'Harney"", 'Andrew D.', ''], ['Sloan', 'Marc', '']]"
1362689,2010.06359,Eleftherios Avramidis,"Eleftherios Avramidis, Vivien Macketanz, Ursula Strohriegel, Aljoscha
  Burchardt and Sebastian M\""oller","Fine-grained linguistic evaluation for state-of-the-art Machine
  Translation","11 pages, 1 figure, Fifth Conference of Machine Translation, WMT20",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  This paper describes a test suite submission providing detailed statistics of
linguistic performance for the state-of-the-art German-English systems of the
Fifth Conference of Machine Translation (WMT20). The analysis covers 107
phenomena organized in 14 categories based on about 5,500 test items, including
a manual annotation effort of 45 person hours. Two systems (Tohoku and Huoshan)
appear to have significantly better test suite accuracy than the others,
although the best system of WMT20 is not significantly better than the one from
WMT19 in a macro-average. Additionally, we identify some linguistic phenomena
where all systems suffer (such as idioms, resultative predicates and
pluperfect), but we are also able to identify particular weaknesses for
individual systems (such as quotation marks, lexical ambiguity and sluicing).
Most of the systems of WMT19 which submitted new versions this year show
improvements.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 13:14:37 GMT'}, {'version': 'v2', 'created': 'Wed, 14 Oct 2020 19:50:28 GMT'}]",2020-10-16,"[['Avramidis', 'Eleftherios', ''], ['Macketanz', 'Vivien', ''], ['Strohriegel', 'Ursula', ''], ['Burchardt', 'Aljoscha', ''], ['Möller', 'Sebastian', '']]"
1364208,2010.07878,Matthias Hertel,"Hannah Bast, Matthias Hertel, Mostafa M. Mohamed",Tokenization Repair in the Presence of Spelling Errors,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We consider the following tokenization repair problem: Given a natural
language text with any combination of missing or spurious spaces, correct
these. Spelling errors can be present, but it's not part of the problem to
correct them. For example, given: ""Tispa per isabout token izaionrep air"",
compute ""Tis paper is about tokenizaion repair"". It is tempting to think of
this problem as a special case of spelling correction or to treat the two
problems together. We make a case that tokenization repair and spelling
correction should and can be treated as separate problems. We investigate a
variety of neural models as well as a number of strong baselines. We identify
three main ingredients to high-quality tokenization repair: deep language
models with a bidirectional component, training the models on text with
spelling errors, and making use of the space information already present. Our
best methods can repair all tokenization errors on 97.5% of the correctly
spelled test sentences and on 96.0% of the misspelled test sentences. With all
spaces removed from the given text (the scenario from previous work), the
accuracy falls to 94.5% and 90.1%, respectively. We conduct a detailed error
analysis.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 16:55:45 GMT'}]",2020-10-16,"[['Bast', 'Hannah', ''], ['Hertel', 'Matthias', ''], ['Mohamed', 'Mostafa M.', '']]"
1364041,2010.07711,Yile Wang,"Yile Wang, Leyang Cui, Yue Zhang",Does Chinese BERT Encode Word Structure?,Accepted by COLING2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Contextualized representations give significantly improved results for a wide
range of NLP tasks. Much work has been dedicated to analyzing the features
captured by representative models such as BERT. Existing work finds that
syntactic, semantic and word sense knowledge are encoded in BERT. However,
little work has investigated word features for character-based languages such
as Chinese. We investigate Chinese BERT using both attention weight
distribution statistics and probing tasks, finding that (1) word information is
captured by BERT; (2) word-level features are mostly in the middle
representation layers; (3) downstream tasks make different use of word features
in BERT, with POS tagging and chunking relying the most on word features, and
natural language inference relying the least on such features.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 12:40:56 GMT'}]",2020-10-16,"[['Wang', 'Yile', ''], ['Cui', 'Leyang', ''], ['Zhang', 'Yue', '']]"
1363705,2010.07375,Aaron Mueller,"Alexandra DeLucia, Aaron Mueller, Xiang Lisa Li, Jo\~ao Sedoc",Decoding Methods for Neural Narrative Generation,20 pages. Submitted to INLG 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Narrative generation is an open-ended NLP task in which a model generates a
story given a prompt. The task is similar to neural response generation for
chatbots; however, innovations in response generation are often not applied to
narrative generation, despite the similarity between these tasks. We aim to
bridge this gap by applying and evaluating advances in decoding methods for
neural response generation to neural narrative generation. In particular, we
employ GPT-2 and perform ablations across nucleus sampling thresholds and
diverse decoding hyperparameters---specifically, maximum mutual
information---analyzing results over multiple criteria with automatic and human
evaluation. We find that (1) nucleus sampling is generally best within $0.7
\leq p \leq 0.9$; (2) a maximum mutual information objective can improve the
quality of generated stories; and (3) established automatic metrics do not
correlate well with human judgments of narrative quality on any qualitative
metric.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 19:32:56 GMT'}]",2020-10-16,"[['DeLucia', 'Alexandra', ''], ['Mueller', 'Aaron', ''], ['Li', 'Xiang Lisa', ''], ['Sedoc', 'João', '']]"
1363904,2010.07574,Simon Flachs,"Simon Flachs, Oph\'elie Lacroix, Helen Yannakoudakis, Marek Rei,
  Anders S{\o}gaard","Grammatical Error Correction in Low Error Density Domains: A New
  Benchmark and Analyses",Accepted at EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Evaluation of grammatical error correction (GEC) systems has primarily
focused on essays written by non-native learners of English, which however is
only part of the full spectrum of GEC applications. We aim to broaden the
target domain of GEC and release CWEB, a new benchmark for GEC consisting of
website text generated by English speakers of varying levels of proficiency.
Website data is a common and important domain that contains far fewer
grammatical errors than learner essays, which we show presents a challenge to
state-of-the-art GEC systems. We demonstrate that a factor behind this is the
inability of systems to rely on a strong internal language model in low error
density domains. We hope this work shall facilitate the development of
open-domain GEC models that generalize to different topics and genres.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 07:52:01 GMT'}]",2020-10-16,"[['Flachs', 'Simon', ''], ['Lacroix', 'Ophélie', ''], ['Yannakoudakis', 'Helen', ''], ['Rei', 'Marek', ''], ['Søgaard', 'Anders', '']]"
1358935,2010.02605,Ekaterina Artemova,"Taisia Glushkova and Alexey Machnev and Alena Fenogenova and Tatiana
  Shavrina and Ekaterina Artemova and Dmitry I. Ignatov",DaNetQA: a yes/no Question Answering Dataset for the Russian Language,"Analysis of Images, Social Networks and Texts - 9 th International
  Conference, AIST 2020, Skolkovo, Russia, October 15-16, 2020, Revised
  Selected Papers. Lecture Notes in Computer Science
  (https://dblp.org/db/series/lncs/index.html), Springer 2020",,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  DaNetQA, a new question-answering corpus, follows (Clark et. al, 2019)
design: it comprises natural yes/no questions. Each question is paired with a
paragraph from Wikipedia and an answer, derived from the paragraph. The task is
to take both the question and a paragraph as input and come up with a yes/no
answer, i.e. to produce a binary output. In this paper, we present a
reproducible approach to DaNetQA creation and investigate transfer learning
methods for task and language transferring. For task transferring we leverage
three similar sentence modelling tasks: 1) a corpus of paraphrases,
Paraphraser, 2) an NLI task, for which we use the Russian part of XNLI, 3)
another question answering task, SberQUAD. For language transferring we use
English to Russian translation together with multilingual language fine-tuning.
","[{'version': 'v1', 'created': 'Tue, 6 Oct 2020 10:30:48 GMT'}, {'version': 'v2', 'created': 'Thu, 15 Oct 2020 10:36:06 GMT'}]",2020-10-16,"[['Glushkova', 'Taisia', ''], ['Machnev', 'Alexey', ''], ['Fenogenova', 'Alena', ''], ['Shavrina', 'Tatiana', ''], ['Artemova', 'Ekaterina', ''], ['Ignatov', 'Dmitry I.', '']]"
1364006,2010.07676,Guanhua Zhang,"Guanhua Zhang, Bing Bai, Jian Liang, Kun Bai, Conghui Zhu, Tiejun Zhao","Reliable Evaluations for Natural Language Inference based on a Unified
  Cross-dataset Benchmark",,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent studies show that crowd-sourced Natural Language Inference (NLI)
datasets may suffer from significant biases like annotation artifacts. Models
utilizing these superficial clues gain mirage advantages on the in-domain
testing set, which makes the evaluation results over-estimated. The lack of
trustworthy evaluation settings and benchmarks stalls the progress of NLI
research. In this paper, we propose to assess a model's trustworthy
generalization performance with cross-datasets evaluation. We present a new
unified cross-datasets benchmark with 14 NLI datasets, and re-evaluate 9
widely-used neural network-based NLI models as well as 5 recently proposed
debiasing methods for annotation artifacts. Our proposed evaluation scheme and
experimental baselines could provide a basis to inspire future reliable NLI
research.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 11:50:12 GMT'}]",2020-10-16,"[['Zhang', 'Guanhua', ''], ['Bai', 'Bing', ''], ['Liang', 'Jian', ''], ['Bai', 'Kun', ''], ['Zhu', 'Conghui', ''], ['Zhao', 'Tiejun', '']]"
1363906,2010.07576,Yu Cao,"Yu Cao, Wei Bi, Meng Fang, Dacheng Tao","Pretrained Language Models for Dialogue Generation with Multiple Input
  Sources","9 pages (containing 4 pages of references and appendix), accepted to
  EMNLP2020-Findings",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large-scale pretrained language models have achieved outstanding performance
on natural language understanding tasks. However, it is still under
investigating how to apply them to dialogue generation tasks, especially those
with responses conditioned on multiple sources. Previous work simply
concatenates all input sources or averages information from different input
sources. In this work, we study dialogue models with multiple input sources
adapted from the pretrained language model GPT2. We explore various methods to
fuse multiple separate attention information corresponding to different
sources. Our experimental results show that proper fusion methods deliver
higher relevance with dialogue history than simple fusion baselines.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 07:53:28 GMT'}]",2020-10-16,"[['Cao', 'Yu', ''], ['Bi', 'Wei', ''], ['Fang', 'Meng', ''], ['Tao', 'Dacheng', '']]"
1363936,2010.07606,Liang Li,"Liang Li, Can Ma, Yinliang Yue, Linjun Shou and Dayong Hu",Learning Better Representation for Tables by Self-Supervised Tasks,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Table-to-text generation aims at automatically generating natural text to
help people to conveniently obtain the important information in tables.
Although neural models for table-to-text have achieved remarkable progress,
some problems still overlooked. The first is that the values recorded in many
tables are mostly numbers in practice. The existing approaches do not do
special treatment for these, and still regard these as words in natural
language text. Secondly, the target texts in training dataset may contain
redundant information or facts do not exist in the input tables. These may give
wrong supervision signals to some methods based on content selection and
planning and auxiliary supervision. To solve these problems, we propose two
self-supervised tasks, Number Ordering and Significance Ordering, to help to
learn better table representation. The former works on the column dimension to
help to incorporate the size property of numbers into table representation. The
latter acts on row dimension and help to learn a significance-aware table
representation. We test our methods on the widely used dataset ROTOWIRE which
consists of NBA game statistic and related news. The experimental results
demonstrate that the model trained together with these two self-supervised
tasks can generate text that contains more salient and well-organized facts,
even without modeling context selection and planning. And we achieve the
state-of-the-art performance on automatic metrics.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 09:03:38 GMT'}]",2020-10-16,"[['Li', 'Liang', ''], ['Ma', 'Can', ''], ['Yue', 'Yinliang', ''], ['Shou', 'Linjun', ''], ['Hu', 'Dayong', '']]"
1363967,2010.07637,Yuzhao Mao,"Yuzhao Mao, Qi Sun, Guang Liu, Xiaojie Wang, Weiguo Gao, Xuan Li,
  Jianping Shen","DialogueTRM: Exploring the Intra- and Inter-Modal Emotional Behaviors in
  the Conversation",,,,,cs.CL cs.MM,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Emotion Recognition in Conversations (ERC) is essential for building
empathetic human-machine systems. Existing studies on ERC primarily focus on
summarizing the context information in a conversation, however, ignoring the
differentiated emotional behaviors within and across different modalities.
Designing appropriate strategies that fit the differentiated multi-modal
emotional behaviors can produce more accurate emotional predictions. Thus, we
propose the DialogueTransformer to explore the differentiated emotional
behaviors from the intra- and inter-modal perspectives. For intra-modal, we
construct a novel Hierarchical Transformer that can easily switch between
sequential and feed-forward structures according to the differentiated context
preference within each modality. For inter-modal, we constitute a novel
Multi-Grained Interactive Fusion that applies both neuron- and vector-grained
feature interactions to learn the differentiated contributions across all
modalities. Experimental results show that DialogueTRM outperforms the
state-of-the-art by a significant margin on three benchmark datasets.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 10:10:41 GMT'}]",2020-10-16,"[['Mao', 'Yuzhao', ''], ['Sun', 'Qi', ''], ['Liu', 'Guang', ''], ['Wang', 'Xiaojie', ''], ['Gao', 'Weiguo', ''], ['Li', 'Xuan', ''], ['Shen', 'Jianping', '']]"
1363856,2010.07526,Ana Marasovi\'c,"Ana Marasovi\'c, Chandra Bhagavatula, Jae Sung Park, Ronan Le Bras,
  Noah A. Smith, Yejin Choi","Natural Language Rationales with Full-Stack Visual Reasoning: From
  Pixels to Semantic Frames to Commonsense Graphs",Accepted to Findings of EMNLP,,,,cs.CL cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Natural language rationales could provide intuitive, higher-level
explanations that are easily understandable by humans, complementing the more
broadly studied lower-level explanations based on gradients or attention
weights. We present the first study focused on generating natural language
rationales across several complex visual reasoning tasks: visual commonsense
reasoning, visual-textual entailment, and visual question answering. The key
challenge of accurate rationalization is comprehensive image understanding at
all levels: not just their explicit content at the pixel level, but their
contextual contents at the semantic and pragmatic levels. We present
Rationale^VT Transformer, an integrated model that learns to generate free-text
rationales by combining pretrained language models with object recognition,
grounded visual semantic frames, and visual commonsense graphs. Our experiments
show that the base pretrained language model benefits from visual adaptation
and that free-text rationalization is a promising research direction to
complement model interpretability for complex visual-textual reasoning tasks.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 05:08:56 GMT'}]",2020-10-16,"[['Marasović', 'Ana', ''], ['Bhagavatula', 'Chandra', ''], ['Park', 'Jae Sung', ''], ['Bras', 'Ronan Le', ''], ['Smith', 'Noah A.', ''], ['Choi', 'Yejin', '']]"
1363995,2010.07665,Hareesh Bahuleyan,Hareesh Bahuleyan and Layla El Asri,Diverse Keyphrase Generation with Neural Unlikelihood Training,Accepted to COLING 2020,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we study sequence-to-sequence (S2S) keyphrase generation
models from the perspective of diversity. Recent advances in neural natural
language generation have made possible remarkable progress on the task of
keyphrase generation, demonstrated through improvements on quality metrics such
as F1-score. However, the importance of diversity in keyphrase generation has
been largely ignored. We first analyze the extent of information redundancy
present in the outputs generated by a baseline model trained using maximum
likelihood estimation (MLE). Our findings show that repetition of keyphrases is
a major issue with MLE training. To alleviate this issue, we adopt neural
unlikelihood (UL) objective for training the S2S model. Our version of UL
training operates at (1) the target token level to discourage the generation of
repeating tokens; (2) the copy token level to avoid copying repetitive tokens
from the source text. Further, to encourage better model planning during the
decoding process, we incorporate K-step ahead token prediction objective that
computes both MLE and UL losses on future tokens as well. Through extensive
experiments on datasets from three different domains we demonstrate that the
proposed approach attains considerably large diversity gains, while maintaining
competitive output quality.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 11:12:26 GMT'}]",2020-10-16,"[['Bahuleyan', 'Hareesh', ''], ['Asri', 'Layla El', '']]"
1363998,2010.07668,Peng Cui,"Peng Cui, Le Hu, Yuanchao Liu","Inducing Alignment Structure with Gated Graph Attention Networks for
  Sentence Matching",,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Sentence matching is a fundamental task of natural language processing with
various applications. Most recent approaches adopt attention-based neural
models to build word- or phrase-level alignment between two sentences. However,
these models usually ignore the inherent structure within the sentences and
fail to consider various dependency relationships among text units. To address
these issues, this paper proposes a graph-based approach for sentence matching.
First, we represent a sentence pair as a graph with several carefully design
strategies. We then employ a novel gated graph attention network to encode the
constructed graph for sentence matching. Experimental results demonstrate that
our method substantially achieves state-of-the-art performance on two datasets
across tasks of natural language and paraphrase identification. Further
discussions show that our model can learn meaningful graph structure,
indicating its superiority on improved interpretability.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 11:25:54 GMT'}]",2020-10-16,"[['Cui', 'Peng', ''], ['Hu', 'Le', ''], ['Liu', 'Yuanchao', '']]"
1363853,2010.07523,Zhengxuan Wu,"Zhengxuan Wu, Desmond C. Ong",Context-Guided BERT for Targeted Aspect-Based Sentiment Analysis,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Aspect-based sentiment analysis (ABSA) and Targeted ASBA (TABSA) allow
finer-grained inferences about sentiment to be drawn from the same text,
depending on context. For example, a given text can have different targets
(e.g., neighborhoods) and different aspects (e.g., price or safety), with
different sentiment associated with each target-aspect pair. In this paper, we
investigate whether adding context to self-attention models improves
performance on (T)ABSA. We propose two variants of Context-Guided BERT
(CG-BERT) that learn to distribute attention under different contexts. We first
adapt a context-aware Transformer to produce a CG-BERT that uses context-guided
softmax-attention. Next, we propose an improved Quasi-Attention CG-BERT model
that learns a compositional attention that supports subtractive attention. We
train both models with pretrained BERT on two (T)ABSA datasets: SentiHood and
SemEval-2014 (Task 4). Both models achieve new state-of-the-art results with
our QACG-BERT model having the best performance. Furthermore, we provide
analyses of the impact of context in the our proposed models. Our work provides
more evidence for the utility of adding context-dependencies to pretrained
self-attention-based language models for context-based natural language tasks.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 05:01:20 GMT'}]",2020-10-16,"[['Wu', 'Zhengxuan', ''], ['Ong', 'Desmond C.', '']]"
1363852,2010.07522,Youmi Ma,"Youmi Ma, Tatsuya Hiraoka, Naoaki Okazaki","Named Entity Recognition and Relation Extraction using Enhanced Table
  Filling by Contextualized Representations",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this study, a novel method for extracting named entities and relations
from unstructured text based on the table representation is presented. By using
contextualized word embeddings, the proposed method computes representations
for entity mentions and long-range dependencies without complicated
hand-crafted features or neural-network architectures. We also adapt a tensor
dot-product to predict relation labels all at once without resorting to
history-based predictions or search strategies. These advances significantly
simplify the model and algorithm for the extraction of named entities and
relations. Despite its simplicity, the experimental results demonstrate that
the proposed method outperforms the state-of-the-art methods on the CoNLL04 and
ACE05 English datasets. We also confirm that the proposed method achieves a
comparable performance with the state-of-the-art NER models on the ACE05
datasets when multiple sentences are provided for context aggregation.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 04:58:23 GMT'}]",2020-10-16,"[['Ma', 'Youmi', ''], ['Hiraoka', 'Tatsuya', ''], ['Okazaki', 'Naoaki', '']]"
1363968,2010.07638,Prathyusha Jwalapuram,"Prathyusha Jwalapuram, Shafiq Joty, Youlin Shen",Pronoun-Targeted Fine-tuning for NMT with Hybrid Losses,EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Popular Neural Machine Translation model training uses strategies like
backtranslation to improve BLEU scores, requiring large amounts of additional
data and training. We introduce a class of conditional
generative-discriminative hybrid losses that we use to fine-tune a trained
machine translation model. Through a combination of targeted fine-tuning
objectives and intuitive re-use of the training data the model has failed to
adequately learn from, we improve the model performance of both a
sentence-level and a contextual model without using any additional data. We
target the improvement of pronoun translations through our fine-tuning and
evaluate our models on a pronoun benchmark testset. Our sentence-level model
shows a 0.5 BLEU improvement on both the WMT14 and the IWSLT13 De-En testsets,
while our contextual model achieves the best results, improving from 31.81 to
32 BLEU on WMT14 De-En testset, and from 32.10 to 33.13 on the IWSLT13 De-En
testset, with corresponding improvements in pronoun translation. We further
show the generalizability of our method by reproducing the improvements on two
additional language pairs, Fr-En and Cs-En. Code available at
<https://github.com/ntunlp/pronoun-finetuning>.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 10:11:40 GMT'}]",2020-10-16,"[['Jwalapuram', 'Prathyusha', ''], ['Joty', 'Shafiq', ''], ['Shen', 'Youlin', '']]"
1363873,2010.07543,Yuanhe Tian,"Yuanhe Tian, Yan Song, Fei Xia, Tong Zhang",Improving Constituency Parsing with Span Attention,"Natural Language Processing. 13 pages, 6 figures. Findings of
  EMNLP-2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Constituency parsing is a fundamental and important task for natural language
understanding, where a good representation of contextual information can help
this task. N-grams, which is a conventional type of feature for contextual
information, have been demonstrated to be useful in many tasks, and thus could
also be beneficial for constituency parsing if they are appropriately modeled.
In this paper, we propose span attention for neural chart-based constituency
parsing to leverage n-gram information. Considering that current chart-based
parsers with Transformer-based encoder represent spans by subtraction of the
hidden states at the span boundaries, which may cause information loss
especially for long spans, we incorporate n-grams into span representations by
weighting them according to their contributions to the parsing process.
Moreover, we propose categorical span attention to further enhance the model by
weighting n-grams within different length categories, and thus benefit
long-sentence parsing. Experimental results on three widely used benchmark
datasets demonstrate the effectiveness of our approach in parsing Arabic,
Chinese, and English, where state-of-the-art performance is obtained by our
approach on all of them.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 06:36:39 GMT'}]",2020-10-16,"[['Tian', 'Yuanhe', ''], ['Song', 'Yan', ''], ['Xia', 'Fei', ''], ['Zhang', 'Tong', '']]"
1100246,1903.07860,Guangneng Hu,Guangneng Hu,Personalized Neural Embeddings for Collaborative Filtering with Text,"NAACL 2019 short papers, oral presentation",NAACL 2019,,,cs.IR cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Collaborative filtering (CF) is a core technique for recommender systems.
Traditional CF approaches exploit user-item relations (e.g., clicks, likes, and
views) only and hence they suffer from the data sparsity issue. Items are
usually associated with unstructured text such as article abstracts and product
reviews. We develop a Personalized Neural Embedding (PNE) framework to exploit
both interactions and words seamlessly. We learn such embeddings of users,
items, and words jointly, and predict user preferences on items based on these
learned representations. PNE estimates the probability that a user will like an
item by two terms---behavior factors and semantic factors. On two real-world
datasets, PNE shows better performance than four state-of-the-art baselines in
terms of three metrics. We also show that PNE learns meaningful word embeddings
by visualization.
","[{'version': 'v1', 'created': 'Tue, 19 Mar 2019 07:05:59 GMT'}]",2020-10-19,"[['Hu', 'Guangneng', '']]"
1341932,2009.00429,Jean-Marc Luck,"Anita Mehta, Jean-Marc Luck",Hearings and mishearings: decrypting the spoken word,"21 pages, 4 figures, 3 tables. To appear in Advances in Complex
  Systems","Adv. Complex Systems 23, 2050008 (2020)",10.1142/S0219525920500083,,cs.CL cond-mat.stat-mech,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a model of the speech perception of individual words in the
presence of mishearings. This phenomenological approach is based on concepts
used in linguistics, and provides a formalism that is universal across
languages. We put forward an efficient two-parameter form for the word length
distribution, and introduce a simple representation of mishearings, which we
use in our subsequent modelling of word recognition. In a context-free
scenario, word recognition often occurs via anticipation when, part-way into a
word, we can correctly guess its full form. We give a quantitative estimate of
this anticipation threshold when no mishearings occur, in terms of model
parameters. As might be expected, the whole anticipation effect disappears when
there are sufficiently many mishearings. Our global approach to the problem of
speech perception is in the spirit of an optimisation problem. We show for
instance that speech perception is easy when the word length is less than a
threshold, to be identified with a static transition, and hard otherwise. We
extend this to the dynamics of word recognition, proposing an intuitive
approach highlighting the distinction between individual, isolated mishearings
and clusters of contiguous mishearings. At least in some parameter range, a
dynamical transition is manifest well before the static transition is reached,
as is the case for many other examples of complex systems.
","[{'version': 'v1', 'created': 'Tue, 1 Sep 2020 13:58:51 GMT'}]",2020-10-19,"[['Mehta', 'Anita', ''], ['Luck', 'Jean-Marc', '']]"
1299072,2006.04558,Yi Ren,"Yi Ren, Chenxu Hu, Xu Tan, Tao Qin, Sheng Zhao, Zhou Zhao, Tie-Yan Liu",FastSpeech 2: Fast and High-Quality End-to-End Text to Speech,,,,,eess.AS cs.CL cs.LG cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Non-autoregressive text to speech (TTS) models such as FastSpeech can
synthesize speech significantly faster than previous autoregressive models with
comparable quality. The training of FastSpeech model relies on an
autoregressive teacher model for duration prediction (to provide more
information as input) and knowledge distillation (to simplify the data
distribution in output), which can ease the one-to-many mapping problem (i.e.,
multiple speech variations correspond to the same text) in TTS. However,
FastSpeech has several disadvantages: 1) the teacher-student distillation
pipeline is complicated and time-consuming, 2) the duration extracted from the
teacher model is not accurate enough, and the target mel-spectrograms distilled
from teacher model suffer from information loss due to data simplification,
both of which limit the voice quality. In this paper, we propose FastSpeech 2,
which addresses the issues in FastSpeech and better solves the one-to-many
mapping problem in TTS by 1) directly training the model with ground-truth
target instead of the simplified output from teacher, and 2) introducing more
variation information of speech (e.g., pitch, energy and more accurate
duration) as conditional inputs. Specifically, we extract duration, pitch and
energy from speech waveform and directly take them as conditional inputs in
training and use predicted values in inference. We further design FastSpeech
2s, which is the first attempt to directly generate speech waveform from text
in parallel, enjoying the benefit of fully end-to-end inference. Experimental
results show that 1) FastSpeech 2 achieves a 3x training speed-up over
FastSpeech, and FastSpeech 2s enjoys even faster inference speed; 2) FastSpeech
2 and 2s outperform FastSpeech in voice quality, and FastSpeech 2 can even
surpass autoregressive models. Audio samples are available at
https://fastspeech2.github.io/fastspeech2/.
","[{'version': 'v1', 'created': 'Mon, 8 Jun 2020 13:05:40 GMT'}, {'version': 'v2', 'created': 'Tue, 9 Jun 2020 09:33:54 GMT'}, {'version': 'v3', 'created': 'Mon, 22 Jun 2020 05:30:06 GMT'}, {'version': 'v4', 'created': 'Fri, 16 Oct 2020 14:34:02 GMT'}]",2020-10-19,"[['Ren', 'Yi', ''], ['Hu', 'Chenxu', ''], ['Tan', 'Xu', ''], ['Qin', 'Tao', ''], ['Zhao', 'Sheng', ''], ['Zhao', 'Zhou', ''], ['Liu', 'Tie-Yan', '']]"
1341259,2008.13537,He Zhao,"He Zhao, Dinh Phung, Viet Huynh, Trung Le, Wray Buntine",Neural Topic Model via Optimal Transport,,,,,cs.IR cs.CL cs.LG stat.ML,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Recently, Neural Topic Models (NTMs) inspired by variational autoencoders
have obtained increasingly research interest due to their promising results on
text analysis. However, it is usually hard for existing NTMs to achieve good
document representation and coherent/diverse topics at the same time. Moreover,
they often degrade their performance severely on short documents. The
requirement of reparameterisation could also comprise their training quality
and model flexibility. To address these shortcomings, we present a new neural
topic model via the theory of optimal transport (OT). Specifically, we propose
to learn the topic distribution of a document by directly minimising its OT
distance to the document's word distributions. Importantly, the cost matrix of
the OT distance models the weights between topics and words, which is
constructed by the distances between topics and words in an embedding space.
Our proposed model can be trained efficiently with a differentiable loss.
Extensive experiments show that our framework significantly outperforms the
state-of-the-art NTMs on discovering more coherent and diverse topics and
deriving better document representations for both regular and short texts.
","[{'version': 'v1', 'created': 'Wed, 12 Aug 2020 06:37:09 GMT'}, {'version': 'v2', 'created': 'Fri, 16 Oct 2020 01:49:09 GMT'}]",2020-10-19,"[['Zhao', 'He', ''], ['Phung', 'Dinh', ''], ['Huynh', 'Viet', ''], ['Le', 'Trung', ''], ['Buntine', 'Wray', '']]"
1358168,2010.01838,Yifan Gao,"Yifan Gao, Chien-Sheng Wu, Jingjing Li, Shafiq Joty, Steven C.H. Hoi,
  Caiming Xiong, Irwin King, Michael R. Lyu","Discern: Discourse-Aware Entailment Reasoning Network for Conversational
  Machine Reading","EMNLP 2020 main conference, 11 pages, 3 Figures",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Document interpretation and dialog understanding are the two major challenges
for conversational machine reading. In this work, we propose Discern, a
discourse-aware entailment reasoning network to strengthen the connection and
enhance the understanding for both document and dialog. Specifically, we split
the document into clause-like elementary discourse units (EDU) using a
pre-trained discourse segmentation model, and we train our model in a
weakly-supervised manner to predict whether each EDU is entailed by the user
feedback in a conversation. Based on the learned EDU and entailment
representations, we either reply to the user our final decision
""yes/no/irrelevant"" of the initial question, or generate a follow-up question
to inquiry more information. Our experiments on the ShARC benchmark (blind,
held-out test set) show that Discern achieves state-of-the-art results of 78.3%
macro-averaged accuracy on decision making and 64.0 BLEU1 on follow-up question
generation. Code and models are released at
https://github.com/Yifan-Gao/Discern.
","[{'version': 'v1', 'created': 'Mon, 5 Oct 2020 07:49:51 GMT'}, {'version': 'v2', 'created': 'Tue, 6 Oct 2020 07:16:32 GMT'}, {'version': 'v3', 'created': 'Fri, 16 Oct 2020 10:06:46 GMT'}]",2020-10-19,"[['Gao', 'Yifan', ''], ['Wu', 'Chien-Sheng', ''], ['Li', 'Jingjing', ''], ['Joty', 'Shafiq', ''], ['Hoi', 'Steven C. H.', ''], ['Xiong', 'Caiming', ''], ['King', 'Irwin', ''], ['Lyu', 'Michael R.', '']]"
1297716,2006.03202,Sharon Levy,Sharon Levy and William Yang Wang,Cross-lingual Transfer Learning for COVID-19 Outbreak Alignment,,,,,cs.CL cs.LG cs.SI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The spread of COVID-19 has become a significant and troubling aspect of
society in 2020. With millions of cases reported across countries, new
outbreaks have occurred and followed patterns of previously affected areas.
Many disease detection models do not incorporate the wealth of social media
data that can be utilized for modeling and predicting its spread. In this case,
it is useful to ask, can we utilize this knowledge in one country to model the
outbreak in another? To answer this, we propose the task of cross-lingual
transfer learning for epidemiological alignment. Utilizing both macro and micro
text features, we train on Italy's early COVID-19 outbreak through Twitter and
transfer to several other countries. Our experiments show strong results with
up to 0.85 Spearman correlation in cross-country predictions.
","[{'version': 'v1', 'created': 'Fri, 5 Jun 2020 02:04:25 GMT'}, {'version': 'v2', 'created': 'Thu, 15 Oct 2020 22:37:43 GMT'}]",2020-10-19,"[['Levy', 'Sharon', ''], ['Wang', 'William Yang', '']]"
1350069,2009.08566,Tejas Gokhale,Tejas Gokhale and Pratyay Banerjee and Chitta Baral and Yezhou Yang,"MUTANT: A Training Paradigm for Out-of-Distribution Generalization in
  Visual Question Answering","Accepted to EMNLP 2020, Long Papers",,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While progress has been made on the visual question answering leaderboards,
models often utilize spurious correlations and priors in datasets under the
i.i.d. setting. As such, evaluation on out-of-distribution (OOD) test samples
has emerged as a proxy for generalization. In this paper, we present MUTANT, a
training paradigm that exposes the model to perceptually similar, yet
semantically distinct mutations of the input, to improve OOD generalization,
such as the VQA-CP challenge. Under this paradigm, models utilize a
consistency-constrained training objective to understand the effect of semantic
changes in input (question-image pair) on the output (answer). Unlike existing
methods on VQA-CP, MUTANT does not rely on the knowledge about the nature of
train and test answer distributions. MUTANT establishes a new state-of-the-art
accuracy on VQA-CP with a $10.57\%$ improvement. Our work opens up avenues for
the use of semantic input mutations for OOD generalization in question
answering.
","[{'version': 'v1', 'created': 'Fri, 18 Sep 2020 00:22:54 GMT'}, {'version': 'v2', 'created': 'Fri, 16 Oct 2020 01:53:08 GMT'}]",2020-10-19,"[['Gokhale', 'Tejas', ''], ['Banerjee', 'Pratyay', ''], ['Baral', 'Chitta', ''], ['Yang', 'Yezhou', '']]"
1354605,2009.13102,Xian Li,"Xian Li, Asa Cooper Stickland, Yuqing Tang, and Xiang Kong",Deep Transformers with Latent Depth,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The Transformer model has achieved state-of-the-art performance in many
sequence modeling tasks. However, how to leverage model capacity with large or
variable depths is still an open challenge. We present a probabilistic
framework to automatically learn which layer(s) to use by learning the
posterior distributions of layer selection. As an extension of this framework,
we propose a novel method to train one shared Transformer network for
multilingual machine translation with different layer selection posteriors for
each language pair. The proposed method alleviates the vanishing gradient issue
and enables stable training of deep Transformers (e.g. 100 layers). We evaluate
on WMT English-German machine translation and masked language modeling tasks,
where our method outperforms existing approaches for training deeper
Transformers. Experiments on multilingual machine translation demonstrate that
this approach can effectively leverage increased model capacity and bring
universal improvement for both many-to-one and one-to-many translation with
diverse language pairs.
","[{'version': 'v1', 'created': 'Mon, 28 Sep 2020 07:13:23 GMT'}, {'version': 'v2', 'created': 'Fri, 16 Oct 2020 03:50:56 GMT'}]",2020-10-19,"[['Li', 'Xian', ''], ['Stickland', 'Asa Cooper', ''], ['Tang', 'Yuqing', ''], ['Kong', 'Xiang', '']]"
1358705,2010.02375,Robert Hawkins,"Robert D. Hawkins, Takateru Yamakoshi, Thomas L. Griffiths, Adele E.
  Goldberg",Investigating representations of verb bias in neural language models,Accepted to EMNLP,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Languages typically provide more than one grammatical construction to express
certain types of messages. A speaker's choice of construction is known to
depend on multiple factors, including the choice of main verb -- a phenomenon
known as \emph{verb bias}. Here we introduce DAIS, a large benchmark dataset
containing 50K human judgments for 5K distinct sentence pairs in the English
dative alternation. This dataset includes 200 unique verbs and systematically
varies the definiteness and length of arguments. We use this dataset, as well
as an existing corpus of naturally occurring data, to evaluate how well recent
neural language models capture human preferences. Results show that larger
models perform better than smaller models, and transformer architectures (e.g.
GPT-2) tend to out-perform recurrent architectures (e.g. LSTMs) even under
comparable parameter and training settings. Additional analyses of internal
feature representations suggest that transformers may better integrate specific
lexical information with grammatical constructions.
","[{'version': 'v1', 'created': 'Mon, 5 Oct 2020 22:39:08 GMT'}, {'version': 'v2', 'created': 'Thu, 15 Oct 2020 19:37:48 GMT'}]",2020-10-19,"[['Hawkins', 'Robert D.', ''], ['Yamakoshi', 'Takateru', ''], ['Griffiths', 'Thomas L.', ''], ['Goldberg', 'Adele E.', '']]"
1180389,1909.10351,Yichun Yin,"Xiaoqi Jiao, Yichun Yin, Lifeng Shang, Xin Jiang, Xiao Chen, Linlin
  Li, Fang Wang and Qun Liu",TinyBERT: Distilling BERT for Natural Language Understanding,"Findings of EMNLP 2020; results have been updated; code and model:
  https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/TinyBERT",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language model pre-training, such as BERT, has significantly improved the
performances of many natural language processing tasks. However, pre-trained
language models are usually computationally expensive, so it is difficult to
efficiently execute them on resource-restricted devices. To accelerate
inference and reduce model size while maintaining accuracy, we first propose a
novel Transformer distillation method that is specially designed for knowledge
distillation (KD) of the Transformer-based models. By leveraging this new KD
method, the plenty of knowledge encoded in a large teacher BERT can be
effectively transferred to a small student Tiny-BERT. Then, we introduce a new
two-stage learning framework for TinyBERT, which performs Transformer
distillation at both the pretraining and task-specific learning stages. This
framework ensures that TinyBERT can capture he general-domain as well as the
task-specific knowledge in BERT.
  TinyBERT with 4 layers is empirically effective and achieves more than 96.8%
the performance of its teacher BERTBASE on GLUE benchmark, while being 7.5x
smaller and 9.4x faster on inference. TinyBERT with 4 layers is also
significantly better than 4-layer state-of-the-art baselines on BERT
distillation, with only about 28% parameters and about 31% inference time of
them. Moreover, TinyBERT with 6 layers performs on-par with its teacher
BERTBASE.
","[{'version': 'v1', 'created': 'Mon, 23 Sep 2019 13:05:35 GMT'}, {'version': 'v2', 'created': 'Tue, 24 Sep 2019 12:39:36 GMT'}, {'version': 'v3', 'created': 'Tue, 3 Dec 2019 01:29:39 GMT'}, {'version': 'v4', 'created': 'Wed, 4 Dec 2019 01:50:34 GMT'}, {'version': 'v5', 'created': 'Fri, 16 Oct 2020 02:12:46 GMT'}]",2020-10-19,"[['Jiao', 'Xiaoqi', ''], ['Yin', 'Yichun', ''], ['Shang', 'Lifeng', ''], ['Jiang', 'Xin', ''], ['Chen', 'Xiao', ''], ['Li', 'Linlin', ''], ['Wang', 'Fang', ''], ['Liu', 'Qun', '']]"
1308060,2006.13546,Stefan Heinrich,"Stefan Heinrich, Yuan Yao, Tobias Hinz, Zhiyuan Liu, Thomas Hummel,
  Matthias Kerzel, Cornelius Weber, and Stefan Wermter",Crossmodal Language Grounding in an Embodied Neurocognitive Model,,"Frontiers in Neurorobotics, vol 14(52), 2020",10.3389/fnbot.2020.00052,,cs.NE cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Human infants are able to acquire natural language seemingly easily at an
early age. Their language learning seems to occur simultaneously with learning
other cognitive functions as well as with playful interactions with the
environment and caregivers. From a neuroscientific perspective, natural
language is embodied, grounded in most, if not all, sensory and sensorimotor
modalities, and acquired by means of crossmodal integration. However,
characterising the underlying mechanisms in the brain is difficult and
explaining the grounding of language in crossmodal perception and action
remains challenging. In this paper, we present a neurocognitive model for
language grounding which reflects bio-inspired mechanisms such as an implicit
adaptation of timescales as well as end-to-end multimodal abstraction. It
addresses developmental robotic interaction and extends its learning
capabilities using larger-scale knowledge-based data. In our scenario, we
utilise the humanoid robot NICO in obtaining the EMIL data collection, in which
the cognitive robot interacts with objects in a children's playground
environment while receiving linguistic labels from a caregiver. The model
analysis shows that crossmodally integrated representations are sufficient for
acquiring language merely from sensory input through interaction with objects
in an environment. The representations self-organise hierarchically and embed
temporal and spatial information through composition and decomposition. This
model can also provide the basis for further crossmodal integration of
perceptually grounded cognitive representations.
","[{'version': 'v1', 'created': 'Wed, 24 Jun 2020 08:12:09 GMT'}, {'version': 'v2', 'created': 'Fri, 16 Oct 2020 08:27:34 GMT'}]",2020-10-19,"[['Heinrich', 'Stefan', ''], ['Yao', 'Yuan', ''], ['Hinz', 'Tobias', ''], ['Liu', 'Zhiyuan', ''], ['Hummel', 'Thomas', ''], ['Kerzel', 'Matthias', ''], ['Weber', 'Cornelius', ''], ['Wermter', 'Stefan', '']]"
1359966,2010.03636,Anthony Chen,"Anthony Chen, Gabriel Stanovsky, Sameer Singh and Matt Gardner","MOCHA: A Dataset for Training and Evaluating Generative Reading
  Comprehension Metrics",,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Posing reading comprehension as a generation problem provides a great deal of
flexibility, allowing for open-ended questions with few restrictions on
possible answers. However, progress is impeded by existing generation metrics,
which rely on token overlap and are agnostic to the nuances of reading
comprehension. To address this, we introduce a benchmark for training and
evaluating generative reading comprehension metrics: MOdeling Correctness with
Human Annotations. MOCHA contains 40K human judgement scores on model outputs
from 6 diverse question answering datasets and an additional set of minimal
pairs for evaluation. Using MOCHA, we train a Learned Evaluation metric for
Reading Comprehension, LERC, to mimic human judgement scores. LERC outperforms
baseline metrics by 10 to 36 absolute Pearson points on held-out annotations.
When we evaluate robustness on minimal pairs, LERC achieves 80% accuracy,
outperforming baselines by 14 to 26 absolute percentage points while leaving
significant room for improvement. MOCHA presents a challenging problem for
developing accurate and robust generative reading comprehension metrics.
","[{'version': 'v1', 'created': 'Wed, 7 Oct 2020 20:22:54 GMT'}, {'version': 'v2', 'created': 'Thu, 15 Oct 2020 18:23:18 GMT'}]",2020-10-19,"[['Chen', 'Anthony', ''], ['Stanovsky', 'Gabriel', ''], ['Singh', 'Sameer', ''], ['Gardner', 'Matt', '']]"
1346468,2009.04965,Meng-Jiun Chiou,"Meng-Jiun Chiou, Roger Zimmermann, Jiashi Feng","Visual Relationship Detection with Visual-Linguistic Knowledge from
  Multimodal Representations","10 pages, 5 figures, 4 tables",,,,cs.CV cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Visual relationship detection aims to reason over relationships among salient
objects in images, which has drawn increasing attention over the past few
years. Inspired by human reasoning mechanism, it is believed that external
visual commonsense knowledge is beneficial for reasoning visual relationships
of objects in images, which is however rarely considered in existing methods.
In this paper, we propose a novel approach named Relational Visual-Linguistic
Bidirectional Encoder Representations from Transformers (RVL-BERT), which
performs relational reasoning with both visual and language commonsense
knowledge learned via self-supervised pre-training with multimodal
representations. RVL-BERT also uses an effective spatial module and a novel
mask attention module to explicitly capture spatial information among the
objects. Moreover, our model decouples object detection from visual
relationship recognition by taking in object names directly, enabling it to be
used on top of any object detection system. We show through quantitative and
qualitative experiments that, with the transferred knowledge and novel modules,
RVL-BERT achieves competitive results on two challenging visual relationship
detection datasets. The source code will be publicly available soon.
","[{'version': 'v1', 'created': 'Thu, 10 Sep 2020 16:15:09 GMT'}, {'version': 'v2', 'created': 'Fri, 16 Oct 2020 14:01:49 GMT'}]",2020-10-19,"[['Chiou', 'Meng-Jiun', ''], ['Zimmermann', 'Roger', ''], ['Feng', 'Jiashi', '']]"
1279108,2004.14338,Jack Hessel,"Jack Hessel, Zhenhai Zhu, Bo Pang, Radu Soricut","Beyond Instructional Videos: Probing for More Diverse Visual-Textual
  Grounding on YouTube",11 pages including supplementary materials,Published in EMNLP 2020,,,cs.CL cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pretraining from unlabelled web videos has quickly become the de-facto means
of achieving high performance on many video understanding tasks. Features are
learned via prediction of grounded relationships between visual content and
automatic speech recognition (ASR) tokens. However, prior pretraining work has
been limited to only instructional videos; a priori, we expect this domain to
be relatively ""easy:"" speakers in instructional videos will often reference the
literal objects/actions being depicted. We ask: can similar models be trained
on more diverse video corpora? And, if so, what types of videos are ""grounded""
and what types are not? We fit a representative pretraining model to the
diverse YouTube8M dataset, and study its success and failure cases. We find
that visual-textual grounding is indeed possible across previously unexplored
video categories, and that pretraining on a more diverse set results in
representations that generalize to both non-instructional and instructional
domains.
","[{'version': 'v1', 'created': 'Wed, 29 Apr 2020 17:10:10 GMT'}, {'version': 'v2', 'created': 'Fri, 16 Oct 2020 17:30:51 GMT'}]",2020-10-19,"[['Hessel', 'Jack', ''], ['Zhu', 'Zhenhai', ''], ['Pang', 'Bo', ''], ['Soricut', 'Radu', '']]"
1364317,2010.07987,Nadezhda Chirkova,"Nadezhda Chirkova, Sergey Troshin",Empirical Study of Transformers for Source Code,,,,,cs.LG cs.CL cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Initially developed for natural language processing (NLP), Transformers are
now widely used for source code processing, due to the format similarity
between source code and text. In contrast to natural language, source code is
strictly structured, i. e. follows the syntax of the programming language.
Several recent works develop Transformer modifications for capturing syntactic
information in source code. The drawback of these works is that they do not
compare to each other and all consider different tasks. In this work, we
conduct a thorough empirical study of the capabilities of Transformers to
utilize syntactic information in different tasks. We consider three tasks (code
completion, function naming and bug fixing) and re-implement different
syntax-capturing modifications in a unified framework. We show that
Transformers are able to make meaningful predictions based purely on syntactic
information and underline the best practices of taking the syntactic
information into account for improving the performance of the model.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 19:09:15 GMT'}]",2020-10-19,"[['Chirkova', 'Nadezhda', ''], ['Troshin', 'Sergey', '']]"
1364653,2010.08323,Kuldeep Singh,"Saeedeh Shekarpour, Abhishek Nadgeri and Kuldeep Singh","QA2Explanation: Generating and Evaluating Explanations for Question
  Answering Systems over Knowledge Graph","Accepted in IntEx-SemPar: Interactive and Executable Semantic Parsing
  EMNLP 2020 Workshop",EMNLP2020 Workshop:IntEx-SemPar,10.18653/v1/P17,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In the era of Big Knowledge Graphs, Question Answering (QA) systems have
reached a milestone in their performance and feasibility. However, their
applicability, particularly in specific domains such as the biomedical domain,
has not gained wide acceptance due to their ""black box"" nature, which hinders
transparency, fairness, and accountability of QA systems. Therefore, users are
unable to understand how and why particular questions have been answered,
whereas some others fail. To address this challenge, in this paper, we develop
an automatic approach for generating explanations during various stages of a
pipeline-based QA system. Our approach is a supervised and automatic approach
which considers three classes (i.e., success, no answer, and wrong answer) for
annotating the output of involved QA components. Upon our prediction, a
template explanation is chosen and integrated into the output of the
corresponding component. To measure the effectiveness of the approach, we
conducted a user survey as to how non-expert users perceive our generated
explanations. The results of our study show a significant increase in the four
dimensions of the human factor from the Human-computer interaction community.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 11:32:12 GMT'}]",2020-10-19,"[['Shekarpour', 'Saeedeh', ''], ['Nadgeri', 'Abhishek', ''], ['Singh', 'Kuldeep', '']]"
967894,1804.06201,Herbert Hu,"Guangneng Hu, Yu Zhang, Qiang Yang","LCMR: Local and Centralized Memories for Collaborative Filtering with
  Unstructured Text",,,,,cs.IR cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Collaborative filtering (CF) is the key technique for recommender systems.
Pure CF approaches exploit the user-item interaction data (e.g., clicks, likes,
and views) only and suffer from the sparsity issue. Items are usually
associated with content information such as unstructured text (e.g., abstracts
of articles and reviews of products). CF can be extended to leverage text. In
this paper, we develop a unified neural framework to exploit interaction data
and content information seamlessly. The proposed framework, called LCMR, is
based on memory networks and consists of local and centralized memories for
exploiting content information and interaction data, respectively. By modeling
content information as local memories, LCMR attentively learns what to exploit
with the guidance of user-item interaction. On real-world datasets, LCMR shows
better performance by comparing with various baselines in terms of the hit
ratio and NDCG metrics. We further conduct analyses to understand how local and
centralized memories work for the proposed framework.
","[{'version': 'v1', 'created': 'Tue, 17 Apr 2018 12:32:23 GMT'}, {'version': 'v2', 'created': 'Fri, 20 Apr 2018 16:23:00 GMT'}]",2020-10-19,"[['Hu', 'Guangneng', ''], ['Zhang', 'Yu', ''], ['Yang', 'Qiang', '']]"
1364572,2010.08242,Shusheng Xu,"Shusheng Xu, Xingxing Zhang, Yi Wu, Furu Wei and Ming Zhou","Unsupervised Extractive Summarization by Pre-training Hierarchical
  Transformers","9 pages, 4 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Unsupervised extractive document summarization aims to select important
sentences from a document without using labeled summaries during training.
Existing methods are mostly graph-based with sentences as nodes and edge
weights measured by sentence similarities. In this work, we find that
transformer attentions can be used to rank sentences for unsupervised
extractive summarization. Specifically, we first pre-train a hierarchical
transformer model using unlabeled documents only. Then we propose a method to
rank sentences using sentence-level self-attentions and pre-training
objectives. Experiments on CNN/DailyMail and New York Times datasets show our
model achieves state-of-the-art performance on unsupervised summarization. We
also find in experiments that our model is less dependent on sentence
positions. When using a linear combination of our model and a recent
unsupervised model explicitly modeling sentence positions, we obtain even
better results.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 08:44:09 GMT'}]",2020-10-19,"[['Xu', 'Shusheng', ''], ['Zhang', 'Xingxing', ''], ['Wu', 'Yi', ''], ['Wei', 'Furu', ''], ['Zhou', 'Ming', '']]"
1364595,2010.08265,Qiang Wang,"Qiang Wang, Tong Xiao, Jingbo Zhu","Training Flexible Depth Model by Multi-Task Learning for Neural Machine
  Translation",Accepted at Findings of EMNLP 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The standard neural machine translation model can only decode with the same
depth configuration as training. Restricted by this feature, we have to deploy
models of various sizes to maintain the same translation latency, because the
hardware conditions on different terminal devices (e.g., mobile phones) may
vary greatly. Such individual training leads to increased model maintenance
costs and slower model iterations, especially for the industry. In this work,
we propose to use multi-task learning to train a flexible depth model that can
adapt to different depth configurations during inference. Experimental results
show that our approach can simultaneously support decoding in 24 depth
configurations and is superior to the individual training and another flexible
depth model training method -- LayerDrop.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 09:37:27 GMT'}]",2020-10-19,"[['Wang', 'Qiang', ''], ['Xiao', 'Tong', ''], ['Zhu', 'Jingbo', '']]"
1364599,2010.08269,Mark Berger,"Mark Berger, Jakub Zavrel, Paul Groth",Effective Distributed Representations for Academic Expert Search,"To be published in the Scholarly Document Processing 2020 Workshop @
  EMNLP 2020 proceedings",,,,cs.IR cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Expert search aims to find and rank experts based on a user's query. In
academia, retrieving experts is an efficient way to navigate through a large
amount of academic knowledge. Here, we study how different distributed
representations of academic papers (i.e. embeddings) impact academic expert
retrieval. We use the Microsoft Academic Graph dataset and experiment with
different configurations of a document-centric voting model for retrieval. In
particular, we explore the impact of the use of contextualized embeddings on
search performance. We also present results for paper embeddings that
incorporate citation information through retrofitting. Additionally,
experiments are conducted using different techniques for assigning author
weights based on author order. We observe that using contextual embeddings
produced by a transformer model trained for sentence similarity tasks produces
the most effective paper representations for document-centric expert retrieval.
However, retrofitting the paper embeddings and using elaborate author
contribution weighting strategies did not improve retrieval performance.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 09:43:18 GMT'}]",2020-10-19,"[['Berger', 'Mark', ''], ['Zavrel', 'Jakub', ''], ['Groth', 'Paul', '']]"
1364605,2010.08275,Hila Gonen,"Hila Gonen, Shauli Ravfogel, Yanai Elazar, Yoav Goldberg","It's not Greek to mBERT: Inducing Word-Level Translations from
  Multilingual BERT",BlackboxNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent works have demonstrated that multilingual BERT (mBERT) learns rich
cross-lingual representations, that allow for transfer across languages. We
study the word-level translation information embedded in mBERT and present two
simple methods that expose remarkable translation capabilities with no
fine-tuning. The results suggest that most of this information is encoded in a
non-linear way, while some of it can also be recovered with purely linear
tools. As part of our analysis, we test the hypothesis that mBERT learns
representations which contain both a language-encoding component and an
abstract, cross-lingual component, and explicitly identify an empirical
language-identity subspace within mBERT representations.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 09:49:32 GMT'}]",2020-10-19,"[['Gonen', 'Hila', ''], ['Ravfogel', 'Shauli', ''], ['Elazar', 'Yanai', ''], ['Goldberg', 'Yoav', '']]"
1364648,2010.08318,Andrew Moore,Andrew Moore and Jeremy Barnes,"Multi-task Learning of Negation and Speculation for Targeted Sentiment
  Classification",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The majority of work in targeted sentiment analysis has concentrated on
finding better methods to improve the overall results. Within this paper we
show that these models are not robust to linguistic phenomena, specifically
negation and speculation. In this paper, we propose a multi-task learning
method to incorporate information from syntactic and semantic auxiliary tasks,
including negation and speculation scope detection, to create models that are
more robust to these phenomena. Further we create two challenge datasets to
evaluate model performance on negated and speculative samples. We find that
multi-task models and transfer learning from a language model can improve
performance on these challenge datasets. However the results indicate that
there is still much room for improvement in making our models more robust to
linguistic phenomena such as negation and speculation.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 11:20:03 GMT'}]",2020-10-19,"[['Moore', 'Andrew', ''], ['Barnes', 'Jeremy', '']]"
1364649,2010.08319,Tim Nugent,"Tim Nugent, Nicole Stelea and Jochen L. Leidner","Detecting ESG topics using domain-specific language models and data
  augmentation approaches","11 pages, 5 tables, 1 figure",,,,cs.CL cs.IR cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Despite recent advances in deep learning-based language modelling, many
natural language processing (NLP) tasks in the financial domain remain
challenging due to the paucity of appropriately labelled data. Other issues
that can limit task performance are differences in word distribution between
the general corpora - typically used to pre-train language models - and
financial corpora, which often exhibit specialized language and symbology.
Here, we investigate two approaches that may help to mitigate these issues.
Firstly, we experiment with further language model pre-training using large
amounts of in-domain data from business and financial news. We then apply
augmentation approaches to increase the size of our dataset for model
fine-tuning. We report our findings on an Environmental, Social and Governance
(ESG) controversies dataset and demonstrate that both approaches are beneficial
to accuracy in classification tasks.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 11:20:07 GMT'}]",2020-10-19,"[['Nugent', 'Tim', ''], ['Stelea', 'Nicole', ''], ['Leidner', 'Jochen L.', '']]"
1279640,2004.14870,Samson Tan,"Samson Tan, Shafiq Joty, Lav R. Varshney, Min-Yen Kan","Mind Your Inflections! Improving NLP for Non-Standard Englishes with
  Base-Inflection Encoding","To appear in the Proceedings of the 2020 Conference on Empirical
  Methods in Natural Language Processing",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Inflectional variation is a common feature of World Englishes such as
Colloquial Singapore English and African American Vernacular English. Although
comprehension by human readers is usually unimpaired by non-standard
inflections, current NLP systems are not yet robust. We propose Base-Inflection
Encoding (BITE), a method to tokenize English text by reducing inflected words
to their base forms before reinjecting the grammatical information as special
symbols. Fine-tuning pretrained NLP models for downstream tasks using our
encoding defends against inflectional adversaries while maintaining performance
on clean data. Models using BITE generalize better to dialects with
non-standard inflections without explicit training and translation models
converge faster when trained with BITE. Finally, we show that our encoding
improves the vocabulary efficiency of popular data-driven subword tokenizers.
Since there has been no prior work on quantitatively evaluating vocabulary
efficiency, we propose metrics to do so.
","[{'version': 'v1', 'created': 'Thu, 30 Apr 2020 15:15:40 GMT'}, {'version': 'v2', 'created': 'Sun, 11 Oct 2020 18:54:40 GMT'}, {'version': 'v3', 'created': 'Fri, 16 Oct 2020 05:20:28 GMT'}]",2020-10-19,"[['Tan', 'Samson', ''], ['Joty', 'Shafiq', ''], ['Varshney', 'Lav R.', ''], ['Kan', 'Min-Yen', '']]"
1364676,2010.08346,Vili Hatonen,"Vili H\""at\""onen and Fiona Melzer","From Talk to Action with Accountability: Monitoring the Public
  Discussion of Finnish Decision-Makers with Deep Neural Networks and Topic
  Modelling","Submitted to NeurIPS 2020 Workshop Tackling Climate Change with
  Machine Learning",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Decades of research on climate have provided a consensus that human activity
has changed the climate and we are currently heading into a climate crisis.
Many tools and methods, some of which utilize machine learning, have been
developed to monitor, evaluate, and predict the changing climate and its
effects on societies. However, the mere existence of tools and increased
awareness have not led to swift action to reduce emissions and mitigate climate
change. Politicians and other policy makers lack the initiative to move from
talking about the climate to concrete climate action. In this work, we
contribute to the efforts of holding decision makers accountable by describing
a system which digests politicians' speeches and statements into a topic
summary. We propose a multi-source hybrid latent Dirichlet allocation model
which can process the large number of publicly available reports, social media
posts, speeches, and other documents of Finnish politicians, providing
transparency and accountability towards the general public.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 12:21:01 GMT'}]",2020-10-19,"[['Hätönen', 'Vili', ''], ['Melzer', 'Fiona', '']]"
1364742,2010.08412,Rumen Dangovski,"Matthew Khoury and Rumen Dangovski and Longwu Ou and Preslav Nakov and
  Yichen Shen and Li Jing","Vector-Vector-Matrix Architecture: A Novel Hardware-Aware Framework for
  Low-Latency Inference in NLP Applications","To appear at the 2020 Conference on Empirical Methods in Natural
  Language Processing (EMNLP '20), November 16-20, 2020, NMT, AI accelerators,
  co-design, TPU, OPU, 10 pages, 3 figures, 4 tables",,,,cs.CL cs.AR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Deep neural networks have become the standard approach to building reliable
Natural Language Processing (NLP) applications, ranging from Neural Machine
Translation (NMT) to dialogue systems. However, improving accuracy by
increasing the model size requires a large number of hardware computations,
which can slow down NLP applications significantly at inference time. To
address this issue, we propose a novel vector-vector-matrix architecture
(VVMA), which greatly reduces the latency at inference time for NMT. This
architecture takes advantage of specialized hardware that has low-latency
vector-vector operations and higher-latency vector-matrix operations. It also
reduces the number of parameters and FLOPs for virtually all models that rely
on efficient matrix multipliers without significantly impacting accuracy. We
present empirical results suggesting that our framework can reduce the latency
of sequence-to-sequence and Transformer models used for NMT by a factor of
four. Finally, we show evidence suggesting that our VVMA extends to other
domains, and we discuss novel hardware for its efficient use.
","[{'version': 'v1', 'created': 'Tue, 6 Oct 2020 16:54:08 GMT'}]",2020-10-19,"[['Khoury', 'Matthew', ''], ['Dangovski', 'Rumen', ''], ['Ou', 'Longwu', ''], ['Nakov', 'Preslav', ''], ['Shen', 'Yichen', ''], ['Jing', 'Li', '']]"
1364752,2010.08422,Wissam Siblini,"Wissam Siblini, Mohamed Challal and Charlotte Pasqual","Delaying Interaction Layers in Transformer-based Encoders for Efficient
  Open Domain Question Answering",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Open Domain Question Answering (ODQA) on a large-scale corpus of documents
(e.g. Wikipedia) is a key challenge in computer science. Although
transformer-based language models such as Bert have shown on SQuAD the ability
to surpass humans for extracting answers in small passages of text, they suffer
from their high complexity when faced to a much larger search space. The most
common way to tackle this problem is to add a preliminary Information Retrieval
step to heavily filter the corpus and only keep the relevant passages. In this
paper, we propose a more direct and complementary solution which consists in
applying a generic change in the architecture of transformer-based models to
delay the attention between subparts of the input and allow a more efficient
management of computations. The resulting variants are competitive with the
original models on the extractive task and allow, on the ODQA setting, a
significant speedup and even a performance improvement in many cases.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 14:36:38 GMT'}]",2020-10-19,"[['Siblini', 'Wissam', ''], ['Challal', 'Mohamed', ''], ['Pasqual', 'Charlotte', '']]"
1364762,2010.08432,Haozhou Wang,"Haozhou Wang, James Henderson, Paola Merlo",Multi-Adversarial Learning for Cross-Lingual Word Embeddings,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Generative adversarial networks (GANs) have succeeded in inducing
cross-lingual word embeddings -- maps of matching words across languages --
without supervision. Despite these successes, GANs' performance for the
difficult case of distant languages is still not satisfactory. These
limitations have been explained by GANs' incorrect assumption that source and
target embedding spaces are related by a single linear mapping and are
approximately isomorphic. We assume instead that, especially across distant
languages, the mapping is only piece-wise linear, and propose a
multi-adversarial learning method. This novel method induces the seed
cross-lingual dictionary through multiple mappings, each induced to fit the
mapping for one subspace. Our experiments on unsupervised bilingual lexicon
induction show that this method improves performance over previous
single-mapping methods, especially for distant languages.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 14:54:28 GMT'}]",2020-10-19,"[['Wang', 'Haozhou', ''], ['Henderson', 'James', ''], ['Merlo', 'Paola', '']]"
1364855,2010.08525,Hongming Zhang,"Hongming Zhang, Muhao Chen, Haoyu Wang, Yangqiu Song, Dan Roth",Analogous Process Structure Induction for Sub-event Sequence Prediction,Accepted by EMNLP 2020,,,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Computational and cognitive studies of event understanding suggest that
identifying, comprehending, and predicting events depend on having structured
representations of a sequence of events and on conceptualizing (abstracting)
its components into (soft) event categories. Thus, knowledge about a known
process such as ""buying a car"" can be used in the context of a new but
analogous process such as ""buying a house"". Nevertheless, most event
understanding work in NLP is still at the ground level and does not consider
abstraction. In this paper, we propose an Analogous Process Structure Induction
APSI framework, which leverages analogies among processes and conceptualization
of sub-event instances to predict the whole sub-event sequence of previously
unseen open-domain processes. As our experiments and analysis indicate, APSI
supports the generation of meaningful sub-event sequences for unseen processes
and can help predict missing events.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 17:35:40 GMT'}]",2020-10-19,"[['Zhang', 'Hongming', ''], ['Chen', 'Muhao', ''], ['Wang', 'Haoyu', ''], ['Song', 'Yangqiu', ''], ['Roth', 'Dan', '']]"
1364870,2010.08540,Kyle Gorman,Angie Waller and Kyle Gorman,Detecting Objectifying Language in Online Professor Reviews,"To appear at the 6th Workshop on Noisy User-generated Text, a
  workshop of EMNLP 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Student reviews often make reference to professors' physical appearances.
Until recently RateMyProfessors.com, the website of this study's focus, used a
design feature to encourage a ""hot or not"" rating of college professors. In the
wake of recent #MeToo and #TimesUp movements, social awareness of the
inappropriateness of these reviews has grown; however, objectifying comments
remain and continue to be posted in this online context. We describe two
supervised text classifiers for detecting objectifying commentary in professor
reviews. We then ensemble these classifiers and use the resulting model to
track objectifying commentary at scale. We measure correlations between
objectifying commentary, changes to the review website interface, and teacher
gender across a ten-year period.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 17:49:59 GMT'}]",2020-10-19,"[['Waller', 'Angie', ''], ['Gorman', 'Kyle', '']]"
1364872,2010.08542,Adrian de Wynter,Adrian de Wynter,Mischief: A Simple Black-Box Attack Against Transformer Architectures,Technical report,,,,cs.CL cs.CR cs.LG,http://creativecommons.org/licenses/by/4.0/,"  We introduce Mischief, a simple and lightweight method to produce a class of
human-readable, realistic adversarial examples for language models. We perform
exhaustive experimentations of our algorithm on four transformer-based
architectures, across a variety of downstream tasks, as well as under varying
concentrations of said examples. Our findings show that the presence of
Mischief-generated adversarial samples in the test set significantly degrades
(by up to $20\%$) the performance of these models with respect to their
reported baselines. Nonetheless, we also demonstrate that, by including similar
examples in the training set, it is possible to restore the baseline scores on
the adversarial test set. Moreover, for certain tasks, the models trained with
Mischief set show a modest increase on performance with respect to their
original, non-adversarial baseline.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 17:52:06 GMT'}]",2020-10-19,"[['de Wynter', 'Adrian', '']]"
1280484,2005.00689,Ziyu Yao,"Ziyu Yao, Yiqi Tang, Wen-tau Yih, Huan Sun, Yu Su",An Imitation Game for Learning Semantic Parsers from User Interaction,"Accepted to EMNLP 2020. 21 pages, 6 figures",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite the widely successful applications, bootstrapping and fine-tuning
semantic parsers are still a tedious process with challenges such as costly
data annotation and privacy risks. In this paper, we suggest an alternative,
human-in-the-loop methodology for learning semantic parsers directly from
users. A semantic parser should be introspective of its uncertainties and
prompt for user demonstration when uncertain. In doing so it also gets to
imitate the user behavior and continue improving itself autonomously with the
hope that eventually it may become as good as the user in interpreting their
questions. To combat the sparsity of demonstration, we propose a novel
annotation-efficient imitation learning algorithm, which iteratively collects
new datasets by mixing demonstrated states and confident predictions and
re-trains the semantic parser in a Dataset Aggregation fashion (Ross et al.,
2011). We provide a theoretical analysis of its cost bound and also empirically
demonstrate its promising performance on the text-to-SQL problem. Code will be
available at https://github.com/sunlab-osu/MISP.
","[{'version': 'v1', 'created': 'Sat, 2 May 2020 03:30:49 GMT'}, {'version': 'v2', 'created': 'Tue, 6 Oct 2020 03:46:18 GMT'}, {'version': 'v3', 'created': 'Thu, 15 Oct 2020 18:31:26 GMT'}]",2020-10-19,"[['Yao', 'Ziyu', ''], ['Tang', 'Yiqi', ''], ['Yih', 'Wen-tau', ''], ['Sun', 'Huan', ''], ['Su', 'Yu', '']]"
1261900,2003.11545,Fernando Alonso-Fernandez,"Nicole Mariah Sharon Belvisi, Naveed Muhammad, Fernando
  Alonso-Fernandez","Forensic Authorship Analysis of Microblogging Texts Using N-Grams and
  Stylometric Features","Accepted for publication at 8th International Workshop on Biometrics
  and Forensics, IWBF 2020","Proc. 8th International Workshop on Biometrics and Forensics,
  IWBF, Porto, Portugal, April 29-30, 2020",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In recent years, messages and text posted on the Internet are used in
criminal investigations. Unfortunately, the authorship of many of them remains
unknown. In some channels, the problem of establishing authorship may be even
harder, since the length of digital texts is limited to a certain number of
characters. In this work, we aim at identifying authors of tweet messages,
which are limited to 280 characters. We evaluate popular features employed
traditionally in authorship attribution which capture properties of the writing
style at different levels. We use for our experiments a self-captured database
of 40 users, with 120 to 200 tweets per user. Results using this small set are
promising, with the different features providing a classification accuracy
between 92% and 98.5%. These results are competitive in comparison to existing
studies which employ short texts such as tweets or SMS.
","[{'version': 'v1', 'created': 'Tue, 24 Mar 2020 19:32:11 GMT'}]",2020-10-19,"[['Belvisi', 'Nicole Mariah Sharon', ''], ['Muhammad', 'Naveed', ''], ['Alonso-Fernandez', 'Fernando', '']]"
1255517,2003.05162,Tejas Gokhale,"Zhiyuan Fang, Tejas Gokhale, Pratyay Banerjee, Chitta Baral, Yezhou
  Yang","Video2Commonsense: Generating Commonsense Descriptions to Enrich Video
  Captioning","Accepted to EMNLP, Long Papers",,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Captioning is a crucial and challenging task for video understanding. In
videos that involve active agents such as humans, the agent's actions can bring
about myriad changes in the scene. Observable changes such as movements,
manipulations, and transformations of the objects in the scene, are reflected
in conventional video captioning. Unlike images, actions in videos are also
inherently linked to social aspects such as intentions (why the action is
taking place), effects (what changes due to the action), and attributes that
describe the agent. Thus for video understanding, such as when captioning
videos or when answering questions about videos, one must have an understanding
of these commonsense aspects. We present the first work on generating
commonsense captions directly from videos, to describe latent aspects such as
intentions, effects, and attributes. We present a new dataset
""Video-to-Commonsense (V2C)"" that contains $\sim9k$ videos of human agents
performing various actions, annotated with 3 types of commonsense descriptions.
Additionally we explore the use of open-ended video-based commonsense question
answering (V2C-QA) as a way to enrich our captions. Both the generation task
and the QA task can be used to enrich video captions.
","[{'version': 'v1', 'created': 'Wed, 11 Mar 2020 08:42:57 GMT'}, {'version': 'v2', 'created': 'Tue, 17 Mar 2020 05:16:13 GMT'}, {'version': 'v3', 'created': 'Fri, 16 Oct 2020 02:08:26 GMT'}]",2020-10-19,"[['Fang', 'Zhiyuan', ''], ['Gokhale', 'Tejas', ''], ['Banerjee', 'Pratyay', ''], ['Baral', 'Chitta', ''], ['Yang', 'Yezhou', '']]"
1283718,2005.03923,Puhai Yang,"Puhai Yang, Heyan Huang, and Xian-Ling Mao","Context-Sensitive Generation Network for Handing Unknown Slot Values in
  Dialogue State Tracking",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As a key component in a dialogue system, dialogue state tracking plays an
important role. It is very important for dialogue state tracking to deal with
the problem of unknown slot values. As far as we known, almost all existing
approaches depend on pointer network to solve the unknown slot value problem.
These pointer network-based methods usually have a hidden assumption that there
is at most one out-of-vocabulary word in an unknown slot value because of the
character of a pointer network. However, often, there are multiple
out-of-vocabulary words in an unknown slot value, and it makes the existing
methods perform bad. To tackle the problem, in this paper, we propose a novel
Context-Sensitive Generation network (CSG) which can facilitate the
representation of out-of-vocabulary words when generating the unknown slot
value. Extensive experiments show that our proposed method performs better than
the state-of-the-art baselines.
","[{'version': 'v1', 'created': 'Fri, 8 May 2020 09:22:33 GMT'}, {'version': 'v2', 'created': 'Sat, 27 Jun 2020 05:49:59 GMT'}, {'version': 'v3', 'created': 'Fri, 16 Oct 2020 09:31:38 GMT'}]",2020-10-19,"[['Yang', 'Puhai', ''], ['Huang', 'Heyan', ''], ['Mao', 'Xian-Ling', '']]"
1364562,2010.08232,Dat Quoc Nguyen,"Dat Quoc Nguyen, Thanh Vu, Afshin Rahimi, Mai Hoang Dao, Linh The
  Nguyen and Long Doan",WNUT-2020 Task 2: Identification of Informative COVID-19 English Tweets,In Proceedings of the 6th Workshop on Noisy User-generated Text,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we provide an overview of the WNUT-2020 shared task on the
identification of informative COVID-19 English Tweets. We describe how we
construct a corpus of 10K Tweets and organize the development and evaluation
phases for this task. In addition, we also present a brief summary of results
obtained from the final system evaluation submissions of 55 teams, finding that
(i) many systems obtain very high performance, up to 0.91 F1 score, (ii) the
majority of the submissions achieve substantially higher results than the
baseline fastText (Joulin et al., 2017), and (iii) fine-tuning pre-trained
language models on relevant language data followed by supervised training
performs well in this task.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 08:28:05 GMT'}]",2020-10-19,"[['Nguyen', 'Dat Quoc', ''], ['Vu', 'Thanh', ''], ['Rahimi', 'Afshin', ''], ['Dao', 'Mai Hoang', ''], ['Nguyen', 'Linh The', ''], ['Doan', 'Long', '']]"
1364543,2010.08213,Yanghoon Kim,"Yanghoon Kim, Seungpil Won, Seunghyun Yoon and Kyomin Jung","Collaborative Training of GANs in Continuous and Discrete Spaces for
  Text Generation",,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Applying generative adversarial networks (GANs) to text-related tasks is
challenging due to the discrete nature of language. One line of research
resolves this issue by employing reinforcement learning (RL) and optimizing the
next-word sampling policy directly in a discrete action space. Such methods
compute the rewards from complete sentences and avoid error accumulation due to
exposure bias. Other approaches employ approximation techniques that map the
text to continuous representation in order to circumvent the non-differentiable
discrete process. Particularly, autoencoder-based methods effectively produce
robust representations that can model complex discrete structures. In this
paper, we propose a novel text GAN architecture that promotes the collaborative
training of the continuous-space and discrete-space methods. Our method employs
an autoencoder to learn an implicit data manifold, providing a learning
objective for adversarial training in a continuous space. Furthermore, the
complete textual output is directly evaluated and updated via RL in a discrete
space. The collaborative interplay between the two adversarial trainings
effectively regularize the text representations in different spaces. The
experimental results on three standard benchmark datasets show that our model
substantially outperforms state-of-the-art text GANs with respect to quality,
diversity, and global consistency.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 07:51:16 GMT'}]",2020-10-19,"[['Kim', 'Yanghoon', ''], ['Won', 'Seungpil', ''], ['Yoon', 'Seunghyun', ''], ['Jung', 'Kyomin', '']]"
1364570,2010.08240,Nandan Thakur,"Nandan Thakur, Nils Reimers, Johannes Daxenberger, Iryna Gurevych","Augmented SBERT: Data Augmentation Method for Improving Bi-Encoders for
  Pairwise Sentence Scoring Tasks",,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  There are two approaches for pairwise sentence scoring: Cross-encoders, which
perform full-attention over the input pair, and Bi-encoders, which map each
input independently to a dense vector space. While cross-encoders often achieve
higher performance, they are too slow for many practical use cases.
Bi-encoders, on the other hand, require substantial training data and
fine-tuning over the target task to achieve competitive performance. We present
a simple yet efficient data augmentation strategy called Augmented SBERT, where
we use the cross-encoder to label a larger set of input pairs to augment the
training data for the bi-encoder. We show that, in this process, selecting the
sentence pairs is non-trivial and crucial for the success of the method. We
evaluate our approach on multiple tasks (in-domain) as well as on a domain
adaptation task. Augmented SBERT achieves an improvement of up to 6 points for
in-domain and of up to 37 points for domain adaptation tasks compared to the
original bi-encoder performance.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 08:43:27 GMT'}]",2020-10-19,"[['Thakur', 'Nandan', ''], ['Reimers', 'Nils', ''], ['Daxenberger', 'Johannes', ''], ['Gurevych', 'Iryna', '']]"
1364527,2010.08197,Boyan Wan,"Boyan Wan, Zhuo Tang, Li Yang","Lexicon-constrained Copying Network for Chinese Abstractive
  Summarization",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Copy mechanism allows sequence-to-sequence models to choose words from the
input and put them directly into the output, which is finding increasing use in
abstractive summarization. However, since there is no explicit delimiter in
Chinese sentences, most existing models for Chinese abstractive summarization
can only perform character copy, resulting in inefficient. To solve this
problem, we propose a lexicon-constrained copying network that models
multi-granularity in both encoder and decoder. On the source side, words and
characters are aggregated into the same input memory using a Transformerbased
encoder. On the target side, the decoder can copy either a character or a
multi-character word at each time step, and the decoding process is guided by a
word-enhanced search algorithm that facilitates the parallel computation and
encourages the model to copy more words. Moreover, we adopt a word selector to
integrate keyword information. Experiments results on a Chinese social media
dataset show that our model can work standalone or with the word selector. Both
forms can outperform previous character-based models and achieve competitive
performances.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 06:59:34 GMT'}]",2020-10-19,"[['Wan', 'Boyan', ''], ['Tang', 'Zhuo', ''], ['Yang', 'Li', '']]"
1310666,2006.16152,David Beauchemin,"Marouane Yassine, David Beauchemin, Fran\c{c}ois Laviolette, Luc
  Lamontagne",Leveraging Subword Embeddings for Multinational Address Parsing,Accepted to IEEE CiSt'20,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Address parsing consists of identifying the segments that make up an address
such as a street name or a postal code. Because of its importance for tasks
like record linkage, address parsing has been approached with many techniques.
Neural network methods defined a new state-of-the-art for address parsing.
While this approach yielded notable results, previous work has only focused on
applying neural networks to achieve address parsing of addresses from one
source country. We propose an approach in which we employ subword embeddings
and a Recurrent Neural Network architecture to build a single model capable of
learning to parse addresses from multiple countries at the same time while
taking into account the difference in languages and address formatting systems.
We achieved accuracies around 99% on the countries used for training with no
pre-processing nor post-processing needed. We explore the possibility of
transferring the address parsing knowledge obtained by training on some
countries' addresses to others with no further training in a zero-shot transfer
learning setting. We achieve good results for 80% of the countries (33 out of
41), almost 50% of which (20 out of 41) is near state-of-the-art performance.
In addition, we propose an open-source Python implementation of our trained
models.
","[{'version': 'v1', 'created': 'Mon, 29 Jun 2020 16:14:27 GMT'}, {'version': 'v2', 'created': 'Fri, 16 Oct 2020 16:03:49 GMT'}]",2020-10-19,"[['Yassine', 'Marouane', ''], ['Beauchemin', 'David', ''], ['Laviolette', 'François', ''], ['Lamontagne', 'Luc', '']]"
1329255,2008.01533,Fernando Alonso-Fernandez,"Fernando Alonso-Fernandez, Nicole Mariah Sharon Belvisi, Kevin
  Hernandez-Diaz, Naveed Muhammad, Josef Bigun",Forensic Writer Identification Using Microblogging Texts,,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Establishing the authorship of online texts is a fundamental issue to combat
several cybercrimes. Unfortunately, some platforms limit the length of the
text, making the challenge harder. Here, we aim at identifying the author of
Twitter messages limited to 140 characters. We evaluate popular stylometric
features, widely used in traditional literary analysis, which capture the
writing style at different levels (character, word, and sentence). We use a
public database of 93 users, containing 1142 to 3209 Tweets per user. We also
evaluate the influence of the number of Tweets per user for enrolment and
testing. If the amount is sufficient (>500), a Rank 1 of 97-99% is achieved. If
data is scarce (e.g. 20 Tweets for testing), the Rank 1 with the best
individual feature method ranges from 54.9% (100 Tweets for enrolment) to 70.6%
(1000 Tweets). By combining the available features, a substantial improvement
is observed, reaching a Rank 1 of 70% when using 100 Tweets for enrolment and
only 20 for testing. With a bigger hit list size, accuracy of the latter case
increases to 86.4% (Rank 5) or 95% (Rank 20). This demonstrates the feasibility
of identifying writers of digital texts, even with few data available.
","[{'version': 'v1', 'created': 'Fri, 31 Jul 2020 00:23:18 GMT'}]",2020-10-19,"[['Alonso-Fernandez', 'Fernando', ''], ['Belvisi', 'Nicole Mariah Sharon', ''], ['Hernandez-Diaz', 'Kevin', ''], ['Muhammad', 'Naveed', ''], ['Bigun', 'Josef', '']]"
1363887,2010.07557,"Laura Oberl\""ander","Laura Oberl\""ander, Roman Klinger","Token Sequence Labeling vs. Clause Classification for English Emotion
  Stimulus Detection",accepted at *SEM 2020,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Emotion stimulus detection is the task of finding the cause of an emotion in
a textual description, similar to target or aspect detection for sentiment
analysis. Previous work approached this in three ways, namely (1) as text
classification into an inventory of predefined possible stimuli (""Is the
stimulus category A or B?""), (2) as sequence labeling of tokens (""Which tokens
describe the stimulus?""), and (3) as clause classification (""Does this clause
contain the emotion stimulus?""). So far, setting (3) has been evaluated broadly
on Mandarin and (2) on English, but no comparison has been performed.
Therefore, we aim to answer whether clause classification or sequence labeling
is better suited for emotion stimulus detection in English. To accomplish that,
we propose an integrated framework which enables us to evaluate the two
different approaches comparably, implement models inspired by state-of-the-art
approaches in Mandarin, and test them on four English data sets from different
domains. Our results show that sequence labeling is superior on three out of
four datasets, in both clause-based and sequence-based evaluation. The only
case in which clause classification performs better is one data set with a high
density of clause annotations. Our error analysis further confirms
quantitatively and qualitatively that clauses are not the appropriate stimulus
unit in English.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 07:11:04 GMT'}, {'version': 'v2', 'created': 'Fri, 16 Oct 2020 07:37:02 GMT'}]",2020-10-19,"[['Oberländer', 'Laura', ''], ['Klinger', 'Roman', '']]"
1363950,2010.07620,Yao Zhang,"Yao Zhang, Xu Zhang, Jun Wang, Hongru Liang, Adam Jatowt, Wenqiang
  Lei, Zhenglu Yang",GMH: A General Multi-hop Reasoning Model for KG Completion,"11 pages, 5 figures and 4 tables",,,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Knowledge graphs are essential for numerous downstream natural language
processing applications, but are typically incomplete with many facts missing.
This results in research efforts on multi-hop reasoning task, which can be
formulated as a search process and current models typically perform short
distance reasoning. However, the long-distance reasoning is also vital with the
ability to connect the superficially unrelated entities. To the best of our
knowledge, there lacks a general framework that approaches multi-hop reasoning
in both short and long scenarios. We argue that there are two key issues for
long distance reasoning: i) which edge to select, and ii) when to stop the
search. In this work, we propose a general model which resolves the issues with
three modules: 1) the local-global knowledge module to estimate the possible
paths, 2) the differentiated action dropout module to explore a diverse set of
paths, and 3) the adaptive stopping search module to avoid over searching. The
comprehensive results on three datasets demonstrate the superiority of our
model with significant improvements against baselines in both short and long
distance reasoning scenarios.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 09:30:46 GMT'}, {'version': 'v2', 'created': 'Fri, 16 Oct 2020 13:48:28 GMT'}]",2020-10-19,"[['Zhang', 'Yao', ''], ['Zhang', 'Xu', ''], ['Wang', 'Jun', ''], ['Liang', 'Hongru', ''], ['Jatowt', 'Adam', ''], ['Lei', 'Wenqiang', ''], ['Yang', 'Zhenglu', '']]"
1364530,2010.08200,Guangyu Zheng,"Wanyun Cui, Guangyu Zheng, Wei Wang","Unsupervised Natural Language Inference via Decoupled Multimodal
  Contrastive Learning",Published at EMNLP 2020,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose to solve the natural language inference problem without any
supervision from the inference labels via task-agnostic multimodal pretraining.
Although recent studies of multimodal self-supervised learning also represent
the linguistic and visual context, their encoders for different modalities are
coupled. Thus they cannot incorporate visual information when encoding plain
text alone. In this paper, we propose Multimodal Aligned Contrastive Decoupled
learning (MACD) network. MACD forces the decoupled text encoder to represent
the visual information via contrastive learning. Therefore, it embeds visual
knowledge even for plain text inference. We conducted comprehensive experiments
over plain text inference datasets (i.e. SNLI and STS-B). The unsupervised MACD
even outperforms the fully-supervised BiLSTM and BiLSTM+ELMO on STS-B.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 07:12:53 GMT'}]",2020-10-19,"[['Cui', 'Wanyun', ''], ['Zheng', 'Guangyu', ''], ['Wang', 'Wei', '']]"
1364302,2010.07972,Junjie Hu,"Junjie Hu and Melvin Johnson and Orhan Firat and Aditya Siddhant and
  Graham Neubig",Explicit Alignment Objectives for Multilingual Bidirectional Encoders,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pre-trained cross-lingual encoders such as mBERT (Devlin et al., 2019) and
XLMR (Conneau et al., 2020) have proven to be impressively effective at
enabling transfer-learning of NLP systems from high-resource languages to
low-resource languages. This success comes despite the fact that there is no
explicit objective to align the contextual embeddings of words/sentences with
similar meanings across languages together in the same space. In this paper, we
present a new method for learning multilingual encoders, AMBER (Aligned
Multilingual Bidirectional EncodeR). AMBER is trained on additional parallel
data using two explicit alignment objectives that align the multilingual
representations at different granularities. We conduct experiments on zero-shot
cross-lingual transfer learning for different tasks including sequence tagging,
sentence retrieval and sentence classification. Experimental results show that
AMBER obtains gains of up to 1.1 average F1 score on sequence tagging and up to
27.3 average accuracy on retrieval over the XLMR-large model which has 4.6x the
parameters of AMBER.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 18:34:13 GMT'}]",2020-10-19,"[['Hu', 'Junjie', ''], ['Johnson', 'Melvin', ''], ['Firat', 'Orhan', ''], ['Siddhant', 'Aditya', ''], ['Neubig', 'Graham', '']]"
1364318,2010.07988,Harish Tayyar Madabushi PhD,Calum Perrio and Harish Tayyar Madabushi,"CXP949 at WNUT-2020 Task 2: Extracting Informative COVID-19 Tweets --
  RoBERTa Ensembles and The Continued Relevance of Handcrafted Features",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents our submission to Task 2 of the Workshop on Noisy
User-generated Text. We explore improving the performance of a pre-trained
transformer-based language model fine-tuned for text classification through an
ensemble implementation that makes use of corpus level information and a
handcrafted feature. We test the effectiveness of including the aforementioned
features in accommodating the challenges of a noisy data set centred on a
specific subject outside the remit of the pre-training data. We show that
inclusion of additional features can improve classification results and achieve
a score within 2 points of the top performing team.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 19:12:52 GMT'}]",2020-10-19,"[['Perrio', 'Calum', ''], ['Madabushi', 'Harish Tayyar', '']]"
1364329,2010.07999,Jie Lei,"Jie Lei, Licheng Yu, Tamara L. Berg, Mohit Bansal","What is More Likely to Happen Next? Video-and-Language Future Event
  Prediction",EMNLP 2020 (17 pages),,,,cs.CL cs.AI cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Given a video with aligned dialogue, people can often infer what is more
likely to happen next. Making such predictions requires not only a deep
understanding of the rich dynamics underlying the video and dialogue, but also
a significant amount of commonsense knowledge. In this work, we explore whether
AI models are able to learn to make such multimodal commonsense next-event
predictions. To support research in this direction, we collect a new dataset,
named Video-and-Language Event Prediction (VLEP), with 28,726 future event
prediction examples (along with their rationales) from 10,234 diverse TV Show
and YouTube Lifestyle Vlog video clips. In order to promote the collection of
non-trivial challenging examples, we employ an adversarial
human-and-model-in-the-loop data collection procedure. We also present a strong
baseline incorporating information from video, dialogue, and commonsense
knowledge. Experiments show that each type of information is useful for this
challenging task, and that compared to the high human performance on VLEP, our
model provides a good starting point but leaves large room for future work. Our
dataset and code are available at:
https://github.com/jayleicn/VideoLanguageFuturePred
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 19:56:47 GMT'}]",2020-10-19,"[['Lei', 'Jie', ''], ['Yu', 'Licheng', ''], ['Berg', 'Tamara L.', ''], ['Bansal', 'Mohit', '']]"
1364284,2010.07954,Alexander Ku,"Alexander Ku and Peter Anderson and Roma Patel and Eugene Ie and Jason
  Baldridge","Room-Across-Room: Multilingual Vision-and-Language Navigation with Dense
  Spatiotemporal Grounding",EMNLP 2020,,,,cs.CV cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We introduce Room-Across-Room (RxR), a new Vision-and-Language Navigation
(VLN) dataset. RxR is multilingual (English, Hindi, and Telugu) and larger
(more paths and instructions) than other VLN datasets. It emphasizes the role
of language in VLN by addressing known biases in paths and eliciting more
references to visible entities. Furthermore, each word in an instruction is
time-aligned to the virtual poses of instruction creators and validators. We
establish baseline scores for monolingual and multilingual settings and
multitask learning when including Room-to-Room annotations. We also provide
results for a model that learns from synchronized pose traces by focusing only
on portions of the panorama attended to in human demonstrations. The size,
scope and detail of RxR dramatically expands the frontier for research on
embodied language agents in simulated, photo-realistic environments.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 18:01:15 GMT'}]",2020-10-19,"[['Ku', 'Alexander', ''], ['Anderson', 'Peter', ''], ['Patel', 'Roma', ''], ['Ie', 'Eugene', ''], ['Baldridge', 'Jason', '']]"
1364351,2010.08021,Udit Arora,"Aman Khullar, Udit Arora","MAST: Multimodal Abstractive Summarization with Trimodal Hierarchical
  Attention","To appear in the first EMNLP Workshop on NLP Beyond Text, 2020. Aman
  Khullar and Udit Arora have equal contribution",,,,cs.CL cs.CV cs.LG cs.MM,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents MAST, a new model for Multimodal Abstractive Text
Summarization that utilizes information from all three modalities -- text,
audio and video -- in a multimodal video. Prior work on multimodal abstractive
text summarization only utilized information from the text and video
modalities. We examine the usefulness and challenges of deriving information
from the audio modality and present a sequence-to-sequence trimodal
hierarchical attention-based model that overcomes these challenges by letting
the model pay more attention to the text modality. MAST outperforms the current
state of the art model (video-text) by 2.51 points in terms of Content F1 score
and 1.00 points in terms of Rouge-L score on the How2 dataset for multimodal
language understanding.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 21:08:20 GMT'}]",2020-10-19,"[['Khullar', 'Aman', ''], ['Arora', 'Udit', '']]"
1364521,2010.08191,Jing Liu,"Yingqi Qu Yuchen Ding, Jing Liu, Kai Liu, Ruiyang Ren, Xin Zhao,
  Daxiang Dong, Hua Wu, Haifeng Wang","RocketQA: An Optimized Training Approach to Dense Passage Retrieval for
  Open-Domain Question Answering",,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In open-domain question answering, dense passage retrieval has become a new
paradigm to retrieve relevant passages for answer finding. Typically, the
dual-encoder architecture is adopted to learn dense representations of
questions and passages for matching. However, it is difficult to train an
effective dual-encoder due to the challenges including the discrepancy between
training and inference, the existence of unlabeled positives and limited
training data. To address these challenges, we propose an optimized training
approach, called RocketQA, to improving dense passage retrieval. We make three
major technical contributions in RocketQA, namely cross-batch negatives,
denoised negative sampling and data augmentation. Extensive experiments show
that RocketQA significantly outperforms previous state-of-the-art models on
both MSMARCO and Natural Questions. Besides, built upon RocketQA, we achieve
the first rank at the leaderboard of MSMARCO Passage Ranking Task.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 06:54:05 GMT'}]",2020-10-19,"[['Ding', 'Yingqi Qu Yuchen', ''], ['Liu', 'Jing', ''], ['Liu', 'Kai', ''], ['Ren', 'Ruiyang', ''], ['Zhao', 'Xin', ''], ['Dong', 'Daxiang', ''], ['Wu', 'Hua', ''], ['Wang', 'Haifeng', '']]"
1364517,2010.08187,Guang-Neng Hu,"Guangneng Hu, Qiang Yang","PrivNet: Safeguarding Private Attributes in Transfer Learning for
  Recommendation",Findings of EMNLP 2020,,,,cs.AI cs.CL cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Transfer learning is an effective technique to improve a target recommender
system with the knowledge from a source domain. Existing research focuses on
the recommendation performance of the target domain while ignores the privacy
leakage of the source domain. The transferred knowledge, however, may
unintendedly leak private information of the source domain. For example, an
attacker can accurately infer user demographics from their historical purchase
provided by a source domain data owner. This paper addresses the above
privacy-preserving issue by learning a privacy-aware neural representation by
improving target performance while protecting source privacy. The key idea is
to simulate the attacks during the training for protecting unseen users'
privacy in the future, modeled by an adversarial game, so that the transfer
learning model becomes robust to attacks. Experiments show that the proposed
PrivNet model can successfully disentangle the knowledge benefitting the
transfer from leaking the privacy.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 06:33:45 GMT'}]",2020-10-19,"[['Hu', 'Guangneng', ''], ['Yang', 'Qiang', '']]"
1364344,2010.08014,Zi-Yi Dou,"Zi-Yi Dou, Pengfei Liu, Hiroaki Hayashi, Zhengbao Jiang, Graham Neubig",GSum: A General Framework for Guided Neural Abstractive Summarization,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Neural abstractive summarization models are flexible and can produce coherent
summaries, but they are sometimes unfaithful and can be difficult to control.
While previous studies attempt to provide different types of guidance to
control the output and increase faithfulness, it is not clear how these
strategies compare and contrast to each other. In this paper, we propose a
general and extensible guided summarization framework (GSum) that can
effectively take different kinds of external guidance as input, and we perform
experiments across several different varieties. Experiments demonstrate that
this model is effective, achieving state-of-the-art performance according to
ROUGE on 4 popular summarization datasets when using highlighted sentences as
guidance. In addition, we show that our guided model can generate more faithful
summaries and demonstrate how different types of guidance generate
qualitatively different summaries, lending a degree of controllability to the
learned models.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 20:46:14 GMT'}]",2020-10-19,"[['Dou', 'Zi-Yi', ''], ['Liu', 'Pengfei', ''], ['Hayashi', 'Hiroaki', ''], ['Jiang', 'Zhengbao', ''], ['Neubig', 'Graham', '']]"
1364508,2010.08178,Xuanfu Wu,"Xuanfu Wu, Yang Feng, Chenze Shao",Generating Diverse Translation from Model Distribution with Dropout,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite the improvement of translation quality, neural machine translation
(NMT) often suffers from the lack of diversity in its generation. In this
paper, we propose to generate diverse translations by deriving a large number
of possible models with Bayesian modelling and sampling models from them for
inference. The possible models are obtained by applying concrete dropout to the
NMT model and each of them has specific confidence for its prediction, which
corresponds to a posterior model distribution under specific training data in
the principle of Bayesian modeling. With variational inference, the posterior
model distribution can be approximated with a variational distribution, from
which the final models for inference are sampled. We conducted experiments on
Chinese-English and English-German translation tasks and the results shows that
our method makes a better trade-off between diversity and accuracy.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 05:50:00 GMT'}]",2020-10-19,"[['Wu', 'Xuanfu', ''], ['Feng', 'Yang', ''], ['Shao', 'Chenze', '']]"
1364515,2010.08185,Tanfang Chen,"Tanfang Chen, Weiwei Wang, Wenyang Wei, Xing Shi, Xiangang Li, Jieping
  Ye, Kevin Knight",DiDi's Machine Translation System for WMT2020,Accepted at WMT 2020,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper describes DiDi AI Labs' submission to the WMT2020 news translation
shared task. We participate in the translation direction of Chinese->English.
In this direction, we use the Transformer as our baseline model, and integrate
several techniques for model enhancement, including data filtering, data
selection, back-translation, fine-tuning, model ensembling, and re-ranking. As
a result, our submission achieves a BLEU score of $36.6$ in Chinese->English.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 06:25:48 GMT'}]",2020-10-19,"[['Chen', 'Tanfang', ''], ['Wang', 'Weiwei', ''], ['Wei', 'Wenyang', ''], ['Shi', 'Xing', ''], ['Li', 'Xiangang', ''], ['Ye', 'Jieping', ''], ['Knight', 'Kevin', '']]"
1364444,2010.08114,Lingbing Guo,"Lingbing Guo, Weiqing Wang, Zequn Sun, Chenghao Liu, Wei Hu",Decentralized Knowledge Graph Representation Learning,submitted to ICLR 2021,,,,cs.LG cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Knowledge graph (KG) representation learning methods have achieved
competitive performance in many KG-oriented tasks, among which the best ones
are usually based on graph neural networks (GNNs), a powerful family of
networks that learns the representation of an entity by aggregating the
features of its neighbors and itself. However, many KG representation learning
scenarios only provide the structure information that describes the
relationships among entities, causing that entities have no input features. In
this case, existing aggregation mechanisms are incapable of inducing embeddings
of unseen entities as these entities have no pre-defined features for
aggregation. In this paper, we present a decentralized KG representation
learning approach, decentRL, which encodes each entity from and only from the
embeddings of its neighbors. For optimization, we design an algorithm to
distill knowledge from the model itself such that the output embeddings can
continuously gain knowledge from the corresponding original embeddings.
Extensive experiments show that the proposed approach performed better than
many cutting-edge models on the entity alignment task, and achieved competitive
performance on the entity prediction task. Furthermore, under the inductive
setting, it significantly outperformed all baselines on both tasks.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 02:31:22 GMT'}]",2020-10-19,"[['Guo', 'Lingbing', ''], ['Wang', 'Weiqing', ''], ['Sun', 'Zequn', ''], ['Liu', 'Chenghao', ''], ['Hu', 'Wei', '']]"
1364420,2010.08090,Chelsea Tanchip,"Chelsea Tanchip, Lei Yu, Aotao Xu, Yang Xu",Inferring symmetry in natural language,"10 pages, 4 figures, Findings of EMNLP",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present a methodological framework for inferring symmetry of verb
predicates in natural language. Empirical work on predicate symmetry has taken
two main approaches. The feature-based approach focuses on linguistic features
pertaining to symmetry. The context-based approach denies the existence of
absolute symmetry but instead argues that such inference is context dependent.
We develop methods that formalize these approaches and evaluate them against a
novel symmetry inference sentence (SIS) dataset comprised of 400 naturalistic
usages of literature-informed verbs spanning the spectrum of
symmetry-asymmetry. Our results show that a hybrid transfer learning model that
integrates linguistic features with contextualized language models most
faithfully predicts the empirical data. Our work integrates existing approaches
to symmetry in natural language and suggests how symmetry inference can improve
systematicity in state-of-the-art language models.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 01:25:01 GMT'}]",2020-10-19,"[['Tanchip', 'Chelsea', ''], ['Yu', 'Lei', ''], ['Xu', 'Aotao', ''], ['Xu', 'Yang', '']]"
1364397,2010.08067,Gene Louis Kim,Gene Louis Kim and Aaron Steven White,Montague Grammar Induction,"18 pages, 2 figures, to be published in SALT 30",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a computational modeling framework for inducing combinatory
categorial grammars from arbitrary behavioral data. This framework provides the
analyst fine-grained control over the assumptions that the induced grammar
should conform to: (i) what the primitive types are; (ii) how complex types are
constructed; (iii) what set of combinators can be used to combine types; and
(iv) whether (and to what) the types of some lexical items should be fixed. In
a proof-of-concept experiment, we deploy our framework for use in
distributional analysis. We focus on the relationship between
s(emantic)-selection and c(ategory)-selection, using as input a lexicon-scale
acceptability judgment dataset focused on English verbs' syntactic distribution
(the MegaAcceptability dataset) and enforcing standard assumptions from the
semantics literature on the induced grammar.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 23:25:01 GMT'}]",2020-10-19,"[['Kim', 'Gene Louis', ''], ['White', 'Aaron Steven', '']]"
1283770,2005.03975,Yan Xu,"Dan Su, Yan Xu, Tiezheng Yu, Farhad Bin Siddique, Elham J. Barezi,
  Pascale Fung","CAiRE-COVID: A Question Answering and Query-focused Multi-Document
  Summarization System for COVID-19 Scholarly Information Management",Accepted EMNLP NLP-COVID Workshop,,,,cs.CL cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The outbreak of COVID-19 raises attention from the researchers from various
communities. While many scientific articles have been published, a system that
can provide reliable information to COVID-19 related questions from the latest
academic resources is crucial, especially for the medical community in the
current time-critical race to treat patients and to find a cure for the virus.
To address the requests, we propose our CAiRE-COVID, a neural-based system that
uses open-domain question answering (QA) techniques combined with summarization
techniques for mining the available scientific literature. It leverages the
Information Retrieval (IR) system and QA models to extract relevant snippets
from existing literature given a query. Fluent summaries are also provided to
help understand the content in a more efficient way. Our system has been
awarded as winner for one of the tasks in CORD-19 Kaggle Challenge. We also
launched our CAiRE-COVID website for broader use. The code for our system is
also open-sourced to bootstrap further study.
","[{'version': 'v1', 'created': 'Mon, 4 May 2020 15:07:27 GMT'}, {'version': 'v2', 'created': 'Fri, 16 Oct 2020 02:47:06 GMT'}]",2020-10-19,"[['Su', 'Dan', ''], ['Xu', 'Yan', ''], ['Yu', 'Tiezheng', ''], ['Siddique', 'Farhad Bin', ''], ['Barezi', 'Elham J.', ''], ['Fung', 'Pascale', '']]"
1365930,2010.09600,Dalton Schutte,"Rui Zhang, Dimitar Hristovski, Dalton Schutte, Andrej Kastrin, Marcelo
  Fiszman, Halil Kilicoglu",Drug Repurposing for COVID-19 via Knowledge Graph Completion,"47 pages, 3 figures, submitted to Journal of Biomedical Informatics",,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Objective: To discover candidate drugs to repurpose for COVID-19 using
literature-derived knowledge and knowledge graph completion methods. Methods:
We propose a novel, integrative, and neural network-based literature-based
discovery (LBD) approach to identify drug candidates from both PubMed and
COVID-19-focused research literature. Our approach relies on semantic triples
extracted using SemRep (via SemMedDB). We identified an informative subset of
semantic triples using filtering rules and an accuracy classifier developed on
a BERT variant, and used this subset to construct a knowledge graph. Five SOTA,
neural knowledge graph completion algorithms were used to predict drug
repurposing candidates. The models were trained and assessed using a time
slicing approach and the predicted drugs were compared with a list of drugs
reported in the literature and evaluated in clinical trials. These models were
complemented by a discovery pattern-based approach. Results: Accuracy
classifier based on PubMedBERT achieved the best performance (F1= 0.854) in
classifying semantic predications. Among five knowledge graph completion
models, TransE outperformed others (MR = 0.923, Hits@1=0.417). Some known drugs
linked to COVID-19 in the literature were identified, as well as some candidate
drugs that have not yet been studied. Discovery patterns enabled generation of
plausible hypotheses regarding the relationships between the candidate drugs
and COVID-19. Among them, five highly ranked and novel drugs (paclitaxel, SB
203580, alpha 2-antiplasmin, pyrrolidine dithiocarbamate, and butylated
hydroxytoluene) with their mechanistic explanations were further discussed.
Conclusion: We show that an LBD approach can be feasible for discovering drug
candidates for COVID-19, and for generating mechanistic explanations. Our
approach can be generalized to other diseases as well as to other clinical
questions.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 15:30:51 GMT'}]",2020-10-20,"[['Zhang', 'Rui', ''], ['Hristovski', 'Dimitar', ''], ['Schutte', 'Dalton', ''], ['Kastrin', 'Andrej', ''], ['Fiszman', 'Marcelo', ''], ['Kilicoglu', 'Halil', '']]"
1365928,2010.09598,Jeroen Offerijns,"Jeroen Offerijns, Suzan Verberne, Tessa Verhoef","Better Distractions: Transformer-based Distractor Generation and
  Multiple Choice Question Filtering",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  For the field of education, being able to generate semantically correct and
educationally relevant multiple choice questions (MCQs) could have a large
impact. While question generation itself is an active research topic,
generating distractors (the incorrect multiple choice options) receives much
less attention. A missed opportunity, since there is still a lot of room for
improvement in this area. In this work, we train a GPT-2 language model to
generate three distractors for a given question and text context, using the
RACE dataset. Next, we train a BERT language model to answer MCQs, and use this
model as a filter, to select only questions that can be answered and therefore
presumably make sense. To evaluate our work, we start by using text generation
metrics, which show that our model outperforms earlier work on distractor
generation (DG) and achieves state-of-the-art performance. Also, by calculating
the question answering ability, we show that larger base models lead to better
performance. Moreover, we conducted a human evaluation study, which confirmed
the quality of the generated questions, but showed no statistically significant
effect of the QA filter.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 15:23:24 GMT'}]",2020-10-20,"[['Offerijns', 'Jeroen', ''], ['Verberne', 'Suzan', ''], ['Verhoef', 'Tessa', '']]"
1094114,1903.01728,Chuan Guo,"Xueyao Zhang, Juan Cao, Xirong Li, Qiang Sheng, Lei Zhong, Kai Shu",Mining Dual Emotion for Fake News Detection,"9 pages, 4 figures",,,,cs.CL cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Emotion plays an important role in detecting fake news online. When
leveraging emotional signals, the existing methods focus on exploiting the
emotions of news contents that conveyed by the publishers (i.e., publisher
emotion). However, fake news is always fabricated to evoke high-arousal or
activating emotions of people to spread like a virus, so the emotions of news
comments that aroused by the crowd (i.e., social emotion) can not be ignored.
Furthermore, it needs to be explored whether there exists a relationship
between publisher emotion and social emotion (i.e., dual emotion), and how the
dual emotion appears in fake news. In the paper, we propose Dual Emotion
Features to mine dual emotion and the relationship between them for fake news
detection. And we design a universal paradigm to plug it into any existing
detectors as an enhancement. Experimental results on three real-world datasets
indicate the effectiveness of the proposed features.
","[{'version': 'v1', 'created': 'Tue, 5 Mar 2019 08:52:33 GMT'}, {'version': 'v2', 'created': 'Tue, 29 Oct 2019 02:47:16 GMT'}, {'version': 'v3', 'created': 'Mon, 19 Oct 2020 17:11:35 GMT'}]",2020-10-20,"[['Zhang', 'Xueyao', ''], ['Cao', 'Juan', ''], ['Li', 'Xirong', ''], ['Sheng', 'Qiang', ''], ['Zhong', 'Lei', ''], ['Shu', 'Kai', '']]"
1365968,2010.09638,Jiawei Sheng,"Jiawei Sheng, Shu Guo, Zhenyu Chen, Juwei Yue, Lihong Wang, Tingwen
  Liu and Hongbo Xu",Adaptive Attentional Network for Few-Shot Knowledge Graph Completion,"11 pages, 3 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Few-shot Knowledge Graph (KG) completion is a focus of current research,
where each task aims at querying unseen facts of a relation given its few-shot
reference entity pairs. Recent attempts solve this problem by learning static
representations of entities and references, ignoring their dynamic properties,
i.e., entities may exhibit diverse roles within task relations, and references
may make different contributions to queries. This work proposes an adaptive
attentional network for few-shot KG completion by learning adaptive entity and
reference representations. Specifically, entities are modeled by an adaptive
neighbor encoder to discern their task-oriented roles, while references are
modeled by an adaptive query-aware aggregator to differentiate their
contributions. Through the attention mechanism, both entities and references
can capture their fine-grained semantic meanings, and thus render more
expressive representations. This will be more predictive for knowledge
acquisition in the few-shot scenario. Evaluation in link prediction on two
public datasets shows that our approach achieves new state-of-the-art results
with different few-shot sizes.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 16:27:48 GMT'}]",2020-10-20,"[['Sheng', 'Jiawei', ''], ['Guo', 'Shu', ''], ['Chen', 'Zhenyu', ''], ['Yue', 'Juwei', ''], ['Wang', 'Lihong', ''], ['Liu', 'Tingwen', ''], ['Xu', 'Hongbo', '']]"
1358669,2010.02339,Ashiqur KhudaBukhsh Ashiqur Rahman KhudaBukhsh,"Ashiqur R. KhudaBukhsh, Rupak Sarkar, Mark S. Kamlet, Tom M. Mitchell","We Don't Speak the Same Language: Interpreting Polarization through
  Machine Translation",,,,,cs.CL cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Polarization among US political parties, media and elites is a widely studied
topic. Prominent lines of prior research across multiple disciplines have
observed and analyzed growing polarization in social media. In this paper, we
present a new methodology that offers a fresh perspective on interpreting
polarization through the lens of machine translation. With a novel proposition
that two sub-communities are speaking in two different \emph{languages}, we
demonstrate that modern machine translation methods can provide a simple yet
powerful and interpretable framework to understand the differences between two
(or more) large-scale social media discussion data sets at the granularity of
words. Via a substantial corpus of 86.6 million comments by 6.5 million users
on over 200,000 news videos hosted by YouTube channels of four prominent US
news networks, we demonstrate that simple word-level and phrase-level
translation pairs can reveal deep insights into the current political divide --
what is \emph{black lives matter} to one can be \emph{all lives matter} to the
other.
","[{'version': 'v1', 'created': 'Mon, 5 Oct 2020 21:16:30 GMT'}, {'version': 'v2', 'created': 'Sun, 18 Oct 2020 07:34:20 GMT'}]",2020-10-20,"[['KhudaBukhsh', 'Ashiqur R.', ''], ['Sarkar', 'Rupak', ''], ['Kamlet', 'Mark S.', ''], ['Mitchell', 'Tom M.', '']]"
1279213,2004.14443,Johny Moreira,"Johny Moreira, Chaina Oliveira, David Mac\^edo, Cleber Zanchettin,
  Luciano Barbosa","Distantly-Supervised Neural Relation Extraction with Side Information
  using BERT",2020 International Joint Conference on Neural Networks (IJCNN),2020 International Joint Conference on Neural Networks (IJCNN),10.1109/IJCNN48605.2020.9206648,,cs.CL cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Relation extraction (RE) consists in categorizing the relationship between
entities in a sentence. A recent paradigm to develop relation extractors is
Distant Supervision (DS), which allows the automatic creation of new datasets
by taking an alignment between a text corpus and a Knowledge Base (KB). KBs can
sometimes also provide additional information to the RE task. One of the
methods that adopt this strategy is the RESIDE model, which proposes a
distantly-supervised neural relation extraction using side information from
KBs. Considering that this method outperformed state-of-the-art baselines, in
this paper, we propose a related approach to RESIDE also using additional side
information, but simplifying the sentence encoding with BERT embeddings.
Through experiments, we show the effectiveness of the proposed method in Google
Distant Supervision and Riedel datasets concerning the BGWA and RESIDE baseline
methods. Although Area Under the Curve is decreased because of unbalanced
datasets, P@N results have shown that the use of BERT as sentence encoding
allows superior performance to baseline methods.
","[{'version': 'v1', 'created': 'Wed, 29 Apr 2020 19:29:10 GMT'}, {'version': 'v2', 'created': 'Sun, 10 May 2020 21:45:15 GMT'}, {'version': 'v3', 'created': 'Thu, 10 Sep 2020 20:30:34 GMT'}]",2020-10-20,"[['Moreira', 'Johny', ''], ['Oliveira', 'Chaina', ''], ['Macêdo', 'David', ''], ['Zanchettin', 'Cleber', ''], ['Barbosa', 'Luciano', '']]"
1365938,2010.09608,David Wan,"David Wan, Chris Kedzie, Faisal Ladhak, Marine Carpuat and Kathleen
  McKeown",Incorporating Terminology Constraints in Automatic Post-Editing,"To appear in WMT, 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Users of machine translation (MT) may want to ensure the use of specific
lexical terminologies. While there exist techniques for incorporating
terminology constraints during inference for MT, current APE approaches cannot
ensure that they will appear in the final translation. In this paper, we
present both autoregressive and non-autoregressive models for lexically
constrained APE, demonstrating that our approach enables preservation of 95% of
the terminologies and also improves translation quality on English-German
benchmarks. Even when applied to lexically constrained MT output, our approach
is able to improve preservation of the terminologies. However, we show that our
models do not learn to copy constraints systematically and suggest a simple
data augmentation technique that leads to improved performance and robustness.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 15:44:03 GMT'}]",2020-10-20,"[['Wan', 'David', ''], ['Kedzie', 'Chris', ''], ['Ladhak', 'Faisal', ''], ['Carpuat', 'Marine', ''], ['McKeown', 'Kathleen', '']]"
1308583,2006.14069,Ramon Ferrer i Cancho,"Ramon Ferrer-i-Cancho, Carlos G\'omez-Rodr\'iguez and Juan Luis
  Esteban",The variation of the sum of edge lengths in linear arrangements of trees,"Clarity and organization have been improved; typos and little
  mathematical errors have been corrected; relevant research by M. Iordanskii's
  is reviewed",,,,cs.DM cs.CL physics.soc-ph,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A fundamental problem in network science is the normalization of the
topological or physical distance between vertices, that requires understanding
the range of variation of the unnormalized distances. Here we investigate the
limits of the variation of the physical distance in linear arrangements of the
vertices of trees. In particular, we investigate various problems on the sum of
edge lengths in trees of a fixed size: the minimum and the maximum value of the
sum for specific trees, the minimum and the maximum in classes of trees (bistar
trees and caterpillar trees) and finally the minimum and the maximum for any
tree. We establish some foundations for research on optimality scores for
spatial networks in one dimension.
","[{'version': 'v1', 'created': 'Wed, 24 Jun 2020 21:53:39 GMT'}, {'version': 'v2', 'created': 'Mon, 19 Oct 2020 09:32:17 GMT'}]",2020-10-20,"[['Ferrer-i-Cancho', 'Ramon', ''], ['Gómez-Rodríguez', 'Carlos', ''], ['Esteban', 'Juan Luis', '']]"
1365847,2010.09517,Bowen Li,"Bowen Li, Taeuk Kim, Reinald Kim Amplayo, Frank Keller",Heads-up! Unsupervised Constituency Parsing via Self-Attention Heads,AACL-IJCNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Transformer-based pre-trained language models (PLMs) have dramatically
improved the state of the art in NLP across many tasks. This has led to
substantial interest in analyzing the syntactic knowledge PLMs learn. Previous
approaches to this question have been limited, mostly using test suites or
probes. Here, we propose a novel fully unsupervised parsing approach that
extracts constituency trees from PLM attention heads. We rank transformer
attention heads based on their inherent properties, and create an ensemble of
high-ranking heads to produce the final tree. Our method is adaptable to
low-resource languages, as it does not rely on development sets, which can be
expensive to annotate. Our experiments show that the proposed method often
outperform existing approaches if there is no development set present. Our
unsupervised parser can also be used as a tool to analyze the grammars PLMs
learn implicitly. For this, we use the parse trees induced by our method to
train a neural PCFG and compare it to a grammar derived from a human-annotated
treebank.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 13:51:40 GMT'}]",2020-10-20,"[['Li', 'Bowen', ''], ['Kim', 'Taeuk', ''], ['Amplayo', 'Reinald Kim', ''], ['Keller', 'Frank', '']]"
1365812,2010.09482,Shahram Khadivi,"Jingjing Huo, Christian Herold, Yingbo Gao, Leonard Dahlmann, Shahram
  Khadivi, and Hermann Ney",Diving Deep into Context-Aware Neural Machine Translation,Accepted at 5th Conference on Machine Translation (WMT20),,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Context-aware neural machine translation (NMT) is a promising direction to
improve the translation quality by making use of the additional context, e.g.,
document-level translation, or having meta-information. Although there exist
various architectures and analyses, the effectiveness of different
context-aware NMT models is not well explored yet. This paper analyzes the
performance of document-level NMT models on four diverse domains with a varied
amount of parallel document-level bilingual data. We conduct a comprehensive
set of experiments to investigate the impact of document-level NMT. We find
that there is no single best approach to document-level NMT, but rather that
different architectures come out on top on different tasks. Looking at
task-specific problems, such as pronoun resolution or headline translation, we
find improvements in the context-aware systems, even in cases where the
corpus-level metrics like BLEU show no significant improvement. We also show
that document-level back-translation significantly helps to compensate for the
lack of document-level bi-texts.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 13:23:12 GMT'}]",2020-10-20,"[['Huo', 'Jingjing', ''], ['Herold', 'Christian', ''], ['Gao', 'Yingbo', ''], ['Dahlmann', 'Leonard', ''], ['Khadivi', 'Shahram', ''], ['Ney', 'Hermann', '']]"
1365789,2010.09459,Leshem Choshen,"Eyal Shnarch, Leshem Choshen, Guy Moshkowich, Noam Slonim, Ranit
  Aharonov","Unsupervised Expressive Rules Provide Explainability and Assist Human
  Experts Grasping New Domains",Accepted to Findings of EMNLP,,,,cs.CL cs.HC cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Approaching new data can be quite deterrent; you do not know how your
categories of interest are realized in it, commonly, there is no labeled data
at hand, and the performance of domain adaptation methods is unsatisfactory.
  Aiming to assist domain experts in their first steps into a new task over a
new corpus, we present an unsupervised approach to reveal complex rules which
cluster the unexplored corpus by its prominent categories (or facets).
  These rules are human-readable, thus providing an important ingredient which
has become in short supply lately - explainability. Each rule provides an
explanation for the commonality of all the texts it clusters together.
  We present an extensive evaluation of the usefulness of these rules in
identifying target categories, as well as a user study which assesses their
interpretability.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 13:07:15 GMT'}]",2020-10-20,"[['Shnarch', 'Eyal', ''], ['Choshen', 'Leshem', ''], ['Moshkowich', 'Guy', ''], ['Slonim', 'Noam', ''], ['Aharonov', 'Ranit', '']]"
1365733,2010.09403,Du\v{s}an Vari\v{s},Du\v{s}an Vari\v{s} and Ond\v{r}ej Bojar,"Unsupervised Pretraining for Neural Machine Translation Using Elastic
  Weight Consolidation",ACL-SRW 2019 (camera-ready),,10.18653/v1/P19-2017,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This work presents our ongoing research of unsupervised pretraining in neural
machine translation (NMT). In our method, we initialize the weights of the
encoder and decoder with two language models that are trained with monolingual
data and then fine-tune the model on parallel data using Elastic Weight
Consolidation (EWC) to avoid forgetting of the original language modeling
tasks. We compare the regularization by EWC with the previous work that focuses
on regularization by language modeling objectives. The positive result is that
using EWC with the decoder achieves BLEU scores similar to the previous work.
However, the model converges 2-3 times faster and does not require the original
unlabeled training data during the fine-tuning stage. In contrast, the
regularization using EWC is less effective if the original and new tasks are
not closely related. We show that initializing the bidirectional NMT encoder
with a left-to-right language model and forcing the model to remember the
original left-to-right language modeling task limits the learning capacity of
the encoder for the whole bidirectional context.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 11:51:45 GMT'}]",2020-10-20,"[['Variš', 'Dušan', ''], ['Bojar', 'Ondřej', '']]"
1359754,2010.03424,Phuong Le-Hong,"The Viet Bui, Phuong Le-Hong",Cross-lingual Extended Named Entity Classification of Wikipedia Articles,Accepted to NTCIR-15,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The FPT.AI team participated in the SHINRA2020-ML subtask of the NTCIR-15
SHINRA task. This paper describes our method to solving the problem and
discusses the official results. Our method focuses on learning cross-lingual
representations, both on the word level and document level for page
classification. We propose a three-stage approach including multilingual model
pre-training, monolingual model fine-tuning and cross-lingual voting. Our
system is able to achieve the best scores for 25 out of 30 languages; and its
accuracy gaps to the best performing systems of the other five languages are
relatively small.
","[{'version': 'v1', 'created': 'Wed, 7 Oct 2020 14:06:09 GMT'}, {'version': 'v2', 'created': 'Sat, 17 Oct 2020 09:06:42 GMT'}]",2020-10-20,"[['Bui', 'The Viet', ''], ['Le-Hong', 'Phuong', '']]"
1365732,2010.09402,Sungwon Lyu,"Sungwon Lyu, Bokyung Son, Kichang Yang, and Jaekyoung Bae",Revisiting Modularized Multilingual NMT to Meet Industrial Demands,"The 2020 Conference on Empirical Methods in Natural Language
  Processing (EMNLP)",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The complete sharing of parameters for multilingual translation (1-1) has
been the mainstream approach in current research. However, degraded performance
due to the capacity bottleneck and low maintainability hinders its extensive
adoption in industries. In this study, we revisit the multilingual neural
machine translation model that only share modules among the same languages (M2)
as a practical alternative to 1-1 to satisfy industrial requirements. Through
comprehensive experiments, we identify the benefits of multi-way training and
demonstrate that the M2 can enjoy these benefits without suffering from the
capacity bottleneck. Furthermore, the interlingual space of the M2 allows
convenient modification of the model. By leveraging trained modules, we find
that incrementally added modules exhibit better performance than singly trained
models. The zero-shot performance of the added modules is even comparable to
supervised models. Our findings suggest that the M2 can be a competent
candidate for multilingual translation in industries.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 11:51:04 GMT'}]",2020-10-20,"[['Lyu', 'Sungwon', ''], ['Son', 'Bokyung', ''], ['Yang', 'Kichang', ''], ['Bae', 'Jaekyoung', '']]"
1365711,2010.09381,"Abdullatif K\""oksal","Abdullatif K\""oksal, Arzucan \""Ozg\""ur","The RELX Dataset and Matching the Multilingual Blanks for Cross-Lingual
  Relation Classification",Findings of EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Relation classification is one of the key topics in information extraction,
which can be used to construct knowledge bases or to provide useful information
for question answering. Current approaches for relation classification are
mainly focused on the English language and require lots of training data with
human annotations. Creating and annotating a large amount of training data for
low-resource languages is impractical and expensive. To overcome this issue, we
propose two cross-lingual relation classification models: a baseline model
based on Multilingual BERT and a new multilingual pretraining setup, which
significantly improves the baseline with distant supervision. For evaluation,
we introduce a new public benchmark dataset for cross-lingual relation
classification in English, French, German, Spanish, and Turkish, called RELX.
We also provide the RELX-Distant dataset, which includes hundreds of thousands
of sentences with relations from Wikipedia and Wikidata collected by distant
supervision for these languages. Our code and data are available at:
https://github.com/boun-tabi/RELX
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 11:08:16 GMT'}]",2020-10-20,"[['Köksal', 'Abdullatif', ''], ['Özgür', 'Arzucan', '']]"
1365987,2010.09657,Nipun Sadvilkar,Nipun Sadvilkar and Mark Neumann,PySBD: Pragmatic Sentence Boundary Disambiguation,"'PySBD: Pragmatic Sentence Boundary Disambiguation' is a short paper
  (5 Pages with references) accepted into 2nd Workshop for Natural Language
  Processing Open Source Software (NLP-OSS) at EMNLP 2020 happening on 19 Nov
  2020",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we present a rule-based sentence boundary disambiguation
Python package that works out-of-the-box for 22 languages. We aim to provide a
realistic segmenter which can provide logical sentences even when the format
and domain of the input text is unknown. In our work, we adapt the Golden Rules
Set (a language-specific set of sentence boundary exemplars) originally
implemented as a ruby gem - pragmatic_segmenter - which we ported to Python
with additional improvements and functionality. PySBD passes 97.92% of the
Golden Rule Set exemplars for English, an improvement of 25% over the next best
open-source Python tool.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 16:56:03 GMT'}]",2020-10-20,"[['Sadvilkar', 'Nipun', ''], ['Neumann', 'Mark', '']]"
1360107,2010.03777,Tianyu Liu,"Tianyu Liu, Xin Zheng, Xiaoan Ding, Baobao Chang and Zhifang Sui","An Empirical Study on Model-agnostic Debiasing Strategies for Robust
  Natural Language Inference",CoNLL 2020,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  The prior work on natural language inference (NLI) debiasing mainly targets
at one or few known biases while not necessarily making the models more robust.
In this paper, we focus on the model-agnostic debiasing strategies and explore
how to (or is it possible to) make the NLI models robust to multiple distinct
adversarial attacks while keeping or even strengthening the models'
generalization power. We firstly benchmark prevailing neural NLI models
including pretrained ones on various adversarial datasets. We then try to
combat distinct known biases by modifying a mixture of experts (MoE) ensemble
method and show that it's nontrivial to mitigate multiple NLI biases at the
same time, and that model-level ensemble method outperforms MoE ensemble
method. We also perform data augmentation including text swap, word
substitution and paraphrase and prove its efficiency in combating various
(though not all) adversarial attacks at the same time. Finally, we investigate
several methods to merge heterogeneous training data (1.35M) and perform model
ensembling, which are straightforward but effective to strengthen NLI models.
","[{'version': 'v1', 'created': 'Thu, 8 Oct 2020 05:40:45 GMT'}, {'version': 'v2', 'created': 'Sat, 17 Oct 2020 14:57:09 GMT'}]",2020-10-20,"[['Liu', 'Tianyu', ''], ['Zheng', 'Xin', ''], ['Ding', 'Xiaoan', ''], ['Chang', 'Baobao', ''], ['Sui', 'Zhifang', '']]"
1365696,2010.09366,Xiaoyu Guo,Xiao-Yu Guo and Yuan-Fang Li and Gholamreza Haffari,Understanding Unnatural Questions Improves Reasoning over Text,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Complex question answering (CQA) over raw text is a challenging task. A
prominent approach to this task is based on the programmer-interpreter
framework, where the programmer maps the question into a sequence of reasoning
actions which is then executed on the raw text by the interpreter. Learning an
effective CQA model requires large amounts of human-annotated data,consisting
of the ground-truth sequence of reasoning actions, which is time-consuming and
expensive to collect at scale. In this paper, we address the challenge of
learning a high-quality programmer (parser) by projecting natural
human-generated questions into unnatural machine-generated questions which are
more convenient to parse. We firstly generate synthetic (question,action
sequence) pairs by a data generator, and train a semantic parser that
associates synthetic questions with their corresponding action sequences. To
capture the diversity when applied tonatural questions, we learn a projection
model to map natural questions into their most similar unnatural questions for
which the parser can work well. Without any natural training data, our
projection model provides high-quality action sequences for the CQA task.
Experimental results show that the QA model trained exclusively with synthetic
data generated by our method outperforms its state-of-the-art counterpart
trained on human-labeled data.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 10:22:16 GMT'}]",2020-10-20,"[['Guo', 'Xiao-Yu', ''], ['Li', 'Yuan-Fang', ''], ['Haffari', 'Gholamreza', '']]"
1365852,2010.09522,Devamanyu Hazarika,"Shagun Uppal, Sarthak Bhagat, Devamanyu Hazarika, Navonil Majumdar,
  Soujanya Poria, Roger Zimmermann, and Amir Zadeh",Emerging Trends of Multimodal Research in Vision and Language,,,,,cs.CV cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Deep Learning and its applications have cascaded impactful research and
development with a diverse range of modalities present in the real-world data.
More recently, this has enhanced research interests in the intersection of the
Vision and Language arena with its numerous applications and fast-paced growth.
In this paper, we present a detailed overview of the latest trends in research
pertaining to visual and language modalities. We look at its applications in
their task formulations and how to solve various problems related to semantic
perception and content generation. We also address task-specific trends, along
with their evaluation strategies and upcoming challenges. Moreover, we shed
some light on multi-disciplinary patterns and insights that have emerged in the
recent past, directing this field towards more modular and transparent
intelligent systems. This survey identifies key trends gravitating recent
literature in VisLang research and attempts to unearth directions that the
field is heading towards.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 13:55:10 GMT'}]",2020-10-20,"[['Uppal', 'Shagun', ''], ['Bhagat', 'Sarthak', ''], ['Hazarika', 'Devamanyu', ''], ['Majumdar', 'Navonil', ''], ['Poria', 'Soujanya', ''], ['Zimmermann', 'Roger', ''], ['Zadeh', 'Amir', '']]"
1357941,2010.01611,Pouya Rezazadeh Kalehbasti,"Liubov Nikolenko, Pouya Rezazadeh Kalehbasti","When in Doubt, Ask: Generating Answerable and Unanswerable Questions,
  Unsupervised",,,,,cs.CL cs.FL cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Question Answering (QA) is key for making possible a robust communication
between human and machine. Modern language models used for QA have surpassed
the human-performance in several essential tasks; however, these models require
large amounts of human-generated training data which are costly and
time-consuming to create. This paper studies augmenting human-made datasets
with synthetic data as a way of surmounting this problem. A state-of-the-art
model based on deep transformers is used to inspect the impact of using
synthetic answerable and unanswerable questions to complement a well-known
human-made dataset. The results indicate a tangible improvement in the
performance of the language model (measured in terms of F1 and EM scores)
trained on the mixed dataset. Specifically, unanswerable question-answers prove
more effective in boosting the model: the F1 score gain from adding to the
original dataset the answerable, unanswerable, and combined question-answers
were 1.3%, 5.0%, and 6.7%, respectively. [Link to the Github repository:
https://github.com/lnikolenko/EQA]
","[{'version': 'v1', 'created': 'Sun, 4 Oct 2020 15:56:44 GMT'}, {'version': 'v2', 'created': 'Mon, 19 Oct 2020 02:29:13 GMT'}]",2020-10-20,"[['Nikolenko', 'Liubov', ''], ['Kalehbasti', 'Pouya Rezazadeh', '']]"
1263287,2003.12932,Anuj Gupta,"Ankit Kumar, Piyush Makhija, Anuj Gupta",Noisy Text Data: Achilles' Heel of BERT,"7 pages, 2 tables, 1 plot",,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Owing to the phenomenal success of BERT on various NLP tasks and benchmark
datasets, industry practitioners are actively experimenting with fine-tuning
BERT to build NLP applications for solving industry use cases. For most
datasets that are used by practitioners to build industrial NLP applications,
it is hard to guarantee absence of any noise in the data. While BERT has
performed exceedingly well for transferring the learnings from one use case to
another, it remains unclear how BERT performs when fine-tuned on noisy text. In
this work, we explore the sensitivity of BERT to noise in the data. We work
with most commonly occurring noise (spelling mistakes, typos) and show that
this results in significant degradation in the performance of BERT. We present
experimental results to show that BERT's performance on fundamental NLP tasks
like sentiment analysis and textual similarity drops significantly in the
presence of (simulated) noise on benchmark datasets viz. IMDB Movie Review,
STS-B, SST-2. Further, we identify shortcomings in the existing BERT pipeline
that are responsible for this drop in performance. Our findings suggest that
practitioners need to be vary of presence of noise in their datasets while
fine-tuning BERT to solve industry use cases.
","[{'version': 'v1', 'created': 'Sun, 29 Mar 2020 02:49:11 GMT'}, {'version': 'v2', 'created': 'Tue, 21 Apr 2020 05:50:31 GMT'}, {'version': 'v3', 'created': 'Sun, 18 Oct 2020 09:22:01 GMT'}]",2020-10-20,"[['Kumar', 'Ankit', ''], ['Makhija', 'Piyush', ''], ['Gupta', 'Anuj', '']]"
1366022,2010.09692,Xusen Yin,"Xusen Yin, Jonathan May, Li Zhou, Kevin Small",Question Generation for Supporting Informational Query Intents,9 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Users frequently ask simple factoid questions when encountering question
answering (QA) systems, attenuating the impact of myriad recent works designed
to support more complex questions. Prompting users with automatically generated
suggested questions (SQs) can improve understanding of QA system capabilities
and thus facilitate using this technology more effectively. While question
generation (QG) is a well-established problem, existing methods are not
targeted at producing SQ guidance for human users seeking more in-depth
information about a specific concept. In particular, existing QG works are
insufficient for this task as the generated questions frequently (1) require
access to supporting documents as comprehension context (e.g., How many points
did LeBron score?) and (2) focus on short answer spans, often producing
peripheral factoid questions unlikely to attract interest. In this work, we aim
to generate self-explanatory questions that focus on the main document topics
and are answerable with variable length passages as appropriate. We satisfy
these requirements by using a BERT-based Pointer-Generator Network (BertPGN)
trained on the Natural Questions (NQ) dataset. First, we show that the BertPGN
model produces state-of-the-art QG performance for long and short answers for
in-domain NQ (BLEU-4 for 20.13 and 28.09, respectively). Secondly, we evaluate
this QG model on the out-of-domain NewsQA dataset automatically and with human
evaluation, demonstrating that our method produces better SQs for news
articles, even those from a different domain than the training data.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 17:30:08 GMT'}]",2020-10-20,"[['Yin', 'Xusen', ''], ['May', 'Jonathan', ''], ['Zhou', 'Li', ''], ['Small', 'Kevin', '']]"
1274857,2004.10087,Libo Qin,"Libo Qin, Xiao Xu, Wanxiang Che, Ting Liu","AGIF: An Adaptive Graph-Interactive Framework for Joint Multiple Intent
  Detection and Slot Filling","Accepted at Findings of EMNLP 2020. Data and code are available at
  this [URL] (https://github.com/LooperXX/AGIF)",,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In real-world scenarios, users usually have multiple intents in the same
utterance. Unfortunately, most spoken language understanding (SLU) models
either mainly focused on the single intent scenario, or simply incorporated an
overall intent context vector for all tokens, ignoring the fine-grained
multiple intents information integration for token-level slot prediction. In
this paper, we propose an Adaptive Graph-Interactive Framework (AGIF) for joint
multiple intent detection and slot filling, where we introduce an intent-slot
graph interaction layer to model the strong correlation between the slot and
intents. Such an interaction layer is applied to each token adaptively, which
has the advantage to automatically extract the relevant intents information,
making a fine-grained intent information integration for the token-level slot
prediction. Experimental results on three multi-intent datasets show that our
framework obtains substantial improvement and achieves the state-of-the-art
performance. In addition, our framework achieves new state-of-the-art
performance on two single-intent datasets.
","[{'version': 'v1', 'created': 'Tue, 21 Apr 2020 15:07:34 GMT'}, {'version': 'v2', 'created': 'Mon, 5 Oct 2020 12:44:09 GMT'}, {'version': 'v3', 'created': 'Tue, 6 Oct 2020 02:23:43 GMT'}, {'version': 'v4', 'created': 'Sat, 17 Oct 2020 04:28:29 GMT'}]",2020-10-20,"[['Qin', 'Libo', ''], ['Xu', 'Xiao', ''], ['Che', 'Wanxiang', ''], ['Liu', 'Ting', '']]"
1273937,2004.09167,Akshay Smit,"Akshay Smit, Saahil Jain, Pranav Rajpurkar, Anuj Pareek, Andrew Y. Ng,
  Matthew P. Lungren","CheXbert: Combining Automatic Labelers and Expert Annotations for
  Accurate Radiology Report Labeling Using BERT",Accepted to EMNLP 2020,,,,cs.CL cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The extraction of labels from radiology text reports enables large-scale
training of medical imaging models. Existing approaches to report labeling
typically rely either on sophisticated feature engineering based on medical
domain knowledge or manual annotations by experts. In this work, we introduce a
BERT-based approach to medical image report labeling that exploits both the
scale of available rule-based systems and the quality of expert annotations. We
demonstrate superior performance of a biomedically pretrained BERT model first
trained on annotations of a rule-based labeler and then finetuned on a small
set of expert annotations augmented with automated backtranslation. We find
that our final model, CheXbert, is able to outperform the previous best
rules-based labeler with statistical significance, setting a new SOTA for
report labeling on one of the largest datasets of chest x-rays.
","[{'version': 'v1', 'created': 'Mon, 20 Apr 2020 09:46:40 GMT'}, {'version': 'v2', 'created': 'Thu, 30 Apr 2020 05:32:06 GMT'}, {'version': 'v3', 'created': 'Sun, 18 Oct 2020 20:30:22 GMT'}]",2020-10-20,"[['Smit', 'Akshay', ''], ['Jain', 'Saahil', ''], ['Rajpurkar', 'Pranav', ''], ['Pareek', 'Anuj', ''], ['Ng', 'Andrew Y.', ''], ['Lungren', 'Matthew P.', '']]"
1268231,2004.03461,Mantas Luko\v{s}evi\v{c}ius,Lukas Stankevi\v{c}ius and Mantas Luko\v{s}evi\v{c}ius,Testing pre-trained Transformer models for Lithuanian news clustering,Submission accepted at https://ivus.ktu.edu/,"Proceedings of the Information Society and University Studies
  2020, pp. 46-53, vol. 2698, CEUR, Kaunas, 2020, ISSN: 1613-0073",,,cs.IR cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A recent introduction of Transformer deep learning architecture made
breakthroughs in various natural language processing tasks. However,
non-English languages could not leverage such new opportunities with the
English text pre-trained models. This changed with research focusing on
multilingual models, where less-spoken languages are the main beneficiaries. We
compare pre-trained multilingual BERT, XLM-R, and older learned text
representation methods as encodings for the task of Lithuanian news clustering.
Our results indicate that publicly available pre-trained multilingual
Transformer models can be fine-tuned to surpass word vectors but still score
much lower than specially trained doc2vec embeddings.
","[{'version': 'v1', 'created': 'Fri, 3 Apr 2020 14:41:54 GMT'}]",2020-10-20,"[['Stankevičius', 'Lukas', ''], ['Lukoševičius', 'Mantas', '']]"
1264902,2004.00132,Jo\~ao Ant\^onio Chagas Nunes,"Jo\~ao Ant\^onio Chagas Nunes, David Mac\^edo, Cleber Zanchettin",AM-MobileNet1D: A Portable Model for Speaker Recognition,2020 International Joint Conference on Neural Networks (IJCNN),2020 International Joint Conference on Neural Networks (IJCNN),10.1109/IJCNN48605.2020.9207519,,cs.SD cs.CL cs.LG eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Speaker Recognition and Speaker Identification are challenging tasks with
essential applications such as automation, authentication, and security. Deep
learning approaches like SincNet and AM-SincNet presented great results on
these tasks. The promising performance took these models to real-world
applications that becoming fundamentally end-user driven and mostly mobile. The
mobile computation requires applications with reduced storage size,
non-processing and memory intensive and efficient energy-consuming. The deep
learning approaches, in contrast, usually are energy expensive, demanding
storage, processing power, and memory. To address this demand, we propose a
portable model called Additive Margin MobileNet1D (AM-MobileNet1D) to Speaker
Identification on mobile devices. We evaluated the proposed approach on TIMIT
and MIT datasets obtaining equivalent or better performances concerning the
baseline methods. Additionally, the proposed model takes only 11.6 megabytes on
disk storage against 91.2 from SincNet and AM-SincNet architectures, making the
model seven times faster, with eight times fewer parameters.
","[{'version': 'v1', 'created': 'Tue, 31 Mar 2020 21:42:59 GMT'}]",2020-10-20,"[['Nunes', 'João Antônio Chagas', ''], ['Macêdo', 'David', ''], ['Zanchettin', 'Cleber', '']]"
1365652,2010.09322,Anuj Diwan,"Anuj Diwan, Preethi Jyothi","Reduce and Reconstruct: Improving Low-resource End-to-end ASR Via
  Reconstruction Using Reduced Vocabularies","5 pages, 1 figure",,,,eess.AS cs.AI cs.CL cs.LG cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  End-to-end automatic speech recognition (ASR) systems are increasingly being
favoured due to their direct treatment of the problem of speech to text
conversion. However, these systems are known to be data hungry and hence
underperform in low-resource settings. In this work, we propose a seemingly
simple but effective technique to improve low-resource end-to-end ASR
performance. We compress the output vocabulary of the end-to-end ASR system
using linguistically meaningful reductions and then reconstruct the original
vocabulary using a standalone module. Our objective is two-fold: to lessen the
burden on the low-resource end-to-end ASR system by reducing the output
vocabulary space and to design a powerful reconstruction module that recovers
sequences in the original vocabulary from sequences in the reduced vocabulary.
We present two reconstruction modules, an encoder decoder-based architecture
and a finite state transducer-based model. We demonstrate the efficacy of our
proposed techniques using ASR systems for two Indian languages, Gujarati and
Telugu.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 08:59:58 GMT'}]",2020-10-20,"[['Diwan', 'Anuj', ''], ['Jyothi', 'Preethi', '']]"
1347334,2009.05831,Kai Sun,"Kai Sun, Dian Yu, Jianshu Chen, Dong Yu, Claire Cardie","Improving Machine Reading Comprehension with Contextualized Commonsense
  Knowledge",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we aim to extract commonsense knowledge to improve machine
reading comprehension. We propose to represent relations implicitly by
situating structured knowledge in a context instead of relying on a pre-defined
set of relations, and we call it contextualized knowledge. Each piece of
contextualized knowledge consists of a pair of interrelated verbal and
nonverbal messages extracted from a script and the scene in which they occur as
context to implicitly represent the relation between the verbal and nonverbal
messages, which are originally conveyed by different modalities within the
script. We propose a two-stage fine-tuning strategy to use the large-scale
weakly-labeled data based on a single type of contextualized knowledge and
employ a teacher-student paradigm to inject multiple types of contextualized
knowledge into a student machine reader. Experimental results demonstrate that
our method outperforms a state-of-the-art baseline by a 4.3% improvement in
accuracy on the machine reading comprehension dataset C^3, wherein most of the
questions require unstated prior knowledge.
","[{'version': 'v1', 'created': 'Sat, 12 Sep 2020 17:20:01 GMT'}, {'version': 'v2', 'created': 'Mon, 19 Oct 2020 02:22:06 GMT'}]",2020-10-20,"[['Sun', 'Kai', ''], ['Yu', 'Dian', ''], ['Chen', 'Jianshu', ''], ['Yu', 'Dong', ''], ['Cardie', 'Claire', '']]"
1348620,2009.07117,Tianyu Zhao,Tianyu Zhao and Tatsuya Kawahara,Multi-Referenced Training for Dialogue Response Generation,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In open-domain dialogue response generation, a dialogue context can be
continued with diverse responses, and the dialogue models should capture such
one-to-many relations. In this work, we first analyze the training objective of
dialogue models from the view of Kullback-Leibler divergence (KLD) and show
that the gap between the real world probability distribution and the
single-referenced data's probability distribution prevents the model from
learning the one-to-many relations efficiently. Then we explore approaches to
multi-referenced training in two aspects. Data-wise, we generate diverse pseudo
references from a powerful pretrained model to build multi-referenced data that
provides a better approximation of the real-world distribution. Model-wise, we
propose to equip variational models with an expressive prior, named linear
Gaussian model (LGM). Experimental results of automated evaluation and human
evaluation show that the methods yield significant improvements over baselines.
We will release our code and data in
https://github.com/ZHAOTING/dialog-processing.
","[{'version': 'v1', 'created': 'Tue, 15 Sep 2020 14:17:53 GMT'}, {'version': 'v2', 'created': 'Sun, 18 Oct 2020 08:02:58 GMT'}]",2020-10-20,"[['Zhao', 'Tianyu', ''], ['Kawahara', 'Tatsuya', '']]"
1255516,2003.05161,Laura Ruis,"Laura Ruis, Jacob Andreas, Marco Baroni, Diane Bouchacourt, Brenden M.
  Lake","A Benchmark for Systematic Generalization in Grounded Language
  Understanding",accepted at NeurIPS 2020,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Humans easily interpret expressions that describe unfamiliar situations
composed from familiar parts (""greet the pink brontosaurus by the ferris
wheel""). Modern neural networks, by contrast, struggle to interpret novel
compositions. In this paper, we introduce a new benchmark, gSCAN, for
evaluating compositional generalization in situated language understanding.
Going beyond a related benchmark that focused on syntactic aspects of
generalization, gSCAN defines a language grounded in the states of a grid
world, facilitating novel evaluations of acquiring linguistically motivated
rules. For example, agents must understand how adjectives such as 'small' are
interpreted relative to the current world state or how adverbs such as
'cautiously' combine with new verbs. We test a strong multi-modal baseline
model and a state-of-the-art compositional method finding that, in most cases,
they fail dramatically when generalization requires systematic compositional
rules.
","[{'version': 'v1', 'created': 'Wed, 11 Mar 2020 08:40:15 GMT'}, {'version': 'v2', 'created': 'Sat, 17 Oct 2020 17:02:02 GMT'}]",2020-10-20,"[['Ruis', 'Laura', ''], ['Andreas', 'Jacob', ''], ['Baroni', 'Marco', ''], ['Bouchacourt', 'Diane', ''], ['Lake', 'Brenden M.', '']]"
1288615,2005.08820,Azzam Mourad Dr.,"Azzam Mourad, Ali Srour, Haidar Harmanani, Cathia Jenainatiy, Mohamad
  Arafeh","Critical Impact of Social Networks Infodemic on Defeating Coronavirus
  COVID-19 Pandemic: Twitter-Based Study and Research Directions","11 pages, 10 figures, Journal Article",https://ieeexplore.ieee.org/document/9223699 (2020),10.1109/TNSM.2020.3031034,"In the IEEE Transactions on Network and Service Management (Early
  Access, 2020)",cs.SI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  News creation and consumption has been changing since the advent of social
media. An estimated 2.95 billion people in 2019 used social media worldwide.
The widespread of the Coronavirus COVID-19 resulted with a tsunami of social
media. Most platforms were used to transmit relevant news, guidelines and
precautions to people. According to WHO, uncontrolled conspiracy theories and
propaganda are spreading faster than the COVID-19 pandemic itself, creating an
infodemic and thus causing psychological panic, misleading medical advises, and
economic disruption. Accordingly, discussions have been initiated with the
objective of moderating all COVID-19 communications, except those initiated
from trusted sources such as the WHO and authorized governmental entities. This
paper presents a large-scale study based on data mined from Twitter. Extensive
analysis has been performed on approximately one million COVID-19 related
tweets collected over a period of two months. Furthermore, the profiles of
288,000 users were analyzed including unique users profiles, meta-data and
tweets context. The study noted various interesting conclusions including the
critical impact of the (1) exploitation of the COVID-19 crisis to redirect
readers to irrelevant topics and (2) widespread of unauthentic medical
precautions and information. Further data analysis revealed the importance of
using social networks in a global pandemic crisis by relying on credible users
with variety of occupations, content developers and influencers in specific
fields. In this context, several insights and findings have been provided while
elaborating computing and non-computing implications and research directions
for potential solutions and social networks management strategies during crisis
periods.
","[{'version': 'v1', 'created': 'Mon, 18 May 2020 15:53:13 GMT'}]",2020-10-20,"[['Mourad', 'Azzam', ''], ['Srour', 'Ali', ''], ['Harmanani', 'Haidar', ''], ['Jenainatiy', 'Cathia', ''], ['Arafeh', 'Mohamad', '']]"
1240378,2002.02955,Xavier Garcia,"Xavier Garcia, Pierre Foret, Thibault Sellam, Ankur P. Parikh",A Multilingual View of Unsupervised Machine Translation,Accepted at Findings of EMNLP 2020 [Fixed processing error.],,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present a probabilistic framework for multilingual neural machine
translation that encompasses supervised and unsupervised setups, focusing on
unsupervised translation. In addition to studying the vanilla case where there
is only monolingual data available, we propose a novel setup where one language
in the (source, target) pair is not associated with any parallel data, but
there may exist auxiliary parallel data that contains the other. This auxiliary
data can naturally be utilized in our probabilistic framework via a novel
cross-translation loss term. Empirically, we show that our approach results in
higher BLEU scores over state-of-the-art unsupervised models on the WMT'14
English-French, WMT'16 English-German, and WMT'16 English-Romanian datasets in
most directions. In particular, we obtain a +1.65 BLEU advantage over the
best-performing unsupervised model in the Romanian-English direction.
","[{'version': 'v1', 'created': 'Fri, 7 Feb 2020 18:50:21 GMT'}, {'version': 'v2', 'created': 'Fri, 21 Feb 2020 20:39:34 GMT'}, {'version': 'v3', 'created': 'Thu, 8 Oct 2020 20:55:25 GMT'}, {'version': 'v4', 'created': 'Fri, 16 Oct 2020 20:41:25 GMT'}]",2020-10-20,"[['Garcia', 'Xavier', ''], ['Foret', 'Pierre', ''], ['Sellam', 'Thibault', ''], ['Parikh', 'Ankur P.', '']]"
1350528,2009.09025,Craig Stewart,"Ricardo Rei, Craig Stewart, Ana C Farinha, Alon Lavie",COMET: A Neural Framework for MT Evaluation,EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present COMET, a neural framework for training multilingual machine
translation evaluation models which obtains new state-of-the-art levels of
correlation with human judgements. Our framework leverages recent breakthroughs
in cross-lingual pretrained language modeling resulting in highly multilingual
and adaptable MT evaluation models that exploit information from both the
source input and a target-language reference translation in order to more
accurately predict MT quality. To showcase our framework, we train three models
with different types of human judgements: Direct Assessments, Human-mediated
Translation Edit Rate and Multidimensional Quality Metrics. Our models achieve
new state-of-the-art performance on the WMT 2019 Metrics shared task and
demonstrate robustness to high-performing systems.
","[{'version': 'v1', 'created': 'Fri, 18 Sep 2020 18:54:15 GMT'}, {'version': 'v2', 'created': 'Mon, 19 Oct 2020 14:10:10 GMT'}]",2020-10-20,"[['Rei', 'Ricardo', ''], ['Stewart', 'Craig', ''], ['Farinha', 'Ana C', ''], ['Lavie', 'Alon', '']]"
1226138,2001.00725,Chenguang Zhu,"Ziyi Yang, Chenguang Zhu, Robert Gmyr, Michael Zeng, Xuedong Huang,
  Eric Darve","TED: A Pretrained Unsupervised Summarization Model with Theme Modeling
  and Denoising",Accepted at EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Text summarization aims to extract essential information from a piece of text
and transform the text into a concise version. Existing unsupervised
abstractive summarization models leverage recurrent neural networks framework
while the recently proposed transformer exhibits much more capability.
Moreover, most of previous summarization models ignore abundant unlabeled
corpora resources available for pretraining. In order to address these issues,
we propose TED, a transformer-based unsupervised abstractive summarization
system with pretraining on large-scale data. We first leverage the lead bias in
news articles to pretrain the model on millions of unlabeled corpora. Next, we
finetune TED on target domains through theme modeling and a denoising
autoencoder to enhance the quality of generated summaries. Notably, TED
outperforms all unsupervised abstractive baselines on NYT, CNN/DM and English
Gigaword datasets with various document styles. Further analysis shows that the
summaries generated by TED are highly abstractive, and each component in the
objective function of TED is highly effective.
","[{'version': 'v1', 'created': 'Fri, 3 Jan 2020 05:15:41 GMT'}, {'version': 'v2', 'created': 'Mon, 6 Jan 2020 02:12:26 GMT'}, {'version': 'v3', 'created': 'Sun, 18 Oct 2020 00:26:09 GMT'}]",2020-10-20,"[['Yang', 'Ziyi', ''], ['Zhu', 'Chenguang', ''], ['Gmyr', 'Robert', ''], ['Zeng', 'Michael', ''], ['Huang', 'Xuedong', ''], ['Darve', 'Eric', '']]"
1283340,2005.03545,Devamanyu Hazarika,"Devamanyu Hazarika, Roger Zimmermann, Soujanya Poria","MISA: Modality-Invariant and -Specific Representations for Multimodal
  Sentiment Analysis",Accepted at ACM MM 2020 (Oral Paper),,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  Multimodal Sentiment Analysis is an active area of research that leverages
multimodal signals for affective understanding of user-generated videos. The
predominant approach, addressing this task, has been to develop sophisticated
fusion techniques. However, the heterogeneous nature of the signals creates
distributional modality gaps that pose significant challenges. In this paper,
we aim to learn effective modality representations to aid the process of
fusion. We propose a novel framework, MISA, which projects each modality to two
distinct subspaces. The first subspace is modality-invariant, where the
representations across modalities learn their commonalities and reduce the
modality gap. The second subspace is modality-specific, which is private to
each modality and captures their characteristic features. These representations
provide a holistic view of the multimodal data, which is used for fusion that
leads to task predictions. Our experiments on popular sentiment analysis
benchmarks, MOSI and MOSEI, demonstrate significant gains over state-of-the-art
models. We also consider the task of Multimodal Humor Detection and experiment
on the recently proposed UR_FUNNY dataset. Here too, our model fares better
than strong baselines, establishing MISA as a useful multimodal framework.
","[{'version': 'v1', 'created': 'Thu, 7 May 2020 15:13:23 GMT'}, {'version': 'v2', 'created': 'Fri, 8 May 2020 12:14:37 GMT'}, {'version': 'v3', 'created': 'Mon, 19 Oct 2020 13:41:27 GMT'}]",2020-10-20,"[['Hazarika', 'Devamanyu', ''], ['Zimmermann', 'Roger', ''], ['Poria', 'Soujanya', '']]"
1355116,2009.13613,Danish Contractor,"Danish Contractor, Shashank Goel, Mausam, Parag Singla",Joint Spatio-Textual Reasoning for Answering Tourism Questions,Updated version,,,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Our goal is to answer real-world tourism questions that seek
Points-of-Interest (POI) recommendations. Such questions express various kinds
of spatial and non-spatial constraints, necessitating a combination of textual
and spatial reasoning. In response, we develop the first joint spatio-textual
reasoning model, which combines geo-spatial knowledge with information in
textual corpora to answer questions. We first develop a modular
spatial-reasoning network that uses geo-coordinates of location names mentioned
in a question, and of candidate answer POIs, to reason over only spatial
constraints. We then combine our spatial-reasoner with a textual reasoner in a
joint model and present experiments on a real world POI recommendation task. We
report substantial improvements over existing models with-out joint
spatio-textual reasoning.
","[{'version': 'v1', 'created': 'Mon, 28 Sep 2020 20:35:00 GMT'}, {'version': 'v2', 'created': 'Mon, 19 Oct 2020 07:18:42 GMT'}]",2020-10-20,"[['Contractor', 'Danish', ''], ['Goel', 'Shashank', ''], ['Mausam', '', ''], ['Singla', 'Parag', '']]"
1223498,1912.11602,Chenguang Zhu,"Chenguang Zhu, Ziyi Yang, Robert Gmyr, Michael Zeng, Xuedong Huang",Make Lead Bias in Your Favor: Zero-shot Abstractive News Summarization,"10 pages, 7 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Lead bias is a common phenomenon in news summarization, where early parts of
an article often contain the most salient information. While many algorithms
exploit this fact in summary generation, it has a detrimental effect on
teaching the model to discriminate and extract important information in
general. We propose that the lead bias can be leveraged in our favor in a
simple and effective way to pre-train abstractive news summarization models on
large-scale unlabeled news corpora: predicting the leading sentences using the
rest of an article. We collect a massive news corpus and conduct data cleaning
and filtering via statistical analysis. We then apply the proposed
self-supervised pre-training to existing generation models BART and T5 for
domain adaptation. Via extensive experiments on six benchmark datasets, we show
that this approach can dramatically improve the summarization quality and
achieve state-of-the-art results for zero-shot news summarization without any
fine-tuning. For example, in the DUC2003 dataset, the ROUGE-1 score of BART
increases 13.7% after the lead-bias pre-training. We deploy the model in
Microsoft News and provide public APIs as well as a demo website for
multi-lingual news summarization.
","[{'version': 'v1', 'created': 'Wed, 25 Dec 2019 06:05:44 GMT'}, {'version': 'v2', 'created': 'Tue, 7 Jan 2020 04:04:03 GMT'}, {'version': 'v3', 'created': 'Fri, 16 Oct 2020 23:43:44 GMT'}]",2020-10-20,"[['Zhu', 'Chenguang', ''], ['Yang', 'Ziyi', ''], ['Gmyr', 'Robert', ''], ['Zeng', 'Michael', ''], ['Huang', 'Xuedong', '']]"
1366027,2010.09697,William Merrill,"William Merrill and Vivek Ramanujan and Yoav Goldberg and Roy Schwartz
  and Noah Smith",Parameter Norm Growth During Training of Transformers,Preprint. 9 body pages with appendix,,,,cs.LG cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The capacity of neural networks like the widely adopted transformer is known
to be very high. Evidence is emerging that they learn successfully due to
inductive bias in the training routine, typically some variant of gradient
descent (GD). To better understand this bias, we study the tendency of
transformer parameters to grow in magnitude during training. We find, both
theoretically and empirically, that, in certain contexts, GD increases the
parameter $L_2$ norm up to a threshold that itself increases with training-set
accuracy. This means increasing training accuracy over time enables the norm to
increase. Empirically, we show that the norm grows continuously over
pretraining for T5 (Raffel et al., 2019). We show that pretrained T5
approximates a semi-discretized network with saturated activation functions.
Such ""saturated"" networks are known to have a reduced capacity compared to the
original network family that can be described in automata-theoretic terms. This
suggests saturation is a new characterization of an inductive bias implicit in
GD that is of particular interest for NLP. While our experiments focus on
transformers, our theoretical analysis extends to other architectures with
similar formal properties, such as feedforward ReLU networks.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 17:40:38 GMT'}]",2020-10-20,"[['Merrill', 'William', ''], ['Ramanujan', 'Vivek', ''], ['Goldberg', 'Yoav', ''], ['Schwartz', 'Roy', ''], ['Smith', 'Noah', '']]"
1366023,2010.09693,David Wan,"David Wan, Zhengping Jiang, Chris Kedzie, Elsbeth Turcan, Peter Bell
  and Kathleen McKeown","Subtitles to Segmentation: Improving Low-Resource Speech-to-Text
  Translation Pipelines",,CLSST@LREC 2020 68-73,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this work, we focus on improving ASR output segmentation in the context of
low-resource language speech-to-text translation. ASR output segmentation is
crucial, as ASR systems segment the input audio using purely acoustic
information and are not guaranteed to output sentence-like segments. Since most
MT systems expect sentences as input, feeding in longer unsegmented passages
can lead to sub-optimal performance. We explore the feasibility of using
datasets of subtitles from TV shows and movies to train better ASR segmentation
models. We further incorporate part-of-speech (POS) tag and dependency label
information (derived from the unsegmented ASR outputs) into our segmentation
model. We show that this noisy syntactic information can improve model
accuracy. We evaluate our models intrinsically on segmentation quality and
extrinsically on downstream MT performance, as well as downstream tasks
including cross-lingual information retrieval (CLIR) tasks and human relevance
assessments. Our model shows improved performance on downstream tasks for
Lithuanian and Bulgarian.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 17:32:40 GMT'}]",2020-10-20,"[['Wan', 'David', ''], ['Jiang', 'Zhengping', ''], ['Kedzie', 'Chris', ''], ['Turcan', 'Elsbeth', ''], ['Bell', 'Peter', ''], ['McKeown', 'Kathleen', '']]"
1357940,2010.01610,Wenjuan Han,"Wenjuan Han, Liwen Zhang, Yong Jiang, Kewei Tu",Adversarial Attack and Defense of Structured Prediction Models,Accepted to EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Building an effective adversarial attacker and elaborating on countermeasures
for adversarial attacks for natural language processing (NLP) have attracted a
lot of research in recent years. However, most of the existing approaches focus
on classification problems. In this paper, we investigate attacks and defenses
for structured prediction tasks in NLP. Besides the difficulty of perturbing
discrete words and the sentence fluency problem faced by attackers in any NLP
tasks, there is a specific challenge to attackers of structured prediction
models: the structured output of structured prediction models is sensitive to
small perturbations in the input. To address these problems, we propose a novel
and unified framework that learns to attack a structured prediction model using
a sequence-to-sequence model with feedbacks from multiple reference models of
the same structured prediction task. Based on the proposed attack, we further
reinforce the victim model with adversarial training, making its prediction
more robust and accurate. We evaluate the proposed framework in dependency
parsing and part-of-speech tagging. Automatic and human evaluations show that
our proposed framework succeeds in both attacking state-of-the-art structured
prediction models and boosting them with adversarial training.
","[{'version': 'v1', 'created': 'Sun, 4 Oct 2020 15:54:03 GMT'}, {'version': 'v2', 'created': 'Sun, 18 Oct 2020 09:39:58 GMT'}]",2020-10-20,"[['Han', 'Wenjuan', ''], ['Zhang', 'Liwen', ''], ['Jiang', 'Yong', ''], ['Tu', 'Kewei', '']]"
1365643,2010.09313,Jonas Wallat,"Jonas Wallat, Jaspreet Singh, Avishek Anand",BERTnesia: Investigating the capture and forgetting of knowledge in BERT,BBNLP 2020,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Probing complex language models has recently revealed several insights into
linguistic and semantic patterns found in the learned representations. In this
paper, we probe BERT specifically to understand and measure the relational
knowledge it captures. We utilize knowledge base completion tasks to probe
every layer of pre-trained as well as fine-tuned BERT (ranking, question
answering, NER). Our findings show that knowledge is not just contained in
BERT's final layers. Intermediate layers contribute a significant amount
(17-60%) to the total knowledge found. Probing intermediate layers also reveals
how different types of knowledge emerge at varying rates. When BERT is
fine-tuned, relational knowledge is forgotten but the extent of forgetting is
impacted by the fine-tuning objective but not the size of the dataset. We found
that ranking models forget the least and retain more knowledge in their final
layer. We release our code on github to repeat the experiments.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 08:46:30 GMT'}]",2020-10-20,"[['Wallat', 'Jonas', ''], ['Singh', 'Jaspreet', ''], ['Anand', 'Avishek', '']]"
1365310,2010.08980,Tom Hosking,"Laurie Burchell, Jie Chi, Tom Hosking, Nina Markl, Bonnie Webber",Querent Intent in Multi-Sentence Questions,"LAW XIV, COLING 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Multi-sentence questions (MSQs) are sequences of questions connected by
relations which, unlike sequences of standalone questions, need to be answered
as a unit. Following Rhetorical Structure Theory (RST), we recognise that
different ""question discourse relations"" between the subparts of MSQs reflect
different speaker intents, and consequently elicit different answering
strategies. Correctly identifying these relations is therefore a crucial step
in automatically answering MSQs. We identify five different types of MSQs in
English, and define five novel relations to describe them. We extract over
162,000 MSQs from Stack Exchange to enable future research. Finally, we
implement a high-precision baseline classifier based on surface features.
","[{'version': 'v1', 'created': 'Sun, 18 Oct 2020 13:17:09 GMT'}]",2020-10-20,"[['Burchell', 'Laurie', ''], ['Chi', 'Jie', ''], ['Hosking', 'Tom', ''], ['Markl', 'Nina', ''], ['Webber', 'Bonnie', '']]"
1360691,2010.04361,Mehdi Rezaee,Mehdi Rezaee and Francis Ferraro,"Event Representation with Sequential, Semi-Supervised Discrete Variables",,,,,cs.LG cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Within the context of event modeling and understanding, we propose a new
method for neural sequence modeling that takes partially-observed sequences of
discrete, external knowledge into account. We construct a sequential, neural
variational autoencoder that uses a carefully defined encoder, and
Gumbel-Softmax reparametrization, to allow for successful backpropagation
during training. We show that our approach outperforms multiple baselines and
the state-of-the-art in narrative script induction on multiple event modeling
tasks. We demonstrate that our approach converges more quickly.
","[{'version': 'v1', 'created': 'Fri, 9 Oct 2020 04:05:49 GMT'}, {'version': 'v2', 'created': 'Fri, 16 Oct 2020 18:54:51 GMT'}]",2020-10-20,"[['Rezaee', 'Mehdi', ''], ['Ferraro', 'Francis', '']]"
1365098,2010.08768,Fatima Haouari,"Fatima Haouari, Maram Hasanain, Reem Suwaileh, Tamer Elsayed","ArCOV19-Rumors: Arabic COVID-19 Twitter Dataset for Misinformation
  Detection",,,,,cs.CL cs.IR cs.SI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper we introduce ArCOV19-Rumors, an Arabic COVID-19 Twitter dataset
for misinformation detection composed of tweets containing claims from 27th
January till the end of April 2020. We collected 138 verified claims, mostly
from popular fact-checking websites, and identified 9.4K relevant tweets to
those claims. We then manually-annotated the tweets by veracity to support
research on misinformation detection, which is one of the major problems faced
during a pandemic. We aim to support two classes of misinformation detection
problems over Twitter: verifying free-text claims (called claim-level
verification) and verifying claims expressed in tweets (called tweet-level
verification). Our dataset covers, in addition to health, claims related to
other topical categories that were influenced by COVID-19, namely, social,
politics, sports, entertainment, and religious.
","[{'version': 'v1', 'created': 'Sat, 17 Oct 2020 11:21:40 GMT'}]",2020-10-20,"[['Haouari', 'Fatima', ''], ['Hasanain', 'Maram', ''], ['Suwaileh', 'Reem', ''], ['Elsayed', 'Tamer', '']]"
1365086,2010.08756,Sara Renjit,"Sara Renjit, Sumam Mary Idicula","CUSATNLP@HASOC-Dravidian-CodeMix-FIRE2020:Identifying Offensive Language
  from ManglishTweets",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  With the popularity of social media, communications through blogs, Facebook,
Twitter, and other plat-forms have increased. Initially, English was the only
medium of communication. Fortunately, now we can communicate in any language.
It has led to people using English and their own native or mother tongue
language in a mixed form. Sometimes, comments in other languages have English
transliterated format or other cases; people use the intended language scripts.
Identifying sentiments and offensive content from such code mixed tweets is a
necessary task in these times. We present a working model submitted for Task2
of the sub-track HASOC Offensive Language Identification- DravidianCodeMix in
Forum for Information Retrieval Evaluation, 2020. It is a message level
classification task. An embedding model-based classifier identifies offensive
and not offensive comments in our approach. We applied this method in the
Manglish dataset provided along with the sub-track.
","[{'version': 'v1', 'created': 'Sat, 17 Oct 2020 10:11:41 GMT'}]",2020-10-20,"[['Renjit', 'Sara', ''], ['Idicula', 'Sumam Mary', '']]"
1365073,2010.08743,Ismini Lourentzou,"Arkin Dharawat and Ismini Lourentzou and Alex Morales and ChengXiang
  Zhai","Drink bleach or do what now? Covid-HeRA: A dataset for risk-informed
  health decision making in the presence of COVID19 misinformation",,,,,cs.CL cs.CY cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Given the wide spread of inaccurate medical advice related to the 2019
coronavirus pandemic (COVID-19), such as fake remedies, treatments and
prevention suggestions, misinformation detection has emerged as an open problem
of high importance and interest for the NLP community. To combat potential harm
of COVID19-related misinformation, we release Covid-HeRA, a dataset for health
risk assessment of COVID-19-related social media posts. More specifically, we
study the severity of each misinformation story, i.e., how harmful a message
believed by the audience can be and what type of signals can be used to
discover high malicious fake news and detect refuted claims. We present a
detailed analysis, evaluate several simple and advanced classification models,
and conclude with our experimental analysis that presents open challenges and
future directions.
","[{'version': 'v1', 'created': 'Sat, 17 Oct 2020 08:34:57 GMT'}]",2020-10-20,"[['Dharawat', 'Arkin', ''], ['Lourentzou', 'Ismini', ''], ['Morales', 'Alex', ''], ['Zhai', 'ChengXiang', '']]"
1365068,2010.08738,Jun Quan,"Jun Quan, Shian Zhang, Qian Cao, Zizhong Li and Deyi Xiong","RiSAWOZ: A Large-Scale Multi-Domain Wizard-of-Oz Dataset with Rich
  Semantic Annotations for Task-Oriented Dialogue Modeling",EMNLP 2020 (long paper),,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In order to alleviate the shortage of multi-domain data and to capture
discourse phenomena for task-oriented dialogue modeling, we propose RiSAWOZ, a
large-scale multi-domain Chinese Wizard-of-Oz dataset with Rich Semantic
Annotations. RiSAWOZ contains 11.2K human-to-human (H2H) multi-turn
semantically annotated dialogues, with more than 150K utterances spanning over
12 domains, which is larger than all previous annotated H2H conversational
datasets. Both single- and multi-domain dialogues are constructed, accounting
for 65% and 35%, respectively. Each dialogue is labeled with comprehensive
dialogue annotations, including dialogue goal in the form of natural language
description, domain, dialogue states and acts at both the user and system side.
In addition to traditional dialogue annotations, we especially provide
linguistic annotations on discourse phenomena, e.g., ellipsis and coreference,
in dialogues, which are useful for dialogue coreference and ellipsis resolution
tasks. Apart from the fully annotated dataset, we also present a detailed
description of the data collection procedure, statistics and analysis of the
dataset. A series of benchmark models and results are reported, including
natural language understanding (intent detection & slot filling), dialogue
state tracking and dialogue context-to-text generation, as well as coreference
and ellipsis resolution, which facilitate the baseline comparison for future
research on this corpus.
","[{'version': 'v1', 'created': 'Sat, 17 Oct 2020 08:18:59 GMT'}]",2020-10-20,"[['Quan', 'Jun', ''], ['Zhang', 'Shian', ''], ['Cao', 'Qian', ''], ['Li', 'Zizhong', ''], ['Xiong', 'Deyi', '']]"
1365055,2010.08725,Chenhui Chu,"Andrew Merritt, Chenhui Chu, Yuki Arase","A Corpus for English-Japanese Multimodal Neural Machine Translation with
  Comparable Sentences",,,,,cs.CL cs.AI cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Multimodal neural machine translation (NMT) has become an increasingly
important area of research over the years because additional modalities, such
as image data, can provide more context to textual data. Furthermore, the
viability of training multimodal NMT models without a large parallel corpus
continues to be investigated due to low availability of parallel sentences with
images, particularly for English-Japanese data. However, this void can be
filled with comparable sentences that contain bilingual terms and parallel
phrases, which are naturally created through media such as social network posts
and e-commerce product descriptions. In this paper, we propose a new multimodal
English-Japanese corpus with comparable sentences that are compiled from
existing image captioning datasets. In addition, we supplement our comparable
sentences with a smaller parallel corpus for validation and test purposes. To
test the performance of this comparable sentence translation scenario, we train
several baseline NMT models with our comparable corpus and evaluate their
English-Japanese translation performance. Due to low translation scores in our
baseline experiments, we believe that current multimodal NMT models are not
designed to effectively utilize comparable sentence data. Despite this, we hope
for our corpus to be used to further research into multimodal NMT with
comparable sentences.
","[{'version': 'v1', 'created': 'Sat, 17 Oct 2020 06:12:25 GMT'}]",2020-10-20,"[['Merritt', 'Andrew', ''], ['Chu', 'Chenhui', ''], ['Arase', 'Yuki', '']]"
1183826,1909.13788,Junxian He,"Junxian He, Jiatao Gu, Jiajun Shen, Marc'Aurelio Ranzato",Revisiting Self-Training for Neural Sequence Generation,"ICLR 2020. The first two authors contributed equally. Updated to fix
  typos",,,,cs.LG cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Self-training is one of the earliest and simplest semi-supervised methods.
The key idea is to augment the original labeled dataset with unlabeled data
paired with the model's prediction (i.e. the pseudo-parallel data). While
self-training has been extensively studied on classification problems, in
complex sequence generation tasks (e.g. machine translation) it is still
unclear how self-training works due to the compositionality of the target
space. In this work, we first empirically show that self-training is able to
decently improve the supervised baseline on neural sequence generation tasks.
Through careful examination of the performance gains, we find that the
perturbation on the hidden states (i.e. dropout) is critical for self-training
to benefit from the pseudo-parallel data, which acts as a regularizer and
forces the model to yield close predictions for similar unlabeled inputs. Such
effect helps the model correct some incorrect predictions on unlabeled data. To
further encourage this mechanism, we propose to inject noise to the input
space, resulting in a ""noisy"" version of self-training. Empirical study on
standard machine translation and text summarization benchmarks shows that noisy
self-training is able to effectively utilize unlabeled data and improve the
performance of the supervised baseline by a large margin.
","[{'version': 'v1', 'created': 'Mon, 30 Sep 2019 15:30:00 GMT'}, {'version': 'v2', 'created': 'Thu, 20 Feb 2020 08:35:41 GMT'}, {'version': 'v3', 'created': 'Sun, 18 Oct 2020 22:49:31 GMT'}]",2020-10-20,"[['He', 'Junxian', ''], ['Gu', 'Jiatao', ''], ['Shen', 'Jiajun', ''], ['Ranzato', ""Marc'Aurelio"", '']]"
1365042,2010.08712,Meng Cao,"Meng Cao, Yue Dong, Jiapeng Wu, Jackie Chi Kit Cheung",Factual Error Correction for Abstractive Summarization Models,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Neural abstractive summarization systems have achieved promising progress,
thanks to the availability of large-scale datasets and models pre-trained with
self-supervised methods. However, ensuring the factual consistency of the
generated summaries for abstractive summarization systems is a challenge. We
propose a post-editing corrector module to address this issue by identifying
and correcting factual errors in generated summaries. The neural corrector
model is pre-trained on artificial examples that are created by applying a
series of heuristic transformations on reference summaries. These
transformations are inspired by an error analysis of state-of-the-art
summarization model outputs. Experimental results show that our model is able
to correct factual errors in summaries generated by other neural summarization
models and outperforms previous models on factual consistency evaluation on the
CNN/DailyMail dataset. We also find that transferring from artificial error
correction to downstream settings is still very challenging.
","[{'version': 'v1', 'created': 'Sat, 17 Oct 2020 04:24:16 GMT'}]",2020-10-20,"[['Cao', 'Meng', ''], ['Dong', 'Yue', ''], ['Wu', 'Jiapeng', ''], ['Cheung', 'Jackie Chi Kit', '']]"
1365038,2010.08708,Wei Han,"Hantao Huang, Tao Han, Wei Han, Deep Yap, Cheng-Ming Chiang","Answer-checking in Context: A Multi-modal FullyAttention Network for
  Visual Question Answering",Accepted in ICPR2020,,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Visual Question Answering (VQA) is challenging due to the complex cross-modal
relations. It has received extensive attention from the research community.
From the human perspective, to answer a visual question, one needs to read the
question and then refer to the image to generate an answer. This answer will
then be checked against the question and image again for the final
confirmation. In this paper, we mimic this process and propose a fully
attention based VQA architecture. Moreover, an answer-checking module is
proposed to perform a unified attention on the jointly answer, question and
image representation to update the answer. This mimics the human answer
checking process to consider the answer in the context. With answer-checking
modules and transferred BERT layers, our model achieves the state-of-the-art
accuracy 71.57\% using fewer parameters on VQA-v2.0 test-standard split.
","[{'version': 'v1', 'created': 'Sat, 17 Oct 2020 03:37:16 GMT'}]",2020-10-20,"[['Huang', 'Hantao', ''], ['Han', 'Tao', ''], ['Han', 'Wei', ''], ['Yap', 'Deep', ''], ['Chiang', 'Cheng-Ming', '']]"
1365014,2010.08684,Mihail Eric,"Shikib Mehri, Mihail Eric, Dilek Hakkani-Tur",Example-Driven Intent Prediction with Observers,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  A key challenge of dialog systems research is to effectively and efficiently
adapt to new domains. A scalable paradigm for adaptation necessitates the
development of generalizable models that perform well in few-shot settings. In
this paper, we focus on the intent classification problem which aims to
identify user intents given utterances addressed to the dialog system. We
propose two approaches for improving the generalizability of utterance
classification models: (1) example-driven training and (2) observers.
Example-driven training learns to classify utterances by comparing to examples,
thereby using the underlying encoder as a sentence similarity model. Prior work
has shown that BERT-like models tend to attribute a significant amount of
attention to the [CLS] token, which we hypothesize results in diluted
representations. Observers are tokens that are not attended to, and are an
alternative to the [CLS] token. The proposed methods attain state-of-the-art
results on three intent prediction datasets (Banking, Clinc}, and HWU) in both
the full data and few-shot (10 examples per intent) settings. Furthermore, we
demonstrate that the proposed approach can transfer to new intents and across
datasets without any additional training.
","[{'version': 'v1', 'created': 'Sat, 17 Oct 2020 01:03:06 GMT'}]",2020-10-20,"[['Mehri', 'Shikib', ''], ['Eric', 'Mihail', ''], ['Hakkani-Tur', 'Dilek', '']]"
1365000,2010.08670,Yanru Qu,"Yanru Qu, Dinghan Shen, Yelong Shen, Sandra Sajeev, Jiawei Han, Weizhu
  Chen","CoDA: Contrast-enhanced and Diversity-promoting Data Augmentation for
  Natural Language Understanding",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Data augmentation has been demonstrated as an effective strategy for
improving model generalization and data efficiency. However, due to the
discrete nature of natural language, designing label-preserving transformations
for text data tends to be more challenging. In this paper, we propose a novel
data augmentation framework dubbed CoDA, which synthesizes diverse and
informative augmented examples by integrating multiple transformations
organically. Moreover, a contrastive regularization objective is introduced to
capture the global relationship among all the data samples. A momentum encoder
along with a memory bank is further leveraged to better estimate the
contrastive loss. To verify the effectiveness of the proposed framework, we
apply CoDA to Transformer-based models on a wide range of natural language
understanding tasks. On the GLUE benchmark, CoDA gives rise to an average
improvement of 2.2% while applied to the RoBERTa-large model. More importantly,
it consistently exhibits stronger results relative to several competitive data
augmentation and adversarial training base-lines (including the low-resource
settings). Extensive experiments show that the proposed contrastive objective
can be flexibly combined with various data augmentation approaches to further
boost their performance, highlighting the wide applicability of the CoDA
framework.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 23:57:03 GMT'}]",2020-10-20,"[['Qu', 'Yanru', ''], ['Shen', 'Dinghan', ''], ['Shen', 'Yelong', ''], ['Sajeev', 'Sandra', ''], ['Han', 'Jiawei', ''], ['Chen', 'Weizhu', '']]"
1364982,2010.08652,Jian Ni,Jian Ni and Taesun Moon and Parul Awasthy and Radu Florian,Cross-Lingual Relation Extraction with Transformers,11 pages,,,,cs.CL cs.AI cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Relation extraction (RE) is one of the most important tasks in information
extraction, as it provides essential information for many NLP applications. In
this paper, we propose a cross-lingual RE approach that does not require any
human annotation in a target language or any cross-lingual resources. Building
upon unsupervised cross-lingual representation learning frameworks, we develop
several deep Transformer based RE models with a novel encoding scheme that can
effectively encode both entity location and entity type information. Our RE
models, when trained with English data, outperform several deep neural network
based English RE models. More importantly, our models can be applied to perform
zero-shot cross-lingual RE, achieving the state-of-the-art cross-lingual RE
performance on two datasets (68-89% of the accuracy of the supervised
target-language RE model). The high cross-lingual transfer efficiency without
requiring additional training data or cross-lingual resources shows that our RE
models are especially useful for low-resource languages.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 22:23:37 GMT'}]",2020-10-20,"[['Ni', 'Jian', ''], ['Moon', 'Taesun', ''], ['Awasthy', 'Parul', ''], ['Florian', 'Radu', '']]"
1364972,2010.08642,Tejas Srinivasan,"Tejas Srinivasan, Ramon Sanabria, Florian Metze, Desmond Elliott",Multimodal Speech Recognition with Unstructured Audio Masking,"Accepted to NLP Beyond Text workshop, EMNLP 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Visual context has been shown to be useful for automatic speech recognition
(ASR) systems when the speech signal is noisy or corrupted. Previous work,
however, has only demonstrated the utility of visual context in an unrealistic
setting, where a fixed set of words are systematically masked in the audio. In
this paper, we simulate a more realistic masking scenario during model
training, called RandWordMask, where the masking can occur for any word
segment. Our experiments on the Flickr 8K Audio Captions Corpus show that
multimodal ASR can generalize to recover different types of masked words in
this unstructured masking setting. Moreover, our analysis shows that our models
are capable of attending to the visual signal when the audio signal is
corrupted. These results show that multimodal ASR systems can leverage the
visual signal in more generalized noisy scenarios.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 21:49:20 GMT'}]",2020-10-20,"[['Srinivasan', 'Tejas', ''], ['Sanabria', 'Ramon', ''], ['Metze', 'Florian', ''], ['Elliott', 'Desmond', '']]"
1364948,2010.08618,Sudha Rao,"Allison Hegel, Sudha Rao, Asli Celikyilmaz and Bill Dolan",Substance over Style: Document-Level Targeted Content Transfer,This paper has been accepted to be published at EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Existing language models excel at writing from scratch, but many real-world
scenarios require rewriting an existing document to fit a set of constraints.
Although sentence-level rewriting has been fairly well-studied, little work has
addressed the challenge of rewriting an entire document coherently. In this
work, we introduce the task of document-level targeted content transfer and
address it in the recipe domain, with a recipe as the document and a dietary
restriction (such as vegan or dairy-free) as the targeted constraint. We
propose a novel model for this task based on the generative pre-trained
language model (GPT-2) and train on a large number of roughly-aligned recipe
pairs (https://github.com/microsoft/document-level-targeted-content-transfer).
Both automatic and human evaluations show that our model out-performs existing
methods by generating coherent and diverse rewrites that obey the constraint
while remaining close to the original document. Finally, we analyze our model's
rewrites to assess progress toward the goal of making language generation more
attuned to constraints that are substantive rather than stylistic.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 20:26:10 GMT'}]",2020-10-20,"[['Hegel', 'Allison', ''], ['Rao', 'Sudha', ''], ['Celikyilmaz', 'Asli', ''], ['Dolan', 'Bill', '']]"
1364936,2010.08606,Yiding Hao,Yiding Hao,Evaluating Attribution Methods using White-Box LSTMs,"To appear in the Proceedings of the 2020 EMNLP Workshop BlackboxNLP:
  Analyzing and Interpreting Neural Networks for NLP",,,,cs.LG cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Interpretability methods for neural networks are difficult to evaluate
because we do not understand the black-box models typically used to test them.
This paper proposes a framework in which interpretability methods are evaluated
using manually constructed networks, which we call white-box networks, whose
behavior is understood a priori. We evaluate five methods for producing
attribution heatmaps by applying them to white-box LSTM classifiers for tasks
based on formal languages. Although our white-box classifiers solve their tasks
perfectly and transparently, we find that all five attribution methods fail to
produce the expected model explanations.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 19:55:32 GMT'}]",2020-10-20,"[['Hao', 'Yiding', '']]"
1364923,2010.08593,Suraj Kothawade,"Suraj Kothawade, Jiten Girdhar, Chandrashekhar Lavania, Rishabh Iyer",Deep Submodular Networks for Extractive Data Summarization,,,,,cs.LG cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Deep Models are increasingly becoming prevalent in summarization problems
(e.g. document, video and images) due to their ability to learn complex feature
interactions and representations. However, they do not model characteristics
such as diversity, representation, and coverage, which are also very important
for summarization tasks. On the other hand, submodular functions naturally
model these characteristics because of their diminishing returns property. Most
approaches for modelling and learning submodular functions rely on very simple
models, such as weighted mixtures of submodular functions. Unfortunately, these
models only learn the relative importance of the different submodular functions
(such as diversity, representation or importance), but cannot learn more
complex feature representations, which are often required for state-of-the-art
performance. We propose Deep Submodular Networks (DSN), an end-to-end learning
framework that facilitates the learning of more complex features and richer
functions, crafted for better modelling of all aspects of summarization. The
DSN framework can be used to learn features appropriate for summarization from
scratch. We demonstrate the utility of DSNs on both generic and query focused
image-collection summarization, and show significant improvement over the
state-of-the-art. In particular, we show that DSNs outperform simple mixture
models using off the shelf features. Secondly, we also show that just using
four submodular functions in a DSN with end-to-end learning performs comparably
to the state-of-the-art mixture model with a hand-crafted set of 594 components
and outperforms other methods for image collection summarization.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 19:06:15 GMT'}]",2020-10-20,"[['Kothawade', 'Suraj', ''], ['Girdhar', 'Jiten', ''], ['Lavania', 'Chandrashekhar', ''], ['Iyer', 'Rishabh', '']]"
1364900,2010.08570,Markus Leippold,Rahul Mishra and Dhruv Gupta and Markus Leippold,Generating Fact Checking Summaries for Web Claims,"Accepted paper; The 2020 Conference on Empirical Methods in Natural
  Language Processing EMNLP - WNUT",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present SUMO, a neural attention-based approach that learns to establish
the correctness of textual claims based on evidence in the form of text
documents (e.g., news articles or Web documents). SUMO further generates an
extractive summary by presenting a diversified set of sentences from the
documents that explain its decision on the correctness of the textual claim.
Prior approaches to address the problem of fact checking and evidence
extraction have relied on simple concatenation of claim and document word
embeddings as an input to claim driven attention weight computation. This is
done so as to extract salient words and sentences from the documents that help
establish the correctness of the claim. However, this design of claim-driven
attention does not capture the contextual information in documents properly. We
improve on the prior art by using improved claim and title guided hierarchical
attention to model effective contextual cues. We show the efficacy of our
approach on datasets concerning political, healthcare, and environmental
issues.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 18:10:47 GMT'}]",2020-10-20,"[['Mishra', 'Rahul', ''], ['Gupta', 'Dhruv', ''], ['Leippold', 'Markus', '']]"
1362533,2010.06203,Art\=urs Stafanovi\v{c}s,"Art\=urs Stafanovi\v{c}s, Toms Bergmanis, M\=arcis Pinnis","Mitigating Gender Bias in Machine Translation with Target Gender
  Annotations",EMNLP 2020 Fifth Conference on Machine Translation (WMT20),,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  When translating ""The secretary asked for details."" to a language with
grammatical gender, it might be necessary to determine the gender of the
subject ""secretary"". If the sentence does not contain the necessary
information, it is not always possible to disambiguate. In such cases, machine
translation systems select the most common translation option, which often
corresponds to the stereotypical translations, thus potentially exacerbating
prejudice and marginalisation of certain groups and people. We argue that the
information necessary for an adequate translation can not always be deduced
from the sentence being translated or even might depend on external knowledge.
Therefore, in this work, we propose to decouple the task of acquiring the
necessary information from the task of learning to translate correctly when
such information is available. To that end, we present a method for training
machine translation systems to use word-level annotations containing
information about subject's gender. To prepare training data, we annotate
regular source language words with grammatical gender information of the
corresponding target language words. Using such data to train machine
translation systems reduces their reliance on gender stereotypes when
information about the subject's gender is available. Our experiments on five
language pairs show that this allows improving accuracy on the WinoMT test set
by up to 25.8 percentage points.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 07:07:59 GMT'}, {'version': 'v2', 'created': 'Sun, 18 Oct 2020 16:41:56 GMT'}]",2020-10-20,"[['Stafanovičs', 'Artūrs', ''], ['Bergmanis', 'Toms', ''], ['Pinnis', 'Mārcis', '']]"
1364896,2010.08566,Peter West,"Peter West, Ximing Lu, Ari Holtzman, Chandra Bhagavatula, Jena Hwang,
  Yejin Choi",Reflective Decoding: Unsupervised Paraphrasing and Abductive Reasoning,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pretrained Language Models (LMs) generate text with remarkable quality,
novelty,and coherence. Yet applying LMs to the problems of paraphrasing and
infilling currently requires direct supervision, since these tasks break the
left-to-right generation setup of pretrained LMs. We present Reflective
Decoding, a novel unsupervised approach to apply the capabilities of pretrained
LMs to non-sequential tasks. Our approach is general and applicable to two
distant tasks - paraphrasing and abductive reasoning. It requires no
supervision or parallel corpora, only two pretrained language models: forward
and backward. Reflective Decoding operates in two intuitive steps. In the
contextualization step, we use LMs to generate many left and right contexts
which collectively capture the meaning of the input sentence. Then, in the
reflection step we decode in the semantic neighborhood of the input,
conditioning on an ensemble of generated contexts with the reverse direction
LM. We reflect through the generated contexts, effectively using them as an
intermediate meaning representation to generate conditional output. Empirical
results demonstrate that Reflective Decoding outperforms strong unsupervised
baselines on both paraphrasing and abductive text infilling, significantly
narrowing the gap between unsupervised and supervised methods.Reflective
Decoding introduces the concept of using generated contexts to represent
meaning, opening up new possibilities for unsupervised conditional text
generation.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 18:02:07 GMT'}]",2020-10-20,"[['West', 'Peter', ''], ['Lu', 'Ximing', ''], ['Holtzman', 'Ari', ''], ['Bhagavatula', 'Chandra', ''], ['Hwang', 'Jena', ''], ['Choi', 'Yejin', '']]"
1364047,2010.07717,Weijie Yu,"Weijie Yu, Chen Xu, Jun Xu, Liang Pang, Xiaopeng Gao, Xiaozhao Wang
  and Ji-Rong Wen","Wasserstein Distance Regularized Sequence Representation for Text
  Matching in Asymmetrical Domains",accepted as long paper by EMNLP 2020,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  One approach to matching texts from asymmetrical domains is projecting the
input sequences into a common semantic space as feature vectors upon which the
matching function can be readily defined and learned. In real-world matching
practices, it is often observed that with the training goes on, the feature
vectors projected from different domains tend to be indistinguishable. The
phenomenon, however, is often overlooked in existing matching models. As a
result, the feature vectors are constructed without any regularization, which
inevitably increases the difficulty of learning the downstream matching
functions. In this paper, we propose a novel match method tailored for text
matching in asymmetrical domains, called WD-Match. In WD-Match, a Wasserstein
distance-based regularizer is defined to regularize the features vectors
projected from different domains. As a result, the method enforces the feature
projection function to generate vectors such that those correspond to different
domains cannot be easily discriminated. The training process of WD-Match
amounts to a game that minimizes the matching loss regularized by the
Wasserstein distance. WD-Match can be used to improve different text matching
methods, by using the method as its underlying matching model. Four popular
text matching methods have been exploited in the paper. Experimental results
based on four publicly available benchmarks showed that WD-Match consistently
outperformed the underlying methods and the baselines.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 12:52:09 GMT'}, {'version': 'v2', 'created': 'Sat, 17 Oct 2020 01:32:08 GMT'}]",2020-10-20,"[['Yu', 'Weijie', ''], ['Xu', 'Chen', ''], ['Xu', 'Jun', ''], ['Pang', 'Liang', ''], ['Gao', 'Xiaopeng', ''], ['Wang', 'Xiaozhao', ''], ['Wen', 'Ji-Rong', '']]"
1323737,2007.12223,Tianlong Chen,"Tianlong Chen, Jonathan Frankle, Shiyu Chang, Sijia Liu, Yang Zhang,
  Zhangyang Wang, Michael Carbin",The Lottery Ticket Hypothesis for Pre-trained BERT Networks,NeurIPS 2020,,,,cs.LG cs.CL cs.NE stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In natural language processing (NLP), enormous pre-trained models like BERT
have become the standard starting point for training on a range of downstream
tasks, and similar trends are emerging in other areas of deep learning. In
parallel, work on the lottery ticket hypothesis has shown that models for NLP
and computer vision contain smaller matching subnetworks capable of training in
isolation to full accuracy and transferring to other tasks. In this work, we
combine these observations to assess whether such trainable, transferrable
subnetworks exist in pre-trained BERT models. For a range of downstream tasks,
we indeed find matching subnetworks at 40% to 90% sparsity. We find these
subnetworks at (pre-trained) initialization, a deviation from prior NLP
research where they emerge only after some amount of training. Subnetworks
found on the masked language modeling task (the same task used to pre-train the
model) transfer universally; those found on other tasks transfer in a limited
fashion if at all. As large-scale pre-training becomes an increasingly central
paradigm in deep learning, our results demonstrate that the main lottery ticket
observations remain relevant in this context. Codes available at
https://github.com/VITA-Group/BERT-Tickets.
","[{'version': 'v1', 'created': 'Thu, 23 Jul 2020 19:35:39 GMT'}, {'version': 'v2', 'created': 'Sun, 18 Oct 2020 20:10:29 GMT'}]",2020-10-20,"[['Chen', 'Tianlong', ''], ['Frankle', 'Jonathan', ''], ['Chang', 'Shiyu', ''], ['Liu', 'Sijia', ''], ['Zhang', 'Yang', ''], ['Wang', 'Zhangyang', ''], ['Carbin', 'Michael', '']]"
1363482,2010.07152,Kai Wang,"Kai Wang, Yu Liu, Qian Ma, Quan Z. Sheng",Multi-teacher Knowledge Distillation for Knowledge Graph Completion,"11 pages, 4 figures",,,,cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Link prediction based on knowledge graph embedding (KGE) aims to predict new
triples to complete knowledge graphs (KGs) automatically. However, recent KGE
models tend to improve performance by excessively increasing vector dimensions,
which would cause enormous training costs and save storage in practical
applications. To address this problem, we first theoretically analyze the
capacity of low-dimensional space for KG embeddings based on the principle of
minimum entropy. Then, we propose a novel knowledge distillation framework for
knowledge graph embedding, utilizing multiple low-dimensional KGE models as
teachers. Under a novel iterative distillation strategy, the MulDE model
produces soft labels according to training epochs and student performance
adaptively. The experimental results show that MulDE can effectively improve
the performance and training speed of low-dimensional KGE models. The distilled
32-dimensional models are very competitive compared to some of state-or-the-art
(SotA) high-dimensional methods on several commonly-used datasets.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 15:09:27 GMT'}, {'version': 'v2', 'created': 'Mon, 19 Oct 2020 09:33:41 GMT'}]",2020-10-20,"[['Wang', 'Kai', ''], ['Liu', 'Yu', ''], ['Ma', 'Qian', ''], ['Sheng', 'Quan Z.', '']]"
1365100,2010.08770,Ismail Shahin,"Mohamed Bader, Ismail Shahin, Abdelfatah Hassan","Studying the Similarity of COVID-19 Sounds based on Correlation Analysis
  of MFCC","5 pages, 4 figures, conference paper",,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently there has been a formidable work which has been put up from the
people who are working in the frontlines such as hospitals, clinics, and labs
alongside researchers and scientists who are also putting tremendous efforts in
the fight against COVID-19 pandemic. Due to the preposterous spread of the
virus, the integration of the artificial intelligence has taken a considerable
part in the health sector, by implementing the fundamentals of Automatic Speech
Recognition (ASR) and deep learning algorithms. In this paper, we illustrate
the importance of speech signal processing in the extraction of the
Mel-Frequency Cepstral Coefficients (MFCCs) of the COVID-19 and non-COVID-19
samples and find their relationship using Pearson correlation coefficients. Our
results show high similarity in MFCCs between different COVID-19 cough and
breathing sounds, while MFCC of voice is more robust between COVID-19 and
non-COVID-19 samples. Moreover, our results are preliminary, and there is a
possibility to exclude the voices of COVID-19 patients from further processing
in diagnosing the disease.
","[{'version': 'v1', 'created': 'Sat, 17 Oct 2020 11:38:05 GMT'}]",2020-10-20,"[['Bader', 'Mohamed', ''], ['Shahin', 'Ismail', ''], ['Hassan', 'Abdelfatah', '']]"
1360622,2010.04292,Douglas Guilbeault R,"Bhargav Srinivasa Desikan, Tasker Hull, Ethan O. Nadler, Douglas
  Guilbeault, Aabir Abubaker Kar, Mark Chu and Donald Ruggiero Lo Sardo",comp-syn: Perceptually Grounded Word Embeddings with Color,"9 pages, 3 figures, all code and data available at
  https://github.com/comp-syn/comp-syn. Forthcoming in the Proceedings of the
  28th International Conference on Computational Linguistics",,,,cs.CL cs.LG cs.SI,http://creativecommons.org/licenses/by/4.0/,"  Popular approaches to natural language processing create word embeddings
based on textual co-occurrence patterns, but often ignore embodied, sensory
aspects of language. Here, we introduce the Python package comp-syn, which
provides grounded word embeddings based on the perceptually uniform color
distributions of Google Image search results. We demonstrate that comp-syn
significantly enriches models of distributional semantics. In particular, we
show that (1) comp-syn predicts human judgments of word concreteness with
greater accuracy and in a more interpretable fashion than word2vec using
low-dimensional word-color embeddings, and (2) comp-syn performs comparably to
word2vec on a metaphorical vs. literal word-pair classification task. comp-syn
is open-source on PyPi and is compatible with mainstream machine-learning
Python packages. Our package release includes word-color embeddings for over
40,000 English words, each associated with crowd-sourced word concreteness
judgments.
","[{'version': 'v1', 'created': 'Thu, 8 Oct 2020 22:50:06 GMT'}, {'version': 'v2', 'created': 'Mon, 19 Oct 2020 05:22:54 GMT'}]",2020-10-20,"[['Desikan', 'Bhargav Srinivasa', ''], ['Hull', 'Tasker', ''], ['Nadler', 'Ethan O.', ''], ['Guilbeault', 'Douglas', ''], ['Kar', 'Aabir Abubaker', ''], ['Chu', 'Mark', ''], ['Sardo', 'Donald Ruggiero Lo', '']]"
1365107,2010.08777,Pengshuai Li,"Pengshuai Li, Xinsong Zhang, Weijia Jia and Wei Zhao","Active Testing: An Unbiased Evaluation Method for Distantly Supervised
  Relation Extraction",accepted to appear at Findings of EMNLP 2020,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Distant supervision has been a widely used method for neural relation
extraction for its convenience of automatically labeling datasets. However,
existing works on distantly supervised relation extraction suffer from the low
quality of test set, which leads to considerable biased performance evaluation.
These biases not only result in unfair evaluations but also mislead the
optimization of neural relation extraction. To mitigate this problem, we
propose a novel evaluation method named active testing through utilizing both
the noisy test set and a few manual annotations. Experiments on a widely used
benchmark show that our proposed approach can yield approximately unbiased
evaluations for distantly supervised relation extractors.
","[{'version': 'v1', 'created': 'Sat, 17 Oct 2020 12:29:09 GMT'}]",2020-10-20,"[['Li', 'Pengshuai', ''], ['Zhang', 'Xinsong', ''], ['Jia', 'Weijia', ''], ['Zhao', 'Wei', '']]"
1365154,2010.08824,Xueliang Zhao,"Xueliang Zhao, Wei Wu, Can Xu, Chongyang Tao, Dongyan Zhao, Rui Yan",Knowledge-Grounded Dialogue Generation with Pre-trained Language Models,Accepted by EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We study knowledge-grounded dialogue generation with pre-trained language
models. To leverage the redundant external knowledge under capacity constraint,
we propose equipping response generation defined by a pre-trained language
model with a knowledge selection module, and an unsupervised approach to
jointly optimizing knowledge selection and response generation with unlabeled
dialogues. Empirical results on two benchmarks indicate that our model can
significantly outperform state-of-the-art methods in both automatic evaluation
and human judgment.
","[{'version': 'v1', 'created': 'Sat, 17 Oct 2020 16:49:43 GMT'}]",2020-10-20,"[['Zhao', 'Xueliang', ''], ['Wu', 'Wei', ''], ['Xu', 'Can', ''], ['Tao', 'Chongyang', ''], ['Zhao', 'Dongyan', ''], ['Yan', 'Rui', '']]"
1365600,2010.09270,Boliang Zhang,"Boliang Zhang, Spencer Whitehead, Lifu Huang and Heng Ji",Global Attention for Name Tagging,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Many name tagging approaches use local contextual information with much
success, but fail when the local context is ambiguous or limited. We present a
new framework to improve name tagging by utilizing local, document-level, and
corpus-level contextual information. We retrieve document-level context from
other sentences within the same document and corpus-level context from
sentences in other topically related documents. We propose a model that learns
to incorporate document-level and corpus-level contextual information alongside
local contextual information via global attentions, which dynamically weight
their respective contextual information, and gating mechanisms, which determine
the influence of this information. Extensive experiments on benchmark datasets
show the effectiveness of our approach, which achieves state-of-the-art results
for Dutch, German, and Spanish on the CoNLL-2002 and CoNLL-2003 datasets.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 07:27:15 GMT'}]",2020-10-20,"[['Zhang', 'Boliang', ''], ['Whitehead', 'Spencer', ''], ['Huang', 'Lifu', ''], ['Ji', 'Heng', '']]"
1365584,2010.09254,Jingang Wang,"Yang Yang, Junmei Hao, Canjia Li, Zili Wang, Jingang Wang, Fuzheng
  Zhang, Rao Fu, Peixu Hou, Gong Zhang, Zhongyuan Wang",Query-aware Tip Generation for Vertical Search,Accepted By CIKM 2020 Applied Research Track,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As a concise form of user reviews, tips have unique advantages to explain the
search results, assist users' decision making, and further improve user
experience in vertical search scenarios. Existing work on tip generation does
not take query into consideration, which limits the impact of tips in search
scenarios. To address this issue, this paper proposes a query-aware tip
generation framework, integrating query information into encoding and
subsequent decoding processes. Two specific adaptations of Transformer and
Recurrent Neural Network (RNN) are proposed. For Transformer, the query impact
is incorporated into the self-attention computation of both the encoder and the
decoder. As for RNN, the query-aware encoder adopts a selective network to
distill query-relevant information from the review, while the query-aware
decoder integrates the query information into the attention computation during
decoding. The framework consistently outperforms the competing methods on both
public and real-world industrial datasets. Last but not least, online
deployment experiments on Dianping demonstrate the advantage of the proposed
framework for tip generation as well as its online business values.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 06:48:40 GMT'}]",2020-10-20,"[['Yang', 'Yang', ''], ['Hao', 'Junmei', ''], ['Li', 'Canjia', ''], ['Wang', 'Zili', ''], ['Wang', 'Jingang', ''], ['Zhang', 'Fuzheng', ''], ['Fu', 'Rao', ''], ['Hou', 'Peixu', ''], ['Zhang', 'Gong', ''], ['Wang', 'Zhongyuan', '']]"
1365582,2010.09252,Tiezheng Yu,Tiezheng Yu and Dan Su and Wenliang Dai and Pascale Fung,"Dimsum @LaySumm 20: BART-based Approach for Scientific Document
  Summarization",4 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Lay summarization aims to generate lay summaries of scientific papers
automatically. It is an essential task that can increase the relevance of
science for all of society. In this paper, we build a lay summary generation
system based on the BART model. We leverage sentence labels as extra
supervision signals to improve the performance of lay summarization. In the
CL-LaySumm 2020 shared task, our model achieves 46.00\% Rouge1-F1 score.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 06:36:11 GMT'}]",2020-10-20,"[['Yu', 'Tiezheng', ''], ['Su', 'Dan', ''], ['Dai', 'Wenliang', ''], ['Fung', 'Pascale', '']]"
1365570,2010.09240,Dan Su,"Dan Su, Yan Xu, Wenliang Dai, Ziwei Ji, Tiezheng Yu, Pascale Fung",Multi-hop Question Generation with Graph Convolutional Network,,,,,cs.CL cs.AI,http://creativecommons.org/publicdomain/zero/1.0/,"  Multi-hop Question Generation (QG) aims to generate answer-related questions
by aggregating and reasoning over multiple scattered evidence from different
paragraphs. It is a more challenging yet under-explored task compared to
conventional single-hop QG, where the questions are generated from the sentence
containing the answer or nearby sentences in the same paragraph without complex
reasoning. To address the additional challenges in multi-hop QG, we propose
Multi-Hop Encoding Fusion Network for Question Generation (MulQG), which does
context encoding in multiple hops with Graph Convolutional Network and encoding
fusion via an Encoder Reasoning Gate. To the best of our knowledge, we are the
first to tackle the challenge of multi-hop reasoning over paragraphs without
any sentence-level information. Empirical results on HotpotQA dataset
demonstrate the effectiveness of our method, in comparison with baselines on
automatic evaluation metrics. Moreover, from the human evaluation, our proposed
model is able to generate fluent questions with high completeness and
outperforms the strongest baseline by 20.8% in the multi-hop evaluation. The
code is publicly available at
https://github.com/HLTCHKUST/MulQG}{https://github.com/HLTCHKUST/MulQG .
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 06:15:36 GMT'}]",2020-10-20,"[['Su', 'Dan', ''], ['Xu', 'Yan', ''], ['Dai', 'Wenliang', ''], ['Ji', 'Ziwei', ''], ['Yu', 'Tiezheng', ''], ['Fung', 'Pascale', '']]"
1365520,2010.09190,Jiaxin Ju,"Jiaxin Ju, Ming Liu, Longxiang Gao and Shirui Pan",SciSummPip: An Unsupervised Scientific Paper Summarization Pipeline,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The Scholarly Document Processing (SDP) workshop is to encourage more efforts
on natural language understanding of scientific task. It contains three shared
tasks and we participate in the LongSumm shared task. In this paper, we
describe our text summarization system, SciSummPip, inspired by SummPip (Zhao
et al., 2020) that is an unsupervised text summarization system for
multi-document in news domain. Our SciSummPip includes a transformer-based
language model SciBERT (Beltagy et al., 2019) for contextual sentence
representation, content selection with PageRank (Page et al., 1999), sentence
graph construction with both deep and linguistic information, sentence graph
clustering and within-graph summary generation. Our work differs from previous
method in that content selection and a summary length constraint is applied to
adapt to the scientific domain. The experiment results on both training dataset
and blind test dataset show the effectiveness of our method, and we empirically
verify the robustness of modules used in SciSummPip with BERTScore (Zhang et
al., 2019a).
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 03:29:21 GMT'}]",2020-10-20,"[['Ju', 'Jiaxin', ''], ['Liu', 'Ming', ''], ['Gao', 'Longxiang', ''], ['Pan', 'Shirui', '']]"
1365519,2010.09189,Sheng Zhang,"Ye Liu, Sheng Zhang, Rui Song, Suo Feng, Yanghua Xiao","Knowledge-guided Open Attribute Value Extraction with Reinforcement
  Learning",EMNLP 2020,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Open attribute value extraction for emerging entities is an important but
challenging task. A lot of previous works formulate the problem as a
\textit{question-answering} (QA) task. While the collections of articles from
web corpus provide updated information about the emerging entities, the
retrieved texts can be noisy, irrelevant, thus leading to inaccurate answers.
Effectively filtering out noisy articles as well as bad answers is the key to
improving extraction accuracy. Knowledge graph (KG), which contains rich, well
organized information about entities, provides a good resource to address the
challenge. In this work, we propose a knowledge-guided reinforcement learning
(RL) framework for open attribute value extraction. Informed by relevant
knowledge in KG, we trained a deep Q-network to sequentially compare extracted
answers to improve extraction accuracy. The proposed framework is applicable to
different information extraction system. Our experimental results show that our
method outperforms the baselines by 16.5 - 27.8\%.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 03:28:27 GMT'}]",2020-10-20,"[['Liu', 'Ye', ''], ['Zhang', 'Sheng', ''], ['Song', 'Rui', ''], ['Feng', 'Suo', ''], ['Xiao', 'Yanghua', '']]"
1365472,2010.09142,Enamul Hoque,Jason Obeid and Enamul Hoque,"Chart-to-Text: Generating Natural Language Descriptions for Charts by
  Adapting the Transformer Model",10 pages,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Information visualizations such as bar charts and line charts are very
popular for exploring data and communicating insights. Interpreting and making
sense of such visualizations can be challenging for some people, such as those
who are visually impaired or have low visualization literacy. In this work, we
introduce a new dataset and present a neural model for automatically generating
natural language summaries for charts. The generated summaries provide an
interpretation of the chart and convey the key insights found within that
chart. Our neural model is developed by extending the state-of-the-art model
for the data-to-text generation task, which utilizes a transformer-based
encoder-decoder architecture. We found that our approach outperforms the base
model on a content selection metric by a wide margin (55.42% vs. 8.49%) and
generates more informative, concise, and coherent summaries.
","[{'version': 'v1', 'created': 'Sun, 18 Oct 2020 23:57:33 GMT'}]",2020-10-20,"[['Obeid', 'Jason', ''], ['Hoque', 'Enamul', '']]"
1365408,2010.09078,Harish Tayyar Madabushi PhD,Anushka Prakash and Harish Tayyar Madabushi,"Incorporating Count-Based Features into Pre-Trained Models for Improved
  Stance Detection",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The explosive growth and popularity of Social Media has revolutionised the
way we communicate and collaborate. Unfortunately, this same ease of accessing
and sharing information has led to an explosion of misinformation and
propaganda. Given that stance detection can significantly aid in veracity
prediction, this work focuses on boosting automated stance detection, a task on
which pre-trained models have been extremely successful on, as on several other
tasks. This work shows that the task of stance detection can benefit from
feature based information, especially on certain under performing classes,
however, integrating such features into pre-trained models using ensembling is
challenging. We propose a novel architecture for integrating features with
pre-trained models that address these challenges and test our method on the
RumourEval 2019 dataset. This method achieves state-of-the-art results with an
F1-score of 63.94 on the test set.
","[{'version': 'v1', 'created': 'Sun, 18 Oct 2020 19:37:24 GMT'}]",2020-10-20,"[['Prakash', 'Anushka', ''], ['Madabushi', 'Harish Tayyar', '']]"
1365402,2010.09072,Harish Tayyar Madabushi PhD,Eleri Sarsfield and Harish Tayyar Madabushi,"UoB at SemEval-2020 Task 1: Automatic Identification of Novel Word
  Senses",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Much as the social landscape in which languages are spoken shifts, language
too evolves to suit the needs of its users. Lexical semantic change analysis is
a burgeoning field of semantic analysis which aims to trace changes in the
meanings of words over time. This paper presents an approach to lexical
semantic change detection based on Bayesian word sense induction suitable for
novel word sense identification. This approach is used for a submission to
SemEval-2020 Task 1, which shows the approach to be capable of the SemEval
task. The same approach is also applied to a corpus gleaned from 15 years of
Twitter data, the results of which are then used to identify words which may be
instances of slang.
","[{'version': 'v1', 'created': 'Sun, 18 Oct 2020 19:27:06 GMT'}]",2020-10-20,"[['Sarsfield', 'Eleri', ''], ['Madabushi', 'Harish Tayyar', '']]"
1365152,2010.08822,Wei Wang,"Wei Wang, Piji Li, Hai-Tao Zheng",Consistency and Coherency Enhanced Story Generation,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Story generation is a challenging task, which demands to maintain consistency
of the plots and characters throughout the story. Previous works have shown
that GPT2, a large-scale language model, has achieved good performance on story
generation. However, we observe that several serious issues still exist in the
stories generated by GPT2 which can be categorized into two folds: consistency
and coherency. In terms of consistency, on one hand, GPT2 cannot guarantee the
consistency of the plots explicitly. On the other hand, the generated stories
usually contain coreference errors. In terms of coherency, GPT2 does not take
account of the discourse relations between sentences of stories directly. To
enhance the consistency and coherency of the generated stories, we propose a
two-stage generation framework, where the first stage is to organize the story
outline which depicts the story plots and events, and the second stage is to
expand the outline into a complete story. Therefore the plots consistency can
be controlled and guaranteed explicitly. In addition, coreference supervision
signals are incorporated to reduce coreference errors and improve the
coreference consistency. Moreover, we design an auxiliary task of discourse
relation modeling to improve the coherency of the generated stories.
Experimental results on a story dataset show that our model outperforms the
baseline approaches in terms of both automatic metrics and human evaluation.
","[{'version': 'v1', 'created': 'Sat, 17 Oct 2020 16:40:37 GMT'}]",2020-10-20,"[['Wang', 'Wei', ''], ['Li', 'Piji', ''], ['Zheng', 'Hai-Tao', '']]"
1365376,2010.09046,Cheonbok  Park,"Yunwon Tae, Cheonbok Park, Taehee Kim, Soyoung Yang, Mohammad Azam
  Khan, Eunjeong Park, Tao Qin and Jaegul Choo",Meta-Learning for Low-Resource Unsupervised Neural MachineTranslation,"10 pages, 4 figures",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Unsupervised machine translation, which utilizes unpaired monolingual corpora
as training data, has achieved comparable performance against supervised
machine translation. However, it still suffers from data-scarce domains. To
address this issue, this paper presents a meta-learning algorithm for
unsupervised neural machine translation (UNMT) that trains the model to adapt
to another domain by utilizing only a small amount of training data. We assume
that domain-general knowledge is a significant factor in handling data-scarce
domains. Hence, we extend the meta-learning algorithm, which utilizes knowledge
learned from high-resource domains to boost the performance of low-resource
UNMT. Our model surpasses a transfer learning-based approach by up to 2-4 BLEU
scores. Extensive experimental results show that our proposed algorithm is
pertinent for fast adaptation and consistently outperforms other baseline
models.
","[{'version': 'v1', 'created': 'Sun, 18 Oct 2020 17:54:13 GMT'}]",2020-10-20,"[['Tae', 'Yunwon', ''], ['Park', 'Cheonbok', ''], ['Kim', 'Taehee', ''], ['Yang', 'Soyoung', ''], ['Khan', 'Mohammad Azam', ''], ['Park', 'Eunjeong', ''], ['Qin', 'Tao', ''], ['Choo', 'Jaegul', '']]"
1365325,2010.08995,Jinta Weng,"Jinta Weng, Ying Gao, Jing Qiu, Guozhu Ding, Huanqin Zheng","Construction and Application of Teaching System Based on Crowdsourcing
  Knowledge Graph","Number of references:15 Classification code:903.3 Information
  Retrieval and Use Conference code: 235759","4th China Conference on Knowledge Graph and Semantic Computing,
  CCKS 2019",10.1007/978-981-15-1956-7_3,,cs.DB cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Through the combination of crowdsourcing knowledge graph and teaching system,
research methods to generate knowledge graph and its applications. Using two
crowdsourcing approaches, crowdsourcing task distribution and reverse captcha
generation, to construct knowledge graph in the field of teaching system.
Generating a complete hierarchical knowledge graph of the teaching domain by
nodes of school, student, teacher, course, knowledge point and exercise type.
The knowledge graph constructed in a crowdsourcing manner requires many users
to participate collaboratively with fully consideration of teachers' guidance
and users' mobilization issues. Based on the three subgraphs of knowledge
graph, prominent teacher, student learning situation and suitable learning
route could be visualized. Personalized exercises recommendation model is used
to formulate the personalized exercise by algorithm based on the knowledge
graph. Collaborative creation model is developed to realize the crowdsourcing
construction mechanism. Though unfamiliarity with the learning mode of
knowledge graph and learners' less attention to the knowledge structure, system
based on Crowdsourcing Knowledge Graph can still get high acceptance around
students and teachers
","[{'version': 'v1', 'created': 'Sun, 18 Oct 2020 14:26:10 GMT'}]",2020-10-20,"[['Weng', 'Jinta', ''], ['Gao', 'Ying', ''], ['Qiu', 'Jing', ''], ['Ding', 'Guozhu', ''], ['Zheng', 'Huanqin', '']]"
1365313,2010.08983,Sahana Ramnath,"Sahana Ramnath, Preksha Nema, Deep Sahni, Mitesh M. Khapra",Towards Interpreting BERT for Reading Comprehension Based QA,7 pages including references and appendix. Accepted at EMNLP 2020,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  BERT and its variants have achieved state-of-the-art performance in various
NLP tasks. Since then, various works have been proposed to analyze the
linguistic information being captured in BERT. However, the current works do
not provide an insight into how BERT is able to achieve near human-level
performance on the task of Reading Comprehension based Question Answering. In
this work, we attempt to interpret BERT for RCQA. Since BERT layers do not have
predefined roles, we define a layer's role or functionality using Integrated
Gradients. Based on the defined roles, we perform a preliminary analysis across
all layers. We observed that the initial layers focus on query-passage
interaction, whereas later layers focus more on contextual understanding and
enhancing the answer prediction. Specifically for quantifier questions (how
much/how many), we notice that BERT focuses on confusing words (i.e., on other
numerical quantities in the passage) in the later layers, but still manages to
predict the answer correctly. The fine-tuning and analysis scripts will be
publicly available at https://github.com/iitmnlp/BERT-Analysis-RCQA .
","[{'version': 'v1', 'created': 'Sun, 18 Oct 2020 13:33:49 GMT'}]",2020-10-20,"[['Ramnath', 'Sahana', ''], ['Nema', 'Preksha', ''], ['Sahni', 'Deep', ''], ['Khapra', 'Mitesh M.', '']]"
1363122,2010.06792,Bowen Tan,"Bowen Tan, Lianhui Qin, Eric P. Xing, Zhiting Hu","Summarizing Text on Any Aspects: A Knowledge-Informed Weakly-Supervised
  Approach","EMNLP 2020, code and data available at
  https://github.com/tanyuqian/aspect-based-summarization",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Given a document and a target aspect (e.g., a topic of interest),
aspect-based abstractive summarization attempts to generate a summary with
respect to the aspect. Previous studies usually assume a small pre-defined set
of aspects and fall short of summarizing on other diverse topics. In this work,
we study summarizing on arbitrary aspects relevant to the document, which
significantly expands the application of the task in practice. Due to the lack
of supervision data, we develop a new weak supervision construction method and
an aspect modeling scheme, both of which integrate rich external knowledge
sources such as ConceptNet and Wikipedia. Experiments show our approach
achieves performance boosts on summarizing both real and synthetic documents
given pre-defined or arbitrary aspects.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 03:20:46 GMT'}, {'version': 'v2', 'created': 'Sun, 18 Oct 2020 08:58:23 GMT'}]",2020-10-20,"[['Tan', 'Bowen', ''], ['Qin', 'Lianhui', ''], ['Xing', 'Eric P.', ''], ['Hu', 'Zhiting', '']]"
1365304,2010.08974,Piyush Makhija,"Piyush Makhija, Ankit Kumar, Anuj Gupta","hinglishNorm -- A Corpus of Hindi-English Code Mixed Sentences for Text
  Normalization","Accepted in COLING2020 industry track, 8 pages (including
  references), 4 tables",,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  We present hinglishNorm -- a human annotated corpus of Hindi-English
code-mixed sentences for text normalization task. Each sentence in the corpus
is aligned to its corresponding human annotated normalized form. To the best of
our knowledge, there is no corpus of Hindi-English code-mixed sentences for
text normalization task that is publicly available. Our work is the first
attempt in this direction. The corpus contains 13494 parallel segments.
Further, we present baseline normalization results on this corpus. We obtain a
Word Error Rate (WER) of 15.55, BiLingual Evaluation Understudy (BLEU) score of
71.2, and Metric for Evaluation of Translation with Explicit ORdering (METEOR)
score of 0.50.
","[{'version': 'v1', 'created': 'Sun, 18 Oct 2020 12:21:37 GMT'}]",2020-10-20,"[['Makhija', 'Piyush', ''], ['Kumar', 'Ankit', ''], ['Gupta', 'Anuj', '']]"
1365291,2010.08961,Zewei Sun,"Zewei Sun, Mingxuan Wang, Hao Zhou, Chengqi Zhao, Shujian Huang,
  Jiajun Chen, Lei Li","Capturing Longer Context for Document-level Neural Machine Translation:
  A Multi-resolutional Approach",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Discourse context has been proven useful when translating documents. It is
quite a challenge to incorporate long document context in the prevailing neural
machine translation models such as Transformer. In this paper, we propose
multi-resolutional (MR) Doc2Doc, a method to train a neural
sequence-to-sequence model for document-level translation. Our trained model
can simultaneously translate sentence by sentence as well as a document as a
whole. We evaluate our method and several recent approaches on nine
document-level datasets and two sentence-level datasets across six languages.
Experiments show that MR Doc2Doc outperforms sentence-level models and previous
methods in a comprehensive set of metrics, including BLEU, four lexical
indices, three newly proposed assistant linguistic indicators, and human
evaluation.
","[{'version': 'v1', 'created': 'Sun, 18 Oct 2020 11:18:29 GMT'}]",2020-10-20,"[['Sun', 'Zewei', ''], ['Wang', 'Mingxuan', ''], ['Zhou', 'Hao', ''], ['Zhao', 'Chengqi', ''], ['Huang', 'Shujian', ''], ['Chen', 'Jiajun', ''], ['Li', 'Lei', '']]"
1365253,2010.08923,Chenyu You,"Chenyu You, Nuo Chen, Fenglin Liu, Dongchao Yang, Yuexian Zou","Towards Data Distillation for End-to-end Spoken Conversational Question
  Answering",,,,,cs.CL cs.AI eess.AS eess.SP,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In spoken question answering, QA systems are designed to answer questions
from contiguous text spans within the related speech transcripts. However, the
most natural way that human seek or test their knowledge is via human
conversations. Therefore, we propose a new Spoken Conversational Question
Answering task (SCQA), aiming at enabling QA systems to model complex dialogues
flow given the speech utterances and text corpora. In this task, our main
objective is to build a QA system to deal with conversational questions both in
spoken and text forms, and to explore the plausibility of providing more cues
in spoken documents with systems in information gathering. To this end, instead
of adopting automatically generated speech transcripts with highly noisy data,
we propose a novel unified data distillation approach, DDNet, which directly
fuse audio-text features to reduce the misalignment between automatic speech
recognition hypotheses and the reference transcriptions. In addition, to
evaluate the capacity of QA systems in a dialogue-style interaction, we
assemble a Spoken Conversational Question Answering (Spoken-CoQA) dataset with
more than 120k question-answer pairs. Experiments demonstrate that our proposed
method achieves superior performance in spoken conversational question
answering.
","[{'version': 'v1', 'created': 'Sun, 18 Oct 2020 05:53:39 GMT'}]",2020-10-20,"[['You', 'Chenyu', ''], ['Chen', 'Nuo', ''], ['Liu', 'Fenglin', ''], ['Yang', 'Dongchao', ''], ['Zou', 'Yuexian', '']]"
1365222,2010.08892,Chenguang Zhu,"Ruochen Xu, Chenguang Zhu, Yu Shi, Michael Zeng, Xuedong Huang",Mixed-Lingual Pre-training for Cross-lingual Summarization,"Accepted at Asia-Pacific Chapter of the Association for Computational
  Linguistics (AACL) 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Cross-lingual Summarization (CLS) aims at producing a summary in the target
language for an article in the source language. Traditional solutions employ a
two-step approach, i.e. translate then summarize or summarize then translate.
Recently, end-to-end models have achieved better results, but these approaches
are mostly limited by their dependence on large-scale labeled data. We propose
a solution based on mixed-lingual pre-training that leverages both
cross-lingual tasks such as translation and monolingual tasks like masked
language models. Thus, our model can leverage the massive monolingual data to
enhance its modeling of language. Moreover, the architecture has no
task-specific components, which saves memory and increases optimization
efficiency. We show in experiments that this pre-training scheme can
effectively boost the performance of cross-lingual summarization. In Neural
Cross-Lingual Summarization (NCLS) dataset, our model achieves an improvement
of 2.82 (English to Chinese) and 1.15 (Chinese to English) ROUGE-1 scores over
state-of-the-art results.
","[{'version': 'v1', 'created': 'Sun, 18 Oct 2020 00:21:53 GMT'}]",2020-10-20,"[['Xu', 'Ruochen', ''], ['Zhu', 'Chenguang', ''], ['Shi', 'Yu', ''], ['Zeng', 'Michael', ''], ['Huang', 'Xuedong', '']]"
1365213,2010.08883,Sai Sharath Japa,Sai Sharath Japa and Rekabdar Banafsheh,Question Answering over Knowledge Base using Language Model Embeddings,,2020 International Joint Conference on Neural Networks (IJCNN),10.1109/IJCNN48605.2020.9206698,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Knowledge Base, represents facts about the world, often in some form of
subsumption ontology, rather than implicitly, embedded in procedural code, the
way a conventional computer program does. While there is a rapid growth in
knowledge bases, it poses a challenge of retrieving information from them.
Knowledge Base Question Answering is one of the promising approaches for
extracting substantial knowledge from Knowledge Bases. Unlike web search,
Question Answering over a knowledge base gives accurate and concise results,
provided that natural language questions can be understood and mapped precisely
to an answer in the knowledge base. However, some of the existing
embedding-based methods for knowledge base question answering systems ignore
the subtle correlation between the question and the Knowledge Base (e.g.,
entity types, relation paths, and context) and suffer from the Out Of
Vocabulary problem. In this paper, we focused on using a pre-trained language
model for the Knowledge Base Question Answering task. Firstly, we used Bert
base uncased for the initial experiments. We further fine-tuned these
embeddings with a two-way attention mechanism from the knowledge base to the
asked question and from the asked question to the knowledge base answer
aspects. Our method is based on a simple Convolutional Neural Network
architecture with a Multi-Head Attention mechanism to represent the asked
question dynamically in multiple aspects. Our experimental results show the
effectiveness and the superiority of the Bert pre-trained language model
embeddings for question answering systems on knowledge bases over other
well-known embedding methods.
","[{'version': 'v1', 'created': 'Sat, 17 Oct 2020 22:59:34 GMT'}]",2020-10-20,"[['Japa', 'Sai Sharath', ''], ['Banafsheh', 'Rekabdar', '']]"
1365195,2010.08865,Thanh Tran,"Thanh Tran, Yifan Hu, Changwei Hu, Kevin Yen, Fei Tan, Kyumin Lee,
  Serim Park",HABERTOR: An Efficient and Effective Deep Hatespeech Detector,,EMNLP 2020,,,cs.CL cs.AI cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present our HABERTOR model for detecting hatespeech in large scale
user-generated content. Inspired by the recent success of the BERT model, we
propose several modifications to BERT to enhance the performance on the
downstream hatespeech classification task. HABERTOR inherits BERT's
architecture, but is different in four aspects: (i) it generates its own
vocabularies and is pre-trained from the scratch using the largest scale
hatespeech dataset; (ii) it consists of Quaternion-based factorized components,
resulting in a much smaller number of parameters, faster training and
inferencing, as well as less memory usage; (iii) it uses our proposed
multi-source ensemble heads with a pooling layer for separate input sources, to
further enhance its effectiveness; and (iv) it uses a regularized adversarial
training with our proposed fine-grained and adaptive noise magnitude to enhance
its robustness. Through experiments on the large-scale real-world hatespeech
dataset with 1.4M annotated comments, we show that HABERTOR works better than
15 state-of-the-art hatespeech detection methods, including fine-tuning
Language Models. In particular, comparing with BERT, our HABERTOR is 4~5 times
faster in the training/inferencing phase, uses less than 1/3 of the memory, and
has better performance, even though we pre-train it by using less than 1% of
the number of words. Our generalizability analysis shows that HABERTOR
transfers well to other unseen hatespeech datasets and is a more efficient and
effective alternative to BERT for the hatespeech classification.
","[{'version': 'v1', 'created': 'Sat, 17 Oct 2020 21:10:08 GMT'}]",2020-10-20,"[['Tran', 'Thanh', ''], ['Hu', 'Yifan', ''], ['Hu', 'Changwei', ''], ['Yen', 'Kevin', ''], ['Tan', 'Fei', ''], ['Lee', 'Kyumin', ''], ['Park', 'Serim', '']]"
1365360,2010.09030,Nazneen Fatema Rajani,"Nazneen Fatema Rajani, Ben Krause, Wengpeng Yin, Tong Niu, Richard
  Socher, Caiming Xiong","Explaining and Improving Model Behavior with k Nearest Neighbor
  Representations",,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Interpretability techniques in NLP have mainly focused on understanding
individual predictions using attention visualization or gradient-based saliency
maps over tokens. We propose using k nearest neighbor (kNN) representations to
identify training examples responsible for a model's predictions and obtain a
corpus-level understanding of the model's behavior. Apart from
interpretability, we show that kNN representations are effective at uncovering
learned spurious associations, identifying mislabeled examples, and improving
the fine-tuned model's performance. We focus on Natural Language Inference
(NLI) as a case study and experiment with multiple datasets. Our method deploys
backoff to kNN for BERT and RoBERTa on examples with low model confidence
without any update to the model parameters. Our results indicate that the kNN
approach makes the finetuned model more robust to adversarial inputs.
","[{'version': 'v1', 'created': 'Sun, 18 Oct 2020 16:55:25 GMT'}]",2020-10-20,"[['Rajani', 'Nazneen Fatema', ''], ['Krause', 'Ben', ''], ['Yin', 'Wengpeng', ''], ['Niu', 'Tong', ''], ['Socher', 'Richard', ''], ['Xiong', 'Caiming', '']]"
1324058,2007.12544,Bertelt Braaksma,"Bertelt Braaksma, Richard Scholtens, Stan van Suijlekom, Remy Wang,
  Ahmet \""Ust\""un",FiSSA at SemEval-2020 Task 9: Fine-tuned For Feelings,"In Proceedings of the 14th International Workshop on Semantic
  Evaluation (SemEval-2020), Barcelona, Spain, December. Association for
  Computational Linguistics",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we present our approach for sentiment classification on
Spanish-English code-mixed social media data in the SemEval-2020 Task 9. We
investigate performance of various pre-trained Transformer models by using
different fine-tuning strategies. We explore both monolingual and multilingual
models with the standard fine-tuning method. Additionally, we propose a custom
model that we fine-tune in two steps: once with a language modeling objective,
and once with a task-specific objective. Although two-step fine-tuning improves
sentiment classification performance over the base model, the large
multilingual XLM-RoBERTa model achieves best weighted F1-score with 0.537 on
development data and 0.739 on test data. With this score, our team jupitter
placed tenth overall in the competition.
","[{'version': 'v1', 'created': 'Fri, 24 Jul 2020 14:48:27 GMT'}, {'version': 'v2', 'created': 'Fri, 31 Jul 2020 15:41:22 GMT'}, {'version': 'v3', 'created': 'Mon, 19 Oct 2020 07:11:18 GMT'}]",2020-10-20,"[['Braaksma', 'Bertelt', ''], ['Scholtens', 'Richard', ''], ['van Suijlekom', 'Stan', ''], ['Wang', 'Remy', ''], ['Üstün', 'Ahmet', '']]"
1279300,2004.14530,Peng Qi,"Peng Qi, Yuhao Zhang, Christopher D. Manning","Stay Hungry, Stay Focused: Generating Informative and Specific Questions
  in Information-Seeking Conversations","Findings of ACL: EMNLP 2020. Code available at:
  https://github.com/qipeng/stay-hungry-stay-focused",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We investigate the problem of generating informative questions in
information-asymmetric conversations. Unlike previous work on question
generation which largely assumes knowledge of what the answer might be, we are
interested in the scenario where the questioner is not given the context from
which answers are drawn, but must reason pragmatically about how to acquire new
information, given the shared conversation history. We identify two core
challenges: (1) formally defining the informativeness of potential questions,
and (2) exploring the prohibitively large space of potential questions to find
the good candidates. To generate pragmatic questions, we use reinforcement
learning to optimize an informativeness metric we propose, combined with a
reward function designed to promote more specific questions. We demonstrate
that the resulting pragmatic questioner substantially improves the
informativeness and specificity of questions generated over a baseline model,
as evaluated by our metrics as well as humans.
","[{'version': 'v1', 'created': 'Thu, 30 Apr 2020 00:49:14 GMT'}, {'version': 'v2', 'created': 'Tue, 20 Oct 2020 16:53:32 GMT'}]",2020-10-21,"[['Qi', 'Peng', ''], ['Zhang', 'Yuhao', ''], ['Manning', 'Christopher D.', '']]"
1279733,2004.14963,Emrah Budur,"Emrah Budur, R{\i}za \""Oz\c{c}elik, Tunga G\""ung\""or, and Christopher
  Potts",Data and Representation for Turkish Natural Language Inference,Accepted to EMNLP 2020,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large annotated datasets in NLP are overwhelmingly in English. This is an
obstacle to progress in other languages. Unfortunately, obtaining new annotated
resources for each task in each language would be prohibitively expensive. At
the same time, commercial machine translation systems are now robust. Can we
leverage these systems to translate English-language datasets automatically? In
this paper, we offer a positive response for natural language inference (NLI)
in Turkish. We translated two large English NLI datasets into Turkish and had a
team of experts validate their translation quality and fidelity to the original
labels. Using these datasets, we address core issues of representation for
Turkish NLI. We find that in-language embeddings are essential and that
morphological parsing can be avoided where the training set is large. Finally,
we show that models trained on our machine-translated datasets are successful
on human-translated evaluation sets. We share all code, models, and data
publicly.
","[{'version': 'v1', 'created': 'Thu, 30 Apr 2020 17:12:52 GMT'}, {'version': 'v2', 'created': 'Fri, 1 May 2020 23:15:03 GMT'}, {'version': 'v3', 'created': 'Tue, 20 Oct 2020 15:25:07 GMT'}]",2020-10-21,"[['Budur', 'Emrah', ''], ['Özçelik', 'Rıza', ''], ['Güngör', 'Tunga', ''], ['Potts', 'Christopher', '']]"
1366327,2010.09997,Haohan Wang,"Haohan Wang, Peiyan Zhang, Eric P. Xing",Word Shape Matters: Robust Machine Translation with Visual Embedding,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Neural machine translation has achieved remarkable empirical performance over
standard benchmark datasets, yet recent evidence suggests that the models can
still fail easily dealing with substandard inputs such as misspelled words, To
overcome this issue, we introduce a new encoding heuristic of the input symbols
for character-level NLP models: it encodes the shape of each character through
the images depicting the letters when printed. We name this new strategy visual
embedding and it is expected to improve the robustness of NLP models because
humans also process the corpus visually through printed letters, instead of
machinery one-hot vectors. Empirically, our method improves models' robustness
against substandard inputs, even in the test scenario where the models are
tested with the noises that are beyond what is available during the training
phase.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 04:08:03 GMT'}]",2020-10-21,"[['Wang', 'Haohan', ''], ['Zhang', 'Peiyan', ''], ['Xing', 'Eric P.', '']]"
1294203,2005.14408,Xiao Yang,"Deepak Muralidharan, Joel Ruben Antony Moniz, Sida Gao, Xiao Yang, Lin
  Li, Justine Kao, Stephen Pulman, Atish Kothari, Ray Shen, Yinying Pan, Vivek
  Kaul, Mubarak Seyed Ibrahim, Gang Xiang, Nan Dun, Yidan Zhou, Andy O, Yuan
  Zhang, Pooja Chitkara, Xuan Wang, Alkesh Patel, Kushal Tayal, Roger Zheng,
  Peter Grasch, Jason Williams",Noise-robust Named Entity Understanding for Virtual Assistants,9 pages,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Named Entity Understanding (NEU) plays an essential role in interactions
between users and voice assistants, since successfully identifying entities and
correctly linking them to their standard forms is crucial to understanding the
user's intent. NEU is a challenging task in voice assistants due to the
ambiguous nature of natural language and because noise introduced by speech
transcription and user errors occur frequently in spoken natural language
queries. In this paper, we propose an architecture with novel features that
jointly solves the recognition of named entities (a.k.a. Named Entity
Recognition, or NER) and the resolution to their canonical forms (a.k.a. Entity
Linking, or EL). We show that by combining NER and EL information in a joint
reranking module, our proposed framework improves accuracy in both tasks. This
improved performance and the features that enable it, also lead to better
accuracy in downstream tasks, such as domain classification and semantic
parsing.
","[{'version': 'v1', 'created': 'Fri, 29 May 2020 06:14:53 GMT'}, {'version': 'v2', 'created': 'Mon, 19 Oct 2020 20:32:55 GMT'}]",2020-10-21,"[['Muralidharan', 'Deepak', ''], ['Moniz', 'Joel Ruben Antony', ''], ['Gao', 'Sida', ''], ['Yang', 'Xiao', ''], ['Li', 'Lin', ''], ['Kao', 'Justine', ''], ['Pulman', 'Stephen', ''], ['Kothari', 'Atish', ''], ['Shen', 'Ray', ''], ['Pan', 'Yinying', ''], ['Kaul', 'Vivek', ''], ['Ibrahim', 'Mubarak Seyed', ''], ['Xiang', 'Gang', ''], ['Dun', 'Nan', ''], ['Zhou', 'Yidan', ''], ['O', 'Andy', ''], ['Zhang', 'Yuan', ''], ['Chitkara', 'Pooja', ''], ['Wang', 'Xuan', ''], ['Patel', 'Alkesh', ''], ['Tayal', 'Kushal', ''], ['Zheng', 'Roger', ''], ['Grasch', 'Peter', ''], ['Williams', 'Jason', '']]"
1366407,2010.10077,Aman Madaan,"Aman Madaan, Yiming Yang",Neural Language Modeling for Contextualized Temporal Graph Generation,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  This paper presents the first study on using large-scale pre-trained language
models for automated generation of an event-level temporal graph for a
document. Despite the huge success of neural pre-training methods in NLP tasks,
its potential for temporal reasoning over event graphs has not been
sufficiently explored. Part of the reason is the difficulty in obtaining large
training corpora with human-annotated events and temporal links. We address
this challenge by using existing IE/NLP tools to automatically generate a large
quantity (89,000) of system-produced document-graph pairs, and propose a novel
formulation of the contextualized graph generation problem as a
sequence-to-sequence mapping task. These strategies enable us to leverage and
fine-tune pre-trained language models on the system-induced training data for
the graph generation task. Our experiments show that our approach is highly
effective in generating structurally and semantically valid graphs. Further,
evaluation on a challenging hand-labeled, out-domain corpus shows that our
method outperforms the closest existing method by a large margin on several
metrics. Code and pre-trained models are available at
https://github.com/madaan/temporal-graph-gen.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 07:08:00 GMT'}]",2020-10-21,"[['Madaan', 'Aman', ''], ['Yang', 'Yiming', '']]"
1366425,2010.10095,Hung Le,"Hung Le, Doyen Sahoo, Nancy F. Chen, Steven C.H. Hoi","BiST: Bi-directional Spatio-Temporal Reasoning for Video-Grounded
  Dialogues",,,,,cs.CV cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Video-grounded dialogues are very challenging due to (i) the complexity of
videos which contain both spatial and temporal variations, and (ii) the
complexity of user utterances which query different segments and/or different
objects in videos over multiple dialogue turns. However, existing approaches to
video-grounded dialogues often focus on superficial temporal-level visual cues,
but neglect more fine-grained spatial signals from videos. To address this
drawback, we propose Bi-directional Spatio-Temporal Learning (BiST), a
vision-language neural framework for high-resolution queries in videos based on
textual cues. Specifically, our approach not only exploits both spatial and
temporal-level information, but also learns dynamic information diffusion
between the two feature spaces through spatial-to-temporal and
temporal-to-spatial reasoning. The bidirectional strategy aims to tackle the
evolving semantics of user queries in the dialogue setting. The retrieved
visual cues are used as contextual information to construct relevant responses
to the users. Our empirical results and comprehensive qualitative analysis show
that BiST achieves competitive performance and generates reasonable responses
on a large-scale AVSD benchmark. We also adapt our BiST models to the Video QA
setting, and substantially outperform prior approaches on the TGIF-QA
benchmark.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 07:43:00 GMT'}]",2020-10-21,"[['Le', 'Hung', ''], ['Sahoo', 'Doyen', ''], ['Chen', 'Nancy F.', ''], ['Hoi', 'Steven C. H.', '']]"
1366441,2010.10111,Sainik Mahata,"Sainik Kumar Mahata, Dipankar Das, Sivaji Bandyopadhyay","JUNLP@Dravidian-CodeMix-FIRE2020: Sentiment Classification of Code-Mixed
  Tweets using Bi-Directional RNN and Language Tags",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Sentiment analysis has been an active area of research in the past two
decades and recently, with the advent of social media, there has been an
increasing demand for sentiment analysis on social media texts. Since the
social media texts are not in one language and are largely code-mixed in
nature, the traditional sentiment classification models fail to produce
acceptable results. This paper tries to solve this very research problem and
uses bi-directional LSTMs along with language tagging, to facilitate sentiment
tagging of code-mixed Tamil texts that have been extracted from social media.
The presented algorithm, when evaluated on the test data, garnered precision,
recall, and F1 scores of 0.59, 0.66, and 0.58 respectively.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 08:10:29 GMT'}]",2020-10-21,"[['Mahata', 'Sainik Kumar', ''], ['Das', 'Dipankar', ''], ['Bandyopadhyay', 'Sivaji', '']]"
1366480,2010.10150,Wei Ping,"Sashank Santhanam, Wei Ping, Raul Puri, Mohammad Shoeybi, Mostofa
  Patwary, Bryan Catanzaro",Local Knowledge Powered Conversational Agents,,,,,cs.CL cs.AI cs.HC cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  State-of-the-art conversational agents have advanced significantly in
conjunction with the use of large transformer-based language models. However,
even with these advancements, conversational agents still lack the ability to
produce responses that are informative and coherent with the local context. In
this work, we propose a dialog framework that incorporates both local knowledge
as well as users' past dialogues to generate high quality conversations. We
introduce an approach to build a dataset based on Reddit conversations, where
outbound URL links are widely available in the conversations and the
hyperlinked documents can be naturally included as local external knowledge.
Using our framework and dataset, we demonstrate that incorporating local
knowledge can largely improve informativeness, coherency and realisticness
measures using human evaluations. In particular, our approach consistently
outperforms the state-of-the-art conversational model on the Reddit dataset
across all three measures. We also find that scaling the size of our models
from 117M to 8.3B parameters yields consistent improvement of validation
perplexity as well as human evaluated metrics. Our model with 8.3B parameters
can generate human-like responses as rated by various human evaluations in a
single-turn dialog setting.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 09:34:40 GMT'}]",2020-10-21,"[['Santhanam', 'Sashank', ''], ['Ping', 'Wei', ''], ['Puri', 'Raul', ''], ['Shoeybi', 'Mohammad', ''], ['Patwary', 'Mostofa', ''], ['Catanzaro', 'Bryan', '']]"
1366486,2010.10156,Shivali Agarwal,"Shivali Agarwal, Shubham Atreja, Vikas Agarwal",Extracting Procedural Knowledge from Technical Documents,,,,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Procedures are an important knowledge component of documents that can be
leveraged by cognitive assistants for automation, question-answering or driving
a conversation. It is a challenging problem to parse big dense documents like
product manuals, user guides to automatically understand which parts are
talking about procedures and subsequently extract them. Most of the existing
research has focused on extracting flows in given procedures or understanding
the procedures in order to answer conceptual questions. Identifying and
extracting multiple procedures automatically from documents of diverse formats
remains a relatively less addressed problem. In this work, we cover some of
this ground by -- 1) Providing insights on how structural and linguistic
properties of documents can be grouped to define types of procedures, 2)
Analyzing documents to extract the relevant linguistic and structural
properties, and 3) Formulating procedure identification as a classification
problem that leverages the features of the document derived from the above
analysis. We first implemented and deployed unsupervised techniques which were
used in different use cases. Based on the evaluation in different use cases, we
figured out the weaknesses of the unsupervised approach. We then designed an
improved version which was supervised. We demonstrate that our technique is
effective in identifying procedures from big and complex documents alike by
achieving accuracy of 89%.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 09:47:52 GMT'}]",2020-10-21,"[['Agarwal', 'Shivali', ''], ['Atreja', 'Shubham', ''], ['Agarwal', 'Vikas', '']]"
1366506,2010.10176,Markus J. Hofmann,"Markus J. Hofmann, Lara M\""uller, Andre R\""olke, Ralph Radach and
  Chris Biemann",Individual corpora predict fast memory retrieval during reading,"Proceedings of the 6th workshop on Cognitive Aspects of the Lexicon
  (CogALex-VI), Barcelona, Spain, December 12, 2020; accepted manuscript; 11
  pages, 2 figures, 4 Tables",,,,cs.CL cs.IR,http://creativecommons.org/licenses/by/4.0/,"  The corpus, from which a predictive language model is trained, can be
considered the experience of a semantic system. We recorded everyday reading of
two participants for two months on a tablet, generating individual corpus
samples of 300/500K tokens. Then we trained word2vec models from individual
corpora and a 70 million-sentence newspaper corpus to obtain individual and
norm-based long-term memory structure. To test whether individual corpora can
make better predictions for a cognitive task of long-term memory retrieval, we
generated stimulus materials consisting of 134 sentences with uncorrelated
individual and norm-based word probabilities. For the subsequent eye tracking
study 1-2 months later, our regression analyses revealed that individual, but
not norm-corpus-based word probabilities can account for first-fixation
duration and first-pass gaze duration. Word length additionally affected gaze
duration and total viewing duration. The results suggest that corpora
representative for an individual's longterm memory structure can better explain
reading performance than a norm corpus, and that recently acquired information
is lexically accessed rapidly.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 10:18:20 GMT'}]",2020-10-21,"[['Hofmann', 'Markus J.', ''], ['Müller', 'Lara', ''], ['Rölke', 'Andre', ''], ['Radach', 'Ralph', ''], ['Biemann', 'Chris', '']]"
1366533,2010.10203,Ondrej Skopek,"Daria Soboleva, Ondrej Skopek, M\'arius \v{S}ajgal\'ik, Victor
  C\u{a}rbune, Felix Weissenberger, Julia Proskurnia, Bogdan Prisacari, Daniel
  Valcarce, Justin Lu, Rohit Prabhavalkar, Balint Miklos","Replacing Human Audio with Synthetic Audio for On-device Unspoken
  Punctuation Prediction",,,,,cs.LG cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present a novel multi-modal unspoken punctuation prediction system for the
English language which combines acoustic and text features. We demonstrate for
the first time, that by relying exclusively on synthetic data generated using a
prosody-aware text-to-speech system, we can outperform a model trained with
expensive human audio recordings on the unspoken punctuation prediction
problem. Our model architecture is well suited for on-device use. This is
achieved by leveraging hash-based embeddings of automatic speech recognition
text output in conjunction with acoustic features as input to a quasi-recurrent
neural network, keeping the model size small and latency low.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 11:30:26 GMT'}]",2020-10-21,"[['Soboleva', 'Daria', ''], ['Skopek', 'Ondrej', ''], ['Šajgalík', 'Márius', ''], ['Cărbune', 'Victor', ''], ['Weissenberger', 'Felix', ''], ['Proskurnia', 'Julia', ''], ['Prisacari', 'Bogdan', ''], ['Valcarce', 'Daniel', ''], ['Lu', 'Justin', ''], ['Prabhavalkar', 'Rohit', ''], ['Miklos', 'Balint', '']]"
1366546,2010.10216,Danish Contractor,"Biswesh Mohapatra, Gaurav Pandey, Danish Contractor, Sachindra Joshi","Simulated Chats for Task-oriented Dialog: Learning to Generate
  Conversations from Instructions",,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Popular task-oriented dialog data sets such as MultiWOZ (Budzianowski et al.
2018) are created by providing crowd-sourced workers a goal instruction,
expressed in natural language, that describes the task to be accomplished.
Crowd-sourced workers play the role of a user and an agent to generate dialogs
to accomplish tasks involving booking restaurant tables, making train
reservations, calling a taxi etc. However, creating large crowd-sourced
datasets can be time consuming and expensive. To reduce the cost associated
with generating such dialog datasets, recent work has explored methods to
automatically create larger datasets from small samples.In this paper, we
present a data creation strategy that uses the pre-trained language model, GPT2
(Radford et al. 2018), to simulate the interaction between crowd-sourced
workers by creating a user bot and an agent bot. We train the simulators using
a smaller percentage of actual crowd-generated conversations and their
corresponding goal instructions. We demonstrate that by using the simulated
data, we achieve significant improvements in both low-resource setting as well
as in over-all task performance. To the best of our knowledge we are the first
to present a model for generating entire conversations by simulating the
crowd-sourced data collection process
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 12:04:19 GMT'}]",2020-10-21,"[['Mohapatra', 'Biswesh', ''], ['Pandey', 'Gaurav', ''], ['Contractor', 'Danish', ''], ['Joshi', 'Sachindra', '']]"
1366568,2010.10238,Thomas Ruprecht,"Richard M\""orbitz and Thomas Ruprecht",Supertagging-based Parsing with Linear Context-free Rewriting Systems,"10 pages, 4 figures, 4 tables",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present the first supertagging-based parser for LCFRS. It utilizes neural
classifiers and tremendously outperforms previous LCFRS-based parsers in both
accuracy and parsing speed. Moreover, our results keep up with the best
(general) discontinuous parsers, particularly the scores for discontinuous
constitutents are excellent. The heart of our approach is an efficient
lexicalization procedure which induces a lexical LCFRS from any discontinuous
treebank. It is an adaptation of previous work by M\""orbitz and Ruprecht
(2020). We also describe a modification to usual chart-based LCFRS parsing that
accounts for supertagging and introduce a procedure for the transformation of
lexical LCFRS derivations into equivalent parse trees of the original treebank.
Our approach is implemented and evaluated on the English Discontinuous Penn
Treebank and the German corpora NeGra and Tiger.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 13:02:42 GMT'}]",2020-10-21,"[['Mörbitz', 'Richard', ''], ['Ruprecht', 'Thomas', '']]"
1366569,2010.10239,Markus Freitag,"Markus Freitag, Orhan Firat",Complete Multilingual Neural Machine Translation,Accepted at WMT 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Multilingual Neural Machine Translation (MNMT) models are commonly trained on
a joint set of bilingual corpora which is acutely English-centric (i.e. English
either as the source or target language). While direct data between two
languages that are non-English is explicitly available at times, its use is not
common. In this paper, we first take a step back and look at the commonly used
bilingual corpora (WMT), and resurface the existence and importance of implicit
structure that existed in it: multi-way alignment across examples (the same
sentence in more than two languages). We set out to study the use of multi-way
aligned examples to enrich the original English-centric parallel corpora. We
reintroduce this direct parallel data from multi-way aligned corpora between
all source and target languages. By doing so, the English-centric graph expands
into a complete graph, every language pair being connected. We call MNMT with
such connectivity pattern complete Multilingual Neural Machine Translation
(cMNMT) and demonstrate its utility and efficacy with a series of experiments
and analysis. In combination with a novel training data sampling strategy that
is conditioned on the target language only, cMNMT yields competitive
translation quality for all language pairs. We further study the size effect of
multi-way aligned data, its transfer learning capabilities and how it eases
adding a new language in MNMT. Finally, we stress test cMNMT at scale and
demonstrate that we can train a cMNMT model with up to 111*112=12,432 language
pairs that provides competitive translation quality for all language pairs.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 13:03:48 GMT'}]",2020-10-21,"[['Freitag', 'Markus', ''], ['Firat', 'Orhan', '']]"
1366575,2010.10245,Markus Freitag,"Markus Freitag, George Foster, David Grangier, Colin Cherry",Human-Paraphrased References Improve Neural Machine Translation,Accepted at WMT 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automatic evaluation comparing candidate translations to human-generated
paraphrases of reference translations has recently been proposed by Freitag et
al. When used in place of original references, the paraphrased versions produce
metric scores that correlate better with human judgment. This effect holds for
a variety of different automatic metrics, and tends to favor natural
formulations over more literal (translationese) ones. In this paper we compare
the results of performing end-to-end system development using standard and
paraphrased references. With state-of-the-art English-German NMT components, we
show that tuning to paraphrased references produces a system that is
significantly better according to human judgment, but 5 BLEU points worse when
tested on standard references. Our work confirms the finding that paraphrased
references yield metric scores that correlate better with human judgment, and
demonstrates for the first time that using these scores for system development
can lead to significant improvements.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 13:14:57 GMT'}]",2020-10-21,"[['Freitag', 'Markus', ''], ['Foster', 'George', ''], ['Grangier', 'David', ''], ['Cherry', 'Colin', '']]"
1366582,2010.10252,Marco Wrzalik,Marco Wrzalik and Dirk Krechel,CoRT: Complementary Rankings from Transformers,Pre-print,,,,cs.IR cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent approaches towards passage retrieval have successfully employed
representations from pretrained Language Models(LMs) with large effectiveness
gains. However, due to high computational cost those approaches are usually
limited to re-ranking scenarios. The candidates in such a scenario are
typically retrieved by scalable bag-of-words retrieval models such as BM25.
Although BM25 has proven decent performance as a first-stage ranker, it tends
to miss relevant passages. In this context we propose CoRT, a framework and
neural first-stage ranking model that leverages contextual representations from
transformer-based language models to complement candidates from term-based
ranking functions while causing no significant delay. Using the MS MARCO
dataset, we show that CoRT significantly increases first-stage ranking quality
and recall by complementing BM25 with missing candidates. Consequently, we
found subsequent re-rankers achieve superior results while requiring less
candidates to saturate ranking quality. Finally, we demonstrate that with CoRT
a representation-focused retrieval at web-scale can be realized with latencies
as low as BM25.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 13:28:27 GMT'}]",2020-10-21,"[['Wrzalik', 'Marco', ''], ['Krechel', 'Dirk', '']]"
1366597,2010.10267,Kakia Chatsiou,Kakia Chatsiou,"Text Classification of COVID-19 Press Briefings using BERT and
  Convolutional Neural Networks","12 pages, 1 figure, 4 tables",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  We build a sentence-level political discourse classifier using existing human
expert annotated corpora of political manifestos from the Manifestos Project
(Volkens et al.,2020a) and applying them to a corpus ofCOVID-19Press Briefings
(Chatsiou,2020). We use manually annotated political manifestos as training
data to train a local topic ConvolutionalNeural Network (CNN) classifier; then
apply it to the COVID-19PressBriefings Corpus to automatically classify
sentences in the test corpus.We report on a series of experiments with CNN
trained on top of pre-trained embeddings for sentence-level classification
tasks. We show thatCNN combined with transformers like BERT outperforms CNN
combined with other embeddings (Word2Vec, Glove, ELMo) and that it is possible
to use a pre-trained classifier to conduct automatic classification on
different political texts without additional training.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 13:39:58 GMT'}]",2020-10-21,"[['Chatsiou', 'Kakia', '']]"
1366616,2010.10286,Wei Peng,"Wei Peng, Yue Hu, Luxi Xing, Yuqiang Xie, Jing Yu, Yajing Sun,
  Xiangpeng Wei","Bi-directional Cognitive Thinking Network for Machine Reading
  Comprehension",Accepted to COLING 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a novel Bi-directional Cognitive Knowledge Framework (BCKF) for
reading comprehension from the perspective of complementary learning systems
theory. It aims to simulate two ways of thinking in the brain to answer
questions, including reverse thinking and inertial thinking. To validate the
effectiveness of our framework, we design a corresponding Bi-directional
Cognitive Thinking Network (BCTN) to encode the passage and generate a question
(answer) given an answer (question) and decouple the bi-directional knowledge.
The model has the ability to reverse reasoning questions which can assist
inertial thinking to generate more accurate answers. Competitive improvement is
observed in DuReader dataset, confirming our hypothesis that bi-directional
knowledge helps the QA task. The novel framework shows an interesting
perspective on machine reading comprehension and cognitive science.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 13:56:30 GMT'}]",2020-10-21,"[['Peng', 'Wei', ''], ['Hu', 'Yue', ''], ['Xing', 'Luxi', ''], ['Xie', 'Yuqiang', ''], ['Yu', 'Jing', ''], ['Sun', 'Yajing', ''], ['Wei', 'Xiangpeng', '']]"
1366653,2010.10323,Chujie Zheng,"Chujie Zheng, Kunpeng Zhang, Harry Jiannan Wang, Ling Fan",Topic-Aware Abstractive Text Summarization,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automatic text summarization aims at condensing a document to a shorter
version while preserving the key information. Different from extractive
summarization which simply selects text fragments from the document,
abstractive summarization generates the summary in a word-by-word manner. Most
current state-of-the-art (SOTA) abstractive summarization methods are based on
the Transformer-based encoder-decoder architecture and focus on novel
self-supervised objectives in pre-training. While these models well capture the
contextual information among words in documents, little attention has been paid
to incorporating global semantics to better fine-tune for the downstream
abstractive summarization task.
  In this study, we propose a topic-aware abstractive summarization (TAAS)
framework by leveraging the underlying semantic structure of documents
represented by their latent topics. Specifically, TAAS seamlessly incorporates
a neural topic modeling into an encoder-decoder based sequence generation
procedure via attention for summarization. This design is able to learn and
preserve global semantics of documents and thus makes summarization effective,
which has been proved by our experiments on real-world datasets. As compared to
several cutting-edge baseline methods, we show that TAAS outperforms BART, a
well-recognized SOTA model, by 2%, 8%, and 12% regarding the F measure of
ROUGE-1, ROUGE-2, and ROUGE-L, respectively. TAAS also achieves comparable
performance to PEGASUS and ProphetNet, which is difficult to accomplish given
that training PEGASUS and ProphetNet requires enormous computing capacity
beyond what we used in this study.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 14:45:25 GMT'}]",2020-10-21,"[['Zheng', 'Chujie', ''], ['Zhang', 'Kunpeng', ''], ['Wang', 'Harry Jiannan', ''], ['Fan', 'Ling', '']]"
1366663,2010.10333,Wenchang Ma,"Wenchang Ma, Ryuichi Takanobu, Minghao Tu, Minlie Huang","Bridging the Gap between Conversational Reasoning and Interactive
  Recommendation",,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  There have been growing interests in building a conversational recommender
system, where the system simultaneously interacts with the user and explores
the user's preference throughout conversational interactions. Recommendation
and conversation were usually treated as two separate modules with limited
information exchange in existing works, which hinders the capability of both
systems: (1) dialog merely incorporated recommendation entities without being
guided by an explicit recommendation-oriented policy; (2) recommendation
utilized dialog only as a form of interaction instead of improving
recommendation effectively. To address the above issues, we propose a novel
recommender dialog model: CR-Walker. In order to view the two separate systems
within a unified framework, we seek high-level mapping between hierarchical
dialog acts and multi-hop knowledge graph reasoning. The model walks on a
large-scale knowledge graph to form a reasoning tree at each turn, then mapped
to dialog acts to guide response generation. With such a mapping mechanism as a
bridge between recommendation and conversation, our framework maximizes the
mutual benefit between two systems: dialog as an enhancement to recommendation
quality and explainability, recommendation as a goal and enrichment to dialog
semantics. Quantitative evaluation shows that our model excels in conversation
informativeness and recommendation effectiveness, at the same time explainable
on the policy level.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 14:53:22 GMT'}]",2020-10-21,"[['Ma', 'Wenchang', ''], ['Takanobu', 'Ryuichi', ''], ['Tu', 'Minghao', ''], ['Huang', 'Minlie', '']]"
1366716,2010.10386,Spyretta Leivaditi,"Spyretta Leivaditi, Julien Rossi, Evangelos Kanoulas",A Benchmark for Lease Contract Review,,,,,cs.IR cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Extracting entities and other useful information from legal contracts is an
important task whose automation can help legal professionals perform contract
reviews more efficiently and reduce relevant risks. In this paper, we tackle
the problem of detecting two different types of elements that play an important
role in a contract review, namely entities and red flags. The latter are terms
or sentences that indicate that there is some danger or other potentially
problematic situation for one or more of the signing parties. We focus on
supporting the review of lease agreements, a contract type that has received
little attention in the legal information extraction literature, and we define
the types of entities and red flags needed for that task. We release a new
benchmark dataset of 179 lease agreement documents that we have manually
annotated with the entities and red flags they contain, and which can be used
to train and test relevant extraction algorithms. Finally, we release a new
language model, called ALeaseBERT, pre-trained on this dataset and fine-tuned
for the detection of the aforementioned elements, providing a baseline for
further research
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 15:50:50 GMT'}]",2020-10-21,"[['Leivaditi', 'Spyretta', ''], ['Rossi', 'Julien', ''], ['Kanoulas', 'Evangelos', '']]"
1366721,2010.10391,Georgios Michalopoulos,"George Michalopoulos, Yuanxin Wang, Hussam Kaka, Helen Chen and Alex
  Wong","UmlsBERT: Clinical Domain Knowledge Augmentation of Contextual
  Embeddings Using the Unified Medical Language System Metathesaurus","8 pages, 4 figures",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Contextual word embedding models, such as BioBERT and Bio_ClinicalBERT, have
achieved state-of-the-art results in biomedical natural language processing
tasks by focusing their pre-training process on domain-specific corpora.
However, such models do not take into consideration expert domain knowledge.
  In this work, we introduced UmlsBERT, a contextual embedding model that
integrates domain knowledge during the pre-training process via a novel
knowledge augmentation strategy. More specifically, the augmentation on
UmlsBERT with the Unified Medical Language System (UMLS) Metathesaurus was
performed in two ways: i) connecting words that have the same underlying
`concept' in UMLS, and ii) leveraging semantic group knowledge in UMLS to
create clinically meaningful input embeddings. By applying these two
strategies, UmlsBERT can encode clinical domain knowledge into word embeddings
and outperform existing domain-specific models on common named-entity
recognition (NER) and clinical natural language inference clinical NLP tasks.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 15:56:31 GMT'}]",2020-10-21,"[['Michalopoulos', 'George', ''], ['Wang', 'Yuanxin', ''], ['Kaka', 'Hussam', ''], ['Chen', 'Helen', ''], ['Wong', 'Alex', '']]"
1366769,2010.10439,Wenhu Chen,"Wenhu Chen, Ming-Wei Chang, Eva Schlinger, William Wang, William W.
  Cohen",Open Question Answering over Tables and Text,Technical Report,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In open question answering (QA), the answer to a question is produced by
retrieving and then analyzing documents that might contain answers to the
question. Most open QA systems have considered only retrieving information from
unstructured text. Here we consider for the first time open QA over both
tabular and textual data and present a new large-scale dataset Open Table-Text
Question Answering (OTT-QA) to evaluate performance on this task. Most
questions in OTT-QA require multi-hop inference across tabular data and
unstructured text, and the evidence required to answer a question can be
distributed in different ways over these two types of input, making evidence
retrieval challenging---our baseline model using an iterative retriever and
BERT-based reader achieves an exact match score less than 10%. We then propose
two novel techniques to address the challenge of retrieving and aggregating
evidence for OTT-QA. The first technique is to use ""early fusion"" to group
multiple highly relevant tabular and textual units into a fused block, which
provides more context for the retriever to search for. The second technique is
to use a cross-block reader to model the cross-dependency between multiple
retrieved evidences with global-local sparse attention. Combining these two
techniques improves the score significantly, to above 27%.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 16:48:14 GMT'}]",2020-10-21,"[['Chen', 'Wenhu', ''], ['Chang', 'Ming-Wei', ''], ['Schlinger', 'Eva', ''], ['Wang', 'William', ''], ['Cohen', 'William W.', '']]"
1366783,2010.10453,Maria Leonor Pacheco,Maria Leonor Pacheco and Dan Goldwasser,Modeling Content and Context with Deep Relational Learning,TACL pre-MIT Press version,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Building models for realistic natural language tasks requires dealing with
long texts and accounting for complicated structural dependencies.
Neural-symbolic representations have emerged as a way to combine the reasoning
capabilities of symbolic methods, with the expressiveness of neural networks.
However, most of the existing frameworks for combining neural and symbolic
representations have been designed for classic relational learning tasks that
work over a universe of symbolic entities and relations. In this paper, we
present DRaiL, an open-source declarative framework for specifying deep
relational models, designed to support a variety of NLP scenarios. Our
framework supports easy integration with expressive language encoders, and
provides an interface to study the interactions between representation,
inference and learning.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 17:09:35 GMT'}]",2020-10-21,"[['Pacheco', 'Maria Leonor', ''], ['Goldwasser', 'Dan', '']]"
1366802,2010.10472,Yiyuan Li,"Yiyuan Li, Antonios Anastasopoulos, Alan W Black","Comparison of Interactive Knowledge Base Spelling Correction Models for
  Low-Resource Languages",9 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Spelling normalization for low resource languages is a challenging task
because the patterns are hard to predict and large corpora are usually required
to collect enough examples. This work shows a comparison of a neural model and
character language models with varying amounts on target language data. Our
usage scenario is interactive correction with nearly zero amounts of training
examples, improving models as more data is collected, for example within a chat
app. Such models are designed to be incrementally improved as feedback is given
from users. In this work, we design a knowledge-base and prediction model
embedded system for spelling correction in low-resource languages. Experimental
results on multiple languages show that the model could become effective with a
small amount of data. We perform experiments on both natural and synthetic
data, as well as on data from two endangered languages (Ainu and Griko). Last,
we built a prototype system that was used for a small case study on Hinglish,
which further demonstrated the suitability of our approach in real world
scenarios.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 17:31:07 GMT'}]",2020-10-21,"[['Li', 'Yiyuan', ''], ['Anastasopoulos', 'Antonios', ''], ['Black', 'Alan W', '']]"
1366374,2010.10044,Xiachong Feng,"Xiachong Feng, Xiaocheng Feng, Bing Qin, Ting Liu","Incorporating Commonsense Knowledge into Abstractive Dialogue
  Summarization via Heterogeneous Graph Networks",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Abstractive dialogue summarization is the task of capturing the highlights of
a dialogue and rewriting them into a concise version. In this paper, we present
a novel multi-speaker dialogue summarizer to demonstrate how large-scale
commonsense knowledge can facilitate dialogue understanding and summary
generation. In detail, we consider utterance and commonsense knowledge as two
different types of data and design a Dialogue Heterogeneous Graph Network
(D-HGN) for modeling both information. Meanwhile, we also add speakers as
heterogeneous nodes to facilitate information flow. Experimental results on the
SAMSum dataset show that our model can outperform various methods. We also
conduct zero-shot setting experiments on the Argumentative Dialogue Summary
Corpus, the results show that our model can better generalized to the new
domain.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 05:44:55 GMT'}]",2020-10-21,"[['Feng', 'Xiachong', ''], ['Feng', 'Xiaocheng', ''], ['Qin', 'Bing', ''], ['Liu', 'Ting', '']]"
1366829,2010.10499,Adrian de Wynter,Adrian de Wynter and Daniel J. Perry,Optimal Subarchitecture Extraction For BERT,Preprint. Under review,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  We extract an optimal subset of architectural parameters for the BERT
architecture from Devlin et al. (2018) by applying recent breakthroughs in
algorithms for neural architecture search. This optimal subset, which we refer
to as ""Bort"", is demonstrably smaller, having an effective (that is, not
counting the embedding layer) size of $5.5\%$ the original BERT-large
architecture, and $16\%$ of the net size. Bort is also able to be pretrained in
$288$ GPU hours, which is $1.2\%$ of the time required to pretrain the
highest-performing BERT parametric architectural variant, RoBERTa-large (Liu et
al., 2019), and about $33\%$ of that of the world-record, in GPU hours,
required to train BERT-large on the same hardware. It is also $7.9$x faster on
a CPU, as well as being better performing than other compressed variants of the
architecture, and some of the non-compressed variants: it obtains performance
improvements of between $0.3\%$ and $31\%$, absolute, with respect to
BERT-large, on multiple public natural language understanding (NLU) benchmarks.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 17:53:01 GMT'}]",2020-10-21,"[['de Wynter', 'Adrian', ''], ['Perry', 'Daniel J.', '']]"
1366372,2010.10042,Yasuhide Miura,"Yasuhide Miura, Yuhao Zhang, Curtis P. Langlotz, Dan Jurafsky","Improving Factual Completeness and Consistency of Image-to-Text
  Radiology Report Generation","13 pages, 3 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Neural image-to-text radiology report generation systems offer the potential
to accelerate clinical processes by saving radiologists from the repetitive
labor of drafting radiology reports and preventing medical errors. However,
existing report generation systems, despite achieving high performances on
natural language generation metrics such as CIDEr or BLEU, still suffer from
incomplete and inconsistent generations, rendering these systems unusable in
practice. In this work, we aim to overcome this problem by proposing two new
metrics that encourage the factual completeness and consistency of generated
radiology reports. The first metric, the Exact Entity Match score, evaluates a
generation by its coverage of radiology domain entities against the references.
The second metric, the Entailing Entity Match score, augments the first metric
by introducing a natural language inference model into the entity match process
to encourage consistent generations that can be entailed from the references.
To achieve this, we also developed an in-domain NLI model via weak supervision
to improve its performance on radiology text. We further propose a report
generation system that optimizes these two new metrics via reinforcement
learning. On two open radiology report datasets, our system not only achieves
the best performance on these two metrics compared to baselines, but also leads
to as much as +2.0 improvement on the F1 score of a clinical finding metric. We
show via analysis and examples that our system leads to generations that are
more complete and consistent compared to the baselines.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 05:42:47 GMT'}]",2020-10-21,"[['Miura', 'Yasuhide', ''], ['Zhang', 'Yuhao', ''], ['Langlotz', 'Curtis P.', ''], ['Jurafsky', 'Dan', '']]"
1366365,2010.10035,Neha Srikanth,"Neha Srikanth, Junyi Jessy Li","Elaborative Simplification: Content Addition and Explanation Generation
  in Text Simplification",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Much of modern day text simplification research focuses on sentence-level
simplification, transforming original, more complex sentences to simplified
versions. However, adding content can often be useful when difficult concepts
and reasoning need to be explained. In this work, we present the first
data-driven study of content addition in document simplification, which we call
elaborative simplification. We introduce a new annotated dataset of 1.3K
instances of elaborative simplification and analyze how entities, ideas, and
concepts are elaborated through the lens of contextual specificity. We
establish baselines for elaboration generation using large scale pre-trained
language models, and illustrate that considering contextual specificity during
generation can improve performance. Our results illustrate the complexities of
elaborative simplification, suggesting many interesting directions for future
work.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 05:06:23 GMT'}]",2020-10-21,"[['Srikanth', 'Neha', ''], ['Li', 'Junyi Jessy', '']]"
1342529,2009.01026,Hammond Pearce,"Hammond Pearce, Benjamin Tan, Ramesh Karri",DAVE: Deriving Automatically Verilog from English,"6 pages, 2 figures",,10.1145/3380446.3430634,,cs.SE cs.CL cs.LG stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While specifications for digital systems are provided in natural language,
engineers undertake significant efforts to translate them into the programming
languages understood by compilers for digital systems. Automating this process
allows designers to work with the language in which they are most comfortable
--the original natural language -- and focus instead on other downstream design
challenges. We explore the use of state-of-the-art machine learning (ML) to
automatically derive Verilog snippets from English via fine-tuning GPT-2, a
natural language ML system. We describe our approach for producing a suitable
dataset of novice-level digital design tasks and provide a detailed exploration
of GPT-2, finding encouraging translation performance across our task sets
(94.8% correct), with the ability to handle both simple and abstract design
tasks.
","[{'version': 'v1', 'created': 'Thu, 27 Aug 2020 15:25:03 GMT'}]",2020-10-21,"[['Pearce', 'Hammond', ''], ['Tan', 'Benjamin', ''], ['Karri', 'Ramesh', '']]"
1358424,2010.02094,Gaurav Arora,Gaurav Arora,"Gauravarora@HASOC-Dravidian-CodeMix-FIRE2020: Pre-training ULMFiT on
  Synthetically Generated Code-Mixed Data for Hate Speech Detection","System description paper for 2nd ranked system in Sub-task B accepted
  at Dravidian-Codemix-HASOC2020@FIRE2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper describes the system submitted to Dravidian-Codemix-HASOC2020:
Hate Speech and Offensive Content Identification in Dravidian languages
(Tamil-English and Malayalam-English). The task aims to identify offensive
language in code-mixed dataset of comments/posts in Dravidian languages
collected from social media. We participated in both Sub-task A, which aims to
identify offensive content in mixed-script (mixture of Native and Roman script)
and Sub-task B, which aims to identify offensive content in Roman script, for
Dravidian languages. In order to address these tasks, we proposed pre-training
ULMFiT on synthetically generated code-mixed data, generated by modelling
code-mixed data generation as a Markov process using Markov chains. Our model
achieved 0.88 weighted F1-score for code-mixed Tamil-English language in
Sub-task B and got 2nd rank on the leader-board. Additionally, our model
achieved 0.91 weighted F1-score (4th Rank) for mixed-script Malayalam-English
in Sub-task A and 0.74 weighted F1-score (5th Rank) for code-mixed
Malayalam-English language in Sub-task B.
","[{'version': 'v1', 'created': 'Mon, 5 Oct 2020 15:25:47 GMT'}, {'version': 'v2', 'created': 'Mon, 19 Oct 2020 18:11:41 GMT'}]",2020-10-21,"[['Arora', 'Gaurav', '']]"
1358682,2010.02352,Julia Kreutzer,"Julia Kreutzer, George Foster, Colin Cherry",Inference Strategies for Machine Translation with Conditional Masking,"EMNLP 2020, updated Fig 3",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Conditional masked language model (CMLM) training has proven successful for
non-autoregressive and semi-autoregressive sequence generation tasks, such as
machine translation. Given a trained CMLM, however, it is not clear what the
best inference strategy is. We formulate masked inference as a factorization of
conditional probabilities of partial sequences, show that this does not harm
performance, and investigate a number of simple heuristics motivated by this
perspective. We identify a thresholding strategy that has advantages over the
standard ""mask-predict"" algorithm, and provide analyses of its behavior on
machine translation tasks.
","[{'version': 'v1', 'created': 'Mon, 5 Oct 2020 21:50:09 GMT'}, {'version': 'v2', 'created': 'Tue, 20 Oct 2020 15:14:40 GMT'}]",2020-10-21,"[['Kreutzer', 'Julia', ''], ['Foster', 'George', ''], ['Cherry', 'Colin', '']]"
1359331,2010.03001,Giannis Bekoulis,"Giannis Bekoulis, Christina Papagiannopoulou, Nikos Deligiannis",A Review on Fact Extraction and VERification: The FEVER case,author preprint version,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Fact Extraction and VERification (FEVER) is a recently introduced task which
aims to identify the veracity of a given claim based on Wikipedia documents. A
lot of methods have been proposed to address this problem which consists of the
subtasks of (i) retrieving the relevant documents (and sentences) from
Wikipedia and (ii) validating whether the information in the documents supports
or refutes a given claim. This task is essential since it can be the building
block of applications that require a deep understanding of the language such as
fake news detection and medical claim verification. In this paper, we aim to
get a better understanding of the challenges in the task by presenting the
literature in a structured and comprehensive way. In addition, we describe the
proposed methods by analyzing the technical perspectives of the different
approaches and discussing the performance results on the FEVER dataset.
","[{'version': 'v1', 'created': 'Tue, 6 Oct 2020 20:05:43 GMT'}, {'version': 'v2', 'created': 'Mon, 19 Oct 2020 20:35:52 GMT'}]",2020-10-21,"[['Bekoulis', 'Giannis', ''], ['Papagiannopoulou', 'Christina', ''], ['Deligiannis', 'Nikos', '']]"
1360062,2010.03732,Inigo Jauregi Unanue,"Inigo Jauregi Unanue, Nazanin Esmaili, Gholamreza Haffari, Massimo
  Piccardi","Leveraging Discourse Rewards for Document-Level Neural Machine
  Translation",Accepted at COLING 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Document-level machine translation focuses on the translation of entire
documents from a source to a target language. It is widely regarded as a
challenging task since the translation of the individual sentences in the
document needs to retain aspects of the discourse at document level. However,
document-level translation models are usually not trained to explicitly ensure
discourse quality. Therefore, in this paper we propose a training approach that
explicitly optimizes two established discourse metrics, lexical cohesion (LC)
and coherence (COH), by using a reinforcement learning objective. Experiments
over four different language pairs and three translation domains have shown
that our training approach has been able to achieve more cohesive and coherent
document translations than other competitive approaches, yet without
compromising the faithfulness to the reference translation. In the case of the
Zh-En language pair, our method has achieved an improvement of 2.46 percentage
points (pp) in LC and 1.17 pp in COH over the runner-up, while at the same time
improving 0.63 pp in BLEU score and 0.47 pp in F_BERT.
","[{'version': 'v1', 'created': 'Thu, 8 Oct 2020 02:26:22 GMT'}, {'version': 'v2', 'created': 'Mon, 19 Oct 2020 23:33:06 GMT'}]",2020-10-21,"[['Unanue', 'Inigo Jauregi', ''], ['Esmaili', 'Nazanin', ''], ['Haffari', 'Gholamreza', ''], ['Piccardi', 'Massimo', '']]"
1360627,2010.04297,Thibault Sellam,"Thibault Sellam, Amy Pu, Hyung Won Chung, Sebastian Gehrmann, Qijun
  Tan, Markus Freitag, Dipanjan Das, Ankur P. Parikh","Learning to Evaluate Translation Beyond English: BLEURT Submissions to
  the WMT Metrics 2020 Shared Task",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The quality of machine translation systems has dramatically improved over the
last decade, and as a result, evaluation has become an increasingly challenging
problem. This paper describes our contribution to the WMT 2020 Metrics Shared
Task, the main benchmark for automatic evaluation of translation. We make
several submissions based on BLEURT, a previously published metric based on
transfer learning. We extend the metric beyond English and evaluate it on 14
language pairs for which fine-tuning data is available, as well as 4
""zero-shot"" language pairs, for which we have no labelled examples.
Additionally, we focus on English to German and demonstrate how to combine
BLEURT's predictions with those of YiSi and use alternative reference
translations to enhance the performance. Empirical results show that the models
achieve competitive results on the WMT Metrics 2019 Shared Task, indicating
their promise for the 2020 edition.
","[{'version': 'v1', 'created': 'Thu, 8 Oct 2020 23:16:26 GMT'}, {'version': 'v2', 'created': 'Mon, 12 Oct 2020 21:45:11 GMT'}, {'version': 'v3', 'created': 'Mon, 19 Oct 2020 22:40:08 GMT'}]",2020-10-21,"[['Sellam', 'Thibault', ''], ['Pu', 'Amy', ''], ['Chung', 'Hyung Won', ''], ['Gehrmann', 'Sebastian', ''], ['Tan', 'Qijun', ''], ['Freitag', 'Markus', ''], ['Das', 'Dipanjan', ''], ['Parikh', 'Ankur P.', '']]"
1362236,2010.05906,Lianhui Qin,"Lianhui Qin, Vered Shwartz, Peter West, Chandra Bhagavatula, Jena
  Hwang, Ronan Le Bras, Antoine Bosselut, Yejin Choi","Back to the Future: Unsupervised Backprop-based Decoding for
  Counterfactual and Abductive Commonsense Reasoning",EMNLP 2020,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Abductive and counterfactual reasoning, core abilities of everyday human
cognition, require reasoning about what might have happened at time t, while
conditioning on multiple contexts from the relative past and future. However,
simultaneous incorporation of past and future contexts using generative
language models (LMs) can be challenging, as they are trained either to
condition only on the past context or to perform narrowly scoped
text-infilling. In this paper, we propose DeLorean, a new unsupervised decoding
algorithm that can flexibly incorporate both the past and future contexts using
only off-the-shelf, left-to-right language models and no supervision. The key
intuition of our algorithm is incorporating the future through
back-propagation, during which, we only update the internal representation of
the output while fixing the model parameters. By alternating between forward
and backward propagation, DeLorean can decode the output representation that
reflects both the left and right contexts. We demonstrate that our approach is
general and applicable to two nonmonotonic reasoning tasks: abductive text
generation and counterfactual story revision, where DeLorean outperforms a
range of unsupervised and some supervised methods, based on automatic and human
evaluation.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 17:58:43 GMT'}, {'version': 'v2', 'created': 'Tue, 20 Oct 2020 05:39:07 GMT'}]",2020-10-21,"[['Qin', 'Lianhui', ''], ['Shwartz', 'Vered', ''], ['West', 'Peter', ''], ['Bhagavatula', 'Chandra', ''], ['Hwang', 'Jena', ''], ['Bras', 'Ronan Le', ''], ['Bosselut', 'Antoine', ''], ['Choi', 'Yejin', '']]"
1364165,2010.07835,Yue Yu,"Yue Yu, Simiao Zuo, Haoming Jiang, Wendi Ren, Tuo Zhao and Chao Zhang","Fine-Tuning Pre-trained Language Model with Weak Supervision: A
  Contrastive-Regularized Self-Training Approach",,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Fine-tuned pre-trained language models (LMs) achieve enormous success in many
natural language processing (NLP) tasks, but they still require excessive
labeled data in the fine-tuning stage. We study the problem of fine-tuning
pre-trained LMs using only weak supervision, without any labeled data. This
problem is challenging because the high capacity of LMs makes them prone to
overfitting the noisy labels generated by weak supervision. To address this
problem, we develop a contrastive self-training framework, COSINE, to enable
fine-tuning LMs with weak supervision. Underpinned by contrastive
regularization and confidence-based reweighting, this contrastive self-training
framework can gradually improve model fitting while effectively suppressing
error propagation. Experiments on sequence, token, and sentence pair
classification tasks show that our model outperforms the strongest baseline by
large margins on 7 benchmarks in 6 tasks, and achieves competitive performance
with fully-supervised fine-tuning methods.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 15:55:08 GMT'}, {'version': 'v2', 'created': 'Tue, 20 Oct 2020 17:05:28 GMT'}]",2020-10-21,"[['Yu', 'Yue', ''], ['Zuo', 'Simiao', ''], ['Jiang', 'Haoming', ''], ['Ren', 'Wendi', ''], ['Zhao', 'Tuo', ''], ['Zhang', 'Chao', '']]"
1364848,2010.08518,Biao Zhang,"Biao Zhang, Ivan Titov, Barry Haddow, Rico Sennrich",Adaptive Feature Selection for End-to-End Speech Translation,"EMNLP2020 Findings; source code is at
  https://github.com/bzhangGo/zero",,,,cs.CL cs.LG cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Information in speech signals is not evenly distributed, making it an
additional challenge for end-to-end (E2E) speech translation (ST) to learn to
focus on informative features. In this paper, we propose adaptive feature
selection (AFS) for encoder-decoder based E2E ST. We first pre-train an ASR
encoder and apply AFS to dynamically estimate the importance of each encoded
speech feature to SR. A ST encoder, stacked on top of the ASR encoder, then
receives the filtered features from the (frozen) ASR encoder. We take L0DROP
(Zhang et al., 2020) as the backbone for AFS, and adapt it to sparsify speech
features with respect to both temporal and feature dimensions. Results on
LibriSpeech En-Fr and MuST-C benchmarks show that AFS facilitates learning of
ST by pruning out ~84% temporal features, yielding an average translation gain
of ~1.3-1.6 BLEU and a decoding speedup of ~1.4x. In particular, AFS reduces
the performance gap compared to the cascade baseline, and outperforms it on
LibriSpeech En-Fr with a BLEU score of 18.56 (without data augmentation)
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 17:21:00 GMT'}, {'version': 'v2', 'created': 'Tue, 20 Oct 2020 13:53:39 GMT'}]",2020-10-21,"[['Zhang', 'Biao', ''], ['Titov', 'Ivan', ''], ['Haddow', 'Barry', ''], ['Sennrich', 'Rico', '']]"
1365743,2010.09413,Du\v{s}an Vari\v{s},"Du\v{s}an Vari\v{s}, Katsuhito Sudoh, and Satoshi Nakamura","Image Captioning with Visual Object Representations Grounded in the
  Textual Modality",,,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present our work in progress exploring the possibilities of a shared
embedding space between textual and visual modality. Leveraging the textual
nature of object detection labels and the hypothetical expressiveness of
extracted visual object representations, we propose an approach opposite to the
current trend, grounding of the representations in the word embedding space of
the captioning system instead of grounding words or sentences in their
associated images. Based on the previous work, we apply additional grounding
losses to the image captioning training objective aiming to force visual object
representations to create more heterogeneous clusters based on their class
label and copy a semantic structure of the word embedding space. In addition,
we provide an analysis of the learned object vector space projection and its
impact on the IC system performance. With only slight change in performance,
grounded models reach the stopping criterion during training faster than the
unconstrained model, needing about two to three times less training updates.
Additionally, an improvement in structural correlation between the word
embeddings and both original and projected object vectors suggests that the
grounding is actually mutual.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 12:21:38 GMT'}, {'version': 'v2', 'created': 'Tue, 20 Oct 2020 12:24:39 GMT'}]",2020-10-21,"[['Variš', 'Dušan', ''], ['Sudoh', 'Katsuhito', ''], ['Nakamura', 'Satoshi', '']]"
1365932,2010.09602,Yusuke Yasuda,"Yusuke Yasuda, Xin Wang, Junichi Yamagishi",End-to-End Text-to-Speech using Latent Duration based on VQ-VAE,,,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Explicit duration modeling is a key to achieving robust and efficient
alignment in text-to-speech synthesis (TTS). We propose a new TTS framework
using explicit duration modeling that incorporates duration as a discrete
latent variable to TTS and enables joint optimization of whole modules from
scratch. We formulate our method based on conditional VQ-VAE to handle discrete
duration in a variational autoencoder and provide a theoretical explanation to
justify our method. In our framework, a connectionist temporal classification
(CTC) -based force aligner acts as the approximate posterior, and
text-to-duration works as the prior in the variational autoencoder. We
evaluated our proposed method with a listening test and compared it with other
TTS methods based on soft-attention or explicit duration modeling. The results
showed that our systems rated between soft-attention-based methods
(Transformer-TTS, Tacotron2) and explicit duration modeling-based methods
(Fastspeech).
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 15:34:49 GMT'}, {'version': 'v2', 'created': 'Tue, 20 Oct 2020 13:46:35 GMT'}]",2020-10-21,"[['Yasuda', 'Yusuke', ''], ['Wang', 'Xin', ''], ['Yamagishi', 'Junichi', '']]"
1365953,2010.09623,Vi Tran Tuan,"Tuan-Vi Tran, Xuan-Thien Pham, Duc-Vu Nguyen, Kiet Van Nguyen, Ngan
  Luu-Thuy Nguyen",An Empirical Study for Vietnamese Constituency Parsing with Pre-training,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this work, we use a span-based approach for Vietnamese constituency
parsing. Our method follows the self-attention encoder architecture and a chart
decoder using a CKY-style inference algorithm. We present analyses of the
experiment results of the comparison of our empirical method using pre-training
models XLM-Roberta and PhoBERT on both Vietnamese datasets VietTreebank and
NIIVTB1. The results show that our model with XLM-Roberta archived the
significantly F1-score better than other pre-training models, VietTreebank at
81.19% and NIIVTB1 at 85.70%.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 16:02:00 GMT'}, {'version': 'v2', 'created': 'Tue, 20 Oct 2020 02:44:02 GMT'}]",2020-10-21,"[['Tran', 'Tuan-Vi', ''], ['Pham', 'Xuan-Thien', ''], ['Nguyen', 'Duc-Vu', ''], ['Van Nguyen', 'Kiet', ''], ['Nguyen', 'Ngan Luu-Thuy', '']]"
1366110,2010.09780,Wenhao Yu,"Wenhao Yu, Lingfei Wu, Yu Deng, Qingkai Zeng, Ruchi Mahindru, Sinem
  Guven, Meng Jiang",Technical Question Answering across Tasks and Domains,"10 pages, 6 figures",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Building automatic technical support system is an important yet challenge
task. Conceptually, to answer a user question on a technical forum, a human
expert has to first retrieve relevant documents, and then read them carefully
to identify the answer snippet. Despite huge success the researchers have
achieved in coping with general domain question answering (QA), much less
attentions have been paid for investigating technical QA. Specifically,
existing methods suffer from several unique challenges (i) the question and
answer rarely overlaps substantially and (ii) very limited data size. In this
paper, we propose a novel framework of deep transfer learning to effectively
address technical QA across tasks and domains. To this end, we present an
adjustable joint learning approach for document retrieval and reading
comprehension tasks. Our experiments on the TechQA demonstrates superior
performance compared with state-of-the-art methods.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 18:39:30 GMT'}]",2020-10-21,"[['Yu', 'Wenhao', ''], ['Wu', 'Lingfei', ''], ['Deng', 'Yu', ''], ['Zeng', 'Qingkai', ''], ['Mahindru', 'Ruchi', ''], ['Guven', 'Sinem', ''], ['Jiang', 'Meng', '']]"
1366118,2010.09788,Yufei Feng,"Mo Yu, Xiaoxiao Guo, Yufei Feng, Xiaodan Zhu, Michael Greenspan,
  Murray Campbell",Deriving Commonsense Inference Tasks from Interactive Fictions,,,,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Commonsense reasoning simulates the human ability to make presumptions about
our physical world, and it is an indispensable cornerstone in building general
AI systems. We propose a new commonsense reasoning dataset based on human's
interactive fiction game playings as human players demonstrate plentiful and
diverse commonsense reasoning. The new dataset mitigates several limitations of
the prior art. Experiments show that our task is solvable to human experts with
sufficient commonsense knowledge but poses challenges to existing machine
reading models, with a big performance gap of more than 30%.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 19:02:34 GMT'}]",2020-10-21,"[['Yu', 'Mo', ''], ['Guo', 'Xiaoxiao', ''], ['Feng', 'Yufei', ''], ['Zhu', 'Xiaodan', ''], ['Greenspan', 'Michael', ''], ['Campbell', 'Murray', '']]"
1366133,2010.09803,Jie Zhao,"Jie Zhao, Huan Sun","Adversarial Training for Code Retrieval with Question-Description
  Relevance Regularization",,,,,cs.CL cs.AI cs.IR cs.PL,http://creativecommons.org/licenses/by/4.0/,"  Code retrieval is a key task aiming to match natural and programming
languages. In this work, we propose adversarial learning for code retrieval,
that is regularized by question-description relevance. First, we adapt a simple
adversarial learning technique to generate difficult code snippets given the
input question, which can help the learning of code retrieval that faces
bi-modal and data-scarce challenges. Second, we propose to leverage
question-description relevance to regularize adversarial learning, such that a
generated code snippet should contribute more to the code retrieval training
loss, only if its paired natural language description is predicted to be less
relevant to the user given question. Experiments on large-scale code retrieval
datasets of two programming languages show that our adversarial learning method
is able to improve the performance of state-of-the-art models. Moreover, using
an additional duplicate question prediction model to regularize adversarial
learning further improves the performance, and this is more effective than
using the duplicated questions in strong multi-task learning baselines
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 19:32:03 GMT'}]",2020-10-21,"[['Zhao', 'Jie', ''], ['Sun', 'Huan', '']]"
1366158,2010.09828,Elliot Schumacher,"Elliot Schumacher, James Mayfield, Mark Dredze",Cross-Lingual Transfer in Zero-Shot Cross-Language Entity Linking,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Cross-language entity linking grounds mentions in multiple languages to a
single-language knowledge base. We propose a neural ranking architecture for
this task that uses multilingual BERT representations of the mention and the
context in a neural network. We find that the multilingual ability of BERT
leads to robust performance in monolingual and multilingual settings.
Furthermore, we explore zero-shot language transfer and find surprisingly
robust performance. We investigate the zero-shot degradation and find that it
can be partially mitigated by a proposed auxiliary training objective, but that
the remaining error can best be attributed to domain shift rather than language
transfer.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 20:08:26 GMT'}]",2020-10-21,"[['Schumacher', 'Elliot', ''], ['Mayfield', 'James', ''], ['Dredze', 'Mark', '']]"
1366235,2010.09905,Ilya Valmianski,"Ilya Valmianski, Ian M. Finn, Nave Frost, Yang Wang, Baodong Liu,
  James J. Zhu, Sunil Karumuri and Daniel S. Zisook","SmartTriage: A system for personalized patient data capture,
  documentation generation, and decision support",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Symptom checkers have emerged as an important tool for collecting symptoms
and diagnosing patients, minimizing the involvement of clinical personnel. We
developed a machine-learning-backed system, SmartTriage, which goes beyond
conventional symptom checking through a tight bi-directional integration with
the electronic medical record (EMR). Conditioned on EMR-derived patient
history, our system identifies the patient's chief complaint from a free-text
entry and then asks a series of discrete questions to obtain relevant
symptomatology. The patient-specific data are used to predict detailed
ICD-10-CM codes as well as medication, laboratory, and imaging orders. Patient
responses and clinical decision support (CDS) predictions are then inserted
back into the EMR. To train the machine learning components of SmartTriage, we
employed novel data sets of over 25 million primary care encounters and 1
million patient free-text reason-for-visit entries. These data sets were used
to construct: (1) a long short-term memory (LSTM) based patient history
representation, (2) a fine-tuned transformer model for chief complaint
extraction, (3) a random forest model for question sequencing, and (4) a
feed-forward network for CDS predictions. We also present the full production
architecture for the pilot deployment of SmartTriage that covers 337 patient
chief complaints.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 22:45:27 GMT'}]",2020-10-21,"[['Valmianski', 'Ilya', ''], ['Finn', 'Ian M.', ''], ['Frost', 'Nave', ''], ['Wang', 'Yang', ''], ['Liu', 'Baodong', ''], ['Zhu', 'James J.', ''], ['Karumuri', 'Sunil', ''], ['Zisook', 'Daniel S.', '']]"
1366256,2010.09926,Neema Kotonya,Neema Kotonya and Francesca Toni,Explainable Automated Fact-Checking for Public Health Claims,"Accepted to EMNLP 2020. 15 pages, 7 figures, 9 tables. The dataset is
  available at https://github.com/neemakot/Health-Fact-Checking",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Fact-checking is the task of verifying the veracity of claims by assessing
their assertions against credible evidence. The vast majority of fact-checking
studies focus exclusively on political claims. Very little research explores
fact-checking for other topics, specifically subject matters for which
expertise is required. We present the first study of explainable fact-checking
for claims which require specific expertise. For our case study we choose the
setting of public health. To support this case study we construct a new dataset
PUBHEALTH of 11.8K claims accompanied by journalist crafted, gold standard
explanations (i.e., judgments) to support the fact-check labels for claims. We
explore two tasks: veracity prediction and explanation generation. We also
define and evaluate, with humans and computationally, three coherence
properties of explanation quality. Our results indicate that, by training on
in-domain data, gains can be made in explainable, automated fact-checking for
claims which require specific expertise.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 23:51:33 GMT'}]",2020-10-21,"[['Kotonya', 'Neema', ''], ['Toni', 'Francesca', '']]"
1366257,2010.09927,Arvind Srikantan,"Karthik Radhakrishnan, Arvind Srikantan, Xi Victoria Lin",ColloQL: Robust Cross-Domain Text-to-SQL Over Search Queries,"IntEx-SemPar Workshop at EMNLP 2020, 12 pages, 3 figures",,,,cs.CL cs.AI cs.DB cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Translating natural language utterances to executable queries is a helpful
technique in making the vast amount of data stored in relational databases
accessible to a wider range of non-tech-savvy end users. Prior work in this
area has largely focused on textual input that is linguistically correct and
semantically unambiguous. However, real-world user queries are often succinct,
colloquial, and noisy, resembling the input of a search engine. In this work,
we introduce data augmentation techniques and a sampling-based content-aware
BERT model (ColloQL) to achieve robust text-to-SQL modeling over natural
language search (NLS) questions. Due to the lack of evaluation data, we curate
a new dataset of NLS questions and demonstrate the efficacy of our approach.
ColloQL's superior performance extends to well-formed text, achieving 84.9%
(logical) and 90.7% (execution) accuracy on the WikiSQL dataset, making it, to
the best of our knowledge, the highest performing model that does not use
execution guided decoding.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 23:53:17 GMT'}]",2020-10-21,"[['Radhakrishnan', 'Karthik', ''], ['Srikantan', 'Arvind', ''], ['Lin', 'Xi Victoria', '']]"
1366265,2010.09935,Faeze Brahman,"Faeze Brahman, Alexandru Petrusca, and Snigdha Chaturvedi",Cue Me In: Content-Inducing Approaches to Interactive Story Generation,AACL 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automatically generating stories is a challenging problem that requires
producing causally related and logical sequences of events about a topic.
Previous approaches in this domain have focused largely on one-shot generation,
where a language model outputs a complete story based on limited initial input
from a user. Here, we instead focus on the task of interactive story
generation, where the user provides the model mid-level sentence abstractions
in the form of cue phrases during the generation process. This provides an
interface for human users to guide the story generation. We present two
content-inducing approaches to effectively incorporate this additional
information. Experimental results from both automatic and human evaluations
show that these methods produce more topically coherent and personalized
stories compared to baseline methods.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 00:36:15 GMT'}]",2020-10-21,"[['Brahman', 'Faeze', ''], ['Petrusca', 'Alexandru', ''], ['Chaturvedi', 'Snigdha', '']]"
1366284,2010.09954,Runzhe Yang,"Runzhe Yang, Jingxiao Chen, Karthik Narasimhan",Generating Strategic Dialogue for Negotiation with Theory of Mind,"12 pages, 3 figures",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a framework to integrate the concept of Theory of Mind (ToM) into
generating utterances for task-oriented dialogue. Our approach explores the
ability to model and infer personality types of opponents, predicts their
responses, and uses this information to adapt the agent's high-level strategy
in negotiation tasks. We introduce a probabilistic formulation for the
first-order theory of mind and test our approach on the CraigslistBargain
dataset. Experiments show that our method using ToM inference achieves a 40\%
higher dialogue agreement rate compared to baselines on a mixed population of
opponents. We also show that our model displays diverse negotiation behavior
with different types of opponents.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 01:46:03 GMT'}]",2020-10-21,"[['Yang', 'Runzhe', ''], ['Chen', 'Jingxiao', ''], ['Narasimhan', 'Karthik', '']]"
1366368,2010.10038,Sameer Dharur,"Sameer Dharur, Purva Tendulkar, Dhruv Batra, Devi Parikh, Ramprasaath
  R. Selvaraju","SOrT-ing VQA Models : Contrastive Gradient Learning for Improved
  Consistency",,,,,cs.CV cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent research in Visual Question Answering (VQA) has revealed
state-of-the-art models to be inconsistent in their understanding of the world
-- they answer seemingly difficult questions requiring reasoning correctly but
get simpler associated sub-questions wrong. These sub-questions pertain to
lower level visual concepts in the image that models ideally should understand
to be able to answer the higher level question correctly. To address this, we
first present a gradient-based interpretability approach to determine the
questions most strongly correlated with the reasoning question on an image, and
use this to evaluate VQA models on their ability to identify the relevant
sub-questions needed to answer a reasoning question. Next, we propose a
contrastive gradient learning based approach called Sub-question Oriented
Tuning (SOrT) which encourages models to rank relevant sub-questions higher
than irrelevant questions for an <$image, reasoning-question$> pair. We show
that SOrT improves model consistency by upto 6.5% points over existing
baselines, while also improving visual grounding.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 05:15:48 GMT'}]",2020-10-21,"[['Dharur', 'Sameer', ''], ['Tendulkar', 'Purva', ''], ['Batra', 'Dhruv', ''], ['Parikh', 'Devi', ''], ['Selvaraju', 'Ramprasaath R.', '']]"
1366831,2010.10501,William Gantt,"William Gantt, Benjamin Kane, Aaron Steven White",Natural Language Inference with Mixed Effects,,"The Ninth Joint Conference on Lexical and Computational Semantics
  (*SEM2020)",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  There is growing evidence that the prevalence of disagreement in the raw
annotations used to construct natural language inference datasets makes the
common practice of aggregating those annotations to a single label problematic.
We propose a generic method that allows one to skip the aggregation step and
train on the raw annotations directly without subjecting the model to unwanted
noise that can arise from annotator response biases. We demonstrate that this
method, which generalizes the notion of a \textit{mixed effects model} by
incorporating \textit{annotator random effects} into any existing neural model,
improves performance over models that do not incorporate such effects.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 17:54:16 GMT'}]",2020-10-21,"[['Gantt', 'William', ''], ['Kane', 'Benjamin', ''], ['White', 'Aaron Steven', '']]"
1278888,2004.14118,Mario Giulianelli,"Mario Giulianelli, Marco Del Tredici, Raquel Fern\'andez","Analysing Lexical Semantic Change with Contextualised Word
  Representations","To appear in Proceedings of the 58th Annual Meeting of the
  Association for Computational Linguistics (ACL-2020)",,10.18653/v1/2020.acl-main.365,,cs.CL cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents the first unsupervised approach to lexical semantic
change that makes use of contextualised word representations. We propose a
novel method that exploits the BERT neural language model to obtain
representations of word usages, clusters these representations into usage
types, and measures change along time with three proposed metrics. We create a
new evaluation dataset and show that the model representations and the detected
semantic shifts are positively correlated with human judgements. Our extensive
qualitative analysis demonstrates that our method captures a variety of
synchronic and diachronic linguistic phenomena. We expect our work to inspire
further research in this direction.
","[{'version': 'v1', 'created': 'Wed, 29 Apr 2020 12:18:14 GMT'}]",2020-10-21,"[['Giulianelli', 'Mario', ''], ['Del Tredici', 'Marco', ''], ['Fernández', 'Raquel', '']]"
1336576,2008.08854,Liesbeth Allein,Liesbeth Allein and Marie-Francine Moens,"Checkworthiness in Automatic Claim Detection Models: Definitions and
  Analysis of Datasets",,,10.1007/978-3-030-61841-4_1,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Public, professional and academic interest in automated fact-checking has
drastically increased over the past decade, with many aiming to automate one of
the first steps in a fact-check procedure: the selection of so-called
checkworthy claims. However, there is little agreement on the definition and
characteristics of checkworthiness among fact-checkers, which is consequently
reflected in the datasets used for training and testing checkworthy claim
detection models. After elaborate analysis of checkworthy claim selection
procedures in fact-check organisations and analysis of state-of-the-art claim
detection datasets, checkworthiness is defined as the concept of having a
spatiotemporal and context-dependent worth and need to have the correctness of
the objectivity it conveys verified. This is irrespective of the claim's
perceived veracity judgement by an individual based on prior knowledge and
beliefs. Concerning the characteristics of current datasets, it is argued that
the data is not only highly imbalanced and noisy, but also too limited in scope
and language. Furthermore, we believe that the subjective concept of
checkworthiness might not be a suitable filter for claim detection.
","[{'version': 'v1', 'created': 'Thu, 20 Aug 2020 09:30:05 GMT'}]",2020-10-21,"[['Allein', 'Liesbeth', ''], ['Moens', 'Marie-Francine', '']]"
1268840,2004.04070,Ivan Vuli\'c,"Ivan Vuli\'c, Sebastian Ruder, and Anders S{\o}gaard",Are All Good Word Vector Spaces Isomorphic?,EMNLP 2020: Long paper. Equal contribution from all three authors,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Existing algorithms for aligning cross-lingual word vector spaces assume that
vector spaces are approximately isomorphic. As a result, they perform poorly or
fail completely on non-isomorphic spaces. Such non-isomorphism has been
hypothesised to result from typological differences between languages. In this
work, we ask whether non-isomorphism is also crucially a sign of degenerate
word vector spaces. We present a series of experiments across diverse languages
which show that variance in performance across language pairs is not only due
to typological differences, but can mostly be attributed to the size of the
monolingual resources available, and to the properties and duration of
monolingual training (e.g. ""under-training"").
","[{'version': 'v1', 'created': 'Wed, 8 Apr 2020 15:49:19 GMT'}, {'version': 'v2', 'created': 'Tue, 20 Oct 2020 17:22:02 GMT'}]",2020-10-21,"[['Vulić', 'Ivan', ''], ['Ruder', 'Sebastian', ''], ['Søgaard', 'Anders', '']]"
1270833,2004.06063,Markus Freitag,"Markus Freitag, David Grangier, Isaac Caswell",BLEU might be Guilty but References are not Innocent,Accepted at EMNLP 2020,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The quality of automatic metrics for machine translation has been
increasingly called into question, especially for high-quality systems. This
paper demonstrates that, while choice of metric is important, the nature of the
references is also critical. We study different methods to collect references
and compare their value in automated evaluation by reporting correlation with
human evaluation for a variety of systems and metrics. Motivated by the finding
that typical references exhibit poor diversity, concentrating around
translationese language, we develop a paraphrasing task for linguists to
perform on existing reference translations, which counteracts this bias. Our
method yields higher correlation with human judgment not only for the
submissions of WMT 2019 English to German, but also for Back-translation and
APE augmented MT output, which have been shown to have low correlation with
automatic metrics using standard references. We demonstrate that our
methodology improves correlation with all modern evaluation metrics we look at,
including embedding-based methods. To complete this picture, we reveal that
multi-reference BLEU does not improve the correlation for high quality output,
and present an alternative multi-reference formulation that is more effective.
","[{'version': 'v1', 'created': 'Mon, 13 Apr 2020 16:49:09 GMT'}, {'version': 'v2', 'created': 'Tue, 20 Oct 2020 13:02:12 GMT'}]",2020-10-21,"[['Freitag', 'Markus', ''], ['Grangier', 'David', ''], ['Caswell', 'Isaac', '']]"
1035942,1810.04755,Maria Leonor Pacheco,"Samuel Jero, Maria Leonor Pacheco, Dan Goldwasser and Cristina
  Nita-Rotaru","Leveraging Textual Specifications for Grammar-based Fuzzing of Network
  Protocols",,,10.1609/aaai.v33i01.33019478,,cs.CR cs.CL cs.NI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Grammar-based fuzzing is a technique used to find software vulnerabilities by
injecting well-formed inputs generated following rules that encode application
semantics. Most grammar-based fuzzers for network protocols rely on human
experts to manually specify these rules. In this work we study automated
learning of protocol rules from textual specifications (i.e. RFCs). We evaluate
the automatically extracted protocol rules by applying them to a
state-of-the-art fuzzer for transport protocols and show that it leads to a
smaller number of test cases while finding the same attacks as the system that
uses manually specified rules.
","[{'version': 'v1', 'created': 'Wed, 10 Oct 2018 21:42:29 GMT'}]",2020-10-21,"[['Jero', 'Samuel', ''], ['Pacheco', 'Maria Leonor', ''], ['Goldwasser', 'Dan', ''], ['Nita-Rotaru', 'Cristina', '']]"
1329099,2008.01377,Stefan Heid,"Stefan Heid, Marcel Wever, Eyke H\""ullermeier","Reliable Part-of-Speech Tagging of Historical Corpora through Set-Valued
  Prediction","14 pages, 8 figures",,,,cs.CL cs.IR cs.LG stat.ML,http://creativecommons.org/licenses/by/4.0/,"  Syntactic annotation of corpora in the form of part-of-speech (POS) tags is a
key requirement for both linguistic research and subsequent automated natural
language processing (NLP) tasks. This problem is commonly tackled using machine
learning methods, i.e., by training a POS tagger on a sufficiently large corpus
of labeled data. While the problem of POS tagging can essentially be considered
as solved for modern languages, historical corpora turn out to be much more
difficult, especially due to the lack of native speakers and sparsity of
training data. Moreover, most texts have no sentences as we know them today,
nor a common orthography. These irregularities render the task of automated POS
tagging more difficult and error-prone. Under these circumstances, instead of
forcing the POS tagger to predict and commit to a single tag, it should be
enabled to express its uncertainty. In this paper, we consider POS tagging
within the framework of set-valued prediction, which allows the POS tagger to
express its uncertainty via predicting a set of candidate POS tags instead of
guessing a single one. The goal is to guarantee a high confidence that the
correct POS tag is included while keeping the number of candidates small. In
our experimental study, we find that extending state-of-the-art POS taggers to
set-valued prediction yields more precise and robust taggings, especially for
unknown words, i.e., words not occurring in the training data.
","[{'version': 'v1', 'created': 'Tue, 4 Aug 2020 07:21:36 GMT'}, {'version': 'v2', 'created': 'Tue, 20 Oct 2020 12:59:57 GMT'}]",2020-10-21,"[['Heid', 'Stefan', ''], ['Wever', 'Marcel', ''], ['Hüllermeier', 'Eyke', '']]"
1232676,2001.07263,"Zolt\'an T\""uske","Zolt\'an T\""uske, George Saon, Kartik Audhkhasi, Brian Kingsbury","Single headed attention based sequence-to-sequence model for
  state-of-the-art results on Switchboard","5 pages, 2 figures",,,,eess.AS cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  It is generally believed that direct sequence-to-sequence (seq2seq) speech
recognition models are competitive with hybrid models only when a large amount
of data, at least a thousand hours, is available for training. In this paper,
we show that state-of-the-art recognition performance can be achieved on the
Switchboard-300 database using a single headed attention, LSTM based model.
Using a cross-utterance language model, our single-pass speaker independent
system reaches 6.4% and 12.5% word error rate (WER) on the Switchboard and
CallHome subsets of Hub5'00, without a pronunciation lexicon. While careful
regularization and data augmentation are crucial in achieving this level of
performance, experiments on Switchboard-2000 show that nothing is more useful
than more data. Overall, the combination of various regularizations and a
simple but fairly large model results in a new state of the art, 4.7% and 7.8%
WER on the Switchboard and CallHome sets, using SWB-2000 without any external
data resources.
","[{'version': 'v1', 'created': 'Mon, 20 Jan 2020 22:03:42 GMT'}, {'version': 'v2', 'created': 'Mon, 19 Oct 2020 01:57:28 GMT'}, {'version': 'v3', 'created': 'Tue, 20 Oct 2020 03:33:19 GMT'}]",2020-10-21,"[['Tüske', 'Zoltán', ''], ['Saon', 'George', ''], ['Audhkhasi', 'Kartik', ''], ['Kingsbury', 'Brian', '']]"
1302901,2006.08387,William Havard,"William N. Havard, Jean-Pierre Chevrot, Laurent Besacier","Catplayinginthesnow: Impact of Prior Segmentation on a Model of Visually
  Grounded Speech",Accepted at CoNLL20,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  The language acquisition literature shows that children do not build their
lexicon by segmenting the spoken input into phonemes and then building up words
from them, but rather adopt a top-down approach and start by segmenting
word-like units and then break them down into smaller units. This suggests that
the ideal way of learning a language is by starting from full semantic units.
In this paper, we investigate if this is also the case for a neural model of
Visually Grounded Speech trained on a speech-image retrieval task. We evaluated
how well such a network is able to learn a reliable speech-to-image mapping
when provided with phone, syllable, or word boundary information. We present a
simple way to introduce such information into an RNN-based model and
investigate which type of boundary is the most efficient. We also explore at
which level of the network's architecture such information should be introduced
so as to maximise its performances. Finally, we show that using multiple
boundary types at once in a hierarchical structure, by which low-level segments
are used to recompose high-level segments, is beneficial and yields better
results than using low-level or high-level segments in isolation.
","[{'version': 'v1', 'created': 'Mon, 15 Jun 2020 13:20:13 GMT'}, {'version': 'v2', 'created': 'Tue, 20 Oct 2020 13:15:59 GMT'}]",2020-10-21,"[['Havard', 'William N.', ''], ['Chevrot', 'Jean-Pierre', ''], ['Besacier', 'Laurent', '']]"
1367147,2010.10817,Chengzhi Zhang,"Yuzhuo Wang, Chengzhi Zhang","Using the Full-text Content of Academic Articles to Identify and
  Evaluate Algorithm Entities in the Domain of Natural Language Processing",,"Journal of Informetrics,2020",10.1016/j.joi.2020.101091,,cs.CL cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In the era of big data, the advancement, improvement, and application of
algorithms in academic research have played an important role in promoting the
development of different disciplines. Academic papers in various disciplines,
especially computer science, contain a large number of algorithms. Identifying
the algorithms from the full-text content of papers can determine popular or
classical algorithms in a specific field and help scholars gain a comprehensive
understanding of the algorithms and even the field. To this end, this article
takes the field of natural language processing (NLP) as an example and
identifies algorithms from academic papers in the field. A dictionary of
algorithms is constructed by manually annotating the contents of papers, and
sentences containing algorithms in the dictionary are extracted through
dictionary-based matching. The number of articles mentioning an algorithm is
used as an indicator to analyze the influence of that algorithm. Our results
reveal the algorithm with the highest influence in NLP papers and show that
classification algorithms represent the largest proportion among the
high-impact algorithms. In addition, the evolution of the influence of
algorithms reflects the changes in research tasks and topics in the field, and
the changes in the influence of different algorithms show different trends. As
a preliminary exploration, this paper conducts an analysis of the impact of
algorithms mentioned in the academic text, and the results can be used as
training data for the automatic extraction of large-scale algorithms in the
future. The methodology in this paper is domain-independent and can be applied
to other domains.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 08:24:18 GMT'}]",2020-10-22,"[['Wang', 'Yuzhuo', ''], ['Zhang', 'Chengzhi', '']]"
1367150,2010.10820,Chan Young Park,"Chan Young Park, Xinru Yan, Anjalie Field, Yulia Tsvetkov","Multilingual Contextual Affective Analysis of LGBT People Portrayals in
  Wikipedia",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Specific lexical choices in how people are portrayed both reflect the
writer's attitudes towards people in the narrative and influence the audience's
reactions. Prior work has examined descriptions of people in English using
contextual affective analysis, a natural language processing (NLP) technique
that seeks to analyze how people are portrayed along dimensions of power,
agency, and sentiment. Our work presents an extension of this methodology to
multilingual settings, which is enabled by a new corpus that we collect and a
new multilingual model. We additionally show how word connotations differ
across languages and cultures, which makes existing English datasets and
methods difficult to generalize. We then demonstrate the usefulness of our
method by analyzing Wikipedia biography pages of members of the LGBT community
across three languages: English, Russian, and Spanish. Our results show
systematic differences in how the LGBT community is portrayed across languages,
surfacing cultural differences in narratives and signs of social biases.
Practically, this model can be used to surface Wikipedia articles for further
manual analysis---articles that might contain content gaps or an imbalanced
representation of particular social groups.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 08:27:36 GMT'}]",2020-10-22,"[['Park', 'Chan Young', ''], ['Yan', 'Xinru', ''], ['Field', 'Anjalie', ''], ['Tsvetkov', 'Yulia', '']]"
1367204,2010.10874,Erik Ekstedt,Erik Ekstedt and Gabriel Skantze,"TurnGPT: a Transformer-based Language Model for Predicting Turn-taking
  in Spoken Dialog",Accepted to Findings of ACL: EMNLP 2020,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Syntactic and pragmatic completeness is known to be important for turn-taking
prediction, but so far machine learning models of turn-taking have used such
linguistic information in a limited way. In this paper, we introduce TurnGPT, a
transformer-based language model for predicting turn-shifts in spoken dialog.
The model has been trained and evaluated on a variety of written and spoken
dialog datasets. We show that the model outperforms two baselines used in prior
work. We also report on an ablation study, as well as attention and gradient
analyses, which show that the model is able to utilize the dialog context and
pragmatic completeness for turn-taking prediction. Finally, we explore the
model's potential in not only detecting, but also projecting, turn-completions.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 09:58:39 GMT'}]",2020-10-22,"[['Ekstedt', 'Erik', ''], ['Skantze', 'Gabriel', '']]"
1367163,2010.10833,Xinyu Zuo,"Xinyu Zuo, Yubo Chen, Kang Liu, Jun Zhao","KnowDis: Knowledge Enhanced Data Augmentation for Event Causality
  Detection via Distant Supervision",Accepted to COLING2020,COLING2020,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Modern models of event causality detection (ECD) are mainly based on
supervised learning from small hand-labeled corpora. However, hand-labeled
training data is expensive to produce, low coverage of causal expressions and
limited in size, which makes supervised methods hard to detect causal relations
between events. To solve this data lacking problem, we investigate a data
augmentation framework for ECD, dubbed as Knowledge Enhanced Distant Data
Augmentation (KnowDis). Experimental results on two benchmark datasets
EventStoryLine corpus and Causal-TimeBank show that 1) KnowDis can augment
available training data assisted with the lexical and causal commonsense
knowledge for ECD via distant supervision, and 2) our method outperforms
previous methods by a large margin assisted with automatically labeled training
data.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 08:44:54 GMT'}]",2020-10-22,"[['Zuo', 'Xinyu', ''], ['Chen', 'Yubo', ''], ['Liu', 'Kang', ''], ['Zhao', 'Jun', '']]"
1367141,2010.10811,Puhai Yang,"Puhai Yang, Heyan Huang, Xianling Mao","STN4DST: A Scalable Dialogue State Tracking based on Slot Tagging
  Navigation",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Scalability for handling unknown slot values is a important problem in
dialogue state tracking (DST). As far as we know, previous scalable DST
approaches generally rely on either the candidate generation from slot tagging
output or the span extraction in dialogue context. However, the candidate
generation based DST often suffers from error propagation due to its pipelined
two-stage process; meanwhile span extraction based DST has the risk of
generating invalid spans in the lack of semantic constraints between start and
end position pointers. To tackle the above drawbacks, in this paper, we propose
a novel scalable dialogue state tracking method based on slot tagging
navigation, which implements an end-to-end single-step pointer to locate and
extract slot value quickly and accurately by the joint learning of slot tagging
and slot value position prediction in the dialogue context, especially for
unknown slot values. Extensive experiments over several benchmark datasets show
that the proposed model performs better than state-of-the-art baselines
greatly.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 08:09:20 GMT'}]",2020-10-22,"[['Yang', 'Puhai', ''], ['Huang', 'Heyan', ''], ['Mao', 'Xianling', '']]"
1367119,2010.10789,Weizhen Qi,"Weizhen Qi, Yeyun Gong, Yu Yan, Jian Jiao, Bo Shao, Ruofei Zhang,
  Houqiang Li, Nan Duan, Ming Zhou","ProphetNet-Ads: A Looking Ahead Strategy for Generative Retrieval Models
  in Sponsored Search Engine",Accepted to NLPCC 2020,,,,cs.IR cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In a sponsored search engine, generative retrieval models are recently
proposed to mine relevant advertisement keywords for users' input queries.
Generative retrieval models generate outputs token by token on a path of the
target library prefix tree (Trie), which guarantees all of the generated
outputs are legal and covered by the target library. In actual use, we found
several typical problems caused by Trie-constrained searching length. In this
paper, we analyze these problems and propose a looking ahead strategy for
generative retrieval models named ProphetNet-Ads. ProphetNet-Ads improves the
retrieval ability by directly optimizing the Trie-constrained searching space.
We build a dataset from a real-word sponsored search engine and carry out
experiments to analyze different generative retrieval models. Compared with
Trie-based LSTM generative retrieval model proposed recently, our single model
result and integrated result improve the recall by 15.58\% and 18.8\%
respectively with beam size 5. Case studies further demonstrate how these
problems are alleviated by ProphetNet-Ads clearly.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 07:03:20 GMT'}]",2020-10-22,"[['Qi', 'Weizhen', ''], ['Gong', 'Yeyun', ''], ['Yan', 'Yu', ''], ['Jiao', 'Jian', ''], ['Shao', 'Bo', ''], ['Zhang', 'Ruofei', ''], ['Li', 'Houqiang', ''], ['Duan', 'Nan', ''], ['Zhou', 'Ming', '']]"
1367166,2010.10836,Deepak P,"Soumya Suvra Ghosal, Deepak P, Anna Jurek-Loughrey",ReSCo-CC: Unsupervised Identification of Key Disinformation Sentences,"The 22nd International Conference on Information Integration and
  Web-based Applications & Services (iiWAS '20), Chiang Mai, Thailand",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Disinformation is often presented in long textual articles, especially when
it relates to domains such as health, often seen in relation to COVID-19. These
articles are typically observed to have a number of trustworthy sentences among
which core disinformation sentences are scattered. In this paper, we propose a
novel unsupervised task of identifying sentences containing key disinformation
within a document that is known to be untrustworthy. We design a three-phase
statistical NLP solution for the task which starts with embedding sentences
within a bespoke feature space designed for the task. Sentences represented
using those features are then clustered, following which the key sentences are
identified through proximity scoring. We also curate a new dataset with
sentence level disinformation scorings to aid evaluation for this task; the
dataset is being made publicly available to facilitate further research. Based
on a comprehensive empirical evaluation against techniques from related tasks
such as claim detection and summarization, as well as against simplified
variants of our proposed approach, we illustrate that our method is able to
identify core disinformation effectively.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 08:53:36 GMT'}]",2020-10-22,"[['Ghosal', 'Soumya Suvra', ''], ['P', 'Deepak', ''], ['Jurek-Loughrey', 'Anna', '']]"
1367087,2010.10757,Srinivasan Iyer,"Srinivasan Iyer, Sewon Min, Yashar Mehdad, Wen-tau Yih","RECONSIDER: Re-Ranking using Span-Focused Cross-Attention for Open
  Domain Question Answering",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  State-of-the-art Machine Reading Comprehension (MRC) models for Open-domain
Question Answering (QA) are typically trained for span selection using
distantly supervised positive examples and heuristically retrieved negative
examples. This training scheme possibly explains empirical observations that
these models achieve a high recall amongst their top few predictions, but a low
overall accuracy, motivating the need for answer re-ranking. We develop a
simple and effective re-ranking approach (RECONSIDER) for span-extraction
tasks, that improves upon the performance of large pre-trained MRC models.
RECONSIDER is trained on positive and negative examples extracted from high
confidence predictions of MRC models, and uses in-passage span annotations to
perform span-focused re-ranking over a smaller candidate set. As a result,
RECONSIDER learns to eliminate close false positive passages, and achieves a
new state of the art on four QA tasks, including 45.5% Exact Match accuracy on
Natural Questions with real user questions, and 61.7% on TriviaQA.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 04:28:42 GMT'}]",2020-10-22,"[['Iyer', 'Srinivasan', ''], ['Min', 'Sewon', ''], ['Mehdad', 'Yashar', ''], ['Yih', 'Wen-tau', '']]"
1367169,2010.10839,Wubo Li,"Wubo Li, Dongwei Jiang, Wei Zou, Xiangang Li","TMT: A Transformer-based Modal Translator for Improving Multimodal
  Sequence Representations in Audio Visual Scene-aware Dialog",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Audio Visual Scene-aware Dialog (AVSD) is a task to generate responses when
discussing about a given video. The previous state-of-the-art model shows
superior performance for this task using Transformer-based architecture.
However, there remain some limitations in learning better representation of
modalities. Inspired by Neural Machine Translation (NMT), we propose the
Transformer-based Modal Translator (TMT) to learn the representations of the
source modal sequence by translating the source modal sequence to the related
target modal sequence in a supervised manner. Based on Multimodal Transformer
Networks (MTN), we apply TMT to video and dialog, proposing MTN-TMT for the
video-grounded dialog system. On the AVSD track of the Dialog System Technology
Challenge 7, MTN-TMT outperforms the MTN and other submission models in both
Video and Text task and Text Only task. Compared with MTN, MTN-TMT improves all
metrics, especially, achieving relative improvement up to 14.1% on CIDEr. Index
Terms: multimodal learning, audio-visual scene-aware dialog, neural machine
translation, multi-task learning
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 09:02:30 GMT'}]",2020-10-22,"[['Li', 'Wubo', ''], ['Jiang', 'Dongwei', ''], ['Zou', 'Wei', ''], ['Li', 'Xiangang', '']]"
1367203,2010.10873,Milad Moradi,"Milad Moradi, Matthias Samwald","Explaining black-box text classifiers for disease-treatment information
  extraction",,,,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Deep neural networks and other intricate Artificial Intelligence (AI) models
have reached high levels of accuracy on many biomedical natural language
processing tasks. However, their applicability in real-world use cases may be
limited due to their vague inner working and decision logic. A post-hoc
explanation method can approximate the behavior of a black-box AI model by
extracting relationships between feature values and outcomes. In this paper, we
introduce a post-hoc explanation method that utilizes confident itemsets to
approximate the behavior of black-box classifiers for medical information
extraction. Incorporating medical concepts and semantics into the explanation
process, our explanator finds semantic relations between inputs and outputs in
different parts of the decision space of a black-box classifier. The
experimental results show that our explanation method can outperform
perturbation and decision set based explanators in terms of fidelity and
interpretability of explanations produced for predictions on a
disease-treatment information extraction task.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 09:58:00 GMT'}]",2020-10-22,"[['Moradi', 'Milad', ''], ['Samwald', 'Matthias', '']]"
1367143,2010.10813,Jinman Zhao,"Zhao Jinman, Shawn Zhong, Xiaomin Zhang, Yingyu Liang",PBoS: Probabilistic Bag-of-Subwords for Generalizing Word Embedding,"16 pages including 4 pages of appendix. Accepted to Findings of EMNLP
  2020 and SustaiNLP 2020. Code can be found at
  [https://github.com/jmzhao/pbos]",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We look into the task of \emph{generalizing} word embeddings: given a set of
pre-trained word vectors over a finite vocabulary, the goal is to predict
embedding vectors for out-of-vocabulary words, \emph{without} extra contextual
information. We rely solely on the spellings of words and propose a model,
along with an efficient algorithm, that simultaneously models subword
segmentation and computes subword-based compositional word embedding. We call
the model probabilistic bag-of-subwords (PBoS), as it applies bag-of-subwords
for all possible segmentations based on their likelihood. Inspections and affix
prediction experiment show that PBoS is able to produce meaningful subword
segmentations and subword rankings without any source of explicit morphological
knowledge. Word similarity and POS tagging experiments show clear advantages of
PBoS over previous subword-level models in the quality of generated word
embeddings across languages.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 08:11:08 GMT'}]",2020-10-22,"[['Jinman', 'Zhao', ''], ['Zhong', 'Shawn', ''], ['Zhang', 'Xiaomin', ''], ['Liang', 'Yingyu', '']]"
1367131,2010.10801,Arthur Jacobs M,Arthur M. Jacobs and Annette Kinder,"Quasi Error-free Text Classification and Authorship Recognition in a
  large Corpus of English Literature based on a Novel Feature Set","18 pages, 3 tables",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The Gutenberg Literary English Corpus (GLEC) provides a rich source of
textual data for research in digital humanities, computational linguistics or
neurocognitive poetics. However, so far only a small subcorpus, the Gutenberg
English Poetry Corpus, has been submitted to quantitative text analyses
providing predictions for scientific studies of literature. Here we show that
in the entire GLEC quasi error-free text classification and authorship
recognition is possible with a method using the same set of five style and five
content features, computed via style and sentiment analysis, in both tasks. Our
results identify two standard and two novel features (i.e., type-token ratio,
frequency, sonority score, surprise) as most diagnostic in these tasks. By
providing a simple tool applicable to both short poems and long novels
generating quantitative predictions about features that co-determe the
cognitive and affective processing of specific text categories or authors, our
data pave the way for many future computational and empirical studies of
literature or experiments in reading psychology.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 07:39:55 GMT'}]",2020-10-22,"[['Jacobs', 'Arthur M.', ''], ['Kinder', 'Annette', '']]"
1367237,2010.10907,Elena Voita,"Elena Voita, Rico Sennrich, Ivan Titov","Analyzing the Source and Target Contributions to Predictions in Neural
  Machine Translation",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In Neural Machine Translation (and, more generally, conditional language
modeling), the generation of a target token is influenced by two types of
context: the source and the prefix of the target sequence. While many attempts
to understand the internal workings of NMT models have been made, none of them
explicitly evaluates relative source and target contributions to a generation
decision. We argue that this relative contribution can be evaluated by adopting
a variant of Layerwise Relevance Propagation (LRP). Its underlying
'conservation principle' makes relevance propagation unique: differently from
other methods, it evaluates not an abstract quantity reflecting token
importance, but the proportion of each token's influence. We extend LRP to the
Transformer and conduct an analysis of NMT models which explicitly evaluates
the source and target relative contributions to the generation process. We
analyze changes in these contributions when conditioning on different types of
prefixes, when varying the training objective or the amount of training data,
and during the training process. We find that models trained with more data
tend to rely on source information more and to have more sharp token
contributions; the training process is non-monotonic with several stages of
different nature.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 11:37:27 GMT'}]",2020-10-22,"[['Voita', 'Elena', ''], ['Sennrich', 'Rico', ''], ['Titov', 'Ivan', '']]"
1367230,2010.10900,Tommaso Soru,Anand Panchbhai and Tommaso Soru and Edgard Marx,Exploring Sequence-to-Sequence Models for SPARQL Pattern Composition,"Proceedings of the First Indo-American Knowledge Graph and Semantic
  Web Conference (KGSWC-India 2020)",,,,cs.CL cs.AI cs.DB,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A booming amount of information is continuously added to the Internet as
structured and unstructured data, feeding knowledge bases such as DBpedia and
Wikidata with billions of statements describing millions of entities. The aim
of Question Answering systems is to allow lay users to access such data using
natural language without needing to write formal queries. However, users often
submit questions that are complex and require a certain level of abstraction
and reasoning to decompose them into basic graph patterns. In this short paper,
we explore the use of architectures based on Neural Machine Translation called
Neural SPARQL Machines to learn pattern compositions. We show that
sequence-to-sequence models are a viable and promising option to transform long
utterances into complex SPARQL queries.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 11:12:01 GMT'}]",2020-10-22,"[['Panchbhai', 'Anand', ''], ['Soru', 'Tommaso', ''], ['Marx', 'Edgard', '']]"
1367085,2010.10755,Bill Yuchen Lin,"Bill Yuchen Lin, Ying Sheng, Nguyen Vo, Sandeep Tata","FreeDOM: A Transferable Neural Architecture for Structured Information
  Extraction on Web Documents",in Proc. of KDD 2020 (Research Track). Figure 5 updated,,10.1145/3394486.3403153,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Extracting structured data from HTML documents is a long-studied problem with
a broad range of applications like augmenting knowledge bases, supporting
faceted search, and providing domain-specific experiences for key verticals
like shopping and movies. Previous approaches have either required a small
number of examples for each target site or relied on carefully handcrafted
heuristics built over visual renderings of websites. In this paper, we present
a novel two-stage neural approach, named FreeDOM, which overcomes both these
limitations. The first stage learns a representation for each DOM node in the
page by combining both the text and markup information. The second stage
captures longer range distance and semantic relatedness using a relational
neural network. By combining these stages, FreeDOM is able to generalize to
unseen sites after training on a small number of seed sites from that vertical
without requiring expensive hand-crafted features over visual renderings of the
page. Through experiments on a public dataset with 8 different verticals, we
show that FreeDOM beats the previous state of the art by nearly 3.7 F1 points
on average without requiring features over rendered pages or expensive
hand-crafted features.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 04:20:13 GMT'}]",2020-10-22,"[['Lin', 'Bill Yuchen', ''], ['Sheng', 'Ying', ''], ['Vo', 'Nguyen', ''], ['Tata', 'Sandeep', '']]"
1367240,2010.10910,Mali Jin,Mali Jin and Nikolaos Aletras,Complaint Identification in Social Media with Transformer Networks,Accepted at COLING 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Complaining is a speech act extensively used by humans to communicate a
negative inconsistency between reality and expectations. Previous work on
automatically identifying complaints in social media has focused on using
feature-based and task-specific neural network models. Adapting
state-of-the-art pre-trained neural language models and their combinations with
other linguistic information from topics or sentiment for complaint prediction
has yet to be explored. In this paper, we evaluate a battery of neural models
underpinned by transformer networks which we subsequently combine with
linguistic information. Experiments on a publicly available data set of
complaints demonstrate that our models outperform previous state-of-the-art
methods by a large margin achieving a macro F1 up to 87.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 11:44:04 GMT'}]",2020-10-22,"[['Jin', 'Mali', ''], ['Aletras', 'Nikolaos', '']]"
1367251,2010.10921,Aibek Makazhanov,"Aibek Makazhanov, Sharon Goldwater, Adam Lopez","LemMED: Fast and Effective Neural Morphological Analysis with Short
  Context Windows",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present LemMED, a character-level encoder-decoder for contextual
morphological analysis (combined lemmatization and tagging). LemMED extends and
is named after two other attention-based models, namely Lematus, a contextual
lemmatizer, and MED, a morphological (re)inflection model. Our approach does
not require training separate lemmatization and tagging models, nor does it
need additional resources and tools, such as morphological dictionaries or
transducers. Moreover, LemMED relies solely on character-level representations
and on local context. Although the model can, in principle, account for global
context on sentence level, our experiments show that using just a single word
of context around each target word is not only more computationally feasible,
but yields better results as well. We evaluate LemMED in the framework of the
SIMGMORPHON-2019 shared task on combined lemmatization and tagging. In terms of
average performance LemMED ranks 5th among 13 systems and is bested only by the
submissions that use contextualized embeddings.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 12:08:02 GMT'}]",2020-10-22,"[['Makazhanov', 'Aibek', ''], ['Goldwater', 'Sharon', ''], ['Lopez', 'Adam', '']]"
1367262,2010.10932,Sungchul Choi,"Jaewoong Choi, Sion Jang, Jaeyoung Kim, Jiho Lee, Janghyeok Yoona,
  Sungchul Choi",Deep learning-based citation recommendation system for patents,,,,,cs.IR cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In this study, we address the challenges in developing a deep learning-based
automatic patent citation recommendation system. Although deep learning-based
recommendation systems have exhibited outstanding performance in various
domains (such as movies, products, and paper citations), their validity in
patent citations has not been investigated, owing to the lack of a freely
available high-quality dataset and relevant benchmark model. To solve these
problems, we present a novel dataset called PatentNet that includes textual
information and metadata for approximately 110,000 patents from the Google Big
Query service. Further, we propose strong benchmark models considering the
similarity of textual information and metadata (such as cooperative patent
classification code). Compared with existing recommendation methods, the
proposed benchmark method achieved a mean reciprocal rank of 0.2377 on the test
set, whereas the existing state-of-the-art recommendation method achieved
0.2073.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 12:18:21 GMT'}]",2020-10-22,"[['Choi', 'Jaewoong', ''], ['Jang', 'Sion', ''], ['Kim', 'Jaeyoung', ''], ['Lee', 'Jiho', ''], ['Yoona', 'Janghyeok', ''], ['Choi', 'Sungchul', '']]"
1367268,2010.10938,Chi-Liang Liu,Chi-Liang Liu and Tsung-Yuan Hsu and Yung-Sung Chuang and Hung-yi Lee,What makes multilingual BERT multilingual?,arXiv admin note: substantial text overlap with arXiv:2004.09205,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, multilingual BERT works remarkably well on cross-lingual transfer
tasks, superior to static non-contextualized word embeddings. In this work, we
provide an in-depth experimental study to supplement the existing literature of
cross-lingual ability. We compare the cross-lingual ability of
non-contextualized and contextualized representation model with the same data.
We found that datasize and context window size are crucial factors to the
transferability.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 05:41:56 GMT'}]",2020-10-22,"[['Liu', 'Chi-Liang', ''], ['Hsu', 'Tsung-Yuan', ''], ['Chuang', 'Yung-Sung', ''], ['Lee', 'Hung-yi', '']]"
1367329,2010.10999,Sohee Yang,"Sohee Yang, Minjoon Seo",Is Retriever Merely an Approximator of Reader?,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The state of the art in open-domain question answering (QA) relies on an
efficient retriever that drastically reduces the search space for the expensive
reader. A rather overlooked question in the community is the relationship
between the retriever and the reader, and in particular, if the whole purpose
of the retriever is just a fast approximation for the reader. Our empirical
evidence indicates that the answer is no, and that the reader and the retriever
are complementary to each other even in terms of accuracy only. We make a
careful conjecture that the architectural constraint of the retriever, which
has been originally intended for enabling approximate search, seems to also
make the model more robust in large-scale search. We then propose to distill
the reader into the retriever so that the retriever absorbs the strength of the
reader while keeping its own benefit. Experimental results show that our method
can enhance the document recall rate as well as the end-to-end QA accuracy of
off-the-shelf retrievers in open-domain QA tasks.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 13:40:15 GMT'}]",2020-10-22,"[['Yang', 'Sohee', ''], ['Seo', 'Minjoon', '']]"
1367333,2010.11003,Chi-Liang Liu,Chi-Liang Liu and Hung-yi Lee,"Unsupervised Deep Learning based Multiple Choices Question Answering:
  Start Learning from Basic Knowledge",preprint,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we study the possibility of almost unsupervised Multiple
Choices Question Answering (MCQA). Starting from very basic knowledge, MCQA
model knows that some choices have higher probabilities of being correct than
the others. The information, though very noisy, guides the training of an MCQA
model. The proposed method is shown to outperform the baseline approaches on
RACE and even comparable with some supervised learning approaches on MC500.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 13:44:35 GMT'}]",2020-10-22,"[['Liu', 'Chi-Liang', ''], ['Lee', 'Hung-yi', '']]"
1367334,2010.11004,Mounica Maddela,"Mounica Maddela, Fernando Alva-Manchego, Wei Xu",Controllable Text Simplification with Explicit Paraphrasing,,,,,cs.CL,http://creativecommons.org/publicdomain/zero/1.0/,"  Text Simplification improves the readability of sentences through several
rewriting transformations, such as lexical paraphrasing, deletion, and
splitting. Current simplification systems are predominantly
sequence-to-sequence models that are trained end-to-end to perform all these
operations simultaneously. However, such systems limit themselves to mostly
deleting words and cannot easily adapt to the requirements of different target
audiences. In this paper, we propose a novel hybrid approach that leverages
linguistically-motivated rules for splitting and deletion, and couples them
with a neural paraphrasing model to produce varied rewriting styles. We
introduce a new data augmentation method to improve the paraphrasing capability
of our model. Through automatic and manual evaluations, we show that our
proposed model establishes a new state-of-the-art for the task, paraphrasing
more often than the existing systems, and can control the degree of each
simplification operation applied to the input texts.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 13:44:40 GMT'}]",2020-10-22,"[['Maddela', 'Mounica', ''], ['Alva-Manchego', 'Fernando', ''], ['Xu', 'Wei', '']]"
1367348,2010.11018,Huaao Zhang,"Huaao Zhang, Shigui Qiu, Xiangyu Duan, Min Zhang",Token Drop mechanism for Neural Machine Translation,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Neural machine translation with millions of parameters is vulnerable to
unfamiliar inputs. We propose Token Drop to improve generalization and avoid
overfitting for the NMT model. Similar to word dropout, whereas we replace
dropped token with a special token instead of setting zero to words. We further
introduce two self-supervised objectives: Replaced Token Detection and Dropped
Token Prediction. Our method aims to force model generating target translation
with less information, in this way the model can learn textual representation
better. Experiments on Chinese-English and English-Romanian benchmark
demonstrate the effectiveness of our approach and our model achieves
significant improvements over a strong Transformer baseline.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 14:02:27 GMT'}]",2020-10-22,"[['Zhang', 'Huaao', ''], ['Qiu', 'Shigui', ''], ['Duan', 'Xiangyu', ''], ['Zhang', 'Min', '']]"
1367224,2010.10894,Junwei Bao Ph.D.,"Yingyao Wang, Junwei Bao, Guangyi Liu, Youzheng Wu, Xiaodong He, Bowen
  Zhou and Tiejun Zhao","Learning to Decouple Relations: Few-Shot Relation Classification with
  Entity-Guided Attention and Confusion-Aware Training","11 pages, 5 figures, accepted by COLING2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper aims to enhance the few-shot relation classification especially
for sentences that jointly describe multiple relations. Due to the fact that
some relations usually keep high co-occurrence in the same context, previous
few-shot relation classifiers struggle to distinguish them with few annotated
instances. To alleviate the above relation confusion problem, we propose CTEG,
a model equipped with two mechanisms to learn to decouple these easily-confused
relations. On the one hand, an Entity-Guided Attention (EGA) mechanism, which
leverages the syntactic relations and relative positions between each word and
the specified entity pair, is introduced to guide the attention to filter out
information causing confusion. On the other hand, a Confusion-Aware Training
(CAT) method is proposed to explicitly learn to distinguish relations by
playing a pushing-away game between classifying a sentence into a true relation
and its confusing relation. Extensive experiments are conducted on the FewRel
dataset, and the results show that our proposed model achieves comparable and
even much better results to strong baselines in terms of accuracy. Furthermore,
the ablation test and case study verify the effectiveness of our proposed EGA
and CAT, especially in addressing the relation confusion problem.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 11:07:53 GMT'}]",2020-10-22,"[['Wang', 'Yingyao', ''], ['Bao', 'Junwei', ''], ['Liu', 'Guangyi', ''], ['Wu', 'Youzheng', ''], ['He', 'Xiaodong', ''], ['Zhou', 'Bowen', ''], ['Zhao', 'Tiejun', '']]"
1367029,2010.10699,Zhao Xinyan,"Xinyan Zhao, Liangwei Chen, Huanhuan Chen","A Graph Based and Patient Demographics Aware Dialogue System for Disease
  Diagnosis",,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A dialogue system for disease diagnosis aims at making a diagnosis by
conversing with patients. Existing disease diagnosis dialogue systems highly
rely on data-driven methods and statistical features, lacking profound
comprehension of medical knowledge, such as symptom-disease relations. In
addition, previous work pays less attention to demographic attributes of a
patient, which are important factors in clinical diagnoses. To tackle these
issues, this work presents a graph based and demographic attributes aware
dialogue system for disease diagnosis. Specifically, we first build a weighted
bidirectional graph based on clinical dialogues to depict the relationship
between symptoms and diseases and then present a bidirectional graph based deep
Q-network (BG-DQN) for dialogue management. By extending Graph Convolutional
Network (GCN) to learn the embeddings of diseases and symptoms from both the
structural and attribute information in the graph, BG-DQN could capture the
relations between diseases and symptoms better. Moreover, BG-DQN also encodes
the demographic attributes of a patient to assist the disease diagnosis
process. Experimental results show that the proposed dialogue system
outperforms several competitive methods in terms of diagnostic accuracy. More
importantly, our method can complete the task with less dialogue turns and
possesses better distinguishing capability on diseases with similar symptoms.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 01:22:37 GMT'}]",2020-10-22,"[['Zhao', 'Xinyan', ''], ['Chen', 'Liangwei', ''], ['Chen', 'Huanhuan', '']]"
1366982,2010.10652,Wei-Fan Chen,"Wei-Fan Chen, Khalid Al-Khatib, Henning Wachsmuth and Benno Stein","Analyzing Political Bias and Unfairness in News Articles at Different
  Levels of Granularity",,NLP+CSS 2020,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Media organizations bear great reponsibility because of their considerable
influence on shaping beliefs and positions of our society. Any form of media
can contain overly biased content, e.g., by reporting on political events in a
selective or incomplete manner. A relevant question hence is whether and how
such form of imbalanced news coverage can be exposed. The research presented in
this paper addresses not only the automatic detection of bias but goes one step
further in that it explores how political bias and unfairness are manifested
linguistically. In this regard we utilize a new corpus of 6964 news articles
with labels derived from adfontesmedia.com and develop a neural model for bias
assessment. By analyzing this model on article excerpts, we find insightful
bias patterns at different levels of text granularity, from single words to the
whole article discourse.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 22:25:00 GMT'}]",2020-10-22,"[['Chen', 'Wei-Fan', ''], ['Al-Khatib', 'Khalid', ''], ['Wachsmuth', 'Henning', ''], ['Stein', 'Benno', '']]"
1367003,2010.10673,Ram\'on Fernandez Astudillo,"Young-Suk Lee, Ramon Fernandez Astudillo, Tahira Naseem, Revanth Gangi
  Reddy, Radu Florian, Salim Roukos",Pushing the Limits of AMR Parsing with Self-Learning,"Accepted to Findings of EMNLP2020, open review
  https://openreview.net/forum?id=4q5-oJgLiO, code
  https://github.com/IBM/transition-amr-parser",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Abstract Meaning Representation (AMR) parsing has experienced a notable
growth in performance in the last two years, due both to the impact of transfer
learning and the development of novel architectures specific to AMR. At the
same time, self-learning techniques have helped push the performance boundaries
of other natural language processing applications, such as machine translation
or question answering. In this paper, we explore different ways in which
trained models can be applied to improve AMR parsing performance, including
generation of synthetic text and AMR annotations as well as refinement of
actions oracle. We show that, without any additional human annotations, these
techniques improve an already performant parser and achieve state-of-the-art
results on AMR 1.0 and AMR 2.0.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 23:45:04 GMT'}]",2020-10-22,"[['Lee', 'Young-Suk', ''], ['Astudillo', 'Ramon Fernandez', ''], ['Naseem', 'Tahira', ''], ['Reddy', 'Revanth Gangi', ''], ['Florian', 'Radu', ''], ['Roukos', 'Salim', '']]"
1340301,2008.12579,Andrea Madotto Mr,"Andrea Madotto, Zhaojiang Lin, Yejin Bang, Pascale Fung",The Adapter-Bot: All-In-One Controllable Conversational Model,"Andrea Madotto and Zhaojiang Lin contributed equally to this work.
  Video demo: https://www.youtube.com/watch?v=Jz8KWE_gKH0&feature=youtu.be",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Considerable progress has been made towards conversational models that
generate coherent and fluent responses by training large language models on
large dialogue datasets. These models have little or no control of the
generated responses and miss two important features: continuous dialogue skills
integration and seamlessly leveraging diverse knowledge sources. In this paper,
we propose the Adapter-Bot, a dialogue model that uses a fixed backbone
conversational model such as DialGPT (Zhang et al., 2019) and triggers
on-demand dialogue skills (e.g., emphatic response, weather information, movie
recommendation) via different adapters (Houlsby et al., 2019). Each adapter can
be trained independently, thus allowing a continual integration of skills
without retraining the entire model. Depending on the skills, the model is able
to process multiple knowledge types, such as text, tables, and graphs, in a
seamless manner. The dialogue skills can be triggered automatically via a
dialogue manager, or manually, thus allowing high-level control of the
generated responses. At the current stage, we have implemented 12 response
styles (e.g., positive, negative etc.), 8 goal-oriented skills (e.g. weather
information, movie recommendation, etc.), and personalized and emphatic
responses. We evaluate our model using automatic evaluation by comparing it
with existing state-of-the-art conversational models, and we have released an
interactive system at adapter.bot.ust.hk.
","[{'version': 'v1', 'created': 'Fri, 28 Aug 2020 10:59:31 GMT'}, {'version': 'v2', 'created': 'Wed, 21 Oct 2020 02:44:30 GMT'}]",2020-10-22,"[['Madotto', 'Andrea', ''], ['Lin', 'Zhaojiang', ''], ['Bang', 'Yejin', ''], ['Fung', 'Pascale', '']]"
1349201,2009.07698,Reuben Tan,"Reuben Tan, Bryan A. Plummer, Kate Saenko",Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News,Accepted at EMNLP 2020,,,,cs.AI cs.CL cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large-scale dissemination of disinformation online intended to mislead or
deceive the general population is a major societal problem. Rapid progression
in image, video, and natural language generative models has only exacerbated
this situation and intensified our need for an effective defense mechanism.
While existing approaches have been proposed to defend against neural fake
news, they are generally constrained to the very limited setting where articles
only have text and metadata such as the title and authors. In this paper, we
introduce the more realistic and challenging task of defending against
machine-generated news that also includes images and captions. To identify the
possible weaknesses that adversaries can exploit, we create a NeuralNews
dataset composed of 4 different types of generated articles as well as conduct
a series of human user study experiments based on this dataset. In addition to
the valuable insights gleaned from our user study experiments, we provide a
relatively effective approach based on detecting visual-semantic
inconsistencies, which will serve as an effective first line of defense and a
useful reference for future work in defending against machine-generated
disinformation.
","[{'version': 'v1', 'created': 'Wed, 16 Sep 2020 14:13:15 GMT'}, {'version': 'v2', 'created': 'Thu, 17 Sep 2020 01:17:19 GMT'}, {'version': 'v3', 'created': 'Tue, 22 Sep 2020 21:37:02 GMT'}, {'version': 'v4', 'created': 'Thu, 24 Sep 2020 21:10:15 GMT'}, {'version': 'v5', 'created': 'Wed, 21 Oct 2020 15:16:20 GMT'}]",2020-10-22,"[['Tan', 'Reuben', ''], ['Plummer', 'Bryan A.', ''], ['Saenko', 'Kate', '']]"
1356289,2009.14786,Nicolas Gontier,Nicolas Gontier and Koustuv Sinha and Siva Reddy and Christopher Pal,"Measuring Systematic Generalization in Neural Proof Generation with
  Transformers",NeurIPS 2020; 17 pages; 9 figures; 6 tables,,,,cs.LG cs.AI cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We are interested in understanding how well Transformer language models
(TLMs) can perform reasoning tasks when trained on knowledge encoded in the
form of natural language. We investigate their systematic generalization
abilities on a logical reasoning task in natural language, which involves
reasoning over relationships between entities grounded in first-order logical
proofs. Specifically, we perform soft theorem-proving by leveraging TLMs to
generate natural language proofs. We test the generated proofs for logical
consistency, along with the accuracy of the final inference. We observe
length-generalization issues when evaluated on longer-than-trained sequences.
However, we observe TLMs improve their generalization performance after being
exposed to longer, exhaustive proofs. In addition, we discover that TLMs are
able to generalize better using backward-chaining proofs compared to their
forward-chaining counterparts, while they find it easier to generate forward
chaining proofs. We observe that models that are not trained to generate proofs
are better at generalizing to problems based on longer proofs. This suggests
that Transformers have efficient internal reasoning strategies that are harder
to interpret. These results highlight the systematic generalization behavior of
TLMs in the context of logical reasoning, and we believe this work motivates
deeper inspection of their underlying reasoning strategies.
","[{'version': 'v1', 'created': 'Wed, 30 Sep 2020 16:54:37 GMT'}, {'version': 'v2', 'created': 'Tue, 20 Oct 2020 20:31:11 GMT'}]",2020-10-22,"[['Gontier', 'Nicolas', ''], ['Sinha', 'Koustuv', ''], ['Reddy', 'Siva', ''], ['Pal', 'Christopher', '']]"
1306394,2006.11880,Jianjun Hu,"Changchang Zeng, Shaobo Li, Qin Li, Jie Hu, and Jianjun Hu","A Survey on Machine Reading Comprehension: Tasks, Evaluation Metrics and
  Benchmark Datasets",68 pages,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Machine Reading Comprehension (MRC) is a challenging Natural Language
Processing(NLP) research field with wide real-world applications. The great
progress of this field in recent years is mainly due to the emergence of
large-scale datasets and deep learning. At present, a lot of MRC models have
already surpassed human performance on various benchmark datasets despite the
obvious giant gap between existing MRC models and genuine human-level reading
comprehension. This shows the need for improving existing datasets, evaluation
metrics, and models to move current MRC models toward ""real"" understanding. To
address the current lack of comprehensive survey of existing MRC tasks,
evaluation metrics, and datasets, herein, (1) we analyze 57 MRC tasks and
datasets and propose a more precise classification method of MRC tasks with 4
different attributes; (2) we summarized 9 evaluation metrics of MRC tasks, 7
attributes and 10 characteristics of MRC datasets; (3) We also discuss key open
issues in MRC research and highlighted future research directions. In addition,
we have collected, organized, and published our data on the companion
website(https://mrc-datasets.github.io/) where MRC researchers could directly
access each MRC dataset, papers, baseline projects, and the leaderboard.
","[{'version': 'v1', 'created': 'Sun, 21 Jun 2020 19:18:54 GMT'}, {'version': 'v2', 'created': 'Wed, 21 Oct 2020 04:19:14 GMT'}]",2020-10-22,"[['Zeng', 'Changchang', ''], ['Li', 'Shaobo', ''], ['Li', 'Qin', ''], ['Hu', 'Jie', ''], ['Hu', 'Jianjun', '']]"
1312322,2007.00808,Li Xiong,"Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul
  Bennett, Junaid Ahmed, Arnold Overwijk","Approximate Nearest Neighbor Negative Contrastive Learning for Dense
  Text Retrieval",,,,,cs.IR cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Conducting text retrieval in a dense learned representation space has many
intriguing advantages over sparse retrieval. Yet the effectiveness of dense
retrieval (DR) often requires combination with sparse retrieval. In this paper,
we identify that the main bottleneck is in the training mechanisms, where the
negative instances used in training are not representative of the irrelevant
documents in testing. This paper presents Approximate nearest neighbor Negative
Contrastive Estimation (ANCE), a training mechanism that constructs negatives
from an Approximate Nearest Neighbor (ANN) index of the corpus, which is
parallelly updated with the learning process to select more realistic negative
training instances. This fundamentally resolves the discrepancy between the
data distribution used in the training and testing of DR. In our experiments,
ANCE boosts the BERT-Siamese DR model to outperform all competitive dense and
sparse retrieval baselines. It nearly matches the accuracy of
sparse-retrieval-and-BERT-reranking using dot-product in the ANCE-learned
representation space and provides almost 100x speed-up.
","[{'version': 'v1', 'created': 'Wed, 1 Jul 2020 23:15:56 GMT'}, {'version': 'v2', 'created': 'Tue, 20 Oct 2020 22:17:19 GMT'}]",2020-10-22,"[['Xiong', 'Lee', ''], ['Xiong', 'Chenyan', ''], ['Li', 'Ye', ''], ['Tang', 'Kwok-Fung', ''], ['Liu', 'Jialin', ''], ['Bennett', 'Paul', ''], ['Ahmed', 'Junaid', ''], ['Overwijk', 'Arnold', '']]"
1363152,2010.06822,Faeze Brahman,"Faeze Brahman, Snigdha Chaturvedi",Modeling Protagonist Emotions for Emotion-Aware Storytelling,"EMNLP 2020, update: Conference version of Weber et al. (2020) is
  cited",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Emotions and their evolution play a central role in creating a captivating
story. In this paper, we present the first study on modeling the emotional
trajectory of the protagonist in neural storytelling. We design methods that
generate stories that adhere to given story titles and desired emotion arcs for
the protagonist. Our models include Emotion Supervision (EmoSup) and two
Emotion-Reinforced (EmoRL) models. The EmoRL models use special rewards
designed to regularize the story generation process through reinforcement
learning. Our automatic and manual evaluations demonstrate that these models
are significantly better at generating stories that follow the desired emotion
arcs compared to baseline methods, without sacrificing story quality.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 06:24:25 GMT'}, {'version': 'v2', 'created': 'Tue, 20 Oct 2020 19:23:52 GMT'}]",2020-10-22,"[['Brahman', 'Faeze', ''], ['Chaturvedi', 'Snigdha', '']]"
1276175,2004.11405,Ori Terner,"Ori Terner, Kfir Bar, Nachum Dershowitz","Transliteration of Judeo-Arabic Texts into Arabic Script Using Recurrent
  Neural Networks",accepted for WANLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We trained a model to automatically transliterate Judeo-Arabic texts into
Arabic script, enabling Arabic readers to access those writings. We employ a
recurrent neural network (RNN), combined with the connectionist temporal
classification (CTC) loss to deal with unequal input/output lengths. This
obligates adjustments in the training data to avoid input sequences that are
shorter than their corresponding outputs. We also utilize a pretraining stage
with a different loss function to improve network converge. Since only a single
source of parallel text was available for training, we take advantage of the
possibility of generating data synthetically. We train a model that has the
capability to memorize words in the output language, and that also utilizes
context for distinguishing ambiguities in the transliteration. We obtain an
improvement over the baseline 9.5% character error, achieving 2% error with our
best configuration. To measure the contribution of context to learning, we also
tested word-shuffled data, for which the error rises to 2.5%.
","[{'version': 'v1', 'created': 'Thu, 23 Apr 2020 18:03:41 GMT'}, {'version': 'v2', 'created': 'Wed, 21 Oct 2020 09:08:53 GMT'}]",2020-10-22,"[['Terner', 'Ori', ''], ['Bar', 'Kfir', ''], ['Dershowitz', 'Nachum', '']]"
1268894,2004.04124,Yihuan Mao,"Yihuan Mao, Yujing Wang, Chufan Wu, Chen Zhang, Yang Wang, Yaming
  Yang, Quanlu Zhang, Yunhai Tong, Jing Bai","LadaBERT: Lightweight Adaptation of BERT through Hybrid Model
  Compression",COLING2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  BERT is a cutting-edge language representation model pre-trained by a large
corpus, which achieves superior performances on various natural language
understanding tasks. However, a major blocking issue of applying BERT to online
services is that it is memory-intensive and leads to unsatisfactory latency of
user requests, raising the necessity of model compression. Existing solutions
leverage the knowledge distillation framework to learn a smaller model that
imitates the behaviors of BERT. However, the training procedure of knowledge
distillation is expensive itself as it requires sufficient training data to
imitate the teacher model. In this paper, we address this issue by proposing a
hybrid solution named LadaBERT (Lightweight adaptation of BERT through hybrid
model compression), which combines the advantages of different model
compression methods, including weight pruning, matrix factorization and
knowledge distillation. LadaBERT achieves state-of-the-art accuracy on various
public datasets while the training overheads can be reduced by an order of
magnitude.
","[{'version': 'v1', 'created': 'Wed, 8 Apr 2020 17:18:56 GMT'}, {'version': 'v2', 'created': 'Wed, 21 Oct 2020 15:15:11 GMT'}]",2020-10-22,"[['Mao', 'Yihuan', ''], ['Wang', 'Yujing', ''], ['Wu', 'Chufan', ''], ['Zhang', 'Chen', ''], ['Wang', 'Yang', ''], ['Yang', 'Yaming', ''], ['Zhang', 'Quanlu', ''], ['Tong', 'Yunhai', ''], ['Bai', 'Jing', '']]"
1255346,2003.04991,Jitin Krishnan,"Jitin Krishnan, Hemant Purohit and Huzefa Rangwala","Unsupervised and Interpretable Domain Adaptation to Rapidly Filter
  Tweets for Emergency Services","8 pages, 4 Figures, 6 Tables, Source Code Available",,,,cs.CL cs.LG cs.SI stat.ML,http://creativecommons.org/licenses/by/4.0/,"  During the onset of a disaster event, filtering relevant information from the
social web data is challenging due to its sparse availability and practical
limitations in labeling datasets of an ongoing crisis. In this paper, we
hypothesize that unsupervised domain adaptation through multi-task learning can
be a useful framework to leverage data from past crisis events for training
efficient information filtering models during the sudden onset of a new crisis.
We present a novel method to classify relevant tweets during an ongoing crisis
without seeing any new examples, using the publicly available dataset of TREC
incident streams. Specifically, we construct a customized multi-task
architecture with a multi-domain discriminator for crisis analytics: multi-task
domain adversarial attention network. This model consists of dedicated
attention layers for each task to provide model interpretability; critical for
real-word applications. As deep networks struggle with sparse datasets, we show
that this can be improved by sharing a base layer for multi-task learning and
domain adversarial training. Evaluation of domain adaptation for crisis events
is performed by choosing a target event as the test set and training on the
rest. Our results show that the multi-task model outperformed its single task
counterpart. For the qualitative evaluation of interpretability, we show that
the attention layer can be used as a guide to explain the model predictions and
empower emergency services for exploring accountability of the model, by
showcasing the words in a tweet that are deemed important in the classification
process. Finally, we show a practical implication of our work by providing a
use-case for the COVID-19 pandemic.
","[{'version': 'v1', 'created': 'Wed, 4 Mar 2020 06:40:14 GMT'}, {'version': 'v2', 'created': 'Tue, 20 Oct 2020 18:01:19 GMT'}]",2020-10-22,"[['Krishnan', 'Jitin', ''], ['Purohit', 'Hemant', ''], ['Rangwala', 'Huzefa', '']]"
1248360,2002.10937,Jitin Krishnan,"Jitin Krishnan, Hemant Purohit, and Huzefa Rangwala","Diversity-Based Generalization for Unsupervised Text Classification
  under Domain Shift","16 pages, 3 figures, 5 Tables, Source Code Available",,,,cs.LG cs.CL stat.ML,http://creativecommons.org/licenses/by/4.0/,"  Domain adaptation approaches seek to learn from a source domain and
generalize it to an unseen target domain. At present, the state-of-the-art
unsupervised domain adaptation approaches for subjective text classification
problems leverage unlabeled target data along with labeled source data. In this
paper, we propose a novel method for domain adaptation of single-task text
classification problems based on a simple but effective idea of diversity-based
generalization that does not require unlabeled target data but still matches
the state-of-the-art in performance. Diversity plays the role of promoting the
model to better generalize and be indiscriminate towards domain shift by
forcing the model not to rely on same features for prediction. We apply this
concept on the most explainable component of neural networks, the attention
layer. To generate sufficient diversity, we create a multi-head attention model
and infuse a diversity constraint between the attention heads such that each
head will learn differently. We further expand upon our model by tri-training
and designing a procedure with an additional diversity constraint between the
attention heads of the tri-trained classifiers. Extensive evaluation using the
standard benchmark dataset of Amazon reviews and a newly constructed dataset of
Crisis events shows that our fully unsupervised method matches with the
competing baselines that uses unlabeled target data. Our results demonstrate
that machine learning architectures that ensure sufficient diversity can
generalize better; encouraging future research to design ubiquitously usable
learning models without using unlabeled target data.
","[{'version': 'v1', 'created': 'Tue, 25 Feb 2020 15:11:02 GMT'}, {'version': 'v2', 'created': 'Tue, 20 Oct 2020 18:06:10 GMT'}]",2020-10-22,"[['Krishnan', 'Jitin', ''], ['Purohit', 'Hemant', ''], ['Rangwala', 'Huzefa', '']]"
1246676,2002.09253,C\'edric Colas,"C\'edric Colas, Tristan Karch, Nicolas Lair, Jean-Michel Dussoux,
  Cl\'ement Moulin-Frier, Peter Ford Dominey, Pierre-Yves Oudeyer","Language as a Cognitive Tool to Imagine Goals in Curiosity-Driven
  Exploration",Contains main article and supplementaries,NeurIPS 2020,,,cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Developmental machine learning studies how artificial agents can model the
way children learn open-ended repertoires of skills. Such agents need to create
and represent goals, select which ones to pursue and learn to achieve them.
Recent approaches have considered goal spaces that were either fixed and
hand-defined or learned using generative models of states. This limited agents
to sample goals within the distribution of known effects. We argue that the
ability to imagine out-of-distribution goals is key to enable creative
discoveries and open-ended learning. Children do so by leveraging the
compositionality of language as a tool to imagine descriptions of outcomes they
never experienced before, targeting them as goals during play. We introduce
IMAGINE, an intrinsically motivated deep reinforcement learning architecture
that models this ability. Such imaginative agents, like children, benefit from
the guidance of a social peer who provides language descriptions. To take
advantage of goal imagination, agents must be able to leverage these
descriptions to interpret their imagined out-of-distribution goals. This
generalization is made possible by modularity: a decomposition between learned
goal-achievement reward function and policy relying on deep sets, gated
attention and object-centered representations. We introduce the Playground
environment and study how this form of goal imagination improves generalization
and exploration over agents lacking this capacity. In addition, we identify the
properties of goal imagination that enable these results and study the impacts
of modularity and social interactions.
","[{'version': 'v1', 'created': 'Fri, 21 Feb 2020 12:59:57 GMT'}, {'version': 'v2', 'created': 'Mon, 20 Apr 2020 11:38:50 GMT'}, {'version': 'v3', 'created': 'Fri, 12 Jun 2020 09:23:40 GMT'}, {'version': 'v4', 'created': 'Wed, 21 Oct 2020 16:48:51 GMT'}]",2020-10-22,"[['Colas', 'Cédric', ''], ['Karch', 'Tristan', ''], ['Lair', 'Nicolas', ''], ['Dussoux', 'Jean-Michel', ''], ['Moulin-Frier', 'Clément', ''], ['Dominey', 'Peter Ford', ''], ['Oudeyer', 'Pierre-Yves', '']]"
1229476,2001.04063,Weizhen Qi,"Weizhen Qi, Yu Yan, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen,
  Ruofei Zhang, Ming Zhou","ProphetNet: Predicting Future N-gram for Sequence-to-Sequence
  Pre-training","Accepted to EMNLP 2020 Findings. Project page:
  https://github.com/microsoft/ProphetNet",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents a new sequence-to-sequence pre-training model called
ProphetNet, which introduces a novel self-supervised objective named future
n-gram prediction and the proposed n-stream self-attention mechanism. Instead
of optimizing one-step-ahead prediction in the traditional sequence-to-sequence
model, the ProphetNet is optimized by n-step ahead prediction that predicts the
next n tokens simultaneously based on previous context tokens at each time
step. The future n-gram prediction explicitly encourages the model to plan for
the future tokens and prevent overfitting on strong local correlations. We
pre-train ProphetNet using a base scale dataset (16GB) and a large-scale
dataset (160GB), respectively. Then we conduct experiments on CNN/DailyMail,
Gigaword, and SQuAD 1.1 benchmarks for abstractive summarization and question
generation tasks. Experimental results show that ProphetNet achieves new
state-of-the-art results on all these datasets compared to the models using the
same scale pre-training corpus.
","[{'version': 'v1', 'created': 'Mon, 13 Jan 2020 05:12:38 GMT'}, {'version': 'v2', 'created': 'Sat, 22 Feb 2020 09:29:12 GMT'}, {'version': 'v3', 'created': 'Wed, 21 Oct 2020 05:45:35 GMT'}]",2020-10-22,"[['Qi', 'Weizhen', ''], ['Yan', 'Yu', ''], ['Gong', 'Yeyun', ''], ['Liu', 'Dayiheng', ''], ['Duan', 'Nan', ''], ['Chen', 'Jiusheng', ''], ['Zhang', 'Ruofei', ''], ['Zhou', 'Ming', '']]"
1287876,2005.08081,Fenglin Liu,"Fenglin Liu, Xuancheng Ren, Guangxiang Zhao, Xu Sun, Liangyou Li",Layer-Wise Cross-View Decoding for Sequence-to-Sequence Learning,"Achieve state-of-the-art BLEU scores on WMT14 EN-DE, EN-FR, and IWSLT
  DE-EN datasets",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In sequence-to-sequence learning, the decoder relies on the attention
mechanism to efficiently extract information from the encoder. While it is
common practice to draw information from only the last encoder layer, recent
work has proposed to use representations from different encoder layers for
diversified levels of information. Nonetheless, the decoder still obtains only
a single view of the source sequences, which might lead to insufficient
training of the encoder layer stack due to the hierarchy bypassing problem. In
this work, we propose layer-wise cross-view decoding, where for each decoder
layer, together with the representations from the last encoder layer, which
serve as a global view, those from other encoder layers are supplemented for a
stereoscopic view of the source sequences. Systematic experiments show that we
successfully address the hierarchy bypassing problem and substantially improve
the performance of sequence-to-sequence learning with deep representations on
diverse tasks.
","[{'version': 'v1', 'created': 'Sat, 16 May 2020 20:00:39 GMT'}, {'version': 'v2', 'created': 'Wed, 3 Jun 2020 10:21:33 GMT'}, {'version': 'v3', 'created': 'Wed, 21 Oct 2020 05:58:38 GMT'}]",2020-10-22,"[['Liu', 'Fenglin', ''], ['Ren', 'Xuancheng', ''], ['Zhao', 'Guangxiang', ''], ['Sun', 'Xu', ''], ['Li', 'Liangyou', '']]"
1366722,2010.10392,Hicham El Boukkouri,"Hicham El Boukkouri, Olivier Ferret, Thomas Lavergne, Hiroshi Noji,
  Pierre Zweigenbaum, Junichi Tsujii","CharacterBERT: Reconciling ELMo and BERT for Word-Level Open-Vocabulary
  Representations From Characters","13 pages, 8 figures and 3 tables. Accepted at COLING 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Due to the compelling improvements brought by BERT, many recent
representation models adopted the Transformer architecture as their main
building block, consequently inheriting the wordpiece tokenization system
despite it not being intrinsically linked to the notion of Transformers. While
this system is thought to achieve a good balance between the flexibility of
characters and the efficiency of full words, using predefined wordpiece
vocabularies from the general domain is not always suitable, especially when
building models for specialized domains (e.g., the medical domain). Moreover,
adopting a wordpiece tokenization shifts the focus from the word level to the
subword level, making the models conceptually more complex and arguably less
convenient in practice. For these reasons, we propose CharacterBERT, a new
variant of BERT that drops the wordpiece system altogether and uses a
Character-CNN module instead to represent entire words by consulting their
characters. We show that this new model improves the performance of BERT on a
variety of medical domain tasks while at the same time producing robust,
word-level and open-vocabulary representations.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 15:58:53 GMT'}, {'version': 'v2', 'created': 'Wed, 21 Oct 2020 14:57:52 GMT'}]",2020-10-22,"[['Boukkouri', 'Hicham El', ''], ['Ferret', 'Olivier', ''], ['Lavergne', 'Thomas', ''], ['Noji', 'Hiroshi', ''], ['Zweigenbaum', 'Pierre', ''], ['Tsujii', 'Junichi', '']]"
1366886,2010.10556,Peidong Wang,"Peidong Wang, Zhuo Chen, DeLiang Wang, Jinyu Li, Yifan Gong",Speaker Separation Using Speaker Inventories and Estimated Speech,,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose speaker separation using speaker inventories and estimated speech
(SSUSIES), a framework leveraging speaker profiles and estimated speech for
speaker separation. SSUSIES contains two methods, speaker separation using
speaker inventories (SSUSI) and speaker separation using estimated speech
(SSUES). SSUSI performs speaker separation with the help of speaker inventory.
By combining the advantages of permutation invariant training (PIT) and speech
extraction, SSUSI significantly outperforms conventional approaches. SSUES is a
widely applicable technique that can substantially improve speaker separation
performance using the output of first-pass separation. We evaluate the models
on both speaker separation and speech recognition metrics.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 18:15:45 GMT'}]",2020-10-22,"[['Wang', 'Peidong', ''], ['Chen', 'Zhuo', ''], ['Wang', 'DeLiang', ''], ['Li', 'Jinyu', ''], ['Gong', 'Yifan', '']]"
1366893,2010.10563,Pablo Messina,"Pablo Messina, Pablo Pino, Denis Parra, Alvaro Soto, Cecilia Besa,
  Sergio Uribe, Marcelo and\'ia, Cristian Tejos, Claudia Prieto and Daniel
  Capurro","A Survey on Deep Learning and Explainability for Automatic Image-based
  Medical Report Generation",,,,,cs.CV cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Every year physicians face an increasing demand of image-based diagnosis from
patients, a problem that can be addressed with recent artificial intelligence
methods. In this context, we survey works in the area of automatic report
generation from medical images, with emphasis on methods using deep neural
networks, with respect to: (1) Datasets, (2) Architecture Design, (3)
Explainability and (4) Evaluation Metrics. Our survey identifies interesting
developments, but also remaining challenges. Among them, the current evaluation
of generated reports is especially weak, since it mostly relies on traditional
Natural Language Processing (NLP) metrics, which do not accurately capture
medical correctness.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 18:48:37 GMT'}]",2020-10-22,"[['Messina', 'Pablo', ''], ['Pino', 'Pablo', ''], ['Parra', 'Denis', ''], ['Soto', 'Alvaro', ''], ['Besa', 'Cecilia', ''], ['Uribe', 'Sergio', ''], ['andía', 'Marcelo', ''], ['Tejos', 'Cristian', ''], ['Prieto', 'Claudia', ''], ['Capurro', 'Daniel', '']]"
1366896,2010.10566,Fei Liu,"Sangwoo Cho and Kaiqiang Song and Chen Li and Dong Yu and Hassan
  Foroosh and Fei Liu",Better Highlighting: Creating Sub-Sentence Summary Highlights,EMNLP 2020 (Long Paper),,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Amongst the best means to summarize is highlighting. In this paper, we aim to
generate summary highlights to be overlaid on the original documents to make it
easier for readers to sift through a large amount of text. The method allows
summaries to be understood in context to prevent a summarizer from distorting
the original meaning, of which abstractive summarizers usually fall short. In
particular, we present a new method to produce self-contained highlights that
are understandable on their own to avoid confusion. Our method combines
determinantal point processes and deep contextualized representations to
identify an optimal set of sub-sentence segments that are both important and
non-redundant to form summary highlights. To demonstrate the flexibility and
modeling power of our method, we conduct extensive experiments on summarization
datasets. Our analysis provides evidence that highlighting is a promising
avenue of research towards future summarization.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 18:57:42 GMT'}]",2020-10-22,"[['Cho', 'Sangwoo', ''], ['Song', 'Kaiqiang', ''], ['Li', 'Chen', ''], ['Yu', 'Dong', ''], ['Foroosh', 'Hassan', ''], ['Liu', 'Fei', '']]"
1366903,2010.10573,Hoang Nguyen Hung Van,"Hoang Van, David Kauchak, Gondy Leroy",AutoMeTS: The Autocomplete for Medical Text Simplification,"9 pages, 3 figures, and 8 tables, Accpeted to COLING 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The goal of text simplification (TS) is to transform difficult text into a
version that is easier to understand and more broadly accessible to a wide
variety of readers. In some domains, such as healthcare, fully automated
approaches cannot be used since information must be accurately preserved.
Instead, semi-automated approaches can be used that assist a human writer in
simplifying text faster and at a higher quality. In this paper, we examine the
application of autocomplete to text simplification in the medical domain. We
introduce a new parallel medical data set consisting of aligned English
Wikipedia with Simple English Wikipedia sentences and examine the application
of pretrained neural language models (PNLMs) on this dataset. We compare four
PNLMs(BERT, RoBERTa, XLNet, and GPT-2), and show how the additional context of
the sentence to be simplified can be incorporated to achieve better results
(6.17% absolute improvement over the best individual model). We also introduce
an ensemble model that combines the four PNLMs and outperforms the best
individual model by 2.1%, resulting in an overall word prediction accuracy of
64.52%.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 19:20:29 GMT'}]",2020-10-22,"[['Van', 'Hoang', ''], ['Kauchak', 'David', ''], ['Leroy', 'Gondy', '']]"
1366927,2010.10597,Aditya Kalyanpur,"Clifton McFate, Aditya Kalyanpur, Dave Ferrucci, Andrea Bradshaw,
  Ariel Diertani, David Melville, Lori Moon",SKATE: A Natural Language Interface for Encoding Structured Knowledge,In submission,,,,cs.CL cs.HC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In Natural Language (NL) applications, there is often a mismatch between what
the NL interface is capable of interpreting and what a lay user knows how to
express. This work describes a novel natural language interface that reduces
this mismatch by refining natural language input through successive,
automatically generated semi-structured templates. In this paper we describe
how our approach, called SKATE, uses a neural semantic parser to parse NL input
and suggest semi-structured templates, which are recursively filled to produce
fully structured interpretations. We also show how SKATE integrates with a
neural rule-generation model to interactively suggest and acquire commonsense
knowledge. We provide a preliminary coverage analysis of SKATE for the task of
story understanding, and then describe a current business use-case of the tool
in a specific domain: COVID-19 policy design.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 20:13:09 GMT'}]",2020-10-22,"[['McFate', 'Clifton', ''], ['Kalyanpur', 'Aditya', ''], ['Ferrucci', 'Dave', ''], ['Bradshaw', 'Andrea', ''], ['Diertani', 'Ariel', ''], ['Melville', 'David', ''], ['Moon', 'Lori', '']]"
1366978,2010.10648,Elman Mansimov,"Elman Mansimov, Mitchell Stern, Mia Chen, Orhan Firat, Jakob
  Uszkoreit, Puneet Jain",Towards End-to-End In-Image Neural Machine Translation,"Accepted as an oral presentation at EMNLP, NLP Beyond Text workshop,
  2020",,,,cs.CL cs.CV cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we offer a preliminary investigation into the task of in-image
machine translation: transforming an image containing text in one language into
an image containing the same text in another language. We propose an end-to-end
neural model for this task inspired by recent approaches to neural machine
translation, and demonstrate promising initial results based purely on
pixel-level supervision. We then offer a quantitative and qualitative
evaluation of our system outputs and discuss some common failure modes.
Finally, we conclude with directions for future work.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 22:20:04 GMT'}]",2020-10-22,"[['Mansimov', 'Elman', ''], ['Stern', 'Mitchell', ''], ['Chen', 'Mia', ''], ['Firat', 'Orhan', ''], ['Uszkoreit', 'Jakob', ''], ['Jain', 'Puneet', '']]"
1366979,2010.10649,Wei-Fan Chen,"Wei-Fan Chen, Khalid Al-Khatib, Benno Stein and Henning Wachsmuth",Detecting Media Bias in News Articles using Gaussian Bias Distributions,,EMNLP 2020 Findings,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Media plays an important role in shaping public opinion. Biased media can
influence people in undesirable directions and hence should be unmasked as
such. We observe that featurebased and neural text classification approaches
which rely only on the distribution of low-level lexical information fail to
detect media bias. This weakness becomes most noticeable for articles on new
events, where words appear in new contexts and hence their ""bias
predictiveness"" is unclear. In this paper, we therefore study how second-order
information about biased statements in an article helps to improve detection
effectiveness. In particular, we utilize the probability distributions of the
frequency, positions, and sequential order of lexical and informational
sentence-level bias in a Gaussian Mixture Model. On an existing media bias
dataset, we find that the frequency and positions of biased statements strongly
impact article-level bias, whereas their exact sequential order is secondary.
Using a standard model for sentence-level bias detection, we provide empirical
evidence that article-level bias detectors that use second-order information
clearly outperform those without.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 22:20:49 GMT'}]",2020-10-22,"[['Chen', 'Wei-Fan', ''], ['Al-Khatib', 'Khalid', ''], ['Stein', 'Benno', ''], ['Wachsmuth', 'Henning', '']]"
1367349,2010.11019,Pranaydeep Singh,Pranaydeep Singh and Els Lefever,"LT3 at SemEval-2020 Task 9: Cross-lingual Embeddings for Sentiment
  Analysis of Hinglish Social Media Text",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper describes our contribution to the SemEval-2020 Task 9 on Sentiment
Analysis for Code-mixed Social Media Text. We investigated two approaches to
solve the task of Hinglish sentiment analysis. The first approach uses
cross-lingual embeddings resulting from projecting Hinglish and pre-trained
English FastText word embeddings in the same space. The second approach
incorporates pre-trained English embeddings that are incrementally retrained
with a set of Hinglish tweets. The results show that the second approach
performs best, with an F1-score of 70.52% on the held-out test data.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 14:03:16 GMT'}]",2020-10-22,"[['Singh', 'Pranaydeep', ''], ['Lefever', 'Els', '']]"
1366999,2010.10669,Ram\'on Fernandez Astudillo,"Ramon Fernandez Astudillo, Miguel Ballesteros, Tahira Naseem, Austin
  Blodgett, Radu Florian",Transition-based Parsing with Stack-Transformers,"Accepted to Findings of EMNLP2020, open review
  https://openreview.net/forum?id=b36spsuUAde, code
  https://github.com/IBM/transition-amr-parser",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Modeling the parser state is key to good performance in transition-based
parsing. Recurrent Neural Networks considerably improved the performance of
transition-based systems by modelling the global state, e.g. stack-LSTM
parsers, or local state modeling of contextualized features, e.g. Bi-LSTM
parsers. Given the success of Transformer architectures in recent parsing
systems, this work explores modifications of the sequence-to-sequence
Transformer architecture to model either global or local parser states in
transition-based parsing. We show that modifications of the cross attention
mechanism of the Transformer considerably strengthen performance both on
dependency and Abstract Meaning Representation (AMR) parsing tasks,
particularly for smaller models or limited training data.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 23:20:31 GMT'}]",2020-10-22,"[['Astudillo', 'Ramon Fernandez', ''], ['Ballesteros', 'Miguel', ''], ['Naseem', 'Tahira', ''], ['Blodgett', 'Austin', ''], ['Florian', 'Radu', '']]"
1367024,2010.10694,Erica Cooper,"Antoine Perquin, Erica Cooper, Junichi Yamagishi",Grapheme or phoneme? An Analysis of Tacotron's Embedded Representations,Submitted to ICASSP 2021,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  End-to-end models, particularly Tacotron-based ones, are currently a popular
solution for text-to-speech synthesis. They allow the production of
high-quality synthesized speech with little to no text preprocessing. Phoneme
inputs are usually preferred over graphemes in order to limit the amount of
pronunciation errors. In this work we show that, in the case of a well-curated
French dataset, graphemes can be used as input without increasing the amount of
pronunciation errors. Furthermore, we perform an analysis of the representation
learned by the Tacotron model and show that the contextual grapheme embeddings
encode phoneme information, and that they can be used for grapheme-to-phoneme
conversion and phoneme control of synthetic speech.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 00:58:29 GMT'}]",2020-10-22,"[['Perquin', 'Antoine', ''], ['Cooper', 'Erica', ''], ['Yamagishi', 'Junichi', '']]"
1367396,2010.11066,Chenyu You,"Chenyu You, Nuo Chen, Yuexian Zou","Contextualized Attention-based Knowledge Transfer for Spoken
  Conversational Question Answering",,,,,cs.CL cs.AI cs.IR cs.LG cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Spoken conversational question answering (SCQA) requires machines to model
complex dialogue flow given the speech utterances and text corpora. Different
from traditional text question answering (QA) tasks, SCQA involves audio signal
processing, passage comprehension, and contextual understanding. However, ASR
systems introduce unexpected noisy signals to the transcriptions, which result
in performance degradation on SCQA. To overcome the problem, we propose CADNet,
a novel contextualized attention-based distillation approach, which applies
both cross-attention and self-attention to obtain ASR-robust contextualized
embedding representations of the passage and dialogue history for performance
improvements. We also introduce the spoken conventional knowledge distillation
framework to distill the ASR-robust knowledge from the estimated probabilities
of the teacher model to the student. We conduct extensive experiments on the
Spoken-CoQA dataset and demonstrate that our approach achieves remarkable
performance in this task.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 15:17:18 GMT'}]",2020-10-22,"[['You', 'Chenyu', ''], ['Chen', 'Nuo', ''], ['Zou', 'Yuexian', '']]"
1367384,2010.11054,Jiaming Luo,"Jiaming Luo, Frederik Hartmann, Enrico Santus, Yuan Cao, Regina
  Barzilay",Deciphering Undersegmented Ancient Scripts Using Phonetic Prior,"TACL 2020, pre-MIT Press publication version",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Most undeciphered lost languages exhibit two characteristics that pose
significant decipherment challenges: (1) the scripts are not fully segmented
into words; (2) the closest known language is not determined. We propose a
decipherment model that handles both of these challenges by building on rich
linguistic constraints reflecting consistent patterns in historical sound
change. We capture the natural phonological geometry by learning character
embeddings based on the International Phonetic Alphabet (IPA). The resulting
generative framework jointly models word segmentation and cognate alignment,
informed by phonological constraints. We evaluate the model on both deciphered
languages (Gothic, Ugaritic) and an undeciphered one (Iberian). The experiments
show that incorporating phonetic geometry leads to clear and consistent gains.
Additionally, we propose a measure for language closeness which correctly
identifies related languages for Gothic and Ugaritic. For Iberian, the method
does not show strong evidence supporting Basque as a related language,
concurring with the favored position by the current scholarship.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 15:03:52 GMT'}]",2020-10-22,"[['Luo', 'Jiaming', ''], ['Hartmann', 'Frederik', ''], ['Santus', 'Enrico', ''], ['Cao', 'Yuan', ''], ['Barzilay', 'Regina', '']]"
1367405,2010.11075,Nils Barlaug,"Nils Barlaug, Jon Atle Gulla",Neural Networks for Entity Matching,Under review in TKDD,,,,cs.DB cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Entity matching is the problem of identifying which records refer to the same
real-world entity. It has been actively researched for decades, and a variety
of different approaches have been developed. Even today, it remains a
challenging problem, and there is still generous room for improvement. In
recent years we have seen new methods based upon deep learning techniques for
natural language processing emerge.
  In this survey, we present how neural networks have been used for entity
matching. Specifically, we identify which steps of the entity matching process
existing work have targeted using neural networks, and provide an overview of
the different techniques used at each step. We also discuss contributions from
deep learning in entity matching compared to traditional methods, and propose a
taxonomy of deep neural networks for entity matching.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 15:36:03 GMT'}]",2020-10-22,"[['Barlaug', 'Nils', ''], ['Gulla', 'Jon Atle', '']]"
1226995,2001.01582,Hossein Amirkhani,"Razieh Baradaran, Razieh Ghiasi, and Hossein Amirkhani",A Survey on Machine Reading Comprehension Systems,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Machine reading comprehension is a challenging task and hot topic in natural
language processing. Its goal is to develop systems to answer the questions
regarding a given context. In this paper, we present a comprehensive survey on
different aspects of machine reading comprehension systems, including their
approaches, structures, input/outputs, and research novelties. We illustrate
the recent trends in this field based on 241 reviewed papers from 2016 to 2020.
Our investigations demonstrate that the focus of research has changed in recent
years from answer extraction to answer generation, from single to
multi-document reading comprehension, and from learning from scratch to using
pre-trained embeddings. We also discuss the popular datasets and the evaluation
metrics in this field. The paper ends with investigating the most cited papers
and their contributions.
","[{'version': 'v1', 'created': 'Mon, 6 Jan 2020 13:54:06 GMT'}, {'version': 'v2', 'created': 'Tue, 20 Oct 2020 20:50:51 GMT'}]",2020-10-22,"[['Baradaran', 'Razieh', ''], ['Ghiasi', 'Razieh', ''], ['Amirkhani', 'Hossein', '']]"
1367397,2010.11067,Chenyu You,"Chenyu You, Nuo Chen, Yuexian Zou","Knowledge Distillation for Improved Accuracy in Spoken Question
  Answering",,,,,cs.CL cs.AI cs.IR cs.LG cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Spoken question answering (SQA) is a challenging task that requires the
machine to fully understand the complex spoken documents. Automatic speech
recognition (ASR) plays a significant role in the development of QA systems.
However, the recent work shows that ASR systems generate highly noisy
transcripts, which critically limit the capability of machine comprehension on
the SQA task. To address the issue, we present a novel distillation framework.
Specifically, we devise a training strategy to perform knowledge distillation
(KD) from spoken documents and written counterparts. Our work makes a step
towards distilling knowledge from the language model as a supervision signal to
lead to better student accuracy by reducing the misalignment between automatic
and manual transcriptions. Experiments demonstrate that our approach
outperforms several state-of-the-art language models on the Spoken-SQuAD
dataset.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 15:18:01 GMT'}]",2020-10-22,"[['You', 'Chenyu', ''], ['Chen', 'Nuo', ''], ['Zou', 'Yuexian', '']]"
1367500,2010.11170,Ozan \.Irsoy,"Tianze Shi, Igor Malioutov, Ozan \.Irsoy",Semantic Role Labeling as Syntactic Dependency Parsing,Appeared in EMNLP 2020,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We reduce the task of (span-based) PropBank-style semantic role labeling
(SRL) to syntactic dependency parsing. Our approach is motivated by our
empirical analysis that shows three common syntactic patterns account for over
98% of the SRL annotations for both English and Chinese data. Based on this
observation, we present a conversion scheme that packs SRL annotations into
dependency tree representations through joint labels that permit highly
accurate recovery back to the original format. This representation allows us to
train statistical dependency parsers to tackle SRL and achieve competitive
performance with the current state of the art. Our findings show the promise of
syntactic dependency trees in encoding semantic role relations within their
syntactic domain of locality, and point to potential further integration of
syntactic methods into semantic role labeling in the future.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 17:46:11 GMT'}]",2020-10-22,"[['Shi', 'Tianze', ''], ['Malioutov', 'Igor', ''], ['İrsoy', 'Ozan', '']]"
1367478,2010.11148,Jiahui Yu,"Jiahui Yu, Chung-Cheng Chiu, Bo Li, Shuo-yiin Chang, Tara N. Sainath,
  Yanzhang He, Arun Narayanan, Wei Han, Anmol Gulati, Yonghui Wu, Ruoming Pang","FastEmit: Low-latency Streaming ASR with Sequence-level Emission
  Regularization",tech report,,,,eess.AS cs.AI cs.CL cs.LG cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Streaming automatic speech recognition (ASR) aims to emit each hypothesized
word as quickly and accurately as possible. However, emitting fast without
degrading quality, as measured by word error rate (WER), is highly challenging.
Existing approaches including Early and Late Penalties and Constrained
Alignments penalize emission delay by manipulating per-token or per-frame
probability prediction in sequence transducer models. While being successful in
reducing delay, these approaches suffer from significant accuracy regression
and also require additional word alignment information from an existing model.
In this work, we propose a sequence-level emission regularization method, named
FastEmit, that applies latency regularization directly on per-sequence
probability in training transducer models, and does not require any alignment.
We demonstrate that FastEmit is more suitable to the sequence-level
optimization of transducer models for streaming ASR by applying it on various
end-to-end streaming ASR networks including RNN-Transducer,
Transformer-Transducer, ConvNet-Transducer and Conformer-Transducer. We achieve
150-300 ms latency reduction with significantly better accuracy over previous
techniques on a Voice Search test set. FastEmit also improves streaming ASR
accuracy from 4.4%/8.9% to 3.1%/7.5% WER, meanwhile reduces 90th percentile
latency from 210 ms to only 30 ms on LibriSpeech.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 17:05:01 GMT'}]",2020-10-22,"[['Yu', 'Jiahui', ''], ['Chiu', 'Chung-Cheng', ''], ['Li', 'Bo', ''], ['Chang', 'Shuo-yiin', ''], ['Sainath', 'Tara N.', ''], ['He', 'Yanzhang', ''], ['Narayanan', 'Arun', ''], ['Han', 'Wei', ''], ['Gulati', 'Anmol', ''], ['Wu', 'Yonghui', ''], ['Pang', 'Ruoming', '']]"
1367470,2010.11140,Yan Zeng,Yan Zeng and Jian-Yun Nie,"Generalized Conditioned Dialogue Generation Based on Pre-trained
  Language Model","9 pages, 2 figures",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We investigate the general problem of conditioned dialogue, in which a
condition label is used as input to designate the type of the target response
such as a persona. A major challenge for conditioned dialogue generation is the
lack of substantial dialogue data labeled with conditions. Thus, we propose to
complement the labeled dialogue data with labeled non-dialogue text data, and
fine-tune BERT based on them. Our fine-tuning approach utilizes BERT for both
encoder and decoder via different input representations and self-attention
masks in order to distinguish the source and target side. On the target
(generation) side, we use a new attention routing mechanism to choose between
generating a generic word or condition-related word at each position. Our model
is instantiated to persona- and topic-related dialogue. Experimental results in
both cases show that our approach can produce significantly better responses
than the state-of-the-art baselines.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 16:56:49 GMT'}]",2020-10-22,"[['Zeng', 'Yan', ''], ['Nie', 'Jian-Yun', '']]"
1367467,2010.11137,Yan Zeng,Yan Zeng and Jian-Yun Nie,Multi-Domain Dialogue State Tracking based on State Graph,"9 pages, 3 figures",,,,cs.CL cs.AI cs.HC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We investigate the problem of multi-domain Dialogue State Tracking (DST) with
open vocabulary, which aims to extract the state from the dialogue. Existing
approaches usually concatenate previous dialogue state with dialogue history as
the input to a bi-directional Transformer encoder. They rely on the
self-attention mechanism of Transformer to connect tokens in them. However,
attention may be paid to spurious connections, leading to wrong inference. In
this paper, we propose to construct a dialogue state graph in which domains,
slots and values from the previous dialogue state are connected properly.
Through training, the graph node and edge embeddings can encode co-occurrence
relations between domain-domain, slot-slot and domain-slot, reflecting the
strong transition paths in general dialogue. The state graph, encoded with
relational-GCN, is fused into the Transformer encoder. Experimental results
show that our approach achieves a new state of the art on the task while
remaining efficient. It outperforms existing open-vocabulary DST approaches.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 16:55:18 GMT'}]",2020-10-22,"[['Zeng', 'Yan', ''], ['Nie', 'Jian-Yun', '']]"
1367462,2010.11132,Te I,"Daniel Li, Te I, Naveen Arivazhagan, Colin Cherry, Dirk Padfield",Sentence Boundary Augmentation For Neural Machine Translation Robustness,"5 pages, 4 figures",,,,cs.CL cs.LG cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Neural Machine Translation (NMT) models have demonstrated strong state of the
art performance on translation tasks where well-formed training and evaluation
data are provided, but they remain sensitive to inputs that include errors of
various types. Specifically, in the context of long-form speech translation
systems, where the input transcripts come from Automatic Speech Recognition
(ASR), the NMT models have to handle errors including phoneme substitutions,
grammatical structure, and sentence boundaries, all of which pose challenges to
NMT robustness. Through in-depth error analysis, we show that sentence boundary
segmentation has the largest impact on quality, and we develop a simple data
augmentation strategy to improve segmentation robustness.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 16:44:48 GMT'}]",2020-10-22,"[['Li', 'Daniel', ''], ['I', 'Te', ''], ['Arivazhagan', 'Naveen', ''], ['Cherry', 'Colin', ''], ['Padfield', 'Dirk', '']]"
1367455,2010.11125,Angela Fan,"Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky,
  Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav
  Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky, Sergey Edunov,
  Edouard Grave, Michael Auli, Armand Joulin",Beyond English-Centric Multilingual Machine Translation,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Existing work in translation demonstrated the potential of massively
multilingual machine translation by training a single model able to translate
between any pair of languages. However, much of this work is English-Centric by
training only on data which was translated from or to English. While this is
supported by large sources of training data, it does not reflect translation
needs worldwide. In this work, we create a true Many-to-Many multilingual
translation model that can translate directly between any pair of 100
languages. We build and open source a training dataset that covers thousands of
language directions with supervised data, created through large-scale mining.
Then, we explore how to effectively increase model capacity through a
combination of dense scaling and language-specific sparse parameters to create
high quality models. Our focus on non-English-Centric models brings gains of
more than 10 BLEU when directly translating between non-English directions
while performing competitively to the best single systems of WMT. We
open-source our scripts so that others may reproduce the data, evaluation, and
final M2M-100 model.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 17:01:23 GMT'}]",2020-10-22,"[['Fan', 'Angela', ''], ['Bhosale', 'Shruti', ''], ['Schwenk', 'Holger', ''], ['Ma', 'Zhiyi', ''], ['El-Kishky', 'Ahmed', ''], ['Goyal', 'Siddharth', ''], ['Baines', 'Mandeep', ''], ['Celebi', 'Onur', ''], ['Wenzek', 'Guillaume', ''], ['Chaudhary', 'Vishrav', ''], ['Goyal', 'Naman', ''], ['Birch', 'Tom', ''], ['Liptchinsky', 'Vitaliy', ''], ['Edunov', 'Sergey', ''], ['Grave', 'Edouard', ''], ['Auli', 'Michael', ''], ['Joulin', 'Armand', '']]"
1367483,2010.11153,Tsz Kin Lam,"Tsz Kin Lam, Shigehiko Schamoni, Stefan Riezler",Cascaded Models With Cyclic Feedback For Direct Speech Translation,"5 pages, 1 figure",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Direct speech translation describes a scenario where only speech inputs and
corresponding translations are available. Such data are notoriously limited. We
present a technique that allows cascades of automatic speech recognition (ASR)
and machine translation (MT) to exploit in-domain direct speech translation
data in addition to out-of-domain MT and ASR data. After pre-training MT and
ASR, we use a feedback cycle where the downstream performance of the MT system
is used as a signal to improve the ASR system by self-training, and the MT
component is fine-tuned on multiple ASR outputs, making it more tolerant
towards spelling variations. A comparison to end-to-end speech translation
using components of identical architecture and the same data shows gains of up
to 3.8 BLEU points on LibriVoxDeEn and up to 5.1 BLEU points on CoVoST for
German-to-English speech translation.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 17:18:51 GMT'}]",2020-10-22,"[['Lam', 'Tsz Kin', ''], ['Schamoni', 'Shigehiko', ''], ['Riezler', 'Stefan', '']]"
1367453,2010.11123,Daniel Ajisafe,"Daniel Ajisafe, Oluwabukola Adegboro, Esther Oduntan, Tayo Arulogun","Towards End-to-End Training of Automatic Speech Recognition for Nigerian
  Pidgin",To appear in ICASSP 2021,,,,eess.AS cs.AI cs.CL cs.LG cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Nigerian Pidgin remains one of the most popular languages in West Africa.
With at least 75 million speakers along the West African coast, the language
has spread to diasporic communities through Nigerian immigrants in England,
Canada, and America, amongst others. In contrast, the language remains an
under-resourced one in the field of natural language processing, particularly
on speech recognition and translation tasks. In this work, we present the first
parallel (speech-to-text) data on Nigerian pidgin. We also trained the first
end-to-end speech recognition system (QuartzNet and Jasper model) on this
language which were both optimized using Connectionist Temporal Classification
(CTC) loss. With baseline results, we were able to achieve a low word error
rate (WER) of 0.77% using a greedy decoder on our dataset. Finally, we
open-source the data and code along with this publication in order to encourage
future research in this direction.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 16:32:58 GMT'}]",2020-10-22,"[['Ajisafe', 'Daniel', ''], ['Adegboro', 'Oluwabukola', ''], ['Oduntan', 'Esther', ''], ['Arulogun', 'Tayo', '']]"
1367449,2010.11119,Torsten Scholak,"Torsten Scholak, Raymond Li, Dzmitry Bahdanau, Harm de Vries, Chris
  Pal",DuoRAT: Towards Simpler Text-to-SQL Models,Code is available at https://github.com/ElementAI/duorat,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent research has shown that neural text-to-SQL models can effectively
translate natural language questions into corresponding SQL queries on unseen
databases. Working mostly on the Spider dataset, researchers have been
proposing increasingly sophisticated modelling approaches to the problem.
Contrary to this trend, in this paper we identify the aspects in which
text-to-SQL models can be simplified. We begin by building DuoRAT, a
re-implementation of the state-of-the-art RAT-SQL model that unlike RAT-SQL is
using only relation-aware or vanilla transformers as the building blocks. We
perform several ablation experiments using DuoRAT as the baseline model. Our
experiments confirm the usefulness of some of the techniques and point out the
redundancy of others, including structural SQL features and features that link
the question with the schema.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 16:27:49 GMT'}]",2020-10-22,"[['Scholak', 'Torsten', ''], ['Li', 'Raymond', ''], ['Bahdanau', 'Dzmitry', ''], ['de Vries', 'Harm', ''], ['Pal', 'Chris', '']]"
1367422,2010.11092,Rian Adam Rajagede,Rian Adam Rajagede and Rochana Prih Hastuti,Stacking Neural Network Models for Automatic Short Answer Scoring,"submitted to The 5th International Conference on Information
  Technology and Digital Applications 2020",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automatic short answer scoring is one of the text classification problems to
assess students' answers during exams automatically. Several challenges can
arise in making an automatic short answer scoring system, one of which is the
quantity and quality of the data. The data labeling process is not easy because
it requires a human annotator who is an expert in their field. Further, the
data imbalance process is also a challenge because the number of labels for
correct answers is always much less than the wrong answers. In this paper, we
propose the use of a stacking model based on neural network and XGBoost for
classification process with sentence embedding feature. We also propose to use
data upsampling method to handle imbalance classes and hyperparameters
optimization algorithm to find a robust model automatically. We use Ukara 1.0
Challenge dataset and our best model obtained an F1-score of 0.821 exceeding
the previous work at the same dataset.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 16:00:09 GMT'}]",2020-10-22,"[['Rajagede', 'Rian Adam', ''], ['Hastuti', 'Rochana Prih', '']]"
1367421,2010.11091,Mohiuddin Md Abdul Qudar,"Mohiuddin Md Abdul Qudar, Vijay Mago","TweetBERT: A Pretrained Language Representation Model for Twitter Text
  Analysis",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Twitter is a well-known microblogging social site where users express their
views and opinions in real-time. As a result, tweets tend to contain valuable
information. With the advancements of deep learning in the domain of natural
language processing, extracting meaningful information from tweets has become a
growing interest among natural language researchers. Applying existing language
representation models to extract information from Twitter does not often
produce good results. Moreover, there is no existing language representation
models for text analysis specific to the social media domain. Hence, in this
article, we introduce two TweetBERT models, which are domain specific language
presentation models, pre-trained on millions of tweets. We show that the
TweetBERT models significantly outperform the traditional BERT models in
Twitter text mining tasks by more than 7% on each Twitter dataset. We also
provide an extensive analysis by evaluating seven BERT models on 31 different
datasets. Our results validate our hypothesis that continuously training
language models on twitter corpus help performance with Twitter.
","[{'version': 'v1', 'created': 'Sat, 17 Oct 2020 00:45:02 GMT'}]",2020-10-22,"[['Qudar', 'Mohiuddin Md Abdul', ''], ['Mago', 'Vijay', '']]"
1367419,2010.11089,U\u{g}ur Merto\u{g}lu,U\u{g}ur Merto\u{g}lu Burkay Gen\c{c},Lexicon generation for detecting fake news,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  With the digitization of media, an immense amount of news data has been
generated by online sources, including mainstream media outlets as well as
social networks. However, the ease of production and distribution resulted in
circulation of fake news as well as credible, authentic news. The pervasive
dissemination of fake news has extreme negative impacts on individuals and
society. Therefore, fake news detection has recently become an emerging topic
as an interdisciplinary research field that is attracting significant attention
from many research disciplines, including social sciences and linguistics. In
this study, we propose a method primarily based on lexicons including a scoring
system to facilitate the detection of the fake news in Turkish. We contribute
to the literature by collecting a novel, large scale, and credible dataset of
Turkish news, and by constructing the first fake news detection lexicon for
Turkish.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 20:39:57 GMT'}]",2020-10-22,"[['Genç', 'Uğur Mertoğlu Burkay', '']]"
1367415,2010.11085,Sai Muralidhar Jayanthi,"Sai Muralidhar Jayanthi, Danish Pruthi, Graham Neubig",NeuSpell: A Neural Spelling Correction Toolkit,Accepted at EMNLP 2020 (system demonstrations),,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We introduce NeuSpell, an open-source toolkit for spelling correction in
English. Our toolkit comprises ten different models, and benchmarks them on
naturally occurring misspellings from multiple sources. We find that many
systems do not adequately leverage the context around the misspelt token. To
remedy this, (i) we train neural models using spelling errors in context,
synthetically constructed by reverse engineering isolated misspellings; and
(ii) use contextual representations. By training on our synthetic examples,
correction rates improve by 9% (absolute) compared to the case when models are
trained on randomly sampled character perturbations. Using richer contextual
representations boosts the correction rate by another 3%. Our toolkit enables
practitioners to use our proposed and existing spelling correction systems,
both via a unified command line, as well as a web interface. Among many
potential applications, we demonstrate the utility of our spell-checkers in
combating adversarial misspellings. The toolkit can be accessed at
neuspell.github.io. Code and pretrained models are available at
http://github.com/neuspell/neuspell.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 15:53:29 GMT'}]",2020-10-22,"[['Jayanthi', 'Sai Muralidhar', ''], ['Pruthi', 'Danish', ''], ['Neubig', 'Graham', '']]"
1367410,2010.11080,Tao Yu,"Tao Yu, Shafiq Joty",Online Conversation Disentanglement with Pointer Networks,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Huge amounts of textual conversations occur online every day, where multiple
conversations take place concurrently. Interleaved conversations lead to
difficulties in not only following the ongoing discussions but also extracting
relevant information from simultaneous messages. Conversation disentanglement
aims to separate intermingled messages into detached conversations. However,
existing disentanglement methods rely mostly on handcrafted features that are
dataset specific, which hinders generalization and adaptability. In this work,
we propose an end-to-end online framework for conversation disentanglement that
avoids time-consuming domain-specific feature engineering. We design a novel
way to embed the whole utterance that comprises timestamp, speaker, and message
text, and proposes a custom attention mechanism that models disentanglement as
a pointing problem while effectively capturing inter-utterance interactions in
an end-to-end fashion. We also introduce a joint-learning objective to better
capture contextual information. Our experiments on the Ubuntu IRC dataset show
that our method achieves state-of-the-art performance in both link and
conversation prediction tasks.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 15:43:07 GMT'}]",2020-10-22,"[['Yu', 'Tao', ''], ['Joty', 'Shafiq', '']]"
1319317,2007.07803,Anant Khandelwal,Anant Khandelwal,Fine-Tune Longformer for Jointly Predicting Rumor Stance and Veracity,"10 pages, 2 figures, 6 tables; Accepted at ACM CoDS-COMAD 2021",,10.1145/3430984.3431007,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Increased usage of social media caused the popularity of news and events
which are not even verified, resulting in spread of rumors allover the web. Due
to widely available social media platforms and increased usage caused the data
to be available in huge amounts.The manual methods to process such large data
is costly and time-taking, so there has been an increased attention to process
and verify such content automatically for the presence of rumors. A lot of
research studies reveal that to identify the stances of posts in the discussion
thread of such events and news is an important preceding step before identify
the rumor veracity. In this paper,we propose a multi-task learning framework
for jointly predicting rumor stance and veracity on the dataset released at
SemEval 2019 RumorEval: Determining rumor veracity and support for
rumors(SemEval 2019 Task 7), which includes social media rumors stem from a
variety of breaking news stories from Reddit as well as Twit-ter. Our framework
consists of two parts: a) The bottom part of our framework classifies the
stance for each post in the conversation thread discussing a rumor via
modelling the multi-turn conversation and make each post aware of its
neighboring posts. b) The upper part predicts the rumor veracity of the
conversation thread with stance evolution obtained from the bottom part.
Experimental results on SemEval 2019 Task 7 dataset show that our method
outperforms previous methods on both rumor stance classification and veracity
prediction
","[{'version': 'v1', 'created': 'Wed, 15 Jul 2020 17:09:17 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 11:25:20 GMT'}]",2020-10-23,"[['Khandelwal', 'Anant', '']]"
1365058,2010.08728,Jin Xu,"Jin Xu, Yinuo Guo, Junfeng Hu","Incorporate Semantic Structures into Machine Translation Evaluation via
  UCCA",WMT2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Copying mechanism has been commonly used in neural paraphrasing networks and
other text generation tasks, in which some important words in the input
sequence are preserved in the output sequence. Similarly, in machine
translation, we notice that there are certain words or phrases appearing in all
good translations of one source text, and these words tend to convey important
semantic information. Therefore, in this work, we define words carrying
important semantic meanings in sentences as semantic core words. Moreover, we
propose an MT evaluation approach named Semantically Weighted Sentence
Similarity (SWSS). It leverages the power of UCCA to identify semantic core
words, and then calculates sentence similarity scores on the overlap of
semantic core words. Experimental results show that SWSS can consistently
improve the performance of popular MT evaluation metrics which are based on
lexical similarity.
","[{'version': 'v1', 'created': 'Sat, 17 Oct 2020 06:47:58 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 03:38:19 GMT'}]",2020-10-23,"[['Xu', 'Jin', ''], ['Guo', 'Yinuo', ''], ['Hu', 'Junfeng', '']]"
1142383,1906.10197,Kanishk Gandhi,Kanishk Gandhi and Brenden M. Lake,Mutual exclusivity as a challenge for deep neural networks,"Published in Advances in Neural Information Processing Systems
  (NeurIPS) 33",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Strong inductive biases allow children to learn in fast and adaptable ways.
Children use the mutual exclusivity (ME) bias to help disambiguate how words
map to referents, assuming that if an object has one label then it does not
need another. In this paper, we investigate whether or not standard neural
architectures have an ME bias, demonstrating that they lack this learning
assumption. Moreover, we show that their inductive biases are poorly matched to
lifelong learning formulations of classification and translation. We
demonstrate that there is a compelling case for designing neural networks that
reason by mutual exclusivity, which remains an open challenge.
","[{'version': 'v1', 'created': 'Mon, 24 Jun 2019 19:47:05 GMT'}, {'version': 'v2', 'created': 'Fri, 6 Dec 2019 18:51:28 GMT'}, {'version': 'v3', 'created': 'Wed, 21 Oct 2020 21:50:33 GMT'}]",2020-10-23,"[['Gandhi', 'Kanishk', ''], ['Lake', 'Brenden M.', '']]"
1367934,2010.11604,Changzhen Ji,"Changzhen Ji, Conghui Zhu and Tiejun Zhao",AI-lead Court Debate Case Investigation,"4 pages, 2 figures",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The multi-role judicial debate composed of the plaintiff, defendant, and
judge is an important part of the judicial trial. Different from other types of
dialogue, questions are raised by the judge, The plaintiff, plaintiff's agent
defendant, and defendant's agent would be to debating so that the trial can
proceed in an orderly manner. Question generation is an important task in
Natural Language Generation. In the judicial trial, it can help the judge raise
efficient questions so that the judge has a clearer understanding of the case.
In this work, we propose an innovative end-to-end question generation
model-Trial Brain Model (TBM) to build a Trial Brain, it can generate the
questions the judge wants to ask through the historical dialogue between the
plaintiff and the defendant. Unlike prior efforts in natural language
generation, our model can learn the judge's questioning intention through
predefined knowledge. We do experiments on real-world datasets, the
experimental results show that our model can provide a more accurate question
in the multi-role court debate scene.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 11:05:14 GMT'}]",2020-10-23,"[['Ji', 'Changzhen', ''], ['Zhu', 'Conghui', ''], ['Zhao', 'Tiejun', '']]"
1333495,2008.05773,Yu Wu,"Sanyuan Chen, Yu Wu, Zhuo Chen, Jian Wu, Jinyu Li, Takuya Yoshioka,
  Chengyi Wang, Shujie Liu, Ming Zhou",Continuous Speech Separation with Conformer,,,,,eess.AS cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Continuous speech separation plays a vital role in complicated speech related
tasks such as conversation transcription. The separation model extracts a
single speaker signal from a mixed speech. In this paper, we use transformer
and conformer in lieu of recurrent neural networks in the separation system, as
we believe capturing global information with the self-attention based method is
crucial for the speech separation. Evaluating on the LibriCSS dataset, the
conformer separation model achieves state of the art results, with a relative
23.5% word error rate (WER) reduction from bi-directional LSTM (BLSTM) in the
utterance-wise evaluation and a 15.4% WER reduction in the continuous
evaluation.
","[{'version': 'v1', 'created': 'Thu, 13 Aug 2020 09:36:05 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 12:38:51 GMT'}]",2020-10-23,"[['Chen', 'Sanyuan', ''], ['Wu', 'Yu', ''], ['Chen', 'Zhuo', ''], ['Wu', 'Jian', ''], ['Li', 'Jinyu', ''], ['Yoshioka', 'Takuya', ''], ['Wang', 'Chengyi', ''], ['Liu', 'Shujie', ''], ['Zhou', 'Ming', '']]"
1204524,1911.05930,Ruobing Xie,"Ruobing Xie, Yanan Lu, Fen Lin, Leyu Lin",FAQ-based Question Answering via Knowledge Anchors,"12 pages, accepted by NLPCC-2020",NLPCC-2020,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Question answering (QA) aims to understand questions and find appropriate
answers. In real-world QA systems, Frequently Asked Question (FAQ) based QA is
usually a practical and effective solution, especially for some complicated
questions (e.g., How and Why). Recent years have witnessed the great successes
of knowledge graphs (KGs) in KBQA systems, while there are still few works
focusing on making full use of KGs in FAQ-based QA. In this paper, we propose a
novel Knowledge Anchor based Question Answering (KAQA) framework for FAQ-based
QA to better understand questions and retrieve more appropriate answers. More
specifically, KAQA mainly consists of three modules: knowledge graph
construction, query anchoring and query-document matching. We consider entities
and triples of KGs in texts as knowledge anchors to precisely capture the core
semantics, which brings in higher precision and better interpretability. The
multi-channel matching strategy also enables most sentence matching models to
be flexibly plugged in our KAQA framework to fit different real-world
computation limitations. In experiments, we evaluate our models on both offline
and online query-document matching tasks on a real-world FAQ-based QA system in
WeChat Search, with detailed analysis, ablation tests and case studies. The
significant improvements confirm the effectiveness and robustness of the KAQA
framework in real-world FAQ-based QA.
","[{'version': 'v1', 'created': 'Thu, 14 Nov 2019 04:18:55 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 07:50:31 GMT'}]",2020-10-23,"[['Xie', 'Ruobing', ''], ['Lu', 'Yanan', ''], ['Lin', 'Fen', ''], ['Lin', 'Leyu', '']]"
1367923,2010.11593,Hari Krishna Vydana Mr,"Hari Krishna Vydana, Lukas Burget, Jan Cernocky",A Technical Report: BUT Speech Translation Systems,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The paper describes the BUT's speech translation systems. The systems are
English$\longrightarrow$German offline speech translation systems. The systems
are based on our previous works \cite{Jointly_trained_transformers}. Though
End-to-End and cascade~(ASR-MT) spoken language translation~(SLT) systems are
reaching comparable performances, a large degradation is observed when
translating ASR hypothesis compared to the oracle input text. To reduce this
performance degradation, we have jointly-trained ASR and MT modules with ASR
objective as an auxiliary loss. Both the networks are connected through the
neural hidden representations. This model has an End-to-End differentiable path
with respect to the final objective function and also utilizes the ASR
objective for better optimization. During the inference both the modules(i.e.,
ASR and MT) are connected through the hidden representations corresponding to
the n-best hypotheses. Ensembling with independently trained ASR and MT models
have further improved the performance of the system.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 10:52:31 GMT'}]",2020-10-23,"[['Vydana', 'Hari Krishna', ''], ['Burget', 'Lukas', ''], ['Cernocky', 'Jan', '']]"
1367908,2010.11578,Navita Goyal,"Navita Goyal, Balaji Vasan Srinivasan, Anandhavelu N, Abhilasha
  Sancheti","Multi-dimensional Style Transfer for Partially Annotated Data using
  Language Models as Discriminators",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Style transfer has been widely explored in natural language generation with
non-parallel corpus by directly or indirectly extracting a notion of style from
source and target domain corpus. A common aspect among the existing approaches
is the prerequisite of joint annotations across all the stylistic dimensions
under consideration. Availability of such dataset across a combination of
styles is a limiting factor in extending state-of-the art style transfer setups
to multiple style dimensions. While cascading single-dimensional models across
multiple styles is a possibility, it suffers from content loss, especially when
the style dimensions are not completely independent of each other. In our work,
we attempt to relax this restriction on requirement of jointly annotated data
across multiple styles being inspected and make use of independently acquired
data across different style dimensions without any additional annotations. We
initialize an encoder-decoder setup with large transformer-based language
models pre-trained on a generic corpus and enhance its re-writing capability to
multiple styles by employing multiple language models as discriminators.
Through quantitative and qualitative evaluation, we show the ability of our
model to control for styles across multiple style-dimensions while preserving
content of the input text and compare it against baselines which involve
cascaded state-of-the-art uni-dimensional style transfer models.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 10:16:29 GMT'}]",2020-10-23,"[['Goyal', 'Navita', ''], ['Srinivasan', 'Balaji Vasan', ''], ['N', 'Anandhavelu', ''], ['Sancheti', 'Abhilasha', '']]"
1367892,2010.11562,Amit Gajbhiye,"Amit Gajbhiye, Thomas Winterbottom, Noura Al Moubayed, and Steven
  Bradley",Bilinear Fusion of Commonsense Knowledge with Attention-Based NLI Models,"Published in Lecture Notes in Computer Science, Springer
  International Publishing",,10.1007/978-3-030-61609-0_50,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We consider the task of incorporating real-world commonsense knowledge into
deep Natural Language Inference (NLI) models. Existing external knowledge
incorporation methods are limited to lexical level knowledge and lack
generalization across NLI models, datasets, and commonsense knowledge sources.
To address these issues, we propose a novel NLI model-independent neural
framework, BiCAM. BiCAM incorporates real-world commonsense knowledge into NLI
models. Combined with convolutional feature detectors and bilinear feature
fusion, BiCAM provides a conceptually simple mechanism that generalizes well.
Quantitative evaluations with two state-of-the-art NLI baselines on SNLI and
SciTail datasets in conjunction with ConceptNet and Aristo Tuple KGs show that
BiCAM considerably improves the accuracy the incorporated NLI baselines. For
example, our BiECAM model, an instance of BiCAM, on the challenging SciTail
dataset, improves the accuracy of incorporated baselines by 7.0% with
ConceptNet, and 8.0% with Aristo Tuple KG.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 09:38:08 GMT'}]",2020-10-23,"[['Gajbhiye', 'Amit', ''], ['Winterbottom', 'Thomas', ''], ['Moubayed', 'Noura Al', ''], ['Bradley', 'Steven', '']]"
1274117,2004.09347,Abhishek Niranjan,"Abhishek Niranjan, Mukesh Sharma, Sai Bharath Chandra Gutha, M Ali
  Basha Shaik","WHALETRANS: E2E WHisper to nAturaL spEech conversion using modified
  TRANSformer network",,,,,eess.AS cs.CL cs.LG cs.SD stat.ML,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  We investigate whisper-to-natural-speech conversion using
sequence-to-sequence approach by proposing modified transformer architecture.
We investigate different features like mel frequency cepstral coefficients and
smoothed spectral features. The proposed networks are trained end-to-end using
supervised approach for feature-to-feature transformation. Further, We also
investigate the effectiveness of embedded auxiliary decoder used after N
encoder sub-layers, and is trained with the frame-level objective function for
identifying source phoneme labels. We show results on wTIMIT and CHAINS
datasets by measuring word error rate using end-to-end ASR and also BLEU scores
for the generated speech. In addition, we measure spectral shape of it by
measuring formant distributions w.r.t. the reference speech, as formant
divergence metric. We have found whisper-to-natural converted speech formants
probability distribution is similar to the ground-truth distribution. To the
authors' best knowledge, this is the first time modified transformer has been
applied for whisper-to-natural-speech conversion and vice versa.
","[{'version': 'v1', 'created': 'Mon, 20 Apr 2020 14:47:46 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 07:08:37 GMT'}]",2020-10-23,"[['Niranjan', 'Abhishek', ''], ['Sharma', 'Mukesh', ''], ['Gutha', 'Sai Bharath Chandra', ''], ['Shaik', 'M Ali Basha', '']]"
1367854,2010.11524,Tatiana Likhomanenko,"Tatiana Likhomanenko, Qiantong Xu, Jacob Kahn, Gabriel Synnaeve, Ronan
  Collobert",slimIPL: Language-Model-Free Iterative Pseudo-Labeling,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent results in end-to-end ASR have demonstrated the efficacy of simple
pseudo-labeling for semi-supervised models trained both with Connectionist
Temporal Classification (CTC) and Sequence-to-Sequence (seq2seq) losses.
Iterative Pseudo-Labeling (IPL), which continuously trains a single model using
pseudo-labels iteratively re-generated as the model learns, has been shown to
further increase performance in ASR. We improve upon the IPL algorithm: as the
model learns, we propose to iteratively re-generate transcriptions with hard
labels (the most probable tokens) assignments, that is without a language
model. We call this approach Language-Model-Free IPL (slimIPL) and we give a
resultant training setup for CTC and seq2seq models. At inference, our
experiments show that decoding with a strong language model is more beneficial
with slimIPL than IPL, asIPL exhibits some language model over-fitting issues.
Compared to prior work on semi-supervised and unsupervised approaches, slimIPL
not only simplifies the training process, but also achieves competitive and
state-of-the-art results on LibriSpeech test sets in both standard and
low-resource settings.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 08:36:33 GMT'}]",2020-10-23,"[['Likhomanenko', 'Tatiana', ''], ['Xu', 'Qiantong', ''], ['Kahn', 'Jacob', ''], ['Synnaeve', 'Gabriel', ''], ['Collobert', 'Ronan', '']]"
1278659,2004.13889,Tasnim Mohiuddin,"Tasnim Mohiuddin, M Saiful Bari, and Shafiq Joty","LNMap: Departures from Isomorphic Assumption in Bilingual Lexicon
  Induction Through Non-Linear Mapping in Latent Space",EMNLP 2020 accepted paper,,,,cs.CL cs.LG,http://creativecommons.org/publicdomain/zero/1.0/,"  Most of the successful and predominant methods for bilingual lexicon
induction (BLI) are mapping-based, where a linear mapping function is learned
with the assumption that the word embedding spaces of different languages
exhibit similar geometric structures (i.e., approximately isomorphic). However,
several recent studies have criticized this simplified assumption showing that
it does not hold in general even for closely related languages. In this work,
we propose a novel semi-supervised method to learn cross-lingual word
embeddings for BLI. Our model is independent of the isomorphic assumption and
uses nonlinear mapping in the latent space of two independently trained
auto-encoders. Through extensive experiments on fifteen (15) different language
pairs (in both directions) comprising resource-rich and low-resource languages
from two different datasets, we demonstrate that our method outperforms
existing models by a good margin. Ablation studies show the importance of
different model components and the necessity of non-linear mapping.
","[{'version': 'v1', 'created': 'Tue, 28 Apr 2020 23:28:26 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 00:42:16 GMT'}]",2020-10-23,"[['Mohiuddin', 'Tasnim', ''], ['Bari', 'M Saiful', ''], ['Joty', 'Shafiq', '']]"
1367883,2010.11553,Hrituraj Singh,"Hrituraj Singh, Gaurav Verma, Balaji Vasan Srinivasan","Incorporating Stylistic Lexical Preferences in Generative Language
  Models",To Appear in Findings of EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While recent advances in language modeling have resulted in powerful
generation models, their generation style remains implicitly dependent on the
training data and can not emulate a specific target style. Leveraging the
generative capabilities of a transformer-based language models, we present an
approach to induce certain target-author attributes by incorporating continuous
multi-dimensional lexical preferences of an author into generative language
models. We introduce rewarding strategies in a reinforcement learning framework
that encourages the use of words across multiple categorical dimensions, to
varying extents. Our experiments demonstrate that the proposed approach can
generate text that distinctively aligns with a given target author's lexical
style. We conduct quantitative and qualitative comparisons with competitive and
relevant baselines to illustrate the benefits of the proposed approach.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 09:24:05 GMT'}]",2020-10-23,"[['Singh', 'Hrituraj', ''], ['Verma', 'Gaurav', ''], ['Srinivasan', 'Balaji Vasan', '']]"
1367878,2010.11548,Artem Kramov,"S.D. Pogorilyy, A.A. Kramov",Method of noun phrase detection in Ukrainian texts,"25 pages, in Ukrainian, 5 figures, 2 tables",Control Systems and Computers. 2019. Issue 5. P. 48-59,10.15407/csc.2019.05.048,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Introduction. The area of natural language processing considers AI-complete
tasks that cannot be solved using traditional algorithmic actions. Such tasks
are commonly implemented with the usage of machine learning methodology and
means of computer linguistics. One of the preprocessing tasks of a text is the
search of noun phrases. The accuracy of this task has implications for the
effectiveness of many other tasks in the area of natural language processing.
In spite of the active development of research in the area of natural language
processing, the investigation of the search for noun phrases within Ukrainian
texts are still at an early stage. Results. The different methods of noun
phrases detection have been analyzed. The expediency of the representation of
sentences as a tree structure has been justified. The key disadvantage of many
methods of noun phrase detection is the severe dependence of the effectiveness
of their detection from the features of a certain language. Taking into account
the unified format of sentence processing and the availability of the trained
model for the building of sentence trees for Ukrainian texts, the Universal
Dependency model has been chosen. The complex method of noun phrases detection
in Ukrainian texts utilizing Universal Dependencies means and named-entity
recognition model has been suggested. Experimental verification of the
effectiveness of the suggested method on the corpus of Ukrainian news has been
performed. Different metrics of method accuracy have been calculated.
Conclusions. The results obtained can indicate that the suggested method can be
used to find noun phrases in Ukrainian texts. An accuracy increase of the
method can be made with the usage of appropriate named-entity recognition
models according to a subject area.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 09:20:24 GMT'}]",2020-10-23,"[['Pogorilyy', 'S. D.', ''], ['Kramov', 'A. A.', '']]"
1206964,1911.08370,Vladimir Vargas-Calder\'on,"Vladimir Vargas-Calder\'on and Nicol\'as Parra-A. and Jorge E. Camargo
  and Herbert Vinck-Posada","Event detection in Colombian security Twitter news using fine-grained
  latent topic analysis","pre-print exposed at CATAI (Bogot\'a, Colombia)",,,,cs.SI cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Cultural and social dynamics are important concepts that must be understood
in order to grasp what a community cares about. To that end, an excellent
source of information on what occurs in a community is the news, especially in
recent years, when mass media giants use social networks to communicate and
interact with their audience. In this work, we use a method to discover latent
topics in tweets from Colombian Twitter news accounts in order to identify the
most prominent events in the country. We pay particular attention to security,
violence and crime-related tweets because of the violent environment that
surrounds Colombian society. The latent topic discovery method that we use
builds vector representations of the tweets by using FastText and finds
clusters of tweets through the K-means clustering algorithm. The number of
clusters is found by measuring the $C_V$ coherence for a range of number of
topics of the Latent Dirichlet Allocation (LDA) model. We finally use Uniform
Manifold Approximation and Projection (UMAP) for dimensionality reduction to
visualise the tweets vectors. Once the clusters related to security, violence
and crime are identified, we proceed to apply the same method within each
cluster to perform a fine-grained analysis in which specific events mentioned
in the news are grouped together. Our method is able to discover event-specific
sets of news, which is the baseline to perform an extensive analysis of how
people engage in Twitter threads on the different types of news, with an
emphasis on security, violence and crime-related tweets.
","[{'version': 'v1', 'created': 'Tue, 19 Nov 2019 15:58:14 GMT'}]",2020-10-23,"[['Vargas-Calderón', 'Vladimir', ''], ['Parra-A.', 'Nicolás', ''], ['Camargo', 'Jorge E.', ''], ['Vinck-Posada', 'Herbert', '']]"
1366378,2010.10048,Renjie Zheng,"Renjie Zheng, Mingbo Ma, Baigong Zheng, Kaibo Liu, Jiahong Yuan,
  Kenneth Church, Liang Huang","Fluent and Low-latency Simultaneous Speech-to-Speech Translation with
  Self-adaptive Training","10 pages, accepted by Findings of EMNLP 2020",Findings of EMNLP 2020,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Simultaneous speech-to-speech translation is widely useful but extremely
challenging, since it needs to generate target-language speech concurrently
with the source-language speech, with only a few seconds delay. In addition, it
needs to continuously translate a stream of sentences, but all recent solutions
merely focus on the single-sentence scenario. As a result, current approaches
accumulate latencies progressively when the speaker talks faster, and introduce
unnatural pauses when the speaker talks slower. To overcome these issues, we
propose Self-Adaptive Translation (SAT) which flexibly adjusts the length of
translations to accommodate different source speech rates. At similar levels of
translation quality (as measured by BLEU), our method generates more fluent
target speech (as measured by the naturalness metric MOS) with substantially
lower latency than the baseline, in both Zh <-> En directions.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 06:02:15 GMT'}, {'version': 'v2', 'created': 'Wed, 21 Oct 2020 19:12:17 GMT'}]",2020-10-23,"[['Zheng', 'Renjie', ''], ['Ma', 'Mingbo', ''], ['Zheng', 'Baigong', ''], ['Liu', 'Kaibo', ''], ['Yuan', 'Jiahong', ''], ['Church', 'Kenneth', ''], ['Huang', 'Liang', '']]"
1367869,2010.11539,Changzhen Ji,"Changzhen Ji, Xin Zhou, Yating Zhang, Xiaozhong Liu, Changlong Sun,
  Conghui Zhu and Tiejun Zhao",Cross Copy Network for Dialogue Generation,"11 pages, 4 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In the past few years, audiences from different fields witness the
achievements of sequence-to-sequence models (e.g., LSTM+attention, Pointer
Generator Networks, and Transformer) to enhance dialogue content generation.
While content fluency and accuracy often serve as the major indicators for
model training, dialogue logics, carrying critical information for some
particular domains, are often ignored. Take customer service and court debate
dialogue as examples, compatible logics can be observed across different
dialogue instances, and this information can provide vital evidence for
utterance generation. In this paper, we propose a novel network architecture -
Cross Copy Networks(CCN) to explore the current dialog context and similar
dialogue instances' logical structure simultaneously. Experiments with two
tasks, court debate and customer service content generation, proved that the
proposed algorithm is superior to existing state-of-art content generation
models.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 09:03:23 GMT'}]",2020-10-23,"[['Ji', 'Changzhen', ''], ['Zhou', 'Xin', ''], ['Zhang', 'Yating', ''], ['Liu', 'Xiaozhong', ''], ['Sun', 'Changlong', ''], ['Zhu', 'Conghui', ''], ['Zhao', 'Tiejun', '']]"
1367904,2010.11574,Jan Christian Blaise Cruz,"Jan Christian Blaise Cruz, Jose Kristian Resabal, James Lin, Dan John
  Velasco and Charibeth Cheng","Investigating the True Performance of Transformers in Low-Resource
  Languages: A Case Study in Automatic Corpus Creation","Code and data available at
  https://github.com/jcblaisecruz02/Filipino-Text-Benchmarks",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Transformers represent the state-of-the-art in Natural Language Processing
(NLP) in recent years, proving effective even in tasks done in low-resource
languages. While pretrained transformers for these languages can be made, it is
challenging to measure their true performance and capacity due to the lack of
hard benchmark datasets, as well as the difficulty and cost of producing them.
In this paper, we present three contributions: First, we propose a methodology
for automatically producing Natural Language Inference (NLI) benchmark datasets
for low-resource languages using published news articles. Through this, we
create and release NewsPH-NLI, the first sentence entailment benchmark dataset
in the low-resource Filipino language. Second, we produce new pretrained
transformers based on the ELECTRA technique to further alleviate the resource
scarcity in Filipino, benchmarking them on our dataset against other
commonly-used transfer learning techniques. Lastly, we perform analyses on
transfer learning techniques to shed light on their true performance when
operating in low-data domains through the use of degradation tests.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 10:09:10 GMT'}]",2020-10-23,"[['Cruz', 'Jan Christian Blaise', ''], ['Resabal', 'Jose Kristian', ''], ['Lin', 'James', ''], ['Velasco', 'Dan John', ''], ['Cheng', 'Charibeth', '']]"
1363409,2010.07079,Emily Dinan,"Jing Xu, Da Ju, Margaret Li, Y-Lan Boureau, Jason Weston, Emily Dinan",Recipes for Safety in Open-domain Chatbots,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Models trained on large unlabeled corpora of human interactions will learn
patterns and mimic behaviors therein, which include offensive or otherwise
toxic behavior and unwanted biases. We investigate a variety of methods to
mitigate these issues in the context of open-domain generative dialogue models.
We introduce a new human-and-model-in-the-loop framework for both training
safer models and for evaluating them, as well as a novel method to distill
safety considerations inside generative models without the use of an external
classifier at deployment time. We conduct experiments comparing these methods
and find our new techniques are (i) safer than existing models as measured by
automatic and human evaluations while (ii) maintaining usability metrics such
as engagingness relative to the state of the art. We then discuss the
limitations of this work by analyzing failure cases of our models.
","[{'version': 'v1', 'created': 'Wed, 14 Oct 2020 13:26:39 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 16:56:50 GMT'}]",2020-10-23,"[['Xu', 'Jing', ''], ['Ju', 'Da', ''], ['Li', 'Margaret', ''], ['Boureau', 'Y-Lan', ''], ['Weston', 'Jason', ''], ['Dinan', 'Emily', '']]"
1305991,2006.11477,Michael Auli,"Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli","wav2vec 2.0: A Framework for Self-Supervised Learning of Speech
  Representations",,,,,cs.CL cs.LG cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We show for the first time that learning powerful representations from speech
audio alone followed by fine-tuning on transcribed speech can outperform the
best semi-supervised methods while being conceptually simpler. wav2vec 2.0
masks the speech input in the latent space and solves a contrastive task
defined over a quantization of the latent representations which are jointly
learned. Experiments using all labeled data of Librispeech achieve 1.8/3.3 WER
on the clean/other test sets. When lowering the amount of labeled data to one
hour, wav2vec 2.0 outperforms the previous state of the art on the 100 hour
subset while using 100 times less labeled data. Using just ten minutes of
labeled data and pre-training on 53k hours of unlabeled data still achieves
4.8/8.2 WER. This demonstrates the feasibility of speech recognition with
limited amounts of labeled data.
","[{'version': 'v1', 'created': 'Sat, 20 Jun 2020 02:35:02 GMT'}, {'version': 'v2', 'created': 'Tue, 22 Sep 2020 04:26:03 GMT'}, {'version': 'v3', 'created': 'Thu, 22 Oct 2020 06:09:10 GMT'}]",2020-10-23,"[['Baevski', 'Alexei', ''], ['Zhou', 'Henry', ''], ['Mohamed', 'Abdelrahman', ''], ['Auli', 'Michael', '']]"
1362320,2010.05990,Jordan J. Bird,"Jordan J. Bird, Anik\'o Ek\'art, Diego R. Faria","Chatbot Interaction with Artificial Intelligence: Human Data
  Augmentation with T5 and Language Transformer Ensemble for Text
  Classification","18 pages, 10 figures, 8 tables",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this work, we present the Chatbot Interaction with Artificial Intelligence
(CI-AI) framework as an approach to the training of deep learning chatbots for
task classification. The intelligent system augments human-sourced data via
artificial paraphrasing in order to generate a large set of training data for
further classical, attention, and language transformation-based learning
approaches for Natural Language Processing. Human beings are asked to
paraphrase commands and questions for task identification for further execution
of a machine. The commands and questions are split into training and validation
sets. A total of 483 responses were recorded. Secondly, the training set is
paraphrased by the T5 model in order to augment it with further data. Seven
state-of-the-art transformer-based text classification algorithms (BERT,
DistilBERT, RoBERTa, DistilRoBERTa, XLM, XLM-RoBERTa, and XLNet) are
benchmarked for both sets after fine-tuning on the training data for two
epochs. We find that all models are improved when training data is augmented by
the T5 model, with an average increase of classification accuracy by 4.01%. The
best result was the RoBERTa model trained on T5 augmented data which achieved
98.96% classification accuracy. Finally, we found that an ensemble of the five
best-performing transformer models via Logistic Regression of output label
predictions led to an accuracy of 99.59% on the dataset of human responses. A
highly-performing model allows the intelligent system to interpret human
commands at the social-interaction level through a chatbot-like interface (e.g.
""Robot, can we have a conversation?"") and allows for better accessibility to AI
by non-technical users.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 19:37:18 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 14:33:08 GMT'}]",2020-10-23,"[['Bird', 'Jordan J.', ''], ['Ekárt', 'Anikó', ''], ['Faria', 'Diego R.', '']]"
1338905,2008.11183,Vladimir Vargas-Calder\'on,"Vladimir Vargas-Calder\'on and Juan S. Fl\'orez and Leonel F. Ardila
  and Nicolas Parra-A. and Jorge E. Camargo and Nelson Vargas",Learning from students' perception on professors through opinion mining,,,,,cs.CL cs.CY cs.NA math.NA,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Students' perception of classes measured through their opinions on teaching
surveys allows to identify deficiencies and problems, both in the environment
and in the learning methodologies. The purpose of this paper is to study,
through sentiment analysis using natural language processing (NLP) and machine
learning (ML) techniques, those opinions in order to identify topics that are
relevant for students, as well as predicting the associated sentiment via
polarity analysis. As a result, it is implemented, trained and tested two
algorithms to predict the associated sentiment as well as the relevant topics
of such opinions. The combination of both approaches then becomes useful to
identify specific properties of the students' opinions associated with each
sentiment label (positive, negative or neutral opinions) and topic.
Furthermore, we explore the possibility that students' perception surveys are
carried out without closed questions, relying on the information that students
can provide through open questions where they express their opinions about
their classes.
","[{'version': 'v1', 'created': 'Tue, 25 Aug 2020 17:36:45 GMT'}]",2020-10-23,"[['Vargas-Calderón', 'Vladimir', ''], ['Flórez', 'Juan S.', ''], ['Ardila', 'Leonel F.', ''], ['Parra-A.', 'Nicolas', ''], ['Camargo', 'Jorge E.', ''], ['Vargas', 'Nelson', '']]"
1368077,2010.11747,Ivana Kvapilikova,"Ivana Kvapil\'ikov\'a, Tom Kocmi, Ond\v{r}ej Bojar","CUNI Systems for the Unsupervised and Very Low Resource Translation Task
  in WMT20",WMT20,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents a description of CUNI systems submitted to the WMT20 task
on unsupervised and very low-resource supervised machine translation between
German and Upper Sorbian. We experimented with training on synthetic data and
pre-training on a related language pair. In the fully unsupervised scenario, we
achieved 25.5 and 23.7 BLEU translating from and into Upper Sorbian,
respectively. Our low-resource systems relied on transfer learning from
German-Czech parallel data and achieved 57.4 BLEU and 56.1 BLEU, which is an
improvement of 10 BLEU points over the baseline trained only on the available
small German-Upper Sorbian parallel corpus.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 14:04:01 GMT'}]",2020-10-23,"[['Kvapilíková', 'Ivana', ''], ['Kocmi', 'Tom', ''], ['Bojar', 'Ondřej', '']]"
1298666,2006.04152,Canwen Xu,"Wangchunshu Zhou and Canwen Xu and Tao Ge and Julian McAuley and Ke Xu
  and Furu Wei",BERT Loses Patience: Fast and Robust Inference with Early Exit,NeurIPS 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we propose Patience-based Early Exit, a straightforward yet
effective inference method that can be used as a plug-and-play technique to
simultaneously improve the efficiency and robustness of a pretrained language
model (PLM). To achieve this, our approach couples an internal-classifier with
each layer of a PLM and dynamically stops inference when the intermediate
predictions of the internal classifiers remain unchanged for a pre-defined
number of steps. Our approach improves inference efficiency as it allows the
model to make a prediction with fewer layers. Meanwhile, experimental results
with an ALBERT model show that our method can improve the accuracy and
robustness of the model by preventing it from overthinking and exploiting
multiple classifiers for prediction, yielding a better accuracy-speed trade-off
compared to existing early exit methods.
","[{'version': 'v1', 'created': 'Sun, 7 Jun 2020 13:38:32 GMT'}, {'version': 'v2', 'created': 'Mon, 29 Jun 2020 04:46:19 GMT'}, {'version': 'v3', 'created': 'Thu, 22 Oct 2020 06:37:36 GMT'}]",2020-10-23,"[['Zhou', 'Wangchunshu', ''], ['Xu', 'Canwen', ''], ['Ge', 'Tao', ''], ['McAuley', 'Julian', ''], ['Xu', 'Ke', ''], ['Wei', 'Furu', '']]"
1342550,2009.01047,Vahid Behzadan,Bibek Upadhayay and Vahid Behzadan,"Sentimental LIAR: Extended Corpus and Deep Learning Models for Fake
  Claim Classification",Accepted for publication in the proceedings of IEEE ISI '20,,,,cs.CL cs.LG cs.SI stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The rampant integration of social media in our every day lives and culture
has given rise to fast and easier access to the flow of information than ever
in human history. However, the inherently unsupervised nature of social media
platforms has also made it easier to spread false information and fake news.
Furthermore, the high volume and velocity of information flow in such platforms
make manual supervision and control of information propagation infeasible. This
paper aims to address this issue by proposing a novel deep learning approach
for automated detection of false short-text claims on social media. We first
introduce Sentimental LIAR, which extends the LIAR dataset of short claims by
adding features based on sentiment and emotion analysis of claims. Furthermore,
we propose a novel deep learning architecture based on the BERT-Base language
model for classification of claims as genuine or fake. Our results demonstrate
that the proposed architecture trained on Sentimental LIAR can achieve an
accuracy of 70%, which is an improvement of ~30% over previously reported
results for the LIAR benchmark.
","[{'version': 'v1', 'created': 'Tue, 1 Sep 2020 02:48:11 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 04:57:21 GMT'}]",2020-10-23,"[['Upadhayay', 'Bibek', ''], ['Behzadan', 'Vahid', '']]"
1347870,2009.06367,Benjamin Krause,"Ben Krause, Akhilesh Deepak Gotmare, Bryan McCann, Nitish Shirish
  Keskar, Shafiq Joty, Richard Socher, Nazneen Fatema Rajani",GeDi: Generative Discriminator Guided Sequence Generation,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While large-scale language models (LMs) are able to imitate the distribution
of natural language well enough to generate realistic text, it is difficult to
control which regions of the distribution they generate. This is especially
problematic because datasets used for training large LMs usually contain
significant toxicity, hate, bias, and negativity. We propose GeDi as an
efficient method for using smaller LMs as generative discriminators to guide
generation from large LMs to make them safer and more controllable. GeDi guides
generation at each step by computing classification probabilities for all
possible next tokens via Bayes rule by normalizing over two class-conditional
distributions; one conditioned on the desired attribute, or control code, and
another conditioned on the undesired attribute, or anti control code. We find
that GeDi gives stronger controllability than the state of the art method while
also achieving generation speeds more than 30 times faster. Additionally,
training GeDi on only four topics allows us to controllably generate new topics
zero-shot from just a keyword, unlocking a new capability that previous
controllable generation methods do not have. Lastly, we show that GeDi can make
GPT-2 (1.5B parameters) significantly less toxic without sacrificing linguistic
quality, making it by far the most practical existing method for detoxifying
large language models while maintaining a fast generation speed.
","[{'version': 'v1', 'created': 'Mon, 14 Sep 2020 17:45:36 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 14:14:09 GMT'}]",2020-10-23,"[['Krause', 'Ben', ''], ['Gotmare', 'Akhilesh Deepak', ''], ['McCann', 'Bryan', ''], ['Keskar', 'Nitish Shirish', ''], ['Joty', 'Shafiq', ''], ['Socher', 'Richard', ''], ['Rajani', 'Nazneen Fatema', '']]"
1348326,2009.06823,Zhenglun Kong,"Wei Niu, Zhenglun Kong, Geng Yuan, Weiwen Jiang, Jiexiong Guan, Caiwen
  Ding, Pu Zhao, Sijia Liu, Bin Ren, Yanzhi Wang",Real-Time Execution of Large-scale Language Models on Mobile,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pre-trained large-scale language models have increasingly demonstrated high
accuracy on many natural language processing (NLP) tasks. However, the limited
weight storage and computational speed on hardware platforms have impeded the
popularity of pre-trained models, especially in the era of edge computing. In
this paper, we seek to find the best model structure of BERT for a given
computation size to match specific devices. We propose the first compiler-aware
neural architecture optimization framework. Our framework can guarantee the
identified model to meet both resource and real-time specifications of mobile
devices, thus achieving real-time execution of large transformer-based models
like BERT variants. We evaluate our model on several NLP tasks, achieving
competitive results on well-known benchmarks with lower latency on mobile
devices. Specifically, our model is 5.2x faster on CPU and 4.1x faster on GPU
with 0.5-2% accuracy loss compared with BERT-base. Our overall framework
achieves up to 7.8x speedup compared with TensorFlow-Lite with only minor
accuracy loss.
","[{'version': 'v1', 'created': 'Tue, 15 Sep 2020 01:59:17 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 17:53:07 GMT'}]",2020-10-23,"[['Niu', 'Wei', ''], ['Kong', 'Zhenglun', ''], ['Yuan', 'Geng', ''], ['Jiang', 'Weiwen', ''], ['Guan', 'Jiexiong', ''], ['Ding', 'Caiwen', ''], ['Zhao', 'Pu', ''], ['Liu', 'Sijia', ''], ['Ren', 'Bin', ''], ['Wang', 'Yanzhi', '']]"
1349119,2009.07616,Junfan Chen,"Junfan Chen, Richong Zhang, Yongyi Mao, Jie Xu",Parallel Interactive Networks for Multi-Domain Dialogue State Generation,Accepted by EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The dependencies between system and user utterances in the same turn and
across different turns are not fully considered in existing multidomain
dialogue state tracking (MDST) models. In this study, we argue that the
incorporation of these dependencies is crucial for the design of MDST and
propose Parallel Interactive Networks (PIN) to model these dependencies.
Specifically, we integrate an interactive encoder to jointly model the in-turn
dependencies and cross-turn dependencies. The slot-level context is introduced
to extract more expressive features for different slots. And a distributed copy
mechanism is utilized to selectively copy words from historical system
utterances or historical user utterances. Empirical studies demonstrated the
superiority of the proposed PIN model.
","[{'version': 'v1', 'created': 'Wed, 16 Sep 2020 11:54:15 GMT'}, {'version': 'v2', 'created': 'Sat, 3 Oct 2020 07:32:21 GMT'}, {'version': 'v3', 'created': 'Thu, 22 Oct 2020 14:19:12 GMT'}]",2020-10-23,"[['Chen', 'Junfan', ''], ['Zhang', 'Richong', ''], ['Mao', 'Yongyi', ''], ['Xu', 'Jie', '']]"
1368075,2010.11745,Gabriel Synnaeve,"Tatiana Likhomanenko, Qiantong Xu, Vineel Pratap, Paden Tomasello,
  Jacob Kahn, Gilad Avidov, Ronan Collobert, Gabriel Synnaeve",Rethinking Evaluation in ASR: Are Our Models Robust Enough?,,,,,cs.LG cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Is pushing numbers on a single benchmark valuable in automatic speech
recognition? Research results in acoustic modeling are typically evaluated
based on performance on a single dataset. While the research community has
coalesced around various benchmarks, we set out to understand generalization
performance in acoustic modeling across datasets -- in particular, if models
trained on a single dataset transfer to other (possibly out-of-domain)
datasets. Further, we demonstrate that when a large enough set of benchmarks is
used, average word error rate (WER) performance over them provides a good proxy
for performance on real-world data. Finally, we show that training a single
acoustic model on the most widely-used datasets -- combined -- reaches
competitive performance on both research and real-world benchmarks.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 14:01:32 GMT'}]",2020-10-23,"[['Likhomanenko', 'Tatiana', ''], ['Xu', 'Qiantong', ''], ['Pratap', 'Vineel', ''], ['Tomasello', 'Paden', ''], ['Kahn', 'Jacob', ''], ['Avidov', 'Gilad', ''], ['Collobert', 'Ronan', ''], ['Synnaeve', 'Gabriel', '']]"
1367969,2010.11639,Li-Hsin Chang,"Li-Hsin Chang, Sampo Pyysalo, Jenna Kanerva, Filip Ginter",Towards Fully Bilingual Deep Language Modeling,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language models based on deep neural networks have facilitated great advances
in natural language processing and understanding tasks in recent years. While
models covering a large number of languages have been introduced, their
multilinguality has come at a cost in terms of monolingual performance, and the
best-performing models at most tasks not involving cross-lingual transfer
remain monolingual. In this paper, we consider the question of whether it is
possible to pre-train a bilingual model for two remotely related languages
without compromising performance at either language. We collect pre-training
data, create a Finnish-English bilingual BERT model and evaluate its
performance on datasets used to evaluate the corresponding monolingual models.
Our bilingual model performs on par with Google's original English BERT on GLUE
and nearly matches the performance of monolingual Finnish BERT on a range of
Finnish NLP tasks, clearly outperforming multilingual BERT. We find that when
the model vocabulary size is increased, the BERT-Base architecture has
sufficient capacity to learn two remotely related languages to a level where it
achieves comparable performance with monolingual models, demonstrating the
feasibility of training fully bilingual deep language models. The model and all
tools involved in its creation are freely available at
https://github.com/TurkuNLP/biBERT
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 12:22:50 GMT'}]",2020-10-23,"[['Chang', 'Li-Hsin', ''], ['Pyysalo', 'Sampo', ''], ['Kanerva', 'Jenna', ''], ['Ginter', 'Filip', '']]"
1355405,2009.13902,Soujanya Poria,"Deepanway Ghosal, Navonil Majumder, Rada Mihalcea, Soujanya Poria",Utterance-level Dialogue Understanding: An Empirical Study,,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  The recent abundance of conversational data on the Web and elsewhere calls
for effective NLP systems for dialog understanding. Complete utterance-level
understanding often requires context understanding, defined by nearby
utterances. In recent years, a number of approaches have been proposed for
various utterance-level dialogue understanding tasks. Most of these approaches
account for the context for effective understanding. In this paper, we explore
and quantify the role of context for different aspects of a dialogue, namely
emotion, intent, and dialogue act identification, using state-of-the-art dialog
understanding methods as baselines. Specifically, we employ various
perturbations to distort the context of a given utterance and study its impact
on the different tasks and baselines. This provides us with insights into the
fundamental contextual controlling factors of different aspects of a dialogue.
Such insights can inspire more effective dialogue understanding models, and
provide support for future text generation approaches. The implementation
pertaining to this work is available at
https://github.com/declare-lab/dialogue-understanding.
","[{'version': 'v1', 'created': 'Tue, 29 Sep 2020 09:50:21 GMT'}, {'version': 'v2', 'created': 'Thu, 1 Oct 2020 16:12:59 GMT'}, {'version': 'v3', 'created': 'Sun, 11 Oct 2020 14:38:07 GMT'}, {'version': 'v4', 'created': 'Mon, 19 Oct 2020 03:03:05 GMT'}, {'version': 'v5', 'created': 'Thu, 22 Oct 2020 11:16:56 GMT'}]",2020-10-23,"[['Ghosal', 'Deepanway', ''], ['Majumder', 'Navonil', ''], ['Mihalcea', 'Rada', ''], ['Poria', 'Soujanya', '']]"
1357391,2010.01061,Nils Rethmeier,Nils Rethmeier and Isabelle Augenstein,"Long-Tail Zero and Few-Shot Learning via Contrastive Pretraining on and
  for Small Data",added citations to current work,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  For natural language processing (NLP) tasks such as sentiment or topic
classification, currently prevailing approaches heavily rely on pretraining
large self-supervised models on massive external data resources. However, this
methodology is being critiqued for: exceptional compute and pretraining data
requirements; diminishing returns on both large and small datasets; and
importantly, favourable evaluation settings that overestimate performance
differences. The core belief behind current methodology, coined `the bitter
lesson' by R. Sutton, is that `compute scale-up beats data and
compute-efficient algorithms', neglecting that progress in compute hardware
scale-up is based almost entirely on the miniaturisation of resource
consumption. We thus approach pretraining from a miniaturisation perspective,
such as not to require massive external data sources and models, or learned
translations from continuous input embeddings to discrete labels. To minimise
overly favourable evaluation, we examine learning on a long-tailed,
low-resource, multi-label text classification dataset with noisy, highly sparse
labels and many rare concepts. To this end, we propose a novel
`dataset-internal' contrastive autoencoding approach to self-supervised
pretraining and demonstrate marked improvements in zero-shot, few-shot and
solely supervised learning performance; even under an unfavorable low-resource
scenario, and without defaulting to large-scale external datasets for
self-supervision. We also find empirical evidence that zero and few-shot
learning markedly benefit from adding more `dataset-internal', self-supervised
training signals, which is of practical importance when retrieving or computing
on large external sources of such signals is infeasible.
","[{'version': 'v1', 'created': 'Fri, 2 Oct 2020 15:41:57 GMT'}, {'version': 'v2', 'created': 'Wed, 21 Oct 2020 18:24:13 GMT'}]",2020-10-23,"[['Rethmeier', 'Nils', ''], ['Augenstein', 'Isabelle', '']]"
1368031,2010.11701,Philipp Sadler,Philipp Sadler,Spatial Attention as an Interface for Image Captioning Models,"A thesis submitted in fulfillment of the requirements for the degree
  Master of Science in Cognitive Systems",,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The internal workings of modern deep learning models stay often unclear to an
external observer, although spatial attention mechanisms are involved. The idea
of this work is to translate these spatial attentions into natural language to
provide a simpler access to the model's function. Thus, I took a neural image
captioning model and measured the reactions to external modification in its
spatial attention for three different interface methods: a fixation over the
whole generation process, a fixation for the first time-steps and an addition
to the generator's attention. The experimental results for bounding box based
spatial attention vectors have shown that the captioning model reacts to method
dependent changes in up to 52.65% and includes in 9.00% of the cases object
categories, which were otherwise unmentioned. Afterwards, I established such a
link to a hierarchical co-attention network for visual question answering by
extraction of its word, phrase and question level spatial attentions. Here,
generated captions for the word level included details of the question-answer
pairs in up to 55.20% of the cases. This work indicates that spatial attention
seen as an external interface for image caption generators is an useful method
to access visual functions in natural language.
","[{'version': 'v1', 'created': 'Tue, 29 Sep 2020 16:04:08 GMT'}]",2020-10-23,"[['Sadler', 'Philipp', '']]"
1185948,1910.02029,Arun Balajee Vasudevan,"Arun Balajee Vasudevan, Dengxin Dai, Luc Van Gool","Talk2Nav: Long-Range Vision-and-Language Navigation with Dual Attention
  and Spatial Memory","Accepted to IJCV 2020, 20 pages, 10 Figures, Demo Video:
  https://people.ee.ethz.ch/~arunv/resources/talk2nav.mp4",,10.1007/s11263-020-01374-3,,cs.CV cs.CL cs.RO,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The role of robots in society keeps expanding, bringing with it the necessity
of interacting and communicating with humans. In order to keep such interaction
intuitive, we provide automatic wayfinding based on verbal navigational
instructions. Our first contribution is the creation of a large-scale dataset
with verbal navigation instructions. To this end, we have developed an
interactive visual navigation environment based on Google Street View; we
further design an annotation method to highlight mined anchor landmarks and
local directions between them in order to help annotators formulate typical,
human references to those. The annotation task was crowdsourced on the AMT
platform, to construct a new Talk2Nav dataset with $10,714$ routes. Our second
contribution is a new learning method. Inspired by spatial cognition research
on the mental conceptualization of navigational instructions, we introduce a
soft dual attention mechanism defined over the segmented language instructions
to jointly extract two partial instructions -- one for matching the next
upcoming visual landmark and the other for matching the local directions to the
next landmark. On the similar lines, we also introduce spatial memory scheme to
encode the local directional transitions. Our work takes advantage of the
advance in two lines of research: mental formalization of verbal navigational
instructions and training neural network agents for automatic way finding.
Extensive experiments show that our method significantly outperforms previous
navigation methods. For demo video, dataset and code, please refer to our
project page: https://www.trace.ethz.ch/publications/2019/talk2nav/index.html
","[{'version': 'v1', 'created': 'Fri, 4 Oct 2019 16:44:59 GMT'}, {'version': 'v2', 'created': 'Mon, 3 Feb 2020 11:25:09 GMT'}, {'version': 'v3', 'created': 'Thu, 22 Oct 2020 12:03:18 GMT'}]",2020-10-23,"[['Vasudevan', 'Arun Balajee', ''], ['Dai', 'Dengxin', ''], ['Van Gool', 'Luc', '']]"
1368013,2010.11683,Xiang Dai,Xiang Dai and Heike Adel,An Analysis of Simple Data Augmentation for Named Entity Recognition,COLING 2020,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Simple yet effective data augmentation techniques have been proposed for
sentence-level and sentence-pair natural language processing tasks. Inspired by
these efforts, we design and compare data augmentation for named entity
recognition, which is usually modeled as a token-level sequence labeling
problem. Through experiments on two data sets from the biomedical and materials
science domains (i2b2-2010 and MaSciP), we show that simple augmentation can
boost performance for both recurrent and transformer-based models, especially
for small training sets.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 13:21:03 GMT'}]",2020-10-23,"[['Dai', 'Xiang', ''], ['Adel', 'Heike', '']]"
1361469,2010.05139,Yiran Chen,"Yiran Chen, Pengfei Liu, Ming Zhong, Zi-Yi Dou, Danqing Wang, Xipeng
  Qiu and Xuanjing Huang","CDEvalSumm: An Empirical Study of Cross-Dataset Evaluation for Neural
  Summarization Systems","13 pages, Findings of EMNLP2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Neural network-based models augmented with unsupervised pre-trained knowledge
have achieved impressive performance on text summarization. However, most
existing evaluation methods are limited to an in-domain setting, where
summarizers are trained and evaluated on the same dataset. We argue that this
approach can narrow our understanding of the generalization ability for
different summarization systems. In this paper, we perform an in-depth analysis
of characteristics of different datasets and investigate the performance of
different summarization models under a cross-dataset setting, in which a
summarizer trained on one corpus will be evaluated on a range of out-of-domain
corpora. A comprehensive study of 11 representative summarization systems on 5
datasets from different domains reveals the effect of model architectures and
generation ways (i.e. abstractive and extractive) on model generalization
ability. Further, experimental results shed light on the limitations of
existing summarizers. Brief introduction and supplementary code can be found in
https://github.com/zide05/CDEvalSumm.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 02:19:15 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 12:11:46 GMT'}]",2020-10-23,"[['Chen', 'Yiran', ''], ['Liu', 'Pengfei', ''], ['Zhong', 'Ming', ''], ['Dou', 'Zi-Yi', ''], ['Wang', 'Danqing', ''], ['Qiu', 'Xipeng', ''], ['Huang', 'Xuanjing', '']]"
1361808,2010.05478,Tanya Goyal,"Tanya Goyal, Greg Durrett",Evaluating Factuality in Generation with Dependency-level Entailment,Findings of Emnlp 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite significant progress in text generation models, a serious limitation
is their tendency to produce text that is factually inconsistent with
information in the input. Recent work has studied whether textual entailment
systems can be used to identify factual errors; however, these sentence-level
entailment models are trained to solve a different problem than generation
filtering and they do not localize which part of a generation is non-factual.
In this paper, we propose a new formulation of entailment that decomposes it at
the level of dependency arcs. Rather than focusing on aggregate decisions, we
instead ask whether the semantic relationship manifested by individual
dependency arcs in the generated output is supported by the input. Human
judgments on this task are difficult to obtain; we therefore propose a method
to automatically create data based on existing entailment or paraphrase
corpora. Experiments show that our dependency arc entailment model trained on
this data can identify factual inconsistencies in paraphrasing and
summarization better than sentence-level methods or those based on question
generation, while additionally localizing the erroneous parts of the
generation.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 06:43:10 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 06:35:58 GMT'}]",2020-10-23,"[['Goyal', 'Tanya', ''], ['Durrett', 'Greg', '']]"
1362070,2010.05740,Yanjie Gou,"Yanjie Gou, Yinjie Lei, Lingqiao Liu","Contextualize Knowledge Bases with Transformer for End-to-end
  Task-Oriented Dialogue Systems",Third version of this work; Correct some typos,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent studies try to build task-oriented dialogue systems in an end-to-end
manner and the existing works make great progress on this task. However, there
is still an issue need to be further considered, i.e., how to effectively
represent the knowledge bases and incorporate that into dialogue systems. To
solve this issue, we design a novel Transformer-based Context-aware Memory
Generator to model the entities in knowledge bases, which can produce entity
representations with perceiving all the relevant entities and dialogue history.
Furthermore, we propose Context-aware Memory Enhanced Transformer (CMET), which
can effectively aggregate information from the dialogue history and knowledge
bases to generate more accurate responses. Through extensive experiments, our
method can achieve superior performance over the state-of-the-art methods.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 14:34:07 GMT'}, {'version': 'v2', 'created': 'Tue, 20 Oct 2020 09:37:22 GMT'}, {'version': 'v3', 'created': 'Thu, 22 Oct 2020 13:37:40 GMT'}]",2020-10-23,"[['Gou', 'Yanjie', ''], ['Lei', 'Yinjie', ''], ['Liu', 'Lingqiao', '']]"
1367996,2010.11666,Pavel Kalaidin,"Nadezhda Zueva, Madina Kabirova, Pavel Kalaidin",Reducing Unintended Identity Bias in Russian Hate Speech Detection,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Toxicity has become a grave problem for many online communities and has been
growing across many languages, including Russian. Hate speech creates an
environment of intimidation, discrimination, and may even incite some
real-world violence. Both researchers and social platforms have been focused on
developing models to detect toxicity in online communication for a while now. A
common problem of these models is the presence of bias towards some words (e.g.
woman, black, jew) that are not toxic, but serve as triggers for the classifier
due to model caveats. In this paper, we describe our efforts towards
classifying hate speech in Russian, and propose simple techniques of reducing
unintended bias, such as generating training data with language models using
terms and words related to protected identities as context and applying word
dropout to such words.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 12:54:14 GMT'}]",2020-10-23,"[['Zueva', 'Nadezhda', ''], ['Kabirova', 'Madina', ''], ['Kalaidin', 'Pavel', '']]"
1368061,2010.11731,Akbar Karimi,"Akbar Karimi, Leonardo Rossi, Andrea Prati",Improving BERT Performance for Aspect-Based Sentiment Analysis,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Aspect-Based Sentiment Analysis (ABSA) studies the consumer opinion on the
market products. It involves examining the type of sentiments as well as
sentiment targets expressed in product reviews. Analyzing the language used in
a review is a difficult task that requires a deep understanding of the
language. In recent years, deep language models, such as BERT
\cite{devlin2019bert}, have shown great progress in this regard. In this work,
we propose two simple modules called Parallel Aggregation and Hierarchical
Aggregation to be utilized on top of BERT for two main ABSA tasks namely Aspect
Extraction (AE) and Aspect Sentiment Classification (ASC) in order to improve
the model's performance. We show that applying the proposed models eliminates
the need for further training of the BERT model. The source code is available
on the Web for further research and reproduction of the results.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 13:52:18 GMT'}]",2020-10-23,"[['Karimi', 'Akbar', ''], ['Rossi', 'Leonardo', ''], ['Prati', 'Andrea', '']]"
1367852,2010.11522,Jiaoyan Chen,"Ziheng Zhang and Jiaoyan Chen and Xi Chen and Hualuo Liu and Yuejia
  Xiang and Bo Liu and Yefeng Zheng",An Industry Evaluation of Embedding-based Entity Alignment,,Coling'2020,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Embedding-based entity alignment has been widely investigated in recent
years, but most proposed methods still rely on an ideal supervised learning
setting with a large number of unbiased seed mappings for training and
validation, which significantly limits their usage. In this study, we evaluate
those state-of-the-art methods in an industrial context, where the impact of
seed mappings with different sizes and different biases is explored. Besides
the popular benchmarks from DBpedia and Wikidata, we contribute and evaluate a
new industrial benchmark that is extracted from two heterogeneous knowledge
graphs (KGs) under deployment for medical applications. The experimental
results enable the analysis of the advantages and disadvantages of these
alignment methods and the further discussion of suitable strategies for their
industrial deployment.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 08:33:58 GMT'}]",2020-10-23,"[['Zhang', 'Ziheng', ''], ['Chen', 'Jiaoyan', ''], ['Chen', 'Xi', ''], ['Liu', 'Hualuo', ''], ['Xiang', 'Yuejia', ''], ['Liu', 'Bo', ''], ['Zheng', 'Yefeng', '']]"
1368094,2010.11764,Aman Madaan,"Aman Madaan, Dheeraj Rajagopal, Yiming Yang, Abhilasha Ravichander,
  Eduard Hovy, Shrimai Prabhumoye",EIGEN: Event Influence GENeration using Pre-trained Language Models,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Reasoning about events and tracking their influences is fundamental to
understanding processes. In this paper, we present EIGEN - a method to leverage
pre-trained language models to generate event influences conditioned on a
context, nature of their influence, and the distance in a reasoning chain. We
also derive a new dataset for research and evaluation of methods for event
influence generation. EIGEN outperforms strong baselines both in terms of
automated evaluation metrics (by 10 ROUGE points) and human judgments on
closeness to reference and relevance of generations. Furthermore, we show that
the event influences generated by EIGEN improve the performance on a ""what-if""
Question Answering (WIQA) benchmark (over 3% F1), especially for questions that
require background knowledge and multi-hop reasoning.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 14:36:04 GMT'}]",2020-10-23,"[['Madaan', 'Aman', ''], ['Rajagopal', 'Dheeraj', ''], ['Yang', 'Yiming', ''], ['Ravichander', 'Abhilasha', ''], ['Hovy', 'Eduard', ''], ['Prabhumoye', 'Shrimai', '']]"
1227793,2001.02380,Yang Liu,Amir Zeldes and Yang Liu,A Neural Approach to Discourse Relation Signal Detection,"33 pages, 7 figures. Submitted to Dialogue & Discourse (D&D);
  Addressed reviewers' comments: strengthened arguments, added references,
  corrected typos etc",,10.5087/dad,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Previous data-driven work investigating the types and distributions of
discourse relation signals, including discourse markers such as 'however' or
phrases such as 'as a result' has focused on the relative frequencies of signal
words within and outside text from each discourse relation. Such approaches do
not allow us to quantify the signaling strength of individual instances of a
signal on a scale (e.g. more or less discourse-relevant instances of 'and'), to
assess the distribution of ambiguity for signals, or to identify words that
hinder discourse relation identification in context ('anti-signals' or
'distractors'). In this paper we present a data-driven approach to signal
detection using a distantly supervised neural network and develop a metric,
Delta s (or 'delta-softmax'), to quantify signaling strength. Ranging between
-1 and 1 and relying on recent advances in contextualized words embeddings, the
metric represents each word's positive or negative contribution to the
identifiability of a relation in specific instances in context. Based on an
English corpus annotated for discourse relations using Rhetorical Structure
Theory and signal type annotations anchored to specific tokens, our analysis
examines the reliability of the metric, the places where it overlaps with and
differs from human judgments, and the implications for identifying features
that neural models may need in order to perform better on automatic discourse
relation classification.
","[{'version': 'v1', 'created': 'Wed, 8 Jan 2020 05:14:49 GMT'}, {'version': 'v2', 'created': 'Wed, 11 Mar 2020 19:56:42 GMT'}]",2020-10-23,"[['Zeldes', 'Amir', ''], ['Liu', 'Yang', '']]"
1367713,2010.11383,Li Wanli,Wanli Li and Tieyun Qian,"Exploit Multiple Reference Graphs for Semi-supervised Relation
  Extraction",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Manual annotation of the labeled data for relation extraction is
time-consuming and labor-intensive. Semi-supervised methods can offer helping
hands for this problem and have aroused great research interests. Existing work
focuses on mapping the unlabeled samples to the classes to augment the labeled
dataset. However, it is hard to find an overall good mapping function,
especially for the samples with complicated syntactic components in one
sentence.
  To tackle this limitation, we propose to build the connection between the
unlabeled data and the labeled ones rather than directly mapping the unlabeled
samples to the classes. Specifically, we first use three kinds of information
to construct reference graphs, including entity reference, verb reference, and
semantics reference. The goal is to semantically or lexically connect the
unlabeled sample(s) to the labeled one(s). Then, we develop a Multiple
Reference Graph (MRefG) model to exploit the reference information for better
recognizing high-quality unlabeled samples. The effectiveness of our method is
demonstrated by extensive comparison experiments with the state-of-the-art
baselines on two public datasets.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 02:14:27 GMT'}]",2020-10-23,"[['Li', 'Wanli', ''], ['Qian', 'Tieyun', '']]"
1367704,2010.11374,Devendra Singh Sachan,"Devendra Singh Sachan and Lingfei Wu and Mrinmaya Sachan and William
  Hamilton",Stronger Transformers for Neural Multi-Hop Question Generation,Code will be made available,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Prior work on automated question generation has almost exclusively focused on
generating simple questions whose answers can be extracted from a single
document. However, there is an increasing interest in developing systems that
are capable of more complex multi-hop question generation, where answering the
questions requires reasoning over multiple documents. In this work, we
introduce a series of strong transformer models for multi-hop question
generation, including a graph-augmented transformer that leverages relations
between entities in the text. While prior work has emphasized the importance of
graph-based models, we show that we can substantially outperform the
state-of-the-art by 5 BLEU points using a standard transformer architecture. We
further demonstrate that graph-based augmentations can provide complimentary
improvements on top of this foundation. Interestingly, we find that several
important factors--such as the inclusion of an auxiliary contrastive objective
and data filtering could have larger impacts on performance. We hope that our
stronger baselines and analysis provide a constructive foundation for future
work in this area.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 01:51:09 GMT'}]",2020-10-23,"[['Sachan', 'Devendra Singh', ''], ['Wu', 'Lingfei', ''], ['Sachan', 'Mrinmaya', ''], ['Hamilton', 'William', '']]"
1367692,2010.11362,Rithesh Kumar,"Rithesh Kumar, Kundan Kumar, Vicki Anand, Yoshua Bengio, Aaron
  Courville",NU-GAN: High resolution neural upsampling with GAN,,,,,cs.SD cs.AI cs.CL cs.LG eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we propose NU-GAN, a new method for resampling audio from
lower to higher sampling rates (upsampling). Audio upsampling is an important
problem since productionizing generative speech technology requires operating
at high sampling rates. Such applications use audio at a resolution of 44.1 kHz
or 48 kHz, whereas current speech synthesis methods are equipped to handle a
maximum of 24 kHz resolution. NU-GAN takes a leap towards solving audio
upsampling as a separate component in the text-to-speech (TTS) pipeline by
leveraging techniques for audio generation using GANs. ABX preference tests
indicate that our NU-GAN resampler is capable of resampling 22 kHz to 44.1 kHz
audio that is distinguishable from original audio only 7.4% higher than random
chance for single speaker dataset, and 10.8% higher than chance for
multi-speaker dataset.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 01:00:23 GMT'}]",2020-10-23,"[['Kumar', 'Rithesh', ''], ['Kumar', 'Kundan', ''], ['Anand', 'Vicki', ''], ['Bengio', 'Yoshua', ''], ['Courville', 'Aaron', '']]"
1367688,2010.11358,Aaron Baier-Reinio,Aaron Baier-Reinio and Hans De Sterck,"N-ODE Transformer: A Depth-Adaptive Variant of the Transformer Using
  Neural Ordinary Differential Equations",,,,,cs.LG cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We use neural ordinary differential equations to formulate a variant of the
Transformer that is depth-adaptive in the sense that an input-dependent number
of time steps is taken by the ordinary differential equation solver. Our goal
in proposing the N-ODE Transformer is to investigate whether its
depth-adaptivity may aid in overcoming some specific known theoretical
limitations of the Transformer in handling nonlocal effects. Specifically, we
consider the simple problem of determining the parity of a binary sequence, for
which the standard Transformer has known limitations that can only be overcome
by using a sufficiently large number of layers or attention heads. We find,
however, that the depth-adaptivity of the N-ODE Transformer does not provide a
remedy for the inherently nonlocal nature of the parity problem, and provide
explanations for why this is so. Next, we pursue regularization of the N-ODE
Transformer by penalizing the arclength of the ODE trajectories, but find that
this fails to improve the accuracy or efficiency of the N-ODE Transformer on
the challenging parity problem. We suggest future avenues of research for
modifications and extensions of the N-ODE Transformer that may lead to improved
accuracy and efficiency for sequence modelling tasks such as neural machine
translation.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 00:48:24 GMT'}]",2020-10-23,"[['Baier-Reinio', 'Aaron', ''], ['De Sterck', 'Hans', '']]"
1367681,2010.11351,Minghan Li,"M. Li, H. Bai, L. Tan, K. Xiong, M. Li, J. Lin","Latte-Mix: Measuring Sentence Semantic Similarity with Latent
  Categorical Mixtures",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Measuring sentence semantic similarity using pre-trained language models such
as BERT generally yields unsatisfactory zero-shot performance, and one main
reason is ineffective token aggregation methods such as mean pooling. In this
paper, we demonstrate under a Bayesian framework that distance between
primitive statistics such as the mean of word embeddings are fundamentally
flawed for capturing sentence-level semantic similarity. To remedy this issue,
we propose to learn a categorical variational autoencoder (VAE) based on
off-the-shelf pre-trained language models. We theoretically prove that
measuring the distance between the latent categorical mixtures, namely
Latte-Mix, can better reflect the true sentence semantic similarity. In
addition, our Bayesian framework provides explanations for why models finetuned
on labelled sentence pairs have better zero-shot performance. We also
empirically demonstrate that these finetuned models could be further improved
by Latte-Mix. Our method not only yields the state-of-the-art zero-shot
performance on semantic similarity datasets such as STS, but also enjoy the
benefits of fast training and having small memory footprints.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 23:45:18 GMT'}]",2020-10-23,"[['Li', 'M.', ''], ['Bai', 'H.', ''], ['Tan', 'L.', ''], ['Xiong', 'K.', ''], ['Li', 'M.', ''], ['Lin', 'J.', '']]"
1367679,2010.11349,Xie Chen,"Xie Chen, Sarangarajan Parthasarathy, William Gale, Shuangyu Chang,
  Michael Zeng","LSTM-LM with Long-Term History for First-Pass Decoding in Conversational
  Speech Recognition",5 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  LSTM language models (LSTM-LMs) have been proven to be powerful and yielded
significant performance improvements over count based n-gram LMs in modern
speech recognition systems. Due to its infinite history states and
computational load, most previous studies focus on applying LSTM-LMs in the
second-pass for rescoring purpose. Recent work shows that it is feasible and
computationally affordable to adopt the LSTM-LMs in the first-pass decoding
within a dynamic (or tree based) decoder framework. In this work, the LSTM-LM
is composed with a WFST decoder on-the-fly for the first-pass decoding.
Furthermore, motivated by the long-term history nature of LSTM-LMs, the use of
context beyond the current utterance is explored for the first-pass decoding in
conversational speech recognition. The context information is captured by the
hidden states of LSTM-LMs across utterance and can be used to guide the
first-pass search effectively. The experimental results in our internal meeting
transcription system show that significant performance improvements can be
obtained by incorporating the contextual information with LSTM-LMs in the
first-pass decoding, compared to applying the contextual information in the
second-pass rescoring.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 23:40:26 GMT'}]",2020-10-23,"[['Chen', 'Xie', ''], ['Parthasarathy', 'Sarangarajan', ''], ['Gale', 'William', ''], ['Chang', 'Shuangyu', ''], ['Zeng', 'Michael', '']]"
1367668,2010.11338,Yun Tang,"Yun Tang, Juan Pino, Changhan Wang, Xutai Ma, Dmitriy Genzel","A General Multi-Task Learning Framework to Leverage Text Data for Speech
  to Text Tasks",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Attention-based sequence-to-sequence modeling provides a powerful and elegant
solution for applications that need to map one sequence to a different
sequence. Its success heavily relies on the availability of large amounts of
training data. This presents a challenge for speech applications where labelled
speech data is very expensive to obtain, such as automatic speech recognition
(ASR) and speech translation (ST). In this study, we propose a general
multi-task learning framework to leverage text data for ASR and ST tasks. Two
auxiliary tasks, a denoising autoencoder task and machine translation task, are
proposed to be co-trained with ASR and ST tasks respectively. We demonstrate
that representing text input as phoneme sequences can reduce the difference
between speech and text inputs, and enhance the knowledge transfer from text
corpora to the speech to text tasks. Our experiments show that the proposed
method achieves a relative 10~15% word error rate reduction on the English
Librispeech task, and improves the speech translation quality on the MuST-C
tasks by 4.2~11.1 BLEU.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 22:40:43 GMT'}]",2020-10-23,"[['Tang', 'Yun', ''], ['Pino', 'Juan', ''], ['Wang', 'Changhan', ''], ['Ma', 'Xutai', ''], ['Genzel', 'Dmitriy', '']]"
1367664,2010.11334,Chiyu Zhang,"Muhammad Abdul-Mageed, Chiyu Zhang, Houda Bouamor and Nizar Habash",NADI 2020: The First Nuanced Arabic Dialect Identification Shared Task,Accepted in WANLP 2020,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  We present the results and findings of the First Nuanced Arabic Dialect
Identification Shared Task (NADI). The shared task includes two subtasks:
country level dialect identification (Subtask 1) and province level sub-dialect
identification (Subtask 2). The data for the shared task covers a total of 100
provinces from 21 Arab countries, and are collected from the Twitter domain. As
such, NADI is the first shared task to target naturally-occurring fine-grained
dialectal text at the sub-country level. A total of 61 teams from 25 countries
registered to participate in the tasks, thus reflecting the interest of the
community in this area. We received 47 submissions for Subtask 1 from 18 teams
and 9 submissions to Subtask 2 from 9 teams.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 22:14:28 GMT'}]",2020-10-23,"[['Abdul-Mageed', 'Muhammad', ''], ['Zhang', 'Chiyu', ''], ['Bouamor', 'Houda', ''], ['Habash', 'Nizar', '']]"
1367663,2010.11333,Yogarshi Vyas,"Yogarshi Vyas, Miguel Ballesteros",Linking Entities to Unseen Knowledge Bases with Arbitrary Schemas,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In entity linking, mentions of named entities in raw text are disambiguated
against a knowledge base (KB). This work focuses on linking to unseen KBs that
do not have training data and whose schema is unknown during training. Our
approach relies on methods to flexibly convert entities from arbitrary KBs with
several attribute-value pairs into flat strings, which we use in conjunction
with state-of-the-art models for zero-shot linking. To improve the
generalization of our model, we use two regularization schemes based on
shuffling of entity attributes and handling of unseen attributes. Experiments
on English datasets where models are trained on the CoNLL dataset, and tested
on the TAC-KBP 2010 dataset show that our models outperform baseline models by
over 12 points of accuracy. Unlike prior work, our approach also allows for
seamlessly combining multiple training datasets. We test this ability by adding
both a completely different dataset (Wikia), as well as increasing amount of
training data from the TAC-KBP 2010 training set. Our models perform favorably
across the board.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 22:07:31 GMT'}]",2020-10-23,"[['Vyas', 'Yogarshi', ''], ['Ballesteros', 'Miguel', '']]"
1367655,2010.11325,Rui Feng,"Rui Feng, Jie Yuan, Chao Zhang","Probing and Fine-tuning Reading Comprehension Models for Few-shot Event
  Extraction",,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  We study the problem of event extraction from text data, which requires both
detecting target event types and their arguments. Typically, both the event
detection and argument detection subtasks are formulated as supervised sequence
labeling problems. We argue that the event extraction models so trained are
inherently label-hungry, and can generalize poorly across domains and text
genres.We propose a reading comprehension framework for event
extraction.Specifically, we formulate event detection as a textual entailment
prediction problem, and argument detection as a question answer-ing problem. By
constructing proper query templates, our approach can effectively distill rich
knowledge about tasks and label semantics from pretrained reading comprehension
models. Moreover, our model can be fine-tuned with a small amount of data to
boost its performance. Our experiment results show that our method performs
strongly for zero-shot and few-shot event extraction, and it achieves
state-of-the-art performance on the ACE 2005 benchmark when trained with full
supervision.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 21:48:39 GMT'}]",2020-10-23,"[['Feng', 'Rui', ''], ['Yuan', 'Jie', ''], ['Zhang', 'Chao', '']]"
1367714,2010.11384,Gabriele Pergola,"Gabriele Pergola, Lin Gui, Yulan He","A Disentangled Adversarial Neural Topic Model for Separating Opinions
  from Plots in User Reviews","12 pages, 4 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The flexibility of the inference process in Variational Autoencoders (VAEs)
has recently led to revising traditional probabilistic topic models giving rise
to Neural Topic Models (NTM). Although these approaches have achieved
significant results, surprisingly very little work has been done on how to
disentangle the latent topics. Existing topic models when applied to reviews
may extract topics associated with writers' subjective opinions mixed with
those related to factual descriptions such as plot summaries in movie and book
reviews. It is thus desirable to automatically separate opinion topics from
plot/neutral ones enabling a better interpretability. In this paper, we propose
a neural topic model combined with adversarial training to disentangle opinion
topics from plot and neutral ones. We conduct an extensive experimental
assessment introducing a new collection of movie and book reviews paired with
their plots, namely MOBO dataset, showing an improved coherence and variety of
topics, a consistent disentanglement rate, and sentiment classification
performance superior to other supervised topic models.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 02:15:13 GMT'}]",2020-10-23,"[['Pergola', 'Gabriele', ''], ['Gui', 'Lin', ''], ['He', 'Yulan', '']]"
1368114,2010.11784,Fangyu Liu,"Fangyu Liu, Ehsan Shareghi, Zaiqiao Meng, Marco Basaldella, Nigel
  Collier",Self-alignment Pre-training for Biomedical Entity Representations,8 pages. work in progress,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite the widespread success of self-supervised learning via masked
language models, learning representations directly from text to accurately
capture complex and fine-grained semantic relationships in the biomedical
domain remains as a challenge. Addressing this is of paramount importance for
tasks such as entity linking where complex relational knowledge is pivotal. We
propose SapBERT, a pre-training scheme based on BERT. It self-aligns the
representation space of biomedical entities with a metric learning objective
function leveraging UMLS, a collection of biomedical ontologies with >4M
concepts. Our experimental results on six medical entity linking benchmarking
datasets demonstrate that SapBERT outperforms many domain-specific BERT-based
variants such as BioBERT, BlueBERT and PubMedBERT, achieving the
state-of-the-art (SOTA) performances.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 14:59:57 GMT'}]",2020-10-23,"[['Liu', 'Fangyu', ''], ['Shareghi', 'Ehsan', ''], ['Meng', 'Zaiqiao', ''], ['Basaldella', 'Marco', ''], ['Collier', 'Nigel', '']]"
1367583,2010.11253,Rico Angell,"Rico Angell, Nicholas Monath, Sunil Mohan, Nishant Yadav and Andrew
  McCallum",Clustering-based Inference for Zero-Shot Biomedical Entity Linking,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Due to large number of entities in biomedical knowledge bases, only a small
fraction of entities have corresponding labelled training data. This
necessitates a zero-shot entity linking model which is able to link mentions of
unseen entities using learned representations of entities. Existing zero-shot
entity linking models however link each mention independently, ignoring the
inter/intra-document relationships between the entity mentions. These relations
can be very useful for linking mentions in biomedical text where linking
decisions are often difficult due mentions having a generic or a highly
specialized form. In this paper, we introduce a model in which linking
decisions can be made not merely by linking to a KB entity but also by grouping
multiple mentions together via clustering and jointly making linking
predictions. In experiments on the largest publicly available biomedical
dataset, we improve the best independent prediction for zero-shot entity
linking by 2.5 points of accuracy, and our joint inference model further
improves entity linking by 1.8 points.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 19:16:27 GMT'}]",2020-10-23,"[['Angell', 'Rico', ''], ['Monath', 'Nicholas', ''], ['Mohan', 'Sunil', ''], ['Yadav', 'Nishant', ''], ['McCallum', 'Andrew', '']]"
1367577,2010.11247,Renjie Zheng,"Junkun Chen, Renjie Zheng, Atsuhito Kita, Mingbo Ma, Liang Huang",Improving Simultaneous Translation with Pseudo References,6 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Simultaneous translation is vastly different from full-sentence translation,
in the sense that it starts translation before the source sentence ends, with
only a few words delay. However, due to the lack of large scale and publicly
available simultaneous translation datasets, most simultaneous translation
systems still train with ordinary full-sentence parallel corpora which are not
suitable for the simultaneous scenario due to the existence of unnecessary
long-distance reorderings. Instead of expensive, time-consuming annotation, we
propose a novel method that rewrites the target side of existing full-sentence
corpus into simultaneous-style translation. Experiments on Chinese-to-English
translation demonstrate about +2.7 BLEU improvements with the addition of newly
generated pseudo references.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 19:03:06 GMT'}]",2020-10-23,"[['Chen', 'Junkun', ''], ['Zheng', 'Renjie', ''], ['Kita', 'Atsuhito', ''], ['Ma', 'Mingbo', ''], ['Huang', 'Liang', '']]"
1367576,2010.11246,Tianze Shi,"Tianze Shi, Chen Zhao, Jordan Boyd-Graber, Hal Daum\'e III and Lillian
  Lee","On the Potential of Lexico-logical Alignments for Semantic Parsing to
  SQL Queries",Findings of ACL: EMNLP 2020,Findings of ACL: EMNLP 2020,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large-scale semantic parsing datasets annotated with logical forms have
enabled major advances in supervised approaches. But can richer supervision
help even more? To explore the utility of fine-grained, lexical-level
supervision, we introduce Squall, a dataset that enriches 11,276
WikiTableQuestions English-language questions with manually created SQL
equivalents plus alignments between SQL and question fragments. Our annotation
enables new training possibilities for encoder-decoder models, including
approaches from machine translation previously precluded by the absence of
alignments. We propose and test two methods: (1) supervised attention; (2)
adopting an auxiliary objective of disambiguating references in the input
queries to table columns. In 5-fold cross validation, these strategies improve
over strong baselines by 4.4% execution accuracy. Oracle experiments suggest
that annotated alignments can support further accuracy gains of up to 23.9%.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 19:01:00 GMT'}]",2020-10-23,"[['Shi', 'Tianze', ''], ['Zhao', 'Chen', ''], ['Boyd-Graber', 'Jordan', ''], ['Daumé', 'Hal', 'III'], ['Lee', 'Lillian', '']]"
1367568,2010.11238,Sirigireddy Dhana Laxmi,"Sirigireddy Dhanalaxmi, Rohit Agarwal, Aman Sinha",Detection of COVID-19 informative tweets using RoBERTa,,,,,cs.CL cs.SI,http://creativecommons.org/publicdomain/zero/1.0/,"  Social media such as Twitter is a hotspot of user-generated information. In
this ongoing Covid-19 pandemic, there has been an abundance of data on social
media which can be classified as informative and uninformative content. In this
paper, we present our work to detect informative Covid-19 English tweets using
RoBERTa model as a part of the W-NUT workshop 2020. We show the efficacy of our
model on a public dataset with an F1-score of 0.89 on the validation dataset
and 0.87 on the leaderboard.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 18:43:13 GMT'}]",2020-10-23,"[['Dhanalaxmi', 'Sirigireddy', ''], ['Agarwal', 'Rohit', ''], ['Sinha', 'Aman', '']]"
1367560,2010.11230,Mohammad Kachuee Mr.,"Mohammad Kachuee, Hao Yuan, Young-Bum Kim, Sungjin Lee","Self-Supervised Contrastive Learning for Efficient User Satisfaction
  Prediction in Conversational Agents",,,,,cs.LG cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Turn-level user satisfaction is one of the most important performance metrics
for conversational agents. It can be used to monitor the agent's performance
and provide insights about defective user experiences. Moreover, a powerful
satisfaction model can be used as an objective function that a conversational
agent continuously optimizes for. While end-to-end deep learning has shown
promising results, having access to a large number of reliable annotated
samples required by these methods remains challenging. In a large-scale
conversational system, there is a growing number of newly developed skills,
making the traditional data collection, annotation, and modeling process
impractical due to the required annotation costs as well as the turnaround
times. In this paper, we suggest a self-supervised contrastive learning
approach that leverages the pool of unlabeled data to learn user-agent
interactions. We show that the pre-trained models using the self-supervised
objective are transferable to the user satisfaction prediction. In addition, we
propose a novel few-shot transfer learning approach that ensures better
transferability for very small sample sizes. The suggested few-shot method does
not require any inner loop optimization process and is scalable to very large
datasets and complex models. Based on our experiments using real-world data
from a large-scale commercial system, the suggested approach is able to
significantly reduce the required number of annotations, while improving the
generalization on unseen out-of-domain skills.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 18:10:58 GMT'}]",2020-10-23,"[['Kachuee', 'Mohammad', ''], ['Yuan', 'Hao', ''], ['Kim', 'Young-Bum', ''], ['Lee', 'Sungjin', '']]"
1367196,2010.10866,Cl\'ement Rebuffel,"Cl\'ement Rebuffel, Laure Soulier, Geoffrey Scoutheeten, Patrick
  Gallinari","PARENTing via Model-Agnostic Reinforcement Learning to Correct
  Pathological Behaviors in Data-to-Text Generation","Accepted at the 13th International Conference on Natural Language
  Generation (INLG 2020)",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In language generation models conditioned by structured data, the classical
training via maximum likelihood almost always leads models to pick up on
dataset divergence (i.e., hallucinations or omissions), and to incorporate them
erroneously in their own generations at inference. In this work, we build ontop
of previous Reinforcement Learning based approaches and show that a
model-agnostic framework relying on the recently introduced PARENT metric is
efficient at reducing both hallucinations and omissions. Evaluations on the
widely used WikiBIO and WebNLG benchmarks demonstrate the effectiveness of this
framework compared to state-of-the-art models.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 09:49:47 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 13:00:20 GMT'}]",2020-10-23,"[['Rebuffel', 'Clément', ''], ['Soulier', 'Laure', ''], ['Scoutheeten', 'Geoffrey', ''], ['Gallinari', 'Patrick', '']]"
1367222,2010.10892,Yang Jiao,Yang Jiao,"BERT for Joint Multichannel Speech Dereverberation with Spatial-aware
  Tasks",,,,,eess.AS cs.CL cs.LG cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a method for joint multichannel speech dereverberation with two
spatial-aware tasks: direction-of-arrival (DOA) estimation and speech
separation. The proposed method addresses involved tasks as a sequence to
sequence mapping problem, which is general enough for a variety of front-end
speech enhancement tasks. The proposed method is inspired by the excellent
sequence modeling capability of bidirectional encoder representation from
transformers (BERT). Instead of utilizing explicit representations from
pretraining in a self-supervised manner, we utilizes transformer encoded hidden
representations in a supervised manner. Both multichannel spectral magnitude
and spectral phase information of varying length utterances are encoded.
Experimental result demonstrates the effectiveness of the proposed method.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 11:05:17 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 02:41:39 GMT'}]",2020-10-23,"[['Jiao', 'Yang', '']]"
1367236,2010.10906,Branden Chan,"Branden Chan, Stefan Schweter, Timo M\""oller",German's Next Language Model,Accepted by COLING2020 Industry Track,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this work we present the experiments which lead to the creation of our
BERT and ELECTRA based German language models, GBERT and GELECTRA. By varying
the input training data, model size, and the presence of Whole Word Masking
(WWM) we were able to attain SoTA performance across a set of document
classification and named entity recognition (NER) tasks for both models of base
and large size. We adopt an evaluation driven approach in training these models
and our results indicate that both adding more data and utilizing WWM improve
model performance. By benchmarking against existing German models, we show that
these models are the best German models to date. Our trained models will be
made publicly available to the research community.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 11:28:23 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 08:39:30 GMT'}]",2020-10-23,"[['Chan', 'Branden', ''], ['Schweter', 'Stefan', ''], ['Möller', 'Timo', '']]"
772506,1609.07028,Ruobing Xie,"Ruobing Xie, Zhiyuan Liu, Huanbo Luan, Maosong Sun",Image-embodied Knowledge Representation Learning,7 pages; Accepted by IJCAI-2017,IJCAI-2017,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Entity images could provide significant visual information for knowledge
representation learning. Most conventional methods learn knowledge
representations merely from structured triples, ignoring rich visual
information extracted from entity images. In this paper, we propose a novel
Image-embodied Knowledge Representation Learning model (IKRL), where knowledge
representations are learned with both triple facts and images. More
specifically, we first construct representations for all images of an entity
with a neural image encoder. These image representations are then integrated
into an aggregated image-based representation via an attention-based method. We
evaluate our IKRL models on knowledge graph completion and triple
classification. Experimental results demonstrate that our models outperform all
baselines on both tasks, which indicates the significance of visual information
for knowledge representations and the capability of our models in learning
knowledge representations with images.
","[{'version': 'v1', 'created': 'Thu, 22 Sep 2016 15:37:45 GMT'}, {'version': 'v2', 'created': 'Mon, 22 May 2017 08:14:27 GMT'}]",2020-10-23,"[['Xie', 'Ruobing', ''], ['Liu', 'Zhiyuan', ''], ['Luan', 'Huanbo', ''], ['Sun', 'Maosong', '']]"
1292326,2005.12531,Dongyang Dai,"Dongyang Dai, Li Chen, Yuping Wang, Mu Wang, Rui Xia, Xuchen Song,
  Zhiyong Wu, Yuxuan Wang","Noise Robust TTS for Low Resource Speakers using Pre-trained Model and
  Speech Enhancement",,,,,eess.AS cs.CL cs.LG cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  With the popularity of deep neural network, speech synthesis task has
achieved significant improvements based on the end-to-end encoder-decoder
framework in the recent days. More and more applications relying on speech
synthesis technology have been widely used in our daily life. Robust speech
synthesis model depends on high quality and customized data which needs lots of
collecting efforts. It is worth investigating how to take advantage of
low-quality and low resource voice data which can be easily obtained from the
Internet for usage of synthesizing personalized voice. In this paper, the
proposed end-to-end speech synthesis model uses both speaker embedding and
noise representation as conditional inputs to model speaker and noise
information respectively. Firstly, the speech synthesis model is pre-trained
with both multi-speaker clean data and noisy augmented data; then the
pre-trained model is adapted on noisy low-resource new speaker data; finally,
by setting the clean speech condition, the model can synthesize the new
speaker's clean voice. Experimental results show that the speech generated by
the proposed approach has better subjective evaluation results than the method
directly fine-tuning pre-trained multi-speaker speech synthesis model with
denoised new speaker data.
","[{'version': 'v1', 'created': 'Tue, 26 May 2020 06:14:06 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 11:36:56 GMT'}]",2020-10-23,"[['Dai', 'Dongyang', ''], ['Chen', 'Li', ''], ['Wang', 'Yuping', ''], ['Wang', 'Mu', ''], ['Xia', 'Rui', ''], ['Song', 'Xuchen', ''], ['Wu', 'Zhiyong', ''], ['Wang', 'Yuxuan', '']]"
1367652,2010.11322,Jonathan Pilault,"Jaehong Park, Jonathan Pilault and Christopher Pal",Learning to Summarize Long Texts with Memory Compression and Transfer,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  We introduce Mem2Mem, a memory-to-memory mechanism for hierarchical recurrent
neural network based encoder decoder architectures and we explore its use for
abstractive document summarization. Mem2Mem transfers ""memories"" via
readable/writable external memory modules that augment both the encoder and
decoder. Our memory regularization compresses an encoded input article into a
more compact set of sentence representations. Most importantly, the memory
compression step performs implicit extraction without labels, sidestepping
issues with suboptimal ground-truth data and exposure bias of hybrid
extractive-abstractive summarization techniques. By allowing the decoder to
read/write over the encoded input memory, the model learns to read salient
information about the input article while keeping track of what has been
generated. Our Mem2Mem approach yields results that are competitive with state
of the art transformer based summarization methods, but with 16 times fewer
parameters
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 21:45:44 GMT'}]",2020-10-23,"[['Park', 'Jaehong', ''], ['Pilault', 'Jonathan', ''], ['Pal', 'Christopher', '']]"
1367836,2010.11506,Lingkai Kong,"Lingkai Kong, Haoming Jiang, Yuchen Zhuang, Jie Lyu, Tuo Zhao, Chao
  Zhang","Calibrated Language Model Fine-Tuning for In- and Out-of-Distribution
  Data",EMNLP2020 long paper,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Fine-tuned pre-trained language models can suffer from severe miscalibration
for both in-distribution and out-of-distribution (OOD) data due to
over-parameterization. To mitigate this issue, we propose a regularized
fine-tuning method. Our method introduces two types of regularization for
better calibration: (1) On-manifold regularization, which generates pseudo
on-manifold samples through interpolation within the data manifold. Augmented
training with these pseudo samples imposes a smoothness regularization to
improve in-distribution calibration. (2) Off-manifold regularization, which
encourages the model to output uniform distributions for pseudo off-manifold
samples to address the over-confidence issue for OOD data. Our experiments
demonstrate that the proposed method outperforms existing calibration methods
for text classification in terms of expectation calibration error,
misclassification detection, and OOD detection on six datasets. Our code can be
found at https://github.com/Lingkai-Kong/Calibrated-BERT-Fine-Tuning.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 07:48:38 GMT'}]",2020-10-23,"[['Kong', 'Lingkai', ''], ['Jiang', 'Haoming', ''], ['Zhuang', 'Yuchen', ''], ['Lyu', 'Jie', ''], ['Zhao', 'Tuo', ''], ['Zhang', 'Chao', '']]"
1367716,2010.11386,Jheng-Hong Yang,"Sheng-Chieh Lin, Jheng-Hong Yang, Jimmy Lin","Distilling Dense Representations for Ranking using Tightly-Coupled
  Teachers",,,,,cs.IR cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present an approach to ranking with dense representations that applies
knowledge distillation to improve the recently proposed late-interaction
ColBERT model. Specifically, we distill the knowledge from ColBERT's expressive
MaxSim operator for computing relevance scores into a simple dot product, thus
enabling single-step ANN search. Our key insight is that during distillation,
tight coupling between the teacher model and the student model enables more
flexible distillation strategies and yields better learned representations. We
empirically show that our approach improves query latency and greatly reduces
the onerous storage requirements of ColBERT, while only making modest
sacrifices in terms of effectiveness. By combining our dense representations
with sparse representations derived from document expansion, we are able to
approach the effectiveness of a standard cross-encoder reranker using BERT that
is orders of magnitude slower.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 02:26:01 GMT'}]",2020-10-23,"[['Lin', 'Sheng-Chieh', ''], ['Yang', 'Jheng-Hong', ''], ['Lin', 'Jimmy', '']]"
1367775,2010.11445,Mingbo Ma,"Junkun Chen, Mingbo Ma, Renjie Zheng, Liang Huang",MAM: Masked Acoustic Modeling for End-to-End Speech-to-Text Translation,10 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  End-to-end Speech-to-text Translation (E2E- ST), which directly translates
source language speech to target language text, is widely useful in practice,
but traditional cascaded approaches (ASR+MT) often suffer from error
propagation in the pipeline. On the other hand, existing end-to-end solutions
heavily depend on the source language transcriptions for pre-training or
multi-task training with Automatic Speech Recognition (ASR). We instead propose
a simple technique to learn a robust speech encoder in a self-supervised
fashion only on the speech side, which can utilize speech data without
transcription. This technique, termed Masked Acoustic Modeling (MAM), can also
perform pre-training, for the first time, on any acoustic signals (including
non-speech ones) without annotation. Compared with current state-of-the-art
models on ST, our technique achieves +1.4 BLEU improvement without using
transcriptions, and +1.2 BLEU using transcriptions. The pre-training of MAM
with arbitrary acoustic signals also boosts the downstream speech-related
tasks.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 05:02:06 GMT'}]",2020-10-23,"[['Chen', 'Junkun', ''], ['Ma', 'Mingbo', ''], ['Zheng', 'Renjie', ''], ['Huang', 'Liang', '']]"
1367820,2010.11490,Christophe Cerisara,"Christophe Cerisara (SYNALP), Pavel Kral, Ladislav Lenc","On the Effects of Using word2vec Representations in Neural Networks for
  Dialogue Act Recognition",,"Computer Speech and Language, Elsevier, 2018, 47, pp.175 - 193",10.1016/j.csl.2017.07.009,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Dialogue act recognition is an important component of a large number of
natural language processing pipelines. Many research works have been carried
out in this area, but relatively few investigate deep neural networks and word
embeddings. This is surprising, given that both of these techniques have proven
exceptionally good in most other language-related domains. We propose in this
work a new deep neural network that explores recurrent models to capture word
sequences within sentences, and further study the impact of pretrained word
embeddings. We validate this model on three languages: English, French and
Czech. The performance of the proposed approach is consistent across these
languages and it is comparable to the state-of-the-art results in English. More
importantly, we confirm that deep neural networks indeed outperform a Maximum
Entropy classifier, which was expected. However , and this is more surprising,
we also found that standard word2vec em-beddings do not seem to bring valuable
information for this task and the proposed model, whatever the size of the
training corpus is. We thus further analyse the resulting embeddings and
conclude that a possible explanation may be related to the mismatch between the
type of lexical-semantic information captured by the word2vec embeddings, and
the kind of relations between words that is the most useful for the dialogue
act recognition task.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 07:21:17 GMT'}]",2020-10-23,"[['Cerisara', 'Christophe', '', 'SYNALP'], ['Kral', 'Pavel', ''], ['Lenc', 'Ladislav', '']]"
1368266,2010.11936,Tomasz Stanis{\l}awek,Rafal Powalski and Tomasz Stanislawek,UniCase -- Rethinking Casing in Language Models,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we introduce a new approach to dealing with the problem of
case-sensitiveness in Language Modelling (LM). We propose simple architecture
modification to the RoBERTa language model, accompanied by a new tokenization
strategy, which we named Unified Case LM (UniCase). We tested our solution on
the GLUE benchmark, which led to increased performance by 0.42 points.
Moreover, we prove that the UniCase model works much better when we have to
deal with text data, where all tokens are uppercased (+5.88 point).
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 17:58:44 GMT'}]",2020-10-23,"[['Powalski', 'Rafal', ''], ['Stanislawek', 'Tomasz', '']]"
1368260,2010.11930,Rodrigo Nogueira,"Ronak Pradeep, Xueguang Ma, Rodrigo Nogueira, Jimmy Lin",Scientific Claim Verification with VERT5ERINI,,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This work describes the adaptation of a pretrained sequence-to-sequence model
to the task of scientific claim verification in the biomedical domain. We
propose VERT5ERINI that exploits T5 for abstract retrieval, sentence selection
and label prediction, which are three critical sub-tasks of claim verification.
We evaluate our pipeline on SCIFACT, a newly curated dataset that requires
models to not just predict the veracity of claims but also provide relevant
sentences from a corpus of scientific literature that support this decision.
Empirically, our pipeline outperforms a strong baseline in each of the three
steps. Finally, we show VERT5ERINI's ability to generalize to two new datasets
of COVID-19 claims using evidence from the ever-expanding CORD-19 corpus.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 17:56:33 GMT'}]",2020-10-23,"[['Pradeep', 'Ronak', ''], ['Ma', 'Xueguang', ''], ['Nogueira', 'Rodrigo', ''], ['Lin', 'Jimmy', '']]"
1368248,2010.11918,"Andreas R\""uckl\'e","Andreas R\""uckl\'e, Gregor Geigle, Max Glockner, Tilman Beck, Jonas
  Pfeiffer, Nils Reimers, Iryna Gurevych",AdapterDrop: On the Efficiency of Adapters in Transformers,,,,,cs.LG cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Massively pre-trained transformer models are computationally expensive to
fine-tune, slow for inference, and have large storage requirements. Recent
approaches tackle these shortcomings by training smaller models, dynamically
reducing the model size, and by training light-weight adapters. In this paper,
we propose AdapterDrop, removing adapters from lower transformer layers during
training and inference, which incorporates concepts from all three directions.
We show that AdapterDrop can dynamically reduce the computational overhead when
performing inference over multiple tasks simultaneously, with minimal decrease
in task performances. We further prune adapters from AdapterFusion, which
improves the inference efficiency while maintaining the task performances
entirely.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 17:49:42 GMT'}]",2020-10-23,"[['Rücklé', 'Andreas', ''], ['Geigle', 'Gregor', ''], ['Glockner', 'Max', ''], ['Beck', 'Tilman', ''], ['Pfeiffer', 'Jonas', ''], ['Reimers', 'Nils', ''], ['Gurevych', 'Iryna', '']]"
1367717,2010.11387,George Boateng,George Boateng,Kwame: A Bilingual AI Teaching Assistant for Online SuaCode Courses,,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Introductory hands-on courses such as our smartphone-based coding courses,
SuaCode require a lot of support for students to accomplish learning goals.
Online environments make it even more difficult to get assistance especially
more recently because of COVID-19. Given the multilingual context of our
students (learners across 38 African countries), in this work, we developed an
AI Teaching Assistant (Kwame) that provides answers to students' coding
questions from our SuaCode courses in English and French. Kwame is a
Sentence-BERT(SBERT)-based question-answering (QA) system that we trained and
evaluated using question-answer pairs created from our course's quizzes and
students' questions in past cohorts. It finds the paragraph most semantically
similar to the question via cosine similarity. We compared the system with
TF-IDF and Universal Sentence Encoder. Our results showed that SBERT performed
the worst for the duration of 6 secs per question but the best for accuracy and
fine-tuning on our course data improved the result.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 02:26:12 GMT'}]",2020-10-23,"[['Boateng', 'George', '']]"
1368199,2010.11869,Lei Xu,"Lei Xu, Ivan Ramirez, Kalyan Veeramachaneni","Rewriting Meaningful Sentences via Conditional BERT Sampling and an
  application on fooling text classifiers",,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Most adversarial attack methods that are designed to deceive a text
classifier change the text classifier's prediction by modifying a few words or
characters. Few try to attack classifiers by rewriting a whole sentence, due to
the difficulties inherent in sentence-level rephrasing as well as the problem
of setting the criteria for legitimate rewriting.
  In this paper, we explore the problem of creating adversarial examples with
sentence-level rewriting. We design a new sampling method, named
ParaphraseSampler, to efficiently rewrite the original sentence in multiple
ways. Then we propose a new criteria for modification, called a sentence-level
threaten model. This criteria allows for both word- and sentence-level changes,
and can be adjusted independently in two dimensions: semantic similarity and
grammatical quality. Experimental results show that many of these rewritten
sentences are misclassified by the classifier. On all 6 datasets, our
ParaphraseSampler achieves a better attack success rate than our baseline.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 17:03:13 GMT'}]",2020-10-23,"[['Xu', 'Lei', ''], ['Ramirez', 'Ivan', ''], ['Veeramachaneni', 'Kalyan', '']]"
1368189,2010.11859,Nikolay Bogoychev Dr,Nikolay Bogoychev,Not all parameters are born equal: Attention is mostly what you need,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Transformers are widely used in state-of-the-art machine translation, but the
key to their success is still unknown. To gain insight into this, we consider
three groups of parameters: embeddings, attention, and feed forward neural
network (FFN) layers. We examine the relative importance of each by performing
an ablation study where we initialise them at random and freeze them, so that
their weights do not change over the course of the training. Through this, we
show that the attention and FFN are equally important and fulfil the same
functionality in a model. We show that the decision about whether a component
is frozen or allowed to train is at least as important for the final model
performance as its number of parameters. At the same time, the number of
parameters alone is not indicative of a component's importance. Finally, while
the embedding layer is the least essential for machine translation tasks, it is
the most important component for language modelling tasks.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 16:49:18 GMT'}]",2020-10-23,"[['Bogoychev', 'Nikolay', '']]"
1367811,2010.11481,Yu-An Chung,Yu-An Chung and Yonatan Belinkov and James Glass,Similarity Analysis of Self-Supervised Speech Representations,,,,,eess.AS cs.CL cs.LG cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Self-supervised speech representation learning has recently been a prosperous
research topic. Many algorithms have been proposed for learning useful
representations from large-scale unlabeled data, and their applications to a
wide range of speech tasks have also been investigated. However, there has been
little research focusing on understanding the properties of existing
approaches. In this work, we aim to provide a comparative study of some of the
most representative self-supervised algorithms. Specifically, we quantify the
similarities between different self-supervised representations using existing
similarity measures. We also design probing tasks to study the correlation
between the models' pre-training loss and the amount of specific speech
information contained in their learned representations. In addition to showing
how various self-supervised models behave differently given the same input, our
study also finds that the training objective has a higher impact on
representation similarity than architectural choices such as building blocks
(RNN/Transformer/CNN) and directionality (uni/bidirectional). Our results also
suggest that there exists a strong correlation between pre-training loss and
downstream performance for some self-supervised algorithms.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 07:02:21 GMT'}]",2020-10-23,"[['Chung', 'Yu-An', ''], ['Belinkov', 'Yonatan', ''], ['Glass', 'James', '']]"
1368245,2010.11915,Akari Asai,Akari Asai and Eunsol Choi,"Challenges in Information Seeking QA:Unanswerable Questions and
  Paragraph Retrieval",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent progress in pretrained language model ""solved"" many reading
comprehension benchmark datasets. Yet information-seeking Question Answering
(QA) datasets, where questions are written without the evidence document,
remain unsolved. We analyze two such datasets (Natural Questions and TyDi QA)
to identify remaining headrooms: paragraph selection and answerability
classification, i.e. determining whether the paired evidence document contains
the answer to the query or not. In other words, given a gold paragraph and
knowing whether it contains an answer or not, models easily outperform a single
annotator in both datasets. After identifying unanswerability as a bottleneck,
we further inspect what makes questions unanswerable. Our study points to
avenues for future research, both for dataset creation and model development.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 17:48:17 GMT'}]",2020-10-23,"[['Asai', 'Akari', ''], ['Choi', 'Eunsol', '']]"
1368185,2010.11855,Michael Wick,"Michael L. Wick, Kate Silverstein, Jean-Baptiste Tristan, Adam Pocock,
  Mark Johnson","Detecting and Exorcising Statistical Demons from Language Models with
  Anti-Models of Negative Data",,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  It's been said that ""Language Models are Unsupervised Multitask Learners.""
Indeed, self-supervised language models trained on ""positive"" examples of
English text generalize in desirable ways to many natural language tasks. But
if such models can stray so far from an initial self-supervision objective, a
wayward model might generalize in undesirable ways too, say to nonsensical
""negative"" examples of unnatural language. A key question in this work is: do
language models trained on (positive) training data also generalize to
(negative) test data? We use this question as a contrivance to assess the
extent to which language models learn undesirable properties of text, such as
n-grams, that might interfere with the learning of more desirable properties of
text, such as syntax. We find that within a model family, as the number of
parameters, training epochs, and data set size increase, so does a model's
ability to generalize to negative n-gram data, indicating standard
self-supervision generalizes too far. We propose a form of inductive bias that
attenuates such undesirable signals with negative data distributions
automatically learned from positive data. We apply the method to remove n-gram
signals from LSTMs and find that doing so causes them to favor syntactic
signals, as demonstrated by large error reductions (up to 46% on the hardest
cases) on a syntactic subject-verb agreement task.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 16:45:32 GMT'}]",2020-10-23,"[['Wick', 'Michael L.', ''], ['Silverstein', 'Kate', ''], ['Tristan', 'Jean-Baptiste', ''], ['Pocock', 'Adam', ''], ['Johnson', 'Mark', '']]"
1368121,2010.11791,Ivan Vuli\'c,Matthew Henderson and Ivan Vuli\'c,ConVEx: Data-Efficient and Few-Shot Slot Labeling,,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  We propose ConVEx (Conversational Value Extractor), an efficient pretraining
and fine-tuning neural approach for slot-labeling dialog tasks. Instead of
relying on more general pretraining objectives from prior work (e.g., language
modeling, response selection), ConVEx's pretraining objective, a novel pairwise
cloze task using Reddit data, is well aligned with its intended usage on
sequence labeling tasks. This enables learning domain-specific slot labelers by
simply fine-tuning decoding layers of the pretrained general-purpose sequence
labeling model, while the majority of the pretrained model's parameters are
kept frozen. We report state-of-the-art performance of ConVEx across a range of
diverse domains and data sets for dialog slot-labeling, with the largest gains
in the most challenging, few-shot setups. We believe that ConVEx's reduced
pretraining times (i.e., only 18 hours on 12 GPUs) and cost, along with its
efficient fine-tuning and strong performance, promise wider portability and
scalability for data-efficient sequence-labeling tasks in general.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 15:13:35 GMT'}]",2020-10-23,"[['Henderson', 'Matthew', ''], ['Vulić', 'Ivan', '']]"
1368183,2010.11853,Johannes E. M. Mosig,"Johannes E. M. Mosig, Shikib Mehri, Thomas Kober",STAR: A Schema-Guided Dialog Dataset for Transfer Learning,"Equal contribution: Johannes E. M. Mosig, Shikib Mehri",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present STAR, a schema-guided task-oriented dialog dataset consisting of
127,833 utterances and knowledge base queries across 5,820 task-oriented
dialogs in 13 domains that is especially designed to facilitate task and domain
transfer learning in task-oriented dialog. Furthermore, we propose a scalable
crowd-sourcing paradigm to collect arbitrarily large datasets of the same
quality as STAR. Moreover, we introduce novel schema-guided dialog models that
use an explicit description of the task(s) to generalize from known to unknown
tasks. We demonstrate the effectiveness of these models, particularly for
zero-shot generalization across tasks and domains.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 16:45:00 GMT'}]",2020-10-23,"[['Mosig', 'Johannes E. M.', ''], ['Mehri', 'Shikib', ''], ['Kober', 'Thomas', '']]"
1368148,2010.11818,Hao Zheng,Hao Zheng and Mirella Lapata,Compositional Generalization via Semantic Tagging,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Although neural sequence-to-sequence models have been successfully applied to
semantic parsing, they struggle to perform well on query-based data splits that
require \emph{composition generalization}, an ability of systematically
generalizing to unseen composition of seen components. Motivated by the
explicitly built-in compositionality in traditional statistical semantic
parsing, we propose a new decoding framework that preserves the expressivity
and generality of sequence-to-sequence models while featuring explicit
lexicon-style alignments and disentangled information processing. Specifically,
we decompose decoding into two phases where an input utterance is first tagged
with semantic symbols representing the meanings of its individual words, and
then a sequence-to-sequence model is used to predict the final meaning
representation conditioning on the utterance and the predicted tag sequence.
Experimental results on three semantic parsing datasets with query-based splits
show that the proposed approach consistently improves compositional
generalization of sequence-to-sequence models across different model
architectures, domains and semantic formalisms.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 15:55:15 GMT'}]",2020-10-23,"[['Zheng', 'Hao', ''], ['Lapata', 'Mirella', '']]"
1366748,2010.10418,Swarnadeep Saha,"Swarnadeep Saha, Yixin Nie, Mohit Bansal",ConjNLI: Natural Language Inference Over Conjunctive Sentences,EMNLP 2020 (14 pages),,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Reasoning about conjuncts in conjunctive sentences is important for a deeper
understanding of conjunctions in English and also how their usages and
semantics differ from conjunctive and disjunctive boolean logic. Existing NLI
stress tests do not consider non-boolean usages of conjunctions and use
templates for testing such model knowledge. Hence, we introduce ConjNLI, a
challenge stress-test for natural language inference over conjunctive
sentences, where the premise differs from the hypothesis by conjuncts removed,
added, or replaced. These sentences contain single and multiple instances of
coordinating conjunctions (""and"", ""or"", ""but"", ""nor"") with quantifiers,
negations, and requiring diverse boolean and non-boolean inferences over
conjuncts. We find that large-scale pre-trained language models like RoBERTa do
not understand conjunctive semantics well and resort to shallow heuristics to
make inferences over such sentences. As some initial solutions, we first
present an iterative adversarial fine-tuning method that uses synthetically
created training data based on boolean and non-boolean heuristics. We also
propose a direct model advancement by making RoBERTa aware of predicate
semantic roles. While we observe some performance gains, ConjNLI is still
challenging for current methods, thus encouraging interesting future work for
better understanding of conjunctions. Our data and code are publicly available
at: https://github.com/swarnaHub/ConjNLI
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 16:29:13 GMT'}, {'version': 'v2', 'created': 'Wed, 21 Oct 2020 21:49:00 GMT'}]",2020-10-23,"[['Saha', 'Swarnadeep', ''], ['Nie', 'Yixin', ''], ['Bansal', 'Mohit', '']]"
1367873,2010.11543,Jee-Weon Jung,"Jee-weon Jung, Hee-Soo Heo, Ha-Jin Yu, Joon Son Chung",Graph Attention Networks for Speaker Verification,"5 pages, 1 figure, 2 tables, submitted to ICASSP 2021 as a conference
  paper",,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This work presents a novel back-end framework for speaker verification using
graph attention networks. Segment-wise speaker embeddings extracted from
multiple crops within an utterance are interpreted as node representations of a
graph. The proposed framework inputs segment-wise speaker embeddings from an
enrollment and a test utterance and directly outputs a similarity score. We
first construct a graph using segment-wise speaker embeddings and then input
these to graph attention networks. After a few graph attention layers with
residual connections, each node is projected into a one-dimensional space using
affine transform, followed by a readout operation resulting in a scalar
similarity score. To enable successful adaptation for speaker verification, we
propose techniques such as separating trainable weights for attention map
calculations between segment-wise speaker embeddings from different utterances.
The effectiveness of the proposed framework is validated using three different
speaker embedding extractors trained with different architectures and objective
functions. Experimental results demonstrate consistent improvement over various
baseline back-end classifiers, with an average equal error rate improvement of
20% over the cosine similarity back-end without test time augmentation.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 09:08:02 GMT'}]",2020-10-24,"[['Jung', 'Jee-weon', ''], ['Heo', 'Hee-Soo', ''], ['Yu', 'Ha-Jin', ''], ['Chung', 'Joon Son', '']]"
1368133,2010.11803,Zeqian Li,"Zeqian Li, Jacob Whitehill","Compositional embedding models for speaker identification and
  diarization with simultaneous speech from 2+ speakers",,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a new method for speaker diarization that can handle overlapping
speech with 2+ people. Our method is based on compositional embeddings [1]:
Like standard speaker embedding methods such as x-vector [2], compositional
embedding models contain a function f that separates speech from different
speakers. In addition, they include a composition function g to compute
set-union operations in the embedding space so as to infer the set of speakers
within the input audio. In an experiment on multi-person speaker identification
using synthesized LibriSpeech data, the proposed method outperforms traditional
embedding methods that are only trained to separate single speakers (not
speaker sets). In a speaker diarization experiment on the AMI Headset Mix
corpus, we achieve state-of-the-art accuracy (DER=22.93%), slightly higher than
the previous best result (23.82% from [3]).
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 15:33:36 GMT'}]",2020-10-24,"[['Li', 'Zeqian', ''], ['Whitehill', 'Jacob', '']]"
1368269,2010.11939,Chu-Cheng Lin,"Chu-Cheng Lin and Aaron Jaech and Xin Li and Matt Gormley and Jason
  Eisner",Autoregressive Modeling is Misspecified for Some Sequence Distributions,,,,,cs.LG cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Should sequences be modeled autoregressively---one symbol at a time? How much
computation is needed to predict the next symbol? While local normalization is
cheap, this also limits its power. We point out that some probability
distributions over discrete sequences cannot be well-approximated by any
autoregressive model whose runtime and parameter size grow polynomially in the
sequence length---even though their unnormalized sequence probabilities are
efficient to compute exactly. Intuitively, the probability of the next symbol
can be expensive to compute or approximate (even via randomized algorithms)
when it marginalizes over exponentially many possible futures, which is in
general $\mathrm{NP}$-hard. Our result is conditional on the widely believed
hypothesis that $\mathrm{NP} \nsubseteq \mathrm{P/poly}$ (without which the
polynomial hierarchy would collapse at the second level). This theoretical
observation serves as a caution to the viewpoint that pumping up parameter size
is a straightforward way to improve autoregressive models (e.g., in language
modeling). It also suggests that globally normalized (energy-based) models may
sometimes outperform locally normalized (autoregressive) models, as we
demonstrate experimentally for language modeling.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 17:59:09 GMT'}]",2020-10-24,"[['Lin', 'Chu-Cheng', ''], ['Jaech', 'Aaron', ''], ['Li', 'Xin', ''], ['Gormley', 'Matt', ''], ['Eisner', 'Jason', '']]"
1260776,2003.10421,"Eric M\""uller-Budack","Eric M\""uller-Budack, Jonas Theiner, Sebastian Diering, Maximilian
  Idahl, Ralph Ewerth","Multimodal Analytics for Real-world News using Measures of Cross-modal
  Entity Consistency","Accepted for publication in: International Conference on Multimedia
  Retrieval (ICMR), Dublin, 2020",,,,cs.CL cs.IR cs.MM,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The World Wide Web has become a popular source for gathering information and
news. Multimodal information, e.g., enriching text with photos, is typically
used to convey the news more effectively or to attract attention. Photo content
can range from decorative, depict additional important information, or can even
contain misleading information. Therefore, automatic approaches to quantify
cross-modal consistency of entity representation can support human assessors to
evaluate the overall multimodal message, for instance, with regard to bias or
sentiment. In some cases such measures could give hints to detect fake news,
which is an increasingly important topic in today's society. In this paper, we
introduce a novel task of cross-modal consistency verification in real-world
news and present a multimodal approach to quantify the entity coherence between
image and text. Named entity linking is applied to extract persons, locations,
and events from news texts. Several measures are suggested to calculate
cross-modal similarity for these entities using state of the art approaches. In
contrast to previous work, our system automatically gathers example data from
the Web and is applicable to real-world news. Results on two novel datasets
that cover different languages, topics, and domains demonstrate the feasibility
of our approach. Datasets and code are publicly available to foster research
towards this new direction.
","[{'version': 'v1', 'created': 'Mon, 23 Mar 2020 17:49:06 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 09:22:53 GMT'}]",2020-10-26,"[['Müller-Budack', 'Eric', ''], ['Theiner', 'Jonas', ''], ['Diering', 'Sebastian', ''], ['Idahl', 'Maximilian', ''], ['Ewerth', 'Ralph', '']]"
1268577,2004.03807,Abhinav Ramesh Kashyap,"Abhinav Ramesh Kashyap, Min-Yen Kan",SciWING -- A Software Toolkit for Scientific Document Processing,"6 pages, 3 figures, First Workshop on Scholarly Document Processing -
  SDP@EMNLP 2020",,,,cs.DL cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We introduce SciWING, an open-source software toolkit which provides access
to pre-trained models for scientific document processing tasks, inclusive of
citation string parsing and logical structure recovery. SciWING enables
researchers to rapidly experiment with different models by swapping and
stacking different modules. It also enables them declare and run models from a
configuration file. It enables researchers to perform production-ready transfer
learning from general, pre-trained transformers (i.e., BERT, SciBERT etc), and
aids development of end-user applications. It includes ready-to-use web and
terminal-based applications and demonstrations (Available from
http://sciwing.io).
","[{'version': 'v1', 'created': 'Wed, 8 Apr 2020 04:43:37 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 07:27:01 GMT'}]",2020-10-26,"[['Kashyap', 'Abhinav Ramesh', ''], ['Kan', 'Min-Yen', '']]"
1278000,2004.13230,Marjan Albooyeh,"Marjan Albooyeh, Rishab Goel, Seyed Mehran Kazemi",Out-of-Sample Representation Learning for Multi-Relational Graphs,,,,,cs.LG cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Many important problems can be formulated as reasoning in knowledge graphs.
Representation learning has proved extremely effective for transductive
reasoning, in which one needs to make new predictions for already observed
entities. This is true for both attributed graphs(where each entity has an
initial feature vector) and non-attributed graphs (where the only initial
information derives from known relations with other entities). For
out-of-sample reasoning, where one needs to make predictions for entities that
were unseen at training time, much prior work considers attributed graph.
However, this problem is surprisingly under-explored for non-attributed graphs.
In this paper, we study the out-of-sample representation learning problem for
non-attributed knowledge graphs, create benchmark datasets for this task,
develop several models and baselines, and provide empirical analyses and
comparisons of the proposed models and baselines.
","[{'version': 'v1', 'created': 'Tue, 28 Apr 2020 00:53:01 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 16:22:50 GMT'}]",2020-10-26,"[['Albooyeh', 'Marjan', ''], ['Goel', 'Rishab', ''], ['Kazemi', 'Seyed Mehran', '']]"
1213482,1912.01586,Tongfei Chen,"Yunmo Chen, Tongfei Chen, Seth Ebner, Aaron Steven White, Benjamin Van
  Durme",Reading the Manual: Event Extraction as Definition Comprehension,Accepted at the EMNLP 2020 Workshop on Structured Prediction for NLP,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We ask whether text understanding has progressed to where we may extract
event information through incremental refinement of bleached statements derived
from annotation manuals. Such a capability would allow for the trivial
construction and extension of an extraction framework by intended end-users
through declarations such as, ""Some person was born in some location at some
time."" We introduce an example of a model that employs such statements, with
experiments illustrating we can extract events under closed ontologies and
generalize to unseen event types simply by reading new definitions.
","[{'version': 'v1', 'created': 'Tue, 3 Dec 2019 18:31:42 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 02:27:24 GMT'}]",2020-10-26,"[['Chen', 'Yunmo', ''], ['Chen', 'Tongfei', ''], ['Ebner', 'Seth', ''], ['White', 'Aaron Steven', ''], ['Van Durme', 'Benjamin', '']]"
1276843,2004.12073,Sho Takase,Sho Takase and Sosuke Kobayashi,All Word Embeddings from One Embedding,NeurIPS 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In neural network-based models for natural language processing (NLP), the
largest part of the parameters often consists of word embeddings. Conventional
models prepare a large embedding matrix whose size depends on the vocabulary
size. Therefore, storing these models in memory and disk storage is costly. In
this study, to reduce the total number of parameters, the embeddings for all
words are represented by transforming a shared embedding. The proposed method,
ALONE (all word embeddings from one), constructs the embedding of a word by
modifying the shared embedding with a filter vector, which is word-specific but
non-trainable. Then, we input the constructed embedding into a feed-forward
neural network to increase its expressiveness. Naively, the filter vectors
occupy the same memory size as the conventional embedding matrix, which depends
on the vocabulary size. To solve this issue, we also introduce a
memory-efficient filter construction approach. We indicate our ALONE can be
used as word representation sufficiently through an experiment on the
reconstruction of pre-trained word embeddings. In addition, we also conduct
experiments on NLP application tasks: machine translation and summarization. We
combined ALONE with the current state-of-the-art encoder-decoder model, the
Transformer, and achieved comparable scores on WMT 2014 English-to-German
translation and DUC 2004 very short summarization with less parameters.
","[{'version': 'v1', 'created': 'Sat, 25 Apr 2020 07:38:08 GMT'}, {'version': 'v2', 'created': 'Mon, 25 May 2020 03:36:32 GMT'}, {'version': 'v3', 'created': 'Fri, 23 Oct 2020 03:12:12 GMT'}]",2020-10-26,"[['Takase', 'Sho', ''], ['Kobayashi', 'Sosuke', '']]"
968940,1804.07247,Dominic Seyler,"Dominic Seyler, Lunan Li, ChengXiang Zhai","Semantic Text Analysis for Detection of Compromised Accounts on Social
  Networks",,,,,cs.SI cs.CL cs.CR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Compromised accounts on social networks are regular user accounts that have
been taken over by an entity with malicious intent. Since the adversary
exploits the already established trust of a compromised account, it is crucial
to detect these accounts to limit the damage they can cause. We propose a novel
general framework for semantic analysis of text messages coming out from an
account to detect compromised accounts. Our framework is built on the
observation that normal users will use language that is measurably different
from the language that an adversary would use when the account is compromised.
We propose to use the difference of language models of users and adversaries to
define novel interpretable semantic features for measuring semantic incoherence
in a message stream. We study the effectiveness of the proposed semantic
features using a Twitter data set. Evaluation results show that the proposed
framework is effective for discovering compromised accounts on social networks
and a KL-divergence-based language model feature works best.
","[{'version': 'v1', 'created': 'Thu, 19 Apr 2018 16:06:29 GMT'}, {'version': 'v2', 'created': 'Wed, 5 Feb 2020 18:06:25 GMT'}, {'version': 'v3', 'created': 'Wed, 6 May 2020 21:26:02 GMT'}, {'version': 'v4', 'created': 'Fri, 23 Oct 2020 15:56:27 GMT'}]",2020-10-26,"[['Seyler', 'Dominic', ''], ['Li', 'Lunan', ''], ['Zhai', 'ChengXiang', '']]"
1246550,2002.09127,Eric Yuan,"Ashutosh Adhikari, Xingdi Yuan, Marc-Alexandre C\^ot\'e, Mikul\'a\v{s}
  Zelinka, Marc-Antoine Rondeau, Romain Laroche, Pascal Poupart, Jian Tang,
  Adam Trischler, William L. Hamilton",Learning Dynamic Belief Graphs to Generalize on Text-Based Games,NeurIPS 2020 cameraready version,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Playing text-based games requires skills in processing natural language and
sequential decision making. Achieving human-level performance on text-based
games remains an open challenge, and prior research has largely relied on
hand-crafted structured representations and heuristics. In this work, we
investigate how an agent can plan and generalize in text-based games using
graph-structured representations learned end-to-end from raw text. We propose a
novel graph-aided transformer agent (GATA) that infers and updates latent
belief graphs during planning to enable effective action selection by capturing
the underlying game dynamics. GATA is trained using a combination of
reinforcement and self-supervised learning. Our work demonstrates that the
learned graph-based representations help agents converge to better policies
than their text-only counterparts and facilitate effective generalization
across game configurations. Experiments on 500+ unique games from the TextWorld
suite show that our best agent outperforms text-based baselines by an average
of 24.2%.
","[{'version': 'v1', 'created': 'Fri, 21 Feb 2020 04:38:37 GMT'}, {'version': 'v2', 'created': 'Thu, 18 Jun 2020 16:22:16 GMT'}, {'version': 'v3', 'created': 'Thu, 22 Oct 2020 20:01:55 GMT'}]",2020-10-26,"[['Adhikari', 'Ashutosh', ''], ['Yuan', 'Xingdi', ''], ['Côté', 'Marc-Alexandre', ''], ['Zelinka', 'Mikuláš', ''], ['Rondeau', 'Marc-Antoine', ''], ['Laroche', 'Romain', ''], ['Poupart', 'Pascal', ''], ['Tang', 'Jian', ''], ['Trischler', 'Adam', ''], ['Hamilton', 'William L.', '']]"
1236729,2001.11316,Akbar Karimi,"Akbar Karimi, Leonardo Rossi, Andrea Prati",Adversarial Training for Aspect-Based Sentiment Analysis with BERT,,,,,cs.LG cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Aspect-Based Sentiment Analysis (ABSA) deals with the extraction of
sentiments and their targets. Collecting labeled data for this task in order to
help neural networks generalize better can be laborious and time-consuming. As
an alternative, similar data to the real-world examples can be produced
artificially through an adversarial process which is carried out in the
embedding space. Although these examples are not real sentences, they have been
shown to act as a regularization method which can make neural networks more
robust. In this work, we apply adversarial training, which was put forward by
Goodfellow et al. (2014), to the post-trained BERT (BERT-PT) language model
proposed by Xu et al. (2019) on the two major tasks of Aspect Extraction and
Aspect Sentiment Classification in sentiment analysis. After improving the
results of post-trained BERT by an ablation study, we propose a novel
architecture called BERT Adversarial Training (BAT) to utilize adversarial
training in ABSA. The proposed model outperforms post-trained BERT in both
tasks. To the best of our knowledge, this is the first study on the application
of adversarial training in ABSA.
","[{'version': 'v1', 'created': 'Thu, 30 Jan 2020 13:53:58 GMT'}, {'version': 'v2', 'created': 'Fri, 31 Jan 2020 12:33:57 GMT'}, {'version': 'v3', 'created': 'Thu, 22 Oct 2020 13:39:32 GMT'}, {'version': 'v4', 'created': 'Fri, 23 Oct 2020 07:39:17 GMT'}]",2020-10-26,"[['Karimi', 'Akbar', ''], ['Rossi', 'Leonardo', ''], ['Prati', 'Andrea', '']]"
1276896,2004.12126,Hongyu Lin,"Hongyu Lin, Yaojie Lu, Jialong Tang, Xianpei Han, Le Sun, Zhicheng
  Wei, Nicholas Jing Yuan","A Rigorous Study on Named Entity Recognition: Can Fine-tuning Pretrained
  Model Lead to the Promised Land?",Accepted to EMNLP2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Fine-tuning pretrained model has achieved promising performance on standard
NER benchmarks. Generally, these benchmarks are blessed with strong name
regularity, high mention coverage and sufficient context diversity.
Unfortunately, when scaling NER to open situations, these advantages may no
longer exist. And therefore it raises a critical question of whether previous
creditable approaches can still work well when facing these challenges. As
there is no currently available dataset to investigate this problem, this paper
proposes to conduct randomization test on standard benchmarks. Specifically, we
erase name regularity, mention coverage and context diversity respectively from
the benchmarks, in order to explore their impact on the generalization ability
of models. To further verify our conclusions, we also construct a new open NER
dataset that focuses on entity types with weaker name regularity and lower
mention coverage to verify our conclusion. From both randomization test and
empirical experiments, we draw the conclusions that 1) name regularity is
critical for the models to generalize to unseen mentions; 2) high mention
coverage may undermine the model generalization ability and 3) context patterns
may not require enormous data to capture when using pretrained encoders.
","[{'version': 'v1', 'created': 'Sat, 25 Apr 2020 12:30:16 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 07:06:06 GMT'}]",2020-10-26,"[['Lin', 'Hongyu', ''], ['Lu', 'Yaojie', ''], ['Tang', 'Jialong', ''], ['Han', 'Xianpei', ''], ['Sun', 'Le', ''], ['Wei', 'Zhicheng', ''], ['Yuan', 'Nicholas Jing', '']]"
1267950,2004.03180,Mamoru Komachi,"Aizhan Imankulova, Masahiro Kaneko, Tosho Hirasawa and Mamoru Komachi",Towards Multimodal Simultaneous Neural Machine Translation,10 pages; WMT 2020,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Simultaneous translation involves translating a sentence before the speaker's
utterance is completed in order to realize real-time understanding in multiple
languages. This task is significantly more challenging than the general full
sentence translation because of the shortage of input information during
decoding. To alleviate this shortage, we propose multimodal simultaneous neural
machine translation (MSNMT), which leverages visual information as an
additional modality. Our experiments with the Multi30k dataset showed that
MSNMT significantly outperforms its text-only counterpart in more timely
translation situations with low latency. Furthermore, we verified the
importance of visual information during decoding by performing an adversarial
evaluation of MSNMT, where we studied how models behaved with incongruent input
modality and analyzed the effect of different word order between source and
target languages.
","[{'version': 'v1', 'created': 'Tue, 7 Apr 2020 08:02:21 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 04:38:38 GMT'}]",2020-10-26,"[['Imankulova', 'Aizhan', ''], ['Kaneko', 'Masahiro', ''], ['Hirasawa', 'Tosho', ''], ['Komachi', 'Mamoru', '']]"
1368731,2010.12401,Gaurish Thakkar Mr,"Gaurish Thakkar, Marcis Pinnis","Pretraining and Fine-Tuning Strategies for Sentiment Analysis of Latvian
  Tweets",,,10.3233/FAIA200602,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we present various pre-training strategies that aid in
im-proving the accuracy of the sentiment classification task. We, at first,
pre-trainlanguage representation models using these strategies and then
fine-tune them onthe downstream task. Experimental results on a time-balanced
tweet evaluation setshow the improvement over the previous technique. We
achieve 76% accuracy forsentiment analysis on Latvian tweets, which is a
substantial improvement over pre-vious work
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 13:45:33 GMT'}]",2020-10-26,"[['Thakkar', 'Gaurish', ''], ['Pinnis', 'Marcis', '']]"
1368857,2010.12527,Peng Qi,"Peng Qi, Haejun Lee, Oghenetegiri ""TG"" Sido, Christopher D. Manning","Retrieve, Rerank, Read, then Iterate: Answering Open-Domain Questions of
  Arbitrary Complexity from Text",Peng Qi and Haejun Lee contributed equally,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Current approaches to open-domain question answering often make crucial
assumptions that prevent them from generalizing to real-world settings,
including the access to parameterized retrieval systems well-tuned for the
task, access to structured metadata like knowledge bases and web links, or a
priori knowledge of the complexity of questions to be answered (e.g.,
single-hop or multi-hop). To address these limitations, we propose a unified
system to answer open-domain questions of arbitrary complexity directly from
text that works with off-the-shelf retrieval systems on arbitrary text
collections. We employ a single multi-task model to perform all the necessary
subtasks---retrieving supporting facts, reranking them, and predicting the
answer from all retrieved documents---in an iterative fashion. To emulate a
more realistic setting, we also constructed a new unified benchmark by
collecting about 200 multi-hop questions that require three Wikipedia pages to
answer, and combining them with existing datasets. We show that our model not
only outperforms state-of-the-art systems on several existing benchmarks that
exclusively feature single-hop or multi-hop open-domain questions, but also
achieves strong performance on the new benchmark.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 16:51:09 GMT'}]",2020-10-26,"[['Qi', 'Peng', ''], ['Lee', 'Haejun', ''], ['Sido', 'Oghenetegiri ""TG""', ''], ['Manning', 'Christopher D.', '']]"
1368635,2010.12305,Lukas Lange,"Lukas Lange, Heike Adel, Jannik Str\""otgen, Dietrich Klakow",Adversarial Learning of Feature-based Meta-Embeddings,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Certain embedding types outperform others in different scenarios, e.g.,
subword-based embeddings can model rare words well and domain-specific
embeddings can better represent in-domain terms. Therefore, recent works
consider attention-based meta-embeddings to combine different embedding types.
We demonstrate that these methods have two shortcomings: First, the attention
weights are calculated without knowledge of word properties. Second, the
different embedding types can form clusters in the common embedding space,
preventing the computation of a meaningful average of different embeddings and
thus, reducing performance. We propose to solve these problems by using
feature-based meta-embeddings learned with adversarial training. Our
experiments and analysis on sentence classification and sequence tagging tasks
show that our approach is effective. We set the new state of the art on various
datasets across languages and domains.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 11:16:53 GMT'}]",2020-10-26,"[['Lange', 'Lukas', ''], ['Adel', 'Heike', ''], ['Strötgen', 'Jannik', ''], ['Klakow', 'Dietrich', '']]"
1368613,2010.12283,Minjeong Kim,"Minjeong Kim, Gyuwan Kim, Sang-Woo Lee, Jung-Woo Ha","ST-BERT: Cross-modal Language Model Pre-training For End-to-end Spoken
  Language Understanding","5 pages, 2 figures",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language model pre-training has shown promising results in various downstream
tasks. In this context, we introduce a cross-modal pre-trained language model,
called Speech-Text BERT (ST-BERT), to tackle end-to-end spoken language
understanding (E2E SLU) tasks. Taking phoneme posterior and subword-level text
as an input, ST-BERT learns a contextualized cross-modal alignment via our two
proposed pre-training tasks: Cross-modal Masked Language Modeling (CM-MLM) and
Cross-modal Conditioned Language Modeling (CM-CLM). Experimental results on
three benchmarks present that our approach is effective for various SLU
datasets and shows a surprisingly marginal performance degradation even when 1%
of the training data are available. Also, our method shows further SLU
performance gain via domain-adaptive pre-training with domain-specific
speech-text pair data.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 10:28:20 GMT'}]",2020-10-26,"[['Kim', 'Minjeong', ''], ['Kim', 'Gyuwan', ''], ['Lee', 'Sang-Woo', ''], ['Ha', 'Jung-Woo', '']]"
1368602,2010.12272,Zhen Ke,"Zhen Ke, Liang Shi, Erli Meng, Bin Wang, Xipeng Qiu",Pre-trained Model for Chinese Word Segmentation with Meta Learning,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent researches show that pre-trained models such as BERT (Devlin et al.,
2019) are beneficial for Chinese Word Segmentation tasks. However, existing
approaches usually finetune pre-trained models directly on a separate
downstream Chinese Word Segmentation corpus. These recent methods don't fully
utilize the prior knowledge of existing segmentation corpora, and don't regard
the discrepancy between the pre-training tasks and the downstream Chinese Word
Segmentation tasks. In this work, we propose a Pre-Trained Model for Chinese
Word Segmentation, which can be abbreviated as PTM-CWS. PTM-CWS model employs a
unified architecture for different segmentation criteria, and is pre-trained on
a joint multi-criteria corpus with meta learning algorithm. Empirical results
show that our PTM-CWS model can utilize the existing prior segmentation
knowledge, reduce the discrepancy between the pre-training tasks and the
downstream Chinese Word Segmentation tasks, and achieve new state-of-the-art
performance on twelve Chinese Word Segmentation corpora.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 10:00:46 GMT'}]",2020-10-26,"[['Ke', 'Zhen', ''], ['Shi', 'Liang', ''], ['Meng', 'Erli', ''], ['Wang', 'Bin', ''], ['Qiu', 'Xipeng', '']]"
1368597,2010.12267,Xinsheng Wang,"Xinsheng Wang, Siyuan Feng, Jihua Zhu, Mark Hasegawa-Johnson, Odette
  Scharenborg",Show and Speak: Directly Synthesize Spoken Description of Images,,,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper proposes a new model, referred to as the show and speak (SAS)
model that, for the first time, is able to directly synthesize spoken
descriptions of images, bypassing the need for any text or phonemes. The basic
structure of SAS is an encoder-decoder architecture that takes an image as
input and predicts the spectrogram of speech that describes this image. The
final speech audio is obtained from the predicted spectrogram via WaveNet.
Extensive experiments on the public benchmark database Flickr8k demonstrate
that the proposed SAS is able to synthesize natural spoken descriptions for
images, indicating that synthesizing spoken descriptions for images while
bypassing text and phonemes is feasible.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 09:53:01 GMT'}]",2020-10-26,"[['Wang', 'Xinsheng', ''], ['Feng', 'Siyuan', ''], ['Zhu', 'Jihua', ''], ['Hasegawa-Johnson', 'Mark', ''], ['Scharenborg', 'Odette', '']]"
1368581,2010.12251,Sunghyun Park,"Sunghyun Park, Han Li, Ameen Patel, Sidharth Mudgal, Sungjin Lee,
  Young-Bum Kim, Spyros Matsoukas, Ruhi Sarikaya","A Scalable Framework for Learning From Implicit User Feedback to Improve
  Natural Language Understanding in Large-Scale Conversational AI Systems",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Natural Language Understanding (NLU) is an established component within a
conversational AI or digital assistant system, and it is responsible for
producing semantic understanding of a user request. We propose a scalable and
automatic approach for improving NLU in a large-scale conversational AI system
by leveraging implicit user feedback, with an insight that user interaction
data and dialog context have rich information embedded from which user
satisfaction and intention can be inferred. In particular, we propose a general
domain-agnostic framework for curating new supervision data for improving NLU
from live production traffic. With an extensive set of experiments, we show the
results of applying the framework and improving NLU for a large-scale
production system and show its impact across 10 domains.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 09:23:44 GMT'}]",2020-10-26,"[['Park', 'Sunghyun', ''], ['Li', 'Han', ''], ['Patel', 'Ameen', ''], ['Mudgal', 'Sidharth', ''], ['Lee', 'Sungjin', ''], ['Kim', 'Young-Bum', ''], ['Matsoukas', 'Spyros', ''], ['Sarikaya', 'Ruhi', '']]"
1368561,2010.12231,Wen-Chin Huang,"Wen-Chin Huang, Yi-Chiao Wu, Tomoki Hayashi, Tomoki Toda","Any-to-One Sequence-to-Sequence Voice Conversion using Self-Supervised
  Discrete Speech Representations",Submitted to ICASSP 2021,,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present a novel approach to any-to-one (A2O) voice conversion (VC) in a
sequence-to-sequence (seq2seq) framework. A2O VC aims to convert any speaker,
including those unseen during training, to a fixed target speaker. We utilize
vq-wav2vec (VQW2V), a discretized self-supervised speech representation that
was learned from massive unlabeled data, which is assumed to be
speaker-independent and well corresponds to underlying linguistic contents.
Given a training dataset of the target speaker, we extract VQW2V and acoustic
features to estimate a seq2seq mapping function from the former to the latter.
With the help of a pretraining method and a newly designed postprocessing
technique, our model can be generalized to only 5 min of data, even
outperforming the same model trained with parallel data.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 08:34:52 GMT'}]",2020-10-26,"[['Huang', 'Wen-Chin', ''], ['Wu', 'Yi-Chiao', ''], ['Hayashi', 'Tomoki', ''], ['Toda', 'Tomoki', '']]"
1368528,2010.12198,Abhinav Ramesh Kashyap,"Abhinav Ramesh Kashyap, Devamanyu Hazarika, Min-Yen Kan, Roger
  Zimmermann",Domain Divergences: a Survey and Empirical Analysis,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Domain divergence plays a significant role in estimating the performance of a
model when applied to new domains. While there is significant literature on
divergence measures, choosing an appropriate divergence measures remains
difficult for researchers. We address this shortcoming by both surveying the
literature and through an empirical study. We contribute a taxonomy of
divergence measures consisting of three groups -- Information-theoretic,
Geometric, and Higher-order measures -- and identify the relationships between
them. We then ground the use of divergence measures in three different
application groups -- 1) Data Selection, 2) Learning Representation, and 3)
Decisions in the Wild. From this, we identify that Information-theoretic
measures are prevalent for 1) and 3), and higher-order measures are common for
2). To further help researchers, we validate these uses empirically through a
correlation analysis of performance drops. We consider the current contextual
word representations (CWR) to contrast with the older word distribution based
representations for this analysis. We find that traditional measures over word
distributions still serve as strong baselines, while higher-order measures with
CWR are effective.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 07:12:52 GMT'}]",2020-10-26,"[['Kashyap', 'Abhinav Ramesh', ''], ['Hazarika', 'Devamanyu', ''], ['Kan', 'Min-Yen', ''], ['Zimmermann', 'Roger', '']]"
1368513,2010.12183,Weizhe Lin,"Zhilin Wang, Weizhe Lin, Xiaodong Wu","Identifying Similar Movie Characters Quickly but Effectively Using
  Non-exhaustive Pair-wise Attention",10 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Identifying similar movie characters is a captivating task that can be our
first step to understand the commonalities between human characteristics and
experiences. Here, we seek to identify similar movie character descriptions and
evaluate our findings based on whether they belong to a common fan-curated
trope (theme). Rather than simply comparing the embedding representation of
character description, we use a pair-wise attention model to make use of
complex word/span-level relationships across the two character descriptions to
predict the similarity of the two characters. Naively, such a model would
require the exhaustive comparison of each character to all other characters,
which is an O(n^2) operation with respect to the number of characters, making
it unfeasible to be used in practice. We reduced this into an O(n) operation
using a two-step approach that involves choosing only a tiny fraction of
character-pairs to perform pairwise attention on while still being effective in
this task. Our approach performs at least 9-27% better than methods based on
state-of-the-art paragraph embedding representations.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 06:28:25 GMT'}]",2020-10-26,"[['Wang', 'Zhilin', ''], ['Lin', 'Weizhe', ''], ['Wu', 'Xiaodong', '']]"
1368510,2010.12180,Sanyuan Chen,"Sanyuan Chen, Yu Wu, Zhuo Chen, Takuya Yoshioka, Shujie Liu, Jinyu Li","Don't shoot butterfly with rifles: Multi-channel Continuous Speech
  Separation with Early Exit Transformer",,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  With its strong modeling capacity that comes from a multi-head and
multi-layer structure, Transformer is a very powerful model for learning a
sequential representation and has been successfully applied to speech
separation recently. However, multi-channel speech separation sometimes does
not necessarily need such a heavy structure for all time frames especially when
the cross-talker challenge happens only occasionally. For example, in
conversation scenarios, most regions contain only a single active speaker,
where the separation task downgrades to a single speaker enhancement problem.
It turns out that using a very deep network structure for dealing with signals
with a low overlap ratio not only negatively affects the inference efficiency
but also hurts the separation performance. To deal with this problem, we
propose an early exit mechanism, which enables the Transformer model to handle
different cases with adaptive depth. Experimental results indicate that not
only does the early exit mechanism accelerate the inference, but it also
improves the accuracy.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 06:21:11 GMT'}]",2020-10-26,"[['Chen', 'Sanyuan', ''], ['Wu', 'Yu', ''], ['Chen', 'Zhuo', ''], ['Yoshioka', 'Takuya', ''], ['Liu', 'Shujie', ''], ['Li', 'Jinyu', '']]"
1368504,2010.12174,Rubungo Andre Niyongabo,Rubungo Andre Niyongabo and Hong Qu and Julia Kreutzer and Li Huang,"KINNEWS and KIRNEWS: Benchmarking Cross-Lingual Text Classification for
  Kinyarwanda and Kirundi",COLING 2020,,,,cs.CL cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent progress in text classification has been focused on high-resource
languages such as English and Chinese. For low-resource languages, amongst them
most African languages, the lack of well-annotated data and effective
preprocessing, is hindering the progress and the transfer of successful
methods. In this paper, we introduce two news datasets (KINNEWS and KIRNEWS)
for multi-class classification of news articles in Kinyarwanda and Kirundi, two
low-resource African languages. The two languages are mutually intelligible,
but while Kinyarwanda has been studied in Natural Language Processing (NLP) to
some extent, this work constitutes the first study on Kirundi. Along with the
datasets, we provide statistics, guidelines for preprocessing, and monolingual
and cross-lingual baseline models. Our experiments show that training
embeddings on the relatively higher-resourced Kinyarwanda yields successful
cross-lingual transfer to Kirundi. In addition, the design of the created
datasets allows for a wider use in NLP beyond text classification in future
studies, such as representation learning, cross-lingual learning with more
distant languages, or as base for new annotations for tasks such as parsing,
POS tagging, and NER. The datasets, stopwords, and pre-trained embeddings are
publicly available at https://github.com/Andrews2017/KINNEWS-and-KIRNEWS-Corpus .
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 05:37:42 GMT'}]",2020-10-26,"[['Niyongabo', 'Rubungo Andre', ''], ['Qu', 'Hong', ''], ['Kreutzer', 'Julia', ''], ['Huang', 'Li', '']]"
1368486,2010.12156,Fei Zhao,"Fei Zhao, Zhen Wu, Xinyu Dai",Attention Transfer Network for Aspect-level Sentiment Classification,Accept to COLING 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Aspect-level sentiment classification (ASC) aims to detect the sentiment
polarity of a given opinion target in a sentence. In neural network-based
methods for ASC, most works employ the attention mechanism to capture the
corresponding sentiment words of the opinion target, then aggregate them as
evidence to infer the sentiment of the target. However, aspect-level datasets
are all relatively small-scale due to the complexity of annotation. Data
scarcity causes the attention mechanism sometimes to fail to focus on the
corresponding sentiment words of the target, which finally weakens the
performance of neural models. To address the issue, we propose a novel
Attention Transfer Network (ATN) in this paper, which can successfully exploit
attention knowledge from resource-rich document-level sentiment classification
datasets to improve the attention capability of the aspect-level sentiment
classification task. In the ATN model, we design two different methods to
transfer attention knowledge and conduct experiments on two ASC benchmark
datasets. Extensive experimental results show that our methods consistently
outperform state-of-the-art works. Further analysis also validates the
effectiveness of ATN.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 04:26:33 GMT'}]",2020-10-26,"[['Zhao', 'Fei', ''], ['Wu', 'Zhen', ''], ['Dai', 'Xinyu', '']]"
1368485,2010.12155,Menglong Xu,"Menglong Xu, Shengqiang Li, Xiao-Lei Zhang","Transformer-based End-to-End Speech Recognition with Local Dense
  Synthesizer Attention","5 pages, 3 figures",,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, several studies reported that dot-product selfattention (SA) may
not be indispensable to the state-of-theart Transformer models. Motivated by
the fact that dense synthesizer attention (DSA), which dispenses with dot
products and pairwise interactions, achieved competitive results in many
language processing tasks, in this paper, we first propose a DSA-based speech
recognition, as an alternative to SA. To reduce the computational complexity
and improve the performance, we further propose local DSA (LDSA) to restrict
the attention scope of DSA to a local range around the current central frame
for speech recognition. Finally, we combine LDSA with SA to extract the local
and global information simultaneously. Experimental results on the Ai-shell1
Mandarine speech recognition corpus show that the proposed LDSA-Transformer
achieves a character error rate (CER) of 6.49%, which is slightly better than
that of the SA-Transformer. Meanwhile, the LDSA-Transformer requires less
computation than the SATransformer. The proposed combination method not only
achieves a CER of 6.18%, which significantly outperforms the SA-Transformer,
but also has roughly the same number of parameters and computational complexity
as the latter. The implementation of the multi-head LDSA is available at
https://github.com/mlxu995/multihead-LDSA.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 04:13:44 GMT'}]",2020-10-26,"[['Xu', 'Menglong', ''], ['Li', 'Shengqiang', ''], ['Zhang', 'Xiao-Lei', '']]"
1368478,2010.12148,Yu-Kun Li,"Dongling Xiao, Yu-Kun Li, Han Zhang, Yu Sun, Hao Tian, Hua Wu and
  Haifeng Wang","ERNIE-Gram: Pre-Training with Explicitly N-Gram Masked Language Modeling
  for Natural Language Understanding",work-in-progress,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Coarse-grained linguistic information, such as name entities or phrases,
facilitates adequately representation learning in pre-training. Previous works
mainly focus on extending the objective of BERT's Masked Language Modeling
(MLM) from masking individual tokens to contiguous sequences of n tokens. We
argue that such continuously masking method neglects to model the
inner-dependencies and inter-relation of coarse-grained information. As an
alternative, we propose ERNIE-Gram, an explicitly n-gram masking method to
enhance the integration of coarse-grained information for pre-training. In
ERNIE-Gram, n-grams are masked and predicted directly using explicit n-gram
identities rather than contiguous sequences of tokens. Furthermore, ERNIE-Gram
employs a generator model to sample plausible n-gram identities as optional
n-gram masks and predict them in both coarse-grained and fine-grained manners
to enable comprehensive n-gram prediction and relation modeling. We pre-train
ERNIE-Gram on English and Chinese text corpora and fine-tune on 19 downstream
tasks. Experimental results show that ERNIE-Gram outperforms previous
pre-training models like XLNet and RoBERTa by a large margin, and achieves
comparable results with state-of-the-art methods.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 03:42:20 GMT'}]",2020-10-26,"[['Xiao', 'Dongling', ''], ['Li', 'Yu-Kun', ''], ['Zhang', 'Han', ''], ['Sun', 'Yu', ''], ['Tian', 'Hao', ''], ['Wu', 'Hua', ''], ['Wang', 'Haifeng', '']]"
1368466,2010.12136,Bowen Li,"Bowen Li, Xiaojuan Qi, Philip H. S. Torr, Thomas Lukasiewicz","Lightweight Generative Adversarial Networks for Text-Guided Image
  Manipulation",NeurIPS 2020,,,,cs.CV cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a novel lightweight generative adversarial network for efficient
image manipulation using natural language descriptions. To achieve this, a new
word-level discriminator is proposed, which provides the generator with
fine-grained training feedback at word-level, to facilitate training a
lightweight generator that has a small number of parameters, but can still
correctly focus on specific visual attributes of an image, and then edit them
without affecting other contents that are not described in the text.
Furthermore, thanks to the explicit training signal related to each word, the
discriminator can also be simplified to have a lightweight structure. Compared
with the state of the art, our method has a much smaller number of parameters,
but still achieves a competitive manipulation performance. Extensive
experimental results demonstrate that our method can better disentangle
different visual attributes, then correctly map them to corresponding semantic
words, and thus achieve a more accurate image modification using natural
language descriptions.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 02:43:02 GMT'}]",2020-10-26,"[['Li', 'Bowen', ''], ['Qi', 'Xiaojuan', ''], ['Torr', 'Philip H. S.', ''], ['Lukasiewicz', 'Thomas', '']]"
1368451,2010.12121,Feiliang Ren,"Feiliang Ren, Juchen Li, Huihui Zhang, Shilei Liu, Bochao Li, Ruicheng
  Ming, Yujia Bai",Knowledge Graph Embedding with Atrous Convolution and Residual Learning,"12pages, 2 figures",,,,cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Knowledge graph embedding is an important task and it will benefit lots of
downstream applications. Currently, deep neural networks based methods achieve
state-of-the-art performance. However, most of these existing methods are very
complex and need much time for training and inference. To address this issue,
we propose a simple but effective atrous convolution based knowledge graph
embedding method. Compared with existing state-of-the-art methods, our method
has following main characteristics. First, it effectively increases feature
interactions by using atrous convolutions. Second, to address the original
information forgotten issue and vanishing/exploding gradient issue, it uses the
residual learning method. Third, it has simpler structure but much higher
parameter efficiency. We evaluate our method on six benchmark datasets with
different evaluation metrics. Extensive experiments show that our model is very
effective. On these diverse datasets, it achieves better results than the
compared state-of-the-art methods on most of evaluation metrics. The source
codes of our model could be found at https://github.com/neukg/AcrE.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 00:57:23 GMT'}]",2020-10-26,"[['Ren', 'Feiliang', ''], ['Li', 'Juchen', ''], ['Zhang', 'Huihui', ''], ['Liu', 'Shilei', ''], ['Li', 'Bochao', ''], ['Ming', 'Ruicheng', ''], ['Bai', 'Yujia', '']]"
1368434,2010.12104,Siyuan Feng,"Siyuan Feng, Piotr \.Zelasko, Laureano Moro-Vel\'azquez, Ali
  Abavisani, Mark Hasegawa-Johnson, Odette Scharenborg, Najim Dehak",How Phonotactics Affect Multilingual and Zero-shot ASR Performance,"Submitted to ICASSP 2021. The first 2 authors contributed equally to
  this work",,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The idea of combining multiple languages' recordings to train a single
automatic speech recognition (ASR) model brings the promise of the emergence of
universal speech representation. Recently, a Transformer encoder-decoder model
has been shown to leverage multilingual data well in IPA transcriptions of
languages presented during training. However, the representations it learned
were not successful in zero-shot transfer to unseen languages. Because that
model lacks an explicit factorization of the acoustic model (AM) and language
model (LM), it is unclear to what degree the performance suffered from
differences in pronunciation or the mismatch in phonotactics. To gain more
insight into the factors limiting zero-shot ASR transfer, we replace the
encoder-decoder with a hybrid ASR system consisting of a separate AM and LM.
Then, we perform an extensive evaluation of monolingual, multilingual, and
crosslingual (zero-shot) acoustic and language models on a set of 13
phonetically diverse languages. We show that the gain from modeling
crosslingual phonotactics is limited, and imposing a too strong model can hurt
the zero-shot transfer. Furthermore, we find that a multilingual LM hurts a
multilingual ASR system's performance, and retaining only the target language's
phonotactic data in LM training is preferable.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 23:07:24 GMT'}]",2020-10-26,"[['Feng', 'Siyuan', ''], ['Żelasko', 'Piotr', ''], ['Moro-Velázquez', 'Laureano', ''], ['Abavisani', 'Ali', ''], ['Hasegawa-Johnson', 'Mark', ''], ['Scharenborg', 'Odette', ''], ['Dehak', 'Najim', '']]"
1368426,2010.12096,Thibault Doutre,"Thibault Doutre, Wei Han, Min Ma, Zhiyun Lu, Chung-Cheng Chiu, Ruoming
  Pang, Arun Narayanan, Ananya Misra, Yu Zhang, Liangliang Cao","Improving Streaming Automatic Speech Recognition With Non-Streaming
  Model Distillation On Unsupervised Data",,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Streaming end-to-end automatic speech recognition (ASR) models are widely
used on smart speakers and on-device applications. Since these models are
expected to transcribe speech with minimal latency, they are constrained to be
causal with no future context, compared to their non-streaming counterparts.
Consequently, streaming models usually perform worse than non-streaming models.
We propose a novel and effective learning method by leveraging a non-streaming
ASR model as a teacher to generate transcripts on an arbitrarily large data
set, which is then used to distill knowledge into streaming ASR models. This
way, we scale the training of streaming models to up to 3 million hours of
YouTube audio. Experiments show that our approach can significantly reduce the
word error rate (WER) of RNNT models not only on LibriSpeech but also on
YouTube data in four languages. For example, in French, we are able to reduce
the WER by 16.4% relatively to a baseline streaming model by leveraging a
non-streaming teacher model trained on the same amount of labeled data as the
baseline.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 22:41:33 GMT'}]",2020-10-26,"[['Doutre', 'Thibault', ''], ['Han', 'Wei', ''], ['Ma', 'Min', ''], ['Lu', 'Zhiyun', ''], ['Chiu', 'Chung-Cheng', ''], ['Pang', 'Ruoming', ''], ['Narayanan', 'Arun', ''], ['Misra', 'Ananya', ''], ['Zhang', 'Yu', ''], ['Cao', 'Liangliang', '']]"
1368413,2010.12083,Simon Stepputtis,"Simon Stepputtis, Joseph Campbell, Mariano Phielipp, Stefan Lee,
  Chitta Baral, Heni Ben Amor",Language-Conditioned Imitation Learning for Robot Manipulation Tasks,"Accepted to the 34th Conference on Neural Information Processing
  Systems (NeurIPS 2020), Vancouver, Canada as spotlight presentation",,,,cs.RO cs.CL cs.CV cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Imitation learning is a popular approach for teaching motor skills to robots.
However, most approaches focus on extracting policy parameters from execution
traces alone (i.e., motion trajectories and perceptual data). No adequate
communication channel exists between the human expert and the robot to describe
critical aspects of the task, such as the properties of the target object or
the intended shape of the motion. Motivated by insights into the human teaching
process, we introduce a method for incorporating unstructured natural language
into imitation learning. At training time, the expert can provide
demonstrations along with verbal descriptions in order to describe the
underlying intent (e.g., ""go to the large green bowl""). The training process
then interrelates these two modalities to encode the correlations between
language, perception, and motion. The resulting language-conditioned visuomotor
policies can be conditioned at runtime on new human commands and instructions,
which allows for more fine-grained control over the trained policies while also
reducing situational ambiguity. We demonstrate in a set of simulation
experiments how our approach can learn language-conditioned manipulation
policies for a seven-degree-of-freedom robot arm and compare the results to a
variety of alternative methods.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 21:49:08 GMT'}]",2020-10-26,"[['Stepputtis', 'Simon', ''], ['Campbell', 'Joseph', ''], ['Phielipp', 'Mariano', ''], ['Lee', 'Stefan', ''], ['Baral', 'Chitta', ''], ['Amor', 'Heni Ben', '']]"
1368407,2010.12077,Daiki Shirafuji,"Daiki Shirafuji, Hiromichi Kameya, Rafal Rzepka and Kenji Araki","Summarizing Utterances from Japanese Assembly Minutes using Political
  Sentence-BERT-based Method for QA Lab-PoliInfo-2 Task of NTCIR-15","8 pages, 1 figure, 8 tables, NTCIR-15 conference",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  There are many discussions held during political meetings, and a large number
of utterances for various topics is included in their transcripts. We need to
read all of them if we want to follow speakers\' intentions or opinions about a
given topic. To avoid such a costly and time-consuming process to grasp often
longish discussions, NLP researchers work on generating concise summaries of
utterances. Summarization subtask in QA Lab-PoliInfo-2 task of the NTCIR-15
addresses this problem for Japanese utterances in assembly minutes, and our
team (SKRA) participated in this subtask. As a first step for summarizing
utterances, we created a new pre-trained sentence embedding model, i.e. the
Japanese Political Sentence-BERT. With this model, we summarize utterances
without labelled data. This paper describes our approach to solving the task
and discusses its results.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 21:37:28 GMT'}]",2020-10-26,"[['Shirafuji', 'Daiki', ''], ['Kameya', 'Hiromichi', ''], ['Rzepka', 'Rafal', ''], ['Araki', 'Kenji', '']]"
1368639,2010.12309,Lukas Lange,"Michael A. Hedderich, Lukas Lange, Heike Adel, Jannik Str\""otgen,
  Dietrich Klakow","A Survey on Recent Approaches for Natural Language Processing in
  Low-Resource Scenarios",,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Current developments in natural language processing offer challenges and
opportunities for low-resource languages and domains. Deep neural networks are
known for requiring large amounts of training data which might not be available
in resource-lean scenarios. However, there is also a growing body of works to
improve the performance in low-resource settings. Motivated by fundamental
changes towards neural models and the currently popular pre-train and fine-tune
paradigm, we give an overview of promising approaches for low-resource natural
language processing. After a discussion about the definition of low-resource
scenarios and the different dimensions of data availability, we then examine
methods that enable learning when training data is sparse. This includes
mechanisms to create additional labeled data like data augmentation and distant
supervision as well as transfer learning settings that reduce the need for
target supervision. The survey closes with a brief look into methods suggested
in non-NLP machine learning communities, which might be beneficial for NLP in
low-resource scenarios
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 11:22:01 GMT'}]",2020-10-26,"[['Hedderich', 'Michael A.', ''], ['Lange', 'Lukas', ''], ['Adel', 'Heike', ''], ['Strötgen', 'Jannik', ''], ['Klakow', 'Dietrich', '']]"
1368338,2010.12008,Siamak Shakeri,"Siamak Shakeri, Noah Constant, Mihir Sanjay Kale, Linting Xue","Multilingual Synthetic Question and Answer Generation for Cross-Lingual
  Reading Comprehension",,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a simple method to generate large amounts of multilingual question
and answer pairs by a single generative model. These synthetic samples are then
applied to augment the available gold multilingual ones to improve the
performance of multilingual QA models on target languages. Our approach only
requires existence of automatically translated samples from English to the
target domain, thus removing the need for human annotations in the target
languages. Experimental results show our proposed approach achieves significant
gains in a number of multilingual datasets.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 19:59:37 GMT'}]",2020-10-26,"[['Shakeri', 'Siamak', ''], ['Constant', 'Noah', ''], ['Kale', 'Mihir Sanjay', ''], ['Xue', 'Linting', '']]"
1368651,2010.12321,Antoine Tixier,"Moussa Kamal Eddine, Antoine J.-P. Tixier, Michalis Vazirgiannis",BARThez: a Skilled Pretrained French Sequence-to-Sequence Model,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Inductive transfer learning, enabled by self-supervised learning, have taken
the entire Natural Language Processing (NLP) field by storm, with models such
as BERT and BART setting new state of the art on countless natural language
understanding tasks. While there are some notable exceptions, most of the
available models and research have been conducted for the English language. In
this work, we introduce BARThez, the first BART model for the French language
(to the best of our knowledge). BARThez was pretrained on a very large
monolingual French corpus from past research that we adapted to suit BART's
perturbation schemes. Unlike already existing BERT-based French language models
such as CamemBERT and FlauBERT, BARThez is particularly well-suited for
generative tasks, since not only its encoder but also its decoder is
pretrained. In addition to discriminative tasks from the FLUE benchmark, we
evaluate BARThez on a novel summarization dataset, OrangeSum, that we release
with this paper. We also continue the pretraining of an already pretrained
multilingual BART on BARThez's corpus, and we show that the resulting model,
which we call mBARTHez, provides a significant boost over vanilla BARThez, and
is on par with or outperforms CamemBERT and FlauBERT.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 11:57:33 GMT'}]",2020-10-26,"[['Eddine', 'Moussa Kamal', ''], ['Tixier', 'Antoine J. -P.', ''], ['Vazirgiannis', 'Michalis', '']]"
1368735,2010.12405,Xin Li,"Xin Li, Lidong Bing, Wenxuan Zhang, Zheng Li, Wai Lam",Unsupervised Cross-lingual Adaptation for Sequence Tagging and Beyond,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Cross-lingual adaptation with multilingual pre-trained language models
(mPTLMs) mainly consists of two lines of works: zero-shot approach and
translation-based approach, which have been studied extensively on the
sequence-level tasks. We further verify the efficacy of these cross-lingual
adaptation approaches by evaluating their performances on more fine-grained
sequence tagging tasks. After re-examining their strengths and drawbacks, we
propose a novel framework to consolidate the zero-shot approach and the
translation-based approach for better adaptation performance. Instead of simply
augmenting the source data with the machine-translated data, we tailor-make a
warm-up mechanism to quickly update the mPTLMs with the gradients estimated on
a few translated data. Then, the adaptation approach is applied to the refined
parameters and the cross-lingual transfer is performed in a warm-start way. The
experimental results on nine target languages demonstrate that our method is
beneficial to the cross-lingual adaptation of various sequence tagging tasks.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 13:47:01 GMT'}]",2020-10-26,"[['Li', 'Xin', ''], ['Bing', 'Lidong', ''], ['Zhang', 'Wenxuan', ''], ['Li', 'Zheng', ''], ['Lam', 'Wai', '']]"
1368896,2010.12566,Aditi Chaudhary,"Aditi Chaudhary, Karthik Raman, Krishna Srinivasan, Jiecao Chen","DICT-MLM: Improved Multilingual Pre-Training using Bilingual
  Dictionaries",13 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pre-trained multilingual language models such as mBERT have shown immense
gains for several natural language processing (NLP) tasks, especially in the
zero-shot cross-lingual setting. Most, if not all, of these pre-trained models
rely on the masked-language modeling (MLM) objective as the key language
learning objective. The principle behind these approaches is that predicting
the masked words with the help of the surrounding text helps learn potent
contextualized representations. Despite the strong representation learning
capability enabled by MLM, we demonstrate an inherent limitation of MLM for
multilingual representation learning. In particular, by requiring the model to
predict the language-specific token, the MLM objective disincentivizes learning
a language-agnostic representation -- which is a key goal of multilingual
pre-training. Therefore to encourage better cross-lingual representation
learning we propose the DICT-MLM method. DICT-MLM works by incentivizing the
model to be able to predict not just the original masked word, but potentially
any of its cross-lingual synonyms as well. Our empirical analysis on multiple
downstream tasks spanning 30+ languages, demonstrates the efficacy of the
proposed approach and its ability to learn better multilingual representations.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 17:53:11 GMT'}]",2020-10-26,"[['Chaudhary', 'Aditi', ''], ['Raman', 'Karthik', ''], ['Srinivasan', 'Krishna', ''], ['Chen', 'Jiecao', '']]"
1368893,2010.12563,Eric Wallace,"Eric Wallace, Tony Z. Zhao, Shi Feng, Sameer Singh",Customizing Triggers with Concealed Data Poisoning,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Adversarial attacks alter NLP model predictions by perturbing test-time
inputs. However, it is much less understood whether, and how, predictions can
be manipulated with small, concealed changes to the training data. In this
work, we develop a new data poisoning attack that allows an adversary to
control model predictions whenever a desired trigger phrase is present in the
input. For instance, we insert 50 poison examples into a sentiment model's
training set that causes the model to frequently predict Positive whenever the
input contains ""James Bond"". Crucially, we craft these poison examples using a
gradient-based procedure so that they do not mention the trigger phrase. We
also apply our poison attack to language modeling (""Apple iPhone"" triggers
negative generations) and machine translation (""iced coffee"" mistranslated as
""hot coffee""). We conclude by proposing three defenses that can mitigate our
attack at some cost in prediction accuracy or extra human annotation.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 17:47:06 GMT'}]",2020-10-26,"[['Wallace', 'Eric', ''], ['Zhao', 'Tony Z.', ''], ['Feng', 'Shi', ''], ['Singh', 'Sameer', '']]"
1368892,2010.12562,Xiaotao Gu,"Xiaotao Gu, Liyuan Liu, Hongkun Yu, Jing Li, Chen Chen, Jiawei Han",On the Transformer Growth for Progressive BERT Training,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As the excessive pre-training cost arouses the need to improve efficiency,
considerable efforts have been made to train BERT progressively--start from an
inferior but low-cost model and gradually increase the computational
complexity. Our objective is to help advance the understanding of such
Transformer growth and discover principles that guide progressive training.
First, we find that similar to network architecture selection, Transformer
growth also favors compound scaling. Specifically, while existing methods only
conduct network growth in a single dimension, we observe that it is beneficial
to use compound growth operators and balance multiple dimensions (e.g., depth,
width, and input length of the model). Moreover, we explore alternative growth
operators in each dimension via controlled comparison to give practical
guidance for operator selection. In light of our analyses, the proposed method
CompoundGrow speeds up BERT pre-training by 73.6% and 82.2% for the base and
large models respectively while achieving comparable performances. Code will be
released for reproduction and future studies.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 17:44:59 GMT'}]",2020-10-26,"[['Gu', 'Xiaotao', ''], ['Liu', 'Liyuan', ''], ['Yu', 'Hongkun', ''], ['Li', 'Jing', ''], ['Chen', 'Chen', ''], ['Han', 'Jiawei', '']]"
1368877,2010.12547,Lin Pan,"Lin Pan, Chung-Wei Hang, Haode Qi, Abhishek Shah, Mo Yu, Saloni Potdar",Multilingual BERT Post-Pretraining Alignment,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a simple method to align multilingual contextual embeddings as a
post-pretraining step for improved zero-shot cross-lingual transferability of
the pretrained models. Using parallel data, our method aligns embeddings on the
word level through the recently proposed Translation Language Modeling
objective as well as on the sentence level via contrastive learning and random
input shuffling. We also perform code-switching with English when finetuning on
downstream tasks. On XNLI, our best model (initialized from mBERT) improves
over mBERT by 4.7% in the zero-shot setting and achieves comparable result to
XLM for translate-train while using less than 18% of the same parallel data and
31% less model parameters. On MLQA, our model outperforms XLM-R_Base that has
57% more parameters than ours.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 17:14:41 GMT'}]",2020-10-26,"[['Pan', 'Lin', ''], ['Hang', 'Chung-Wei', ''], ['Qi', 'Haode', ''], ['Shah', 'Abhishek', ''], ['Yu', 'Mo', ''], ['Potdar', 'Saloni', '']]"
1368862,2010.12532,Nicole Peinelt,"Nicole Peinelt, Marek Rei and Maria Liakata","GiBERT: Introducing Linguistic Knowledge into BERT through a Lightweight
  Gated Injection Method",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large pre-trained language models such as BERT have been the driving force
behind recent improvements across many NLP tasks. However, BERT is only trained
to predict missing words - either behind masks or in the next sentence - and
has no knowledge of lexical, syntactic or semantic information beyond what it
picks up through unsupervised pre-training. We propose a novel method to
explicitly inject linguistic knowledge in the form of word embeddings into any
layer of a pre-trained BERT. Our performance improvements on multiple semantic
similarity datasets when injecting dependency-based and counter-fitted
embeddings indicate that such information is beneficial and currently missing
from the original model. Our qualitative analysis shows that counter-fitted
embedding injection particularly helps with cases involving synonym pairs.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 17:00:26 GMT'}]",2020-10-26,"[['Peinelt', 'Nicole', ''], ['Rei', 'Marek', ''], ['Liakata', 'Maria', '']]"
1368853,2010.12523,Yinfei Yang,"Jing Lu, Gustavo Hernandez Abrego, Ji Ma, Jianmo Ni, Yinfei Yang",Neural Passage Retrieval with Improved Negative Contrast,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper we explore the effects of negative sampling in dual encoder
models used to retrieve passages for automatic question answering. We explore
four negative sampling strategies that complement the straightforward random
sampling of negatives, typically used to train dual encoder models. Out of the
four strategies, three are based on retrieval and one on heuristics. Our
retrieval-based strategies are based on the semantic similarity and the lexical
overlap between questions and passages. We train the dual encoder models in two
stages: pre-training with synthetic data and fine tuning with domain-specific
data. We apply negative sampling to both stages. The approach is evaluated in
two passage retrieval tasks. Even though it is not evident that there is one
single sampling strategy that works best in all the tasks, it is clear that our
strategies contribute to improving the contrast between the response and all
the other passages. Furthermore, mixing the negatives from different strategies
achieve performance on par with the best performing strategy in all tasks. Our
results establish a new state-of-the-art level of performance on two of the
open-domain question answering datasets that we evaluated.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 16:45:06 GMT'}]",2020-10-26,"[['Lu', 'Jing', ''], ['Abrego', 'Gustavo Hernandez', ''], ['Ma', 'Ji', ''], ['Ni', 'Jianmo', ''], ['Yang', 'Yinfei', '']]"
1368842,2010.12512,Linyi Yang,"Linyi Yang, Eoin M. Kenny, Tin Lok James Ng, Yi Yang, Barry Smyth, and
  Ruihai Dong","Generating Plausible Counterfactual Explanations for Deep Transformers
  in Financial Text Classification",Accepted by COLING-20 (Oral),,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Corporate mergers and acquisitions (M&A) account for billions of dollars of
investment globally every year, and offer an interesting and challenging domain
for artificial intelligence. However, in these highly sensitive domains, it is
crucial to not only have a highly robust and accurate model, but be able to
generate useful explanations to garner a user's trust in the automated system.
Regrettably, the recent research regarding eXplainable AI (XAI) in financial
text classification has received little to no attention, and many current
methods for generating textual-based explanations result in highly implausible
explanations, which damage a user's trust in the system. To address these
issues, this paper proposes a novel methodology for producing plausible
counterfactual explanations, whilst exploring the regularization benefits of
adversarial training on language models in the domain of FinTech. Exhaustive
quantitative experiments demonstrate that not only does this approach improve
the model accuracy when compared to the current state-of-the-art and human
performance, but it also generates counterfactual explanations which are
significantly more plausible based on human trials.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 16:29:26 GMT'}]",2020-10-26,"[['Yang', 'Linyi', ''], ['Kenny', 'Eoin M.', ''], ['Ng', 'Tin Lok James', ''], ['Yang', 'Yi', ''], ['Smyth', 'Barry', ''], ['Dong', 'Ruihai', '']]"
1368840,2010.12510,Nafise Sadat Moosavi,"Nafise Sadat Moosavi, Marcel de Boer, Prasetya Ajie Utama, Iryna
  Gurevych","Improving Robustness by Augmenting Training Sentences with
  Predicate-Argument Structures",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Existing NLP datasets contain various biases, and models tend to quickly
learn those biases, which in turn limits their robustness. Existing approaches
to improve robustness against dataset biases mostly focus on changing the
training objective so that models learn less from biased examples. Besides,
they mostly focus on addressing a specific bias, and while they improve the
performance on adversarial evaluation sets of the targeted bias, they may bias
the model in other ways, and therefore, hurt the overall robustness. In this
paper, we propose to augment the input sentences in the training data with
their corresponding predicate-argument structures, which provide a higher-level
abstraction over different realizations of the same meaning and help the model
to recognize important parts of sentences. We show that without targeting a
specific bias, our sentence augmentation improves the robustness of transformer
models against multiple biases. In addition, we show that models can still be
vulnerable to the lexical overlap bias, even when the training data does not
contain this bias, and that the sentence augmentation also improves the
robustness in this scenario. We will release our adversarial datasets to
evaluate bias in such a scenario as well as our augmentation scripts at
https://github.com/UKPLab/data-augmentation-for-robustness.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 16:22:05 GMT'}]",2020-10-26,"[['Moosavi', 'Nafise Sadat', ''], ['de Boer', 'Marcel', ''], ['Utama', 'Prasetya Ajie', ''], ['Gurevych', 'Iryna', '']]"
1368835,2010.12505,Tim Draws,"Tim Draws, Jody Liu, Nava Tintarev","Helping users discover perspectives: Enhancing opinion mining with joint
  topic models","Accepted at the SENTIRE workshop at ICDM 2020:
  https://sentic.net/sentire/#2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Support or opposition concerning a debated claim such as abortion should be
legal can have different underlying reasons, which we call perspectives. This
paper explores how opinion mining can be enhanced with joint topic modeling, to
identify distinct perspectives within the topic, providing an informative
overview from unstructured text. We evaluate four joint topic models (TAM, JST,
VODUM, and LAM) in a user study assessing human understandability of the
extracted perspectives. Based on the results, we conclude that joint topic
models such as TAM can discover perspectives that align with human judgments.
Moreover, our results suggest that users are not influenced by their
pre-existing stance on the topic of abortion when interpreting the output of
topic models.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 16:13:06 GMT'}]",2020-10-26,"[['Draws', 'Tim', ''], ['Liu', 'Jody', ''], ['Tintarev', 'Nava', '']]"
1368827,2010.12497,Omid Ghahabi,"Omid Ghahabi, Volker Fischer",EML System Description for VoxCeleb Speaker Diarization Challenge 2020,,,,,cs.SD cs.CL eess.AS,http://creativecommons.org/licenses/by/4.0/,"  This technical report describes the EML submission to the first VoxCeleb
speaker diarization challenge. Although the aim of the challenge has been the
offline processing of the signals, the submitted system is basically the EML
online algorithm which decides about the speaker labels in runtime
approximately every 1.2 sec. For the first phase of the challenge, only
VoxCeleb2 dev dataset was used for training. The results on the provided
VoxConverse dev set show much better accuracy in terms of both DER and JER
compared to the offline baseline provided in the challenge. The real-time
factor of the whole diarization process is about 0.01 using a single CPU
machine.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 16:01:28 GMT'}]",2020-10-26,"[['Ghahabi', 'Omid', ''], ['Fischer', 'Volker', '']]"
1368825,2010.12495,Daniel Deutsch,"Daniel Deutsch, Dan Roth","Understanding the Extent to which Summarization Evaluation Metrics
  Measure the Information Quality of Summaries",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Reference-based metrics such as ROUGE or BERTScore evaluate the content
quality of a summary by comparing the summary to a reference. Ideally, this
comparison should measure the summary's information quality by calculating how
much information the summaries have in common. In this work, we analyze the
token alignments used by ROUGE and BERTScore to compare summaries and argue
that their scores largely cannot be interpreted as measuring information
overlap, but rather the extent to which they discuss the same topics. Further,
we provide evidence that this result holds true for many other summarization
evaluation metrics. The consequence of this result is that it means the
summarization community has not yet found a reliable automatic metric that
aligns with its research goal, to generate summaries with high-quality
information. Then, we propose a simple and interpretable method of evaluating
summaries which does directly measure information overlap and demonstrate how
it can be used to gain insights into model behavior that could not be provided
by other methods alone.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 15:55:15 GMT'}]",2020-10-26,"[['Deutsch', 'Daniel', ''], ['Roth', 'Dan', '']]"
1368817,2010.12487,Damien Garreau,Dina Mardaoui and Damien Garreau,An Analysis of LIME for Text Data,"29 pages, 17 figures",,,,stat.ML cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Text data are increasingly handled in an automated fashion by machine
learning algorithms. But the models handling these data are not always
well-understood due to their complexity and are more and more often referred to
as ""black-boxes."" Interpretability methods aim to explain how these models
operate. Among them, LIME has become one of the most popular in recent years.
However, it comes without theoretical guarantees: even for simple models, we
are not sure that LIME behaves accurately. In this paper, we provide a first
theoretical analysis of LIME for text data. As a consequence of our theoretical
findings, we show that LIME indeed provides meaningful explanations for simple
models, namely decision trees and linear models.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 15:40:13 GMT'}]",2020-10-26,"[['Mardaoui', 'Dina', ''], ['Garreau', 'Damien', '']]"
1368803,2010.12473,Henning Wachsmuth,Henning Wachsmuth and Till Werner,Intrinsic Quality Assessment of Arguments,Accepted at COLING 2020,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Several quality dimensions of natural language arguments have been
investigated. Some are likely to be reflected in linguistic features (e.g., an
argument's arrangement), whereas others depend on context (e.g., relevance) or
topic knowledge (e.g., acceptability). In this paper, we study the intrinsic
computational assessment of 15 dimensions, i.e., only learning from an
argument's text. In systematic experiments with eight feature types on an
existing corpus, we observe moderate but significant learning success for most
dimensions. Rhetorical quality seems hardest to assess, and subjectivity
features turn out strong, although length bias in the corpus impedes full
validity. We also find that human assessors differ more clearly to each other
than to our approach.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 15:16:10 GMT'}]",2020-10-26,"[['Wachsmuth', 'Henning', ''], ['Werner', 'Till', '']]"
1368802,2010.12472,Tommaso Caselli,"Tommaso Caselli, Valerio Basile, Jelena Mitrovi\'c, Michael Granitzer",HateBERT: Retraining BERT for Abusive Language Detection in English,,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  In this paper, we introduce HateBERT, a re-trained BERT model for abusive
language detection in English. The model was trained on RAL-E, a large-scale
dataset of Reddit comments in English from communities banned for being
offensive, abusive, or hateful that we have collected and made available to the
public. We present the results of a detailed comparison between a general
pre-trained language model and the abuse-inclined version obtained by
retraining with posts from the banned communities on three English datasets for
offensive, abusive language and hate speech detection tasks. In all datasets,
HateBERT outperforms the corresponding general BERT model. We also discuss a
battery of experiments comparing the portability of the general pre-trained
language model and its corresponding abusive language-inclined counterpart
across the datasets, indicating that portability is affected by compatibility
of the annotated phenomena.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 15:14:14 GMT'}]",2020-10-26,"[['Caselli', 'Tommaso', ''], ['Basile', 'Valerio', ''], ['Mitrović', 'Jelena', ''], ['Granitzer', 'Michael', '']]"
1368763,2010.12433,Gaurish Thakkar Mr,"Diego Alves, Gaurish Thakkar, Marko Tadi\'c","Natural Language Processing Chains Inside a Cross-lingual Event-Centric
  Knowledge Pipeline for European Union Under-resourced Languages",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This article presents the strategy for developing a platform containing
Language Processing Chains for European Union languages, consisting of
Tokenization to Parsing, also including Named Entity recognition andwith
addition ofSentiment Analysis. These chains are part of the first step of an
event-centric knowledge processing pipeline whose aim is to process
multilingual media information about major events that can cause an impactin
Europe and the rest of the world. Due to the differences in terms of
availability of language resources for each language, we have built this
strategy in three steps, starting with processing chains for the well-resourced
languages and finishing with the development of new modules for the
under-resourced ones. In order to classify all European Union official
languages in terms of resources, we have analysed the size of annotated corpora
as well as the existence of pre-trained models in mainstream Language
Processing tools, and we have combined this information with the proposed
classification published at META-NETwhitepaper series.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 14:26:30 GMT'}]",2020-10-26,"[['Alves', 'Diego', ''], ['Thakkar', 'Gaurish', ''], ['Tadić', 'Marko', '']]"
1368758,2010.12428,Gaurish Thakkar Mr,"Diego Alves, Gaurish Thakkar, Marko Tadi\'c","Evaluating Language Tools for Fifteen EU-official Under-resourced
  Languages",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This article presents the results of the evaluation campaign of language
tools available for fifteen EU-official under-resourced languages. The
evaluation was conducted within the MSC ITN CLEOPATRA action that aims at
building the cross-lingual event-centric knowledge processing on top of the
application of linguistic processing chains (LPCs) for at least 24 EU-official
languages. In this campaign, we concentrated on three existing NLP platforms
(Stanford CoreNLP, NLP Cube, UDPipe) that all provide models for
under-resourced languages and in this first run we covered 15 under-resourced
languages for which the models were available. We present the design of the
evaluation campaign and present the results as well as discuss them. We
considered the difference between reported and our tested results within a
single percentage point as being within the limits of acceptable tolerance and
thus consider this result as reproducible. However, for a number of languages,
the results are below what was reported in the literature, and in some cases,
our testing results are even better than the ones reported previously.
Particularly problematic was the evaluation of NERC systems. One of the reasons
is the absence of universally or cross-lingually applicable named entities
classification scheme that would serve the NERC task in different languages
analogous to the Universal Dependency scheme in parsing task. To build such a
scheme has become one of our the future research directions.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 14:21:03 GMT'}]",2020-10-26,"[['Alves', 'Diego', ''], ['Thakkar', 'Gaurish', ''], ['Tadić', 'Marko', '']]"
1368748,2010.12418,Ahmed Al-Ali,"Ahmed Ghanim Al-Ali, Robert Phaal, Donald Sull","Deep Learning Framework for Measuring the Digital Strategy of Companies
  from Earnings Calls","Accepted for The 28th International Conference on Computational
  Linguistics, 9 pages, 1 figure",,,,cs.CL cs.CY cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Companies today are racing to leverage the latest digital technologies, such
as artificial intelligence, blockchain, and cloud computing. However, many
companies report that their strategies did not achieve the anticipated business
results. This study is the first to apply state of the art NLP models on
unstructured data to understand the different clusters of digital strategy
patterns that companies are Adopting. We achieve this by analyzing earnings
calls from Fortune Global 500 companies between 2015 and 2019. We use
Transformer based architecture for text classification which show a better
understanding of the conversation context. We then investigate digital strategy
patterns by applying clustering analysis. Our findings suggest that Fortune 500
companies use four distinct strategies which are product led, customer
experience led, service led, and efficiency led. This work provides an
empirical baseline for companies and researchers to enhance our understanding
of the field.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 14:07:12 GMT'}]",2020-10-26,"[['Al-Ali', 'Ahmed Ghanim', ''], ['Phaal', 'Robert', ''], ['Sull', 'Donald', '']]"
1368742,2010.12412,Ohad Rubin,Ohad Rubin and Jonathan Berant,SmBoP: Semi-autoregressive Bottom-up Semantic Parsing,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The de-facto standard decoding method for semantic parsing in recent years
has been to autoregressively decode the abstract syntax tree of the target
program using a top-down depth-first traversal. In this work, we propose an
alternative approach: a Semi-autoregressive Bottom-up Parser (SmBoP) that
constructs at decoding step $t$ the top-$K$ sub-trees of height $\leq t$. Our
parser enjoys several benefits compared to top-down autoregressive parsing.
First, since sub-trees in each decoding step are generated in parallel, the
theoretical runtime is logarithmic rather than linear. Second, our bottom-up
approach learns representations with meaningful semantic sub-programs at each
step, rather than semantically vague partial trees. Last, SmBoP includes
Transformer-based layers that contextualize sub-trees with one another,
allowing us, unlike traditional beam-search, to score trees conditioned on
other trees that have been previously explored. We apply SmBoP on Spider, a
challenging zero-shot semantic parsing benchmark, and show that SmBoP is
competitive with top-down autoregressive parsing. On the test set, SmBoP
obtains an EM score of $60.5\%$, similar to the best published score for a
model that does not use database content, which is at $60.6\%$.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 14:02:32 GMT'}]",2020-10-26,"[['Rubin', 'Ohad', ''], ['Berant', 'Jonathan', '']]"
1368736,2010.12406,Gaurish Thakkar Mr,"Diego Alves, Tin Kuculo, Gabriel Amaral, Gaurish Thakkar, and Marko
  Tadic",UNER: Universal Named-Entity RecognitionFramework,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We introduce the Universal Named-Entity Recognition (UNER)framework, a
4-level classification hierarchy, and the methodology that isbeing adopted to
create the first multilingual UNER corpus: the SETimesparallel corpus annotated
for named-entities. First, the English SETimescorpus will be annotated using
existing tools and knowledge bases. Afterevaluating the resulting annotations
through crowdsourcing campaigns,they will be propagated automatically to other
languages within the SE-Times corpora. Finally, as an extrinsic evaluation, the
UNER multilin-gual dataset will be used to train and test available NER tools.
As part offuture research directions, we aim to increase the number of
languages inthe UNER corpus and to investigate possible ways of integrating
UNERwith available knowledge graphs to improve named-entity recognition.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 13:53:31 GMT'}]",2020-10-26,"[['Alves', 'Diego', ''], ['Kuculo', 'Tin', ''], ['Amaral', 'Gabriel', ''], ['Thakkar', 'Gaurish', ''], ['Tadic', 'Marko', '']]"
1368652,2010.12322,Lukas Lange,"Lukas Lange, Xiang Dai, Heike Adel, Jannik Str\""otgen","NLNDE at CANTEMIST: Neural Sequence Labeling and Parsing Approaches for
  Clinical Concept Extraction",IberLEF 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The recognition and normalization of clinical information, such as tumor
morphology mentions, is an important, but complex process consisting of
multiple subtasks. In this paper, we describe our system for the CANTEMIST
shared task, which is able to extract, normalize and rank ICD codes from
Spanish electronic health records using neural sequence labeling and parsing
approaches with context-aware embeddings. Our best system achieves 85.3 F1,
76.7 F1, and 77.0 MAP for the three tasks, respectively.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 11:59:28 GMT'}]",2020-10-26,"[['Lange', 'Lukas', ''], ['Dai', 'Xiang', ''], ['Adel', 'Heike', ''], ['Strötgen', 'Jannik', '']]"
1368327,2010.11997,Zhanwen Chen,"Zhanwen Chen, Shiyao Li, Roxanne Rashedi, Xiaoman Zi, Morgan
  Elrod-Erickson, Bryan Hollis, Angela Maliakal, Xinyu Shen, Simeng Zhao,
  Maithilee Kunda","Characterizing Datasets for Social Visual Question Answering, and the
  New TinySocial Dataset","To appear in the Joint IEEE International Conference on Development
  and Learning and on Epigenetic Robotics (ICDL), 2020",,,,cs.HC cs.CL cs.CV cs.SI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Modern social intelligence includes the ability to watch videos and answer
questions about social and theory-of-mind-related content, e.g., for a scene in
Harry Potter, ""Is the father really upset about the boys flying the car?""
Social visual question answering (social VQA) is emerging as a valuable
methodology for studying social reasoning in both humans (e.g., children with
autism) and AI agents. However, this problem space spans enormous variations in
both videos and questions. We discuss methods for creating and characterizing
social VQA datasets, including 1) crowdsourcing versus in-house authoring,
including sample comparisons of two new datasets that we created
(TinySocial-Crowd and TinySocial-InHouse) and the previously existing Social-IQ
dataset; 2) a new rubric for characterizing the difficulty and content of a
given video; and 3) a new rubric for characterizing question types. We close by
describing how having well-characterized social VQA datasets will enhance the
explainability of AI agents and can also inform assessments and educational
interventions for people.
","[{'version': 'v1', 'created': 'Thu, 8 Oct 2020 03:20:23 GMT'}]",2020-10-26,"[['Chen', 'Zhanwen', ''], ['Li', 'Shiyao', ''], ['Rashedi', 'Roxanne', ''], ['Zi', 'Xiaoman', ''], ['Elrod-Erickson', 'Morgan', ''], ['Hollis', 'Bryan', ''], ['Maliakal', 'Angela', ''], ['Shen', 'Xinyu', ''], ['Zhao', 'Simeng', ''], ['Kunda', 'Maithilee', '']]"
1368553,2010.12223,Richard Moot,"Richard Moot (TEXTE, LIRMM, CNRS)",Proof-theoretic aspects of NL$\lambda$,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present a proof-theoretic analysis of the logic NL$\lambda$ (Barker \&
Shan 2014, Barker 2019). We notably introduce a novel calculus of proof nets
and prove it is sound and complete with respect to the sequent calculus for the
logic. We study decidability and complexity of the logic using this new
calculus, proving a new upper bound for complexity of the logic (showing it is
in NP) and a new lower bound for the class of formal language generated by the
formalism (mildly context-sensitive languages extended with a permutation
closure operation). Finally, thanks to this new calculus, we present a novel
comparison between NL$\lambda$ and the hybrid type-logical grammars of Kubota
\& Levine (2020). We show there is an unexpected convergence of the natural
language analyses proposed in the two formalism. In addition to studying the
proof-theoretic properties of NL$\lambda$, we greatly extends its linguistic
coverage.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 08:13:39 GMT'}]",2020-10-26,"[['Moot', 'Richard', '', 'TEXTE, LIRMM, CNRS']]"
1368315,2010.11985,Jianing Yang,"Jianing Yang, Yongxin Wang, Ruitao Yi, Yuying Zhu, Azaan Rehman, Amir
  Zadeh, Soujanya Poria, Louis-Philippe Morency","MTGAT: Multimodal Temporal Graph Attention Networks for Unaligned Human
  Multimodal Language Sequences",,,,,cs.CL cs.CV cs.LG cs.MM,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Human communication is multimodal in nature; it is through multiple
modalities, i.e., language, voice, and facial expressions, that opinions and
emotions are expressed. Data in this domain exhibits complex multi-relational
and temporal interactions. Learning from this data is a fundamentally
challenging research problem. In this paper, we propose Multimodal Temporal
Graph Attention Networks (MTGAT). MTGAT is an interpretable graph-based neural
model that provides a suitable framework for analyzing this type of multimodal
sequential data. We first introduce a procedure to convert unaligned multimodal
sequence data into a graph with heterogeneous nodes and edges that captures the
rich interactions between different modalities through time. Then, a novel
graph operation, called Multimodal Temporal Graph Attention, along with a
dynamic pruning and read-out technique is designed to efficiently process this
multimodal temporal graph. By learning to focus only on the important
interactions within the graph, our MTGAT is able to achieve state-of-the-art
performance on multimodal sentiment analysis and emotion recognition benchmarks
including IEMOCAP and CMU-MOSI, while utilizing significantly fewer
computations.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 18:58:50 GMT'}]",2020-10-26,"[['Yang', 'Jianing', ''], ['Wang', 'Yongxin', ''], ['Yi', 'Ruitao', ''], ['Zhu', 'Yuying', ''], ['Rehman', 'Azaan', ''], ['Zadeh', 'Amir', ''], ['Poria', 'Soujanya', ''], ['Morency', 'Louis-Philippe', '']]"
1352535,2009.11032,Arie Cattan,"Arie Cattan, Alon Eirew, Gabriel Stanovsky, Mandar Joshi, and Ido
  Dagan","Streamlining Cross-Document Coreference Resolution: Evaluation and
  Modeling",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent evaluation protocols for Cross-document (CD) coreference resolution
have often been inconsistent or lenient, leading to incomparable results across
works and overestimation of performance. To facilitate proper future research
on this task, our primary contribution is proposing a pragmatic evaluation
methodology which assumes access to only raw text -- rather than assuming gold
mentions, disregards singleton prediction, and addresses typical targeted
settings in CD coreference resolution. Aiming to set baseline results for
future research that would follow our evaluation methodology, we build the
first end-to-end model for this task. Our model adapts and extends recent
neural models for within-document coreference resolution to address the CD
coreference setting, which outperforms state-of-the-art results by a
significant margin.
","[{'version': 'v1', 'created': 'Wed, 23 Sep 2020 10:02:10 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 12:18:01 GMT'}, {'version': 'v3', 'created': 'Fri, 23 Oct 2020 13:40:30 GMT'}]",2020-10-26,"[['Cattan', 'Arie', ''], ['Eirew', 'Alon', ''], ['Stanovsky', 'Gabriel', ''], ['Joshi', 'Mandar', ''], ['Dagan', 'Ido', '']]"
1355321,2009.13818,Dinghan Shen,"Dinghan Shen, Mingzhi Zheng, Yelong Shen, Yanru Qu, Weizhu Chen","A Simple but Tough-to-Beat Data Augmentation Approach for Natural
  Language Understanding and Generation",Source code is available at: https://github.com/dinghanshen/cutoff,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Adversarial training has been shown effective at endowing the learned
representations with stronger generalization ability. However, it typically
requires expensive computation to determine the direction of the injected
perturbations. In this paper, we introduce a set of simple yet effective data
augmentation strategies dubbed cutoff, where part of the information within an
input sentence is erased to yield its restricted views (during the fine-tuning
stage). Notably, this process relies merely on stochastic sampling and thus
adds little computational overhead. A Jensen-Shannon Divergence consistency
loss is further utilized to incorporate these augmented samples into the
training objective in a principled manner. To verify the effectiveness of the
proposed strategies, we apply cutoff to both natural language understanding and
generation problems. On the GLUE benchmark, it is demonstrated that cutoff, in
spite of its simplicity, performs on par or better than several competitive
adversarial-based approaches. We further extend cutoff to machine translation
and observe significant gains in BLEU scores (based upon the Transformer Base
model). Moreover, cutoff consistently outperforms adversarial training and
achieves state-of-the-art results on the IWSLT2014 German-English dataset.
","[{'version': 'v1', 'created': 'Tue, 29 Sep 2020 07:08:35 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 03:19:58 GMT'}]",2020-10-26,"[['Shen', 'Dinghan', ''], ['Zheng', 'Mingzhi', ''], ['Shen', 'Yelong', ''], ['Qu', 'Yanru', ''], ['Chen', 'Weizhu', '']]"
1368318,2010.11988,Bailin Wang,"Bailin Wang, Mirella Lapata and Ivan Titov",Meta-Learning for Domain Generalization in Semantic Parsing,V1.0,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The importance of building semantic parsers which can be applied to new
domains and generate programs unseen at training has long been acknowledged,
and datasets testing out-of-domain performance are becoming increasingly
available. However, little or no attention has been devoted to studying
learning algorithms or objectives which promote domain generalization, with
virtually all existing approaches relying on standard supervised learning. In
this work, we use a meta-learning framework which targets specifically
zero-shot domain generalization for semantic parsing. We apply a model-agnostic
training algorithm that simulates zero-shot parsing by constructing virtual
train and test sets from disjoint domains. The learning objective capitalizes
on the intuition that gradient steps that improve source-domain performance
should also improve target-domain performance, thus encouraging a parser to
generalize well to unseen target domains. Experimental results on the (English)
Spider and Chinese Spider datasets show that the meta-learning objective
significantly boosts the performance of a baseline parser.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 19:00:36 GMT'}]",2020-10-26,"[['Wang', 'Bailin', ''], ['Lapata', 'Mirella', ''], ['Titov', 'Ivan', '']]"
1287478,2005.07683,Victor Sanh,"Victor Sanh, Thomas Wolf, Alexander M. Rush",Movement Pruning: Adaptive Sparsity by Fine-Tuning,"14 pages, 6 figures, 3 tables. Published at NeurIPS2020. Code:
  \url{huggingface.co/mvp}",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Magnitude pruning is a widely used strategy for reducing model size in pure
supervised learning; however, it is less effective in the transfer learning
regime that has become standard for state-of-the-art natural language
processing applications. We propose the use of movement pruning, a simple,
deterministic first-order weight pruning method that is more adaptive to
pretrained model fine-tuning. We give mathematical foundations to the method
and compare it to existing zeroth- and first-order pruning methods. Experiments
show that when pruning large pretrained language models, movement pruning shows
significant improvements in high-sparsity regimes. When combined with
distillation, the approach achieves minimal accuracy loss with down to only 3%
of the model parameters.
","[{'version': 'v1', 'created': 'Fri, 15 May 2020 17:54:15 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 16:14:58 GMT'}]",2020-10-26,"[['Sanh', 'Victor', ''], ['Wolf', 'Thomas', ''], ['Rush', 'Alexander M.', '']]"
1359487,2010.03157,Sheng Bi,"Sheng Bi and Xiya Cheng and Yuan-Fang Li and Yongzhen Wang and Guilin
  Qi","Knowledge-enriched, Type-constrained and Grammar-guided Question
  Generation over Knowledge Bases",Accepted by COLING 2020,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Question generation over knowledge bases (KBQG) aims at generating
natural-language questions about a subgraph, i.e. a set of (connected) triples.
Two main challenges still face the current crop of encoder-decoder-based
methods, especially on small subgraphs: (1) low diversity and poor fluency due
to the limited information contained in the subgraphs, and (2) semantic drift
due to the decoder's oblivion of the semantics of the answer entity. We propose
an innovative knowledge-enriched, type-constrained and grammar-guided KBQG
model, named KTG, to addresses the above challenges. In our model, the encoder
is equipped with auxiliary information from the KB, and the decoder is
constrained with word types during QG. Specifically, entity domain and
description, as well as relation hierarchy information are considered to
construct question contexts, while a conditional copy mechanism is incorporated
to modulate question semantics according to current word types. Besides, a
novel reward function featuring grammatical similarity is designed to improve
both generative richness and syntactic correctness via reinforcement learning.
Extensive experiments show that our proposed model outperforms existing methods
by a significant margin on two widely-used benchmark datasets SimpleQuestion
and PathQuestion.
","[{'version': 'v1', 'created': 'Wed, 7 Oct 2020 04:49:48 GMT'}, {'version': 'v2', 'created': 'Thu, 8 Oct 2020 05:39:58 GMT'}, {'version': 'v3', 'created': 'Fri, 23 Oct 2020 03:32:38 GMT'}]",2020-10-26,"[['Bi', 'Sheng', ''], ['Cheng', 'Xiya', ''], ['Li', 'Yuan-Fang', ''], ['Wang', 'Yongzhen', ''], ['Qi', 'Guilin', '']]"
1362970,2010.06640,Gathika Ratnayaka,"Gathika Ratnayaka, Thushari Atapattu, Mahen Herath, Georgia Zhang,
  Katrina Falkner",Enhancing the Identification of Cyberbullying through Participant Roles,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Cyberbullying is a prevalent social problem that inflicts detrimental
consequences to the health and safety of victims such as psychological
distress, anti-social behaviour, and suicide. The automation of cyberbullying
detection is a recent but widely researched problem, with current research
having a strong focus on a binary classification of bullying versus
non-bullying. This paper proposes a novel approach to enhancing cyberbullying
detection through role modeling. We utilise a dataset from ASKfm to perform
multi-class classification to detect participant roles (e.g. victim, harasser).
Our preliminary results demonstrate promising performance including 0.83 and
0.76 of F1-score for cyberbullying and role classification respectively,
outperforming baselines.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 19:13:07 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 01:15:20 GMT'}]",2020-10-26,"[['Ratnayaka', 'Gathika', ''], ['Atapattu', 'Thushari', ''], ['Herath', 'Mahen', ''], ['Zhang', 'Georgia', ''], ['Falkner', 'Katrina', '']]"
1279095,2004.14325,Daniel Loureiro,Daniel Loureiro and Jose Camacho-Collados,"Don't Neglect the Obvious: On the Role of Unambiguous Words in Word
  Sense Disambiguation",Accepted to EMNLP 2020. Website: http://danlou.github.io/uwa,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  State-of-the-art methods for Word Sense Disambiguation (WSD) combine two
different features: the power of pre-trained language models and a propagation
method to extend the coverage of such models. This propagation is needed as
current sense-annotated corpora lack coverage of many instances in the
underlying sense inventory (usually WordNet). At the same time, unambiguous
words make for a large portion of all words in WordNet, while being poorly
covered in existing sense-annotated corpora. In this paper, we propose a simple
method to provide annotations for most unambiguous words in a large corpus. We
introduce the UWA (Unambiguous Word Annotations) dataset and show how a
state-of-the-art propagation-based model can use it to extend the coverage and
quality of its word sense embeddings by a significant margin, improving on its
original results on WSD.
","[{'version': 'v1', 'created': 'Wed, 29 Apr 2020 16:51:21 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Oct 2020 08:57:53 GMT'}, {'version': 'v3', 'created': 'Fri, 23 Oct 2020 09:20:11 GMT'}]",2020-10-26,"[['Loureiro', 'Daniel', ''], ['Camacho-Collados', 'Jose', '']]"
1365865,2010.09535,Michelle Yuan,"Michelle Yuan, Hsuan-Tien Lin, Jordan Boyd-Graber",Cold-start Active Learning through Self-supervised Language Modeling,Published in EMNLP 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Active learning strives to reduce annotation costs by choosing the most
critical examples to label. Typically, the active learning strategy is
contingent on the classification model. For instance, uncertainty sampling
depends on poorly calibrated model confidence scores. In the cold-start
setting, active learning is impractical because of model instability and data
scarcity. Fortunately, modern NLP provides an additional source of information:
pre-trained language models. The pre-training loss can find examples that
surprise the model and should be labeled for efficient fine-tuning. Therefore,
we treat the language modeling loss as a proxy for classification uncertainty.
With BERT, we develop a simple strategy based on the masked language modeling
loss that minimizes labeling costs for text classification. Compared to other
baselines, our approach reaches higher accuracy within less sampling iterations
and computation time.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 14:09:17 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 18:51:04 GMT'}]",2020-10-26,"[['Yuan', 'Michelle', ''], ['Lin', 'Hsuan-Tien', ''], ['Boyd-Graber', 'Jordan', '']]"
1300709,2006.06195,Zhe Gan,"Zhe Gan, Yen-Chun Chen, Linjie Li, Chen Zhu, Yu Cheng, Jingjing Liu","Large-Scale Adversarial Training for Vision-and-Language Representation
  Learning",NeurIPS 2020 Spotlight paper,,,,cs.CV cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present VILLA, the first known effort on large-scale adversarial training
for vision-and-language (V+L) representation learning. VILLA consists of two
training stages: (i) task-agnostic adversarial pre-training; followed by (ii)
task-specific adversarial finetuning. Instead of adding adversarial
perturbations on image pixels and textual tokens, we propose to perform
adversarial training in the embedding space of each modality. To enable
large-scale training, we adopt the ""free"" adversarial training strategy, and
combine it with KL-divergence-based regularization to promote higher invariance
in the embedding space. We apply VILLA to current best-performing V+L models,
and achieve new state of the art on a wide range of tasks, including Visual
Question Answering, Visual Commonsense Reasoning, Image-Text Retrieval,
Referring Expression Comprehension, Visual Entailment, and NLVR2.
","[{'version': 'v1', 'created': 'Thu, 11 Jun 2020 05:14:35 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 18:12:53 GMT'}]",2020-10-26,"[['Gan', 'Zhe', ''], ['Chen', 'Yen-Chun', ''], ['Li', 'Linjie', ''], ['Zhu', 'Chen', ''], ['Cheng', 'Yu', ''], ['Liu', 'Jingjing', '']]"
1301414,2006.06900,Yue Wu,"Yue Wu, Pan Zhou, Andrew Gordon Wilson, Eric P. Xing, Zhiting Hu","Improving GAN Training with Probability Ratio Clipping and Sample
  Reweighting",NeurIPS 2020 camera ready version,,,,cs.LG cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite success on a wide range of problems related to vision, generative
adversarial networks (GANs) often suffer from inferior performance due to
unstable training, especially for text generation. To solve this issue, we
propose a new variational GAN training framework which enjoys superior training
stability. Our approach is inspired by a connection of GANs and reinforcement
learning under a variational perspective. The connection leads to (1)
probability ratio clipping that regularizes generator training to prevent
excessively large updates, and (2) a sample re-weighting mechanism that
improves discriminator training by downplaying bad-quality fake samples.
Moreover, our variational GAN framework can provably overcome the training
issue in many GANs that an optimal discriminator cannot provide any informative
gradient to training generator. By plugging the training approach in diverse
state-of-the-art GAN architectures, we obtain significantly improved
performance over a range of tasks, including text generation, text style
transfer, and image generation.
","[{'version': 'v1', 'created': 'Fri, 12 Jun 2020 01:39:48 GMT'}, {'version': 'v2', 'created': 'Tue, 30 Jun 2020 15:02:27 GMT'}, {'version': 'v3', 'created': 'Fri, 23 Oct 2020 03:24:01 GMT'}]",2020-10-26,"[['Wu', 'Yue', ''], ['Zhou', 'Pan', ''], ['Wilson', 'Andrew Gordon', ''], ['Xing', 'Eric P.', ''], ['Hu', 'Zhiting', '']]"
1366371,2010.10041,Chi-Liang Liu,"Chi-Liang Liu and Tsung-Yuan Hsu and Yung-Sung Chuang and Chung-Yi Li
  and Hung-yi Lee","Language Representation in Multilingual BERT and its applications to
  improve Cross-lingual Generalization",preprint,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A token embedding in multilingual BERT (m-BERT) contains both language and
semantic information. We find that representation of a language can be obtained
by simply averaging the embeddings of the tokens of the language. With the
language representation, we can control the output languages of multilingual
BERT by manipulating the token embeddings and achieve unsupervised token
translation. We further propose a computationally cheap but effective approach
to improve the cross-lingual ability of m-BERT based on the observation.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 05:41:35 GMT'}, {'version': 'v2', 'created': 'Wed, 21 Oct 2020 07:26:02 GMT'}, {'version': 'v3', 'created': 'Fri, 23 Oct 2020 05:47:46 GMT'}]",2020-10-26,"[['Liu', 'Chi-Liang', ''], ['Hsu', 'Tsung-Yuan', ''], ['Chuang', 'Yung-Sung', ''], ['Li', 'Chung-Yi', ''], ['Lee', 'Hung-yi', '']]"
1302851,2006.08337,Jinfeng Xiao,"Jinfeng Xiao, Lidan Wang, Franck Dernoncourt, Trung Bui, Tong Sun,
  Jiawei Han",Open-Domain Question Answering with Pre-Constructed Question Spaces,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Open-domain question answering aims at solving the task of locating the
answers to user-generated questions in massive collections of documents. There
are two families of solutions available: retriever-readers, and
knowledge-graph-based approaches. A retriever-reader usually first uses
information retrieval methods like TF-IDF to locate some documents or
paragraphs that are likely to be relevant to the question, and then feeds the
retrieved text to a neural network reader to extract the answer. Alternatively,
knowledge graphs can be constructed from the corpus and be queried against to
answer user questions. We propose a novel algorithm with a reader-retriever
structure that differs from both families. Our reader-retriever first uses an
offline reader to read the corpus and generate collections of all answerable
questions associated with their answers, and then uses an online retriever to
respond to user queries by searching the pre-constructed question spaces for
answers that are most likely to be asked in the given way. We further combine
retriever-reader and reader-retriever results into one single answer by
examining the consistency between the two components. We claim that our
algorithm solves some bottlenecks in existing work, and demonstrate that it
achieves superior accuracy on real-world datasets.
","[{'version': 'v1', 'created': 'Tue, 2 Jun 2020 04:31:09 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 02:10:07 GMT'}]",2020-10-26,"[['Xiao', 'Jinfeng', ''], ['Wang', 'Lidan', ''], ['Dernoncourt', 'Franck', ''], ['Bui', 'Trung', ''], ['Sun', 'Tong', ''], ['Han', 'Jiawei', '']]"
1366693,2010.10363,Laurel Orr,"Laurel Orr, Megan Leszczynski, Simran Arora, Sen Wu, Neel Guha, Xiao
  Ling, Christopher Re","Bootleg: Chasing the Tail with Self-Supervised Named Entity
  Disambiguation",,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A challenge for named entity disambiguation (NED), the task of mapping
textual mentions to entities in a knowledge base, is how to disambiguate
entities that appear rarely in the training data, termed tail entities. Humans
use subtle reasoning patterns based on knowledge of entity facts, relations,
and types to disambiguate unfamiliar entities. Inspired by these patterns, we
introduce Bootleg, a self-supervised NED system that is explicitly grounded in
reasoning patterns for disambiguation. We define core reasoning patterns for
disambiguation, create a learning procedure to encourage the self-supervised
model to learn the patterns, and show how to use weak supervision to enhance
the signals in the training data. Encoding the reasoning patterns in a simple
Transformer architecture, Bootleg meets or exceeds state-of-the-art on three
NED benchmarks. We further show that the learned representations from Bootleg
successfully transfer to other non-disambiguation tasks that require
entity-based knowledge: we set a new state-of-the-art in the popular TACRED
relation extraction task by 1.0 F1 points and demonstrate up to 8% performance
lift in highly optimized production search and assistant tasks at a major
technology company
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 15:17:49 GMT'}, {'version': 'v2', 'created': 'Wed, 21 Oct 2020 02:19:08 GMT'}, {'version': 'v3', 'created': 'Fri, 23 Oct 2020 16:21:13 GMT'}]",2020-10-26,"[['Orr', 'Laurel', ''], ['Leszczynski', 'Megan', ''], ['Arora', 'Simran', ''], ['Wu', 'Sen', ''], ['Guha', 'Neel', ''], ['Ling', 'Xiao', ''], ['Re', 'Christopher', '']]"
1367073,2010.10743,Jianhao Yan,"Jianhao Yan, Fandong Meng, Jie Zhou",Multi-Unit Transformers for Neural Machine Translation,Accepted as a main conference paper in EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Transformer models achieve remarkable success in Neural Machine Translation.
Many efforts have been devoted to deepening the Transformer by stacking several
units (i.e., a combination of Multihead Attentions and FFN) in a cascade, while
the investigation over multiple parallel units draws little attention. In this
paper, we propose the Multi-Unit Transformers (MUTE), which aim to promote the
expressiveness of the Transformer by introducing diverse and complementary
units. Specifically, we use several parallel units and show that modeling with
multiple units improves model performance and introduces diversity. Further, to
better leverage the advantage of the multi-unit setting, we design biased
module and sequential dependency that guide and encourage complementariness
among different units. Experimental results on three machine translation tasks,
the NIST Chinese-to-English, WMT'14 English-to-German and WMT'18
Chinese-to-English, show that the MUTE models significantly outperform the
Transformer-Base, by up to +1.52, +1.90 and +1.10 BLEU points, with only a mild
drop in inference speed (about 3.1%). In addition, our methods also surpass the
Transformer-Big model, with only 54\% of its parameters. These results
demonstrate the effectiveness of the MUTE, as well as its efficiency in both
the inference process and parameter usage.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 03:41:49 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 11:33:45 GMT'}]",2020-10-26,"[['Yan', 'Jianhao', ''], ['Meng', 'Fandong', ''], ['Zhou', 'Jie', '']]"
1366215,2010.09885,Seyone Chithrananda,"Seyone Chithrananda, Gabriel Grand and Bharath Ramsundar","ChemBERTa: Large-Scale Self-Supervised Pretraining for Molecular
  Property Prediction",Submitted to NeurIPS 2020 ML for Molecules Workshop,,,,cs.LG cs.CL physics.chem-ph q-bio.BM,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  GNNs and chemical fingerprints are the predominant approaches to representing
molecules for property prediction. However, in NLP, transformers have become
the de-facto standard for representation learning thanks to their strong
downstream task transfer. In parallel, the software ecosystem around
transformers is maturing rapidly, with libraries like HuggingFace and BertViz
enabling streamlined training and introspection. In this work, we make one of
the first attempts to systematically evaluate transformers on molecular
property prediction tasks via our ChemBERTa model. ChemBERTa scales well with
pretraining dataset size, offering competitive downstream performance on
MoleculeNet and useful attention-based visualization modalities. Our results
suggest that transformers offer a promising avenue of future work for molecular
representation learning and property prediction. To facilitate these efforts,
we release a curated dataset of 77M SMILES from PubChem suitable for
large-scale self-supervised pretraining.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 21:41:41 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 04:22:37 GMT'}]",2020-10-26,"[['Chithrananda', 'Seyone', ''], ['Grand', 'Gabriel', ''], ['Ramsundar', 'Bharath', '']]"
1368312,2010.11982,Avia Efrat,Avia Efrat and Omer Levy,The Turking Test: Can Language Models Understand Instructions?,,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Supervised machine learning provides the learner with a set of input-output
examples of the target task. Humans, however, can also learn to perform new
tasks from instructions in natural language. Can machines learn to understand
instructions as well? We present the Turking Test, which examines a model's
ability to follow natural language instructions of varying complexity. These
range from simple tasks, like retrieving the nth word of a sentence, to ones
that require creativity, such as generating examples for SNLI and SQuAD in
place of human intelligence workers (""turkers""). Despite our lenient evaluation
methodology, we observe that a large pretrained language model performs poorly
across all tasks. Analyzing the model's error patterns reveals that the model
tends to ignore explicit instructions and often generates outputs that cannot
be construed as an attempt to solve the task. While it is not yet clear whether
instruction understanding can be captured by traditional language models, the
sheer expressivity of instruction understanding makes it an appealing
alternative to the rising few-shot inference paradigm.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 18:44:16 GMT'}]",2020-10-26,"[['Efrat', 'Avia', ''], ['Levy', 'Omer', '']]"
1368296,2010.11966,David Lowell,"David Lowell, Brian E. Howard, Zachary C. Lipton, Byron C. Wallace","Unsupervised Data Augmentation with Naive Augmentation and without
  Unlabeled Data",,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Unsupervised Data Augmentation (UDA) is a semi-supervised technique that
applies a consistency loss to penalize differences between a model's
predictions on (a) observed (unlabeled) examples; and (b) corresponding
'noised' examples produced via data augmentation. While UDA has gained
popularity for text classification, open questions linger over which design
decisions are necessary and over how to extend the method to sequence labeling
tasks. This method has recently gained traction for text classification. In
this paper, we re-examine UDA and demonstrate its efficacy on several
sequential tasks. Our main contribution is an empirical study of UDA to
establish which components of the algorithm confer benefits in NLP. Notably,
although prior work has emphasized the use of clever augmentation techniques
including back-translation, we find that enforcing consistency between
predictions assigned to observed and randomly substituted words often yields
comparable (or greater) benefits compared to these complex perturbation models.
Furthermore, we find that applying its consistency loss affords meaningful
gains without any unlabeled data at all, i.e., in a standard supervised
setting. In short: UDA need not be unsupervised, and does not require complex
data augmentation to be effective.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 18:01:51 GMT'}]",2020-10-26,"[['Lowell', 'David', ''], ['Howard', 'Brian E.', ''], ['Lipton', 'Zachary C.', ''], ['Wallace', 'Byron C.', '']]"
1368303,2010.11973,Badr M. Abdullah,"Badr M. Abdullah, Jacek Kudera, Tania Avgustinova, Bernd M\""obius,
  Dietrich Klakow","Rediscovering the Slavic Continuum in Representations Emerging from
  Neural Models of Spoken Language Identification",Accepted in VarDial 2020 Workshop,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Deep neural networks have been employed for various spoken language
recognition tasks, including tasks that are multilingual by definition such as
spoken language identification. In this paper, we present a neural model for
Slavic language identification in speech signals and analyze its emergent
representations to investigate whether they reflect objective measures of
language relatedness and/or non-linguists' perception of language similarity.
While our analysis shows that the language representation space indeed captures
language relatedness to a great extent, we find perceptual confusability
between languages in our study to be the best predictor of the language
representation similarity.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 18:18:19 GMT'}]",2020-10-26,"[['Abdullah', 'Badr M.', ''], ['Kudera', 'Jacek', ''], ['Avgustinova', 'Tania', ''], ['Möbius', 'Bernd', ''], ['Klakow', 'Dietrich', '']]"
1368310,2010.11980,Tuan Manh Lai,"Tuan Manh Lai, Trung Bui, Doo Soon Kim, Quan Hung Tran","A Joint Learning Approach based on Self-Distillation for Keyphrase
  Extraction from Scientific Documents",Accepted to COLING 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Keyphrase extraction is the task of extracting a small set of phrases that
best describe a document. Most existing benchmark datasets for the task
typically have limited numbers of annotated documents, making it challenging to
train increasingly complex neural networks. In contrast, digital libraries
store millions of scientific articles online, covering a wide range of topics.
While a significant portion of these articles contain keyphrases provided by
their authors, most other articles lack such kind of annotations. Therefore, to
effectively utilize these large amounts of unlabeled articles, we propose a
simple and efficient joint learning approach based on the idea of
self-distillation. Experimental results show that our approach consistently
improves the performance of baseline models for keyphrase extraction.
Furthermore, our best models outperform previous methods for the task,
achieving new state-of-the-art results on two public benchmarks: Inspec and
SemEval-2017.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 18:36:31 GMT'}]",2020-10-26,"[['Lai', 'Tuan Manh', ''], ['Bui', 'Trung', ''], ['Kim', 'Doo Soon', ''], ['Tran', 'Quan Hung', '']]"
1368277,2010.11947,Zekun Xu,"Zekun Xu, Abhinav Aggarwal, Oluwaseyi Feyisetan, Nathanael Teissier","A Differentially Private Text Perturbation Method Using a Regularized
  Mahalanobis Metric","11 pages, 7 figures",,,,cs.CL cs.CR cs.LG stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Balancing the privacy-utility tradeoff is a crucial requirement of many
practical machine learning systems that deal with sensitive customer data. A
popular approach for privacy-preserving text analysis is noise injection, in
which text data is first mapped into a continuous embedding space, perturbed by
sampling a spherical noise from an appropriate distribution, and then projected
back to the discrete vocabulary space. While this allows the perturbation to
admit the required metric differential privacy, often the utility of downstream
tasks modeled on this perturbed data is low because the spherical noise does
not account for the variability in the density around different words in the
embedding space. In particular, words in a sparse region are likely unchanged
even when the noise scale is large. %Using the global sensitivity of the
mechanism can potentially add too much noise to the words in the dense regions
of the embedding space, causing a high utility loss, whereas using local
sensitivity can leak information through the scale of the noise added.
  In this paper, we propose a text perturbation mechanism based on a carefully
designed regularized variant of the Mahalanobis metric to overcome this
problem. For any given noise scale, this metric adds an elliptical noise to
account for the covariance structure in the embedding space. This heterogeneity
in the noise scale along different directions helps ensure that the words in
the sparse region have sufficient likelihood of replacement without sacrificing
the overall utility. We provide a text-perturbation algorithm based on this
metric and formally prove its privacy guarantees. Additionally, we empirically
show that our mechanism improves the privacy statistics to achieve the same
level of utility as compared to the state-of-the-art Laplace mechanism.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 23:06:44 GMT'}]",2020-10-26,"[['Xu', 'Zekun', ''], ['Aggarwal', 'Abhinav', ''], ['Feyisetan', 'Oluwaseyi', ''], ['Teissier', 'Nathanael', '']]"
1368297,2010.11967,Chenguang Wang,"Chenguang Wang, Xiao Liu, Dawn Song",Language Models are Open Knowledge Graphs,"30 pages, 32 figures, 3 tables",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper shows how to construct knowledge graphs (KGs) from pre-trained
language models (e.g., BERT, GPT-2/3), without human supervision. Popular KGs
(e.g, Wikidata, NELL) are built in either a supervised or semi-supervised
manner, requiring humans to create knowledge. Recent deep language models
automatically acquire knowledge from large-scale corpora via pre-training. The
stored knowledge has enabled the language models to improve downstream NLP
tasks, e.g., answering questions, and writing code and articles. In this paper,
we propose an unsupervised method to cast the knowledge contained within
language models into KGs. We show that KGs are constructed with a single
forward pass of the pre-trained language models (without fine-tuning) over the
corpora. We demonstrate the quality of the constructed KGs by comparing to two
KGs (Wikidata, TAC KBP) created by humans. Our KGs also provide open factual
knowledge that is new in the existing KGs. Our code and KGs will be made
publicly available.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 18:01:56 GMT'}]",2020-10-26,"[['Wang', 'Chenguang', ''], ['Liu', 'Xiao', ''], ['Song', 'Dawn', '']]"
1131884,1905.13448,Xuenan Xu,"Xuenan Xu, Heinrich Dinkel, Mengyue Wu, Kai Yu",Audio Caption in a Car Setting with a Sentence-Level Loss,,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Captioning has attracted much attention in image and video understanding
while a small amount of work examines audio captioning. This paper contributes
a Mandarin-annotated dataset for audio captioning within a car scene. A
sentence-level loss is proposed to be used in tandem with a GRU encoder-decoder
model to generate captions with higher semantic similarity to human
annotations. We evaluate the model on the newly-proposed Car dataset, a
previously published Mandarin Hospital dataset and the Joint dataset,
indicating its generalization capability across different scenes. An
improvement in all metrics can be observed, including classical natural
language generation (NLG) metrics, sentence richness and human evaluation
ratings. However, though detailed audio captions can now be automatically
generated, human annotations still outperform model captions on many aspects.
","[{'version': 'v1', 'created': 'Fri, 31 May 2019 07:30:15 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 06:58:36 GMT'}]",2020-10-26,"[['Xu', 'Xuenan', ''], ['Dinkel', 'Heinrich', ''], ['Wu', 'Mengyue', ''], ['Yu', 'Kai', '']]"
1367987,2010.11657,Renyu Wang,"Renyu Wang, Ruilin Tong, Yu Ting Yeung, Xiao Chen","The HUAWEI Speaker Diarisation System for the VoxCeleb Speaker
  Diarisation Challenge","5 pages, 2 figures, A report about our diarisation system for
  VoxCeleb Challenge, Interspeech conference workshop",,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper describes system setup of our submission to speaker diarisation
track (Track 4) of VoxCeleb Speaker Recognition Challenge 2020. Our diarisation
system consists of a well-trained neural network based speech enhancement model
as pre-processing front-end of input speech signals. We replace conventional
energy-based voice activity detection (VAD) with a neural network based VAD.
The neural network based VAD provides more accurate annotation of speech
segments containing only background music, noise, and other interference, which
is crucial to diarisation performance. We apply agglomerative hierarchical
clustering (AHC) of x-vectors and variational Bayesian hidden Markov model
(VB-HMM) based iterative clustering for speaker clustering. Experimental
results demonstrate that our proposed system achieves substantial improvements
over the baseline system, yielding diarisation error rate (DER) of 10.45%, and
Jacard error rate (JER) of 22.46% on the evaluation set.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 12:42:07 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 07:45:47 GMT'}]",2020-10-26,"[['Wang', 'Renyu', ''], ['Tong', 'Ruilin', ''], ['Yeung', 'Yu Ting', ''], ['Chen', 'Xiao', '']]"
1367808,2010.11478,Minho Ryu,Minho Ryu and Kichun Lee,Knowledge Distillation for BERT Unsupervised Domain Adaptation,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A pre-trained language model, BERT, has brought significant performance
improvements across a range of natural language processing tasks. Since the
model is trained on a large corpus of diverse topics, it shows robust
performance for domain shift problems in which data distributions at training
(source data) and testing (target data) differ while sharing similarities.
Despite its great improvements compared to previous models, it still suffers
from performance degradation due to domain shifts. To mitigate such problems,
we propose a simple but effective unsupervised domain adaptation method,
adversarial adaptation with distillation (AAD), which combines the adversarial
discriminative domain adaptation (ADDA) framework with knowledge distillation.
We evaluate our approach in the task of cross-domain sentiment classification
on 30 domain pairs, advancing the state-of-the-art performance for unsupervised
domain adaptation in text sentiment classification.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 06:51:24 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 02:12:06 GMT'}]",2020-10-26,"[['Ryu', 'Minho', ''], ['Lee', 'Kichun', '']]"
1367725,2010.11395,Xie Chen,"Xie Chen, Yu Wu, Zhenghao Wang, Shujie Liu, Jinyu Li","Developing Real-time Streaming Transformer Transducer for Speech
  Recognition on Large-scale Dataset",5 pages,,,,cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, Transformer based end-to-end models have achieved great success in
many areas including speech recognition. However, compared to LSTM models, the
heavy computational cost of the Transformer during inference is a key issue to
prevent their applications. In this work, we explored the potential of
Transformer Transducer (T-T) models for the fist pass decoding with low latency
and fast speed on a large-scale dataset. We combine the idea of Transformer-XL
and chunk-wise streaming processing to design a streamable Transformer
Transducer model. We demonstrate that T-T outperforms the hybrid model, RNN
Transducer (RNN-T), and streamable Transformer attention-based encoder-decoder
model in the streaming scenario. Furthermore, the runtime cost and latency can
be optimized with a relatively small look-ahead.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 03:01:21 GMT'}]",2020-10-26,"[['Chen', 'Xie', ''], ['Wu', 'Yu', ''], ['Wang', 'Zhenghao', ''], ['Liu', 'Shujie', ''], ['Li', 'Jinyu', '']]"
1369125,2010.12795,Navita Goyal,"Navita Goyal, Roodram Paneri, Ayush Agarwal, Udit Kalani, Abhilasha
  Sancheti, Niyati Chhaya",CaM-Gen:Causally-aware Metric-guided Text Generation,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Content is created for a well-defined purpose, often described by a metric or
a signal represented in the form of structured information. The relationship
between the metrics or the goal of a target content and the content itself are
non-trivial. While large scale language models show promising text generation
capabilities, guiding and informing the generated text with external metrics is
challenging. These metrics and the content tend to have inherent relationships
and not all of them may directly impact the content. We introduce a CaM-Gen:
Causally-aware Generative Networks guided by user-defined input metrics
incorporating the causal relationships between the metric and the content
features. We leverage causal inference techniques to identify the causally
significant aspects of text that leads to the target metric and then explicitly
guide the generative model towards these by a feedback mechanism. We propose
this mechanism for variational autoencoder-based and transformer-based
generative models. The proposed models beat baselines in terms of the target
metric accuracy while maintaining the fluency and the language quality of the
generated text. To the best of our knowledge, this is one of the early attempts
at incorporating a metric-guide using causal inference towards controlled
generation.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 06:17:35 GMT'}]",2020-10-27,"[['Goyal', 'Navita', ''], ['Paneri', 'Roodram', ''], ['Agarwal', 'Ayush', ''], ['Kalani', 'Udit', ''], ['Sancheti', 'Abhilasha', ''], ['Chhaya', 'Niyati', '']]"
1369124,2010.12794,Zihan Wang,Zihan Wang and Dheeraj Mekala and Jingbo Shang,X-Class: Text Classification with Extremely Weak Supervision,,,,,cs.CL cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we explore to conduct text classification with extremely weak
supervision, i.e., only relying on the surface text of class names. This is a
more challenging setting than the seed-driven weak supervision, which allows a
few seed words per class. We opt to attack this problem from a representation
learning perspective -- ideal document representations should lead to very
close results between clustering and the desired classification. In particular,
one can classify the same corpus differently (e.g., based on topics and
locations), so document representations must be adaptive to the given class
names. We propose a novel framework X-Class to realize it. Specifically, we
first estimate comprehensive class representations by incrementally adding the
most similar word to each class until inconsistency appears. Following a
tailored mixture of class attention mechanisms, we obtain the document
representation via a weighted average of contextualized token representations.
We then cluster and align the documents to classes with the prior of each
document assigned to its nearest class. Finally, we pick the most confident
documents from each cluster to train a text classifier. Extensive experiments
demonstrate that X-Class can rival and even outperform seed-driven weakly
supervised methods on 7 benchmark datasets.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 06:09:51 GMT'}]",2020-10-27,"[['Wang', 'Zihan', ''], ['Mekala', 'Dheeraj', ''], ['Shang', 'Jingbo', '']]"
1369119,2010.12789,Limin Zhang,Limin Zhang,"Exploration of NLU: disassemble the information represented by Natural
  Language, based on the understanding of the internal structure of
  information, modeling the storage and processing system of information","13 pages, 8 figures, 11 tables",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Natural language is one of the ways information is encoded and it has highly
abstracted and conceptualized the information. This paper disassembles the
information represented by natural language, analyzes the classification coding
system of attribute information and the abstraction relation between attribute
information and entities in the real world, constructs the storage model of
information, and simulate the attribute information precessing process in one
of the attribute spaces, interprets how the relations which represented by
""Be"", ""Of"", ""Have"", and so on are embodied in the information storage data
structures and the corresponding data reading modes, reclassifies the sentences
types from the perspective of task types and data reading modes. Then,
simulated the understanding process (the information processing process) on a
dialogue example. Finally, the author summarizes the basic conditions of
understanding and gives out the definition of understanding from a personal
point of view. The study in this paper provides a practical, theoretical basis
and research methods for NLU. It also can be applied in large-scale, multi-type
information processing in the artificial intelligence (AI) area.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 05:40:47 GMT'}]",2020-10-27,"[['Zhang', 'Limin', '']]"
1369117,2010.12787,Kung-Hsiang Huang,"Kung-Hsiang Huang, Nanyun Peng","Efficient End-to-end Learning of Cross-event Dependencies for
  Document-level Event Extraction","10 pages, 3 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Document-level event extraction is important for indexing the most important
information in a document to facilitate downstream tasks such as information
retrieval or question answering. However, it is a challenging task because it
requires the understanding of event and entity coreference, and capturing
arguments that span across different sentences. Existing works on event
extraction generally confine on extracting events from single sentences, which
fail to capture the relationships between the event mentions at the scale of a
document, as well as the event arguments that appear in a different sentence
than the event trigger. In this paper, we propose an end-to-end model
leveraging Deep Value Networks (DVN), a structured prediction algorithm, to
efficiently capture cross-event dependencies for document-level event
extraction. Experimental results show that our approach achieves comparable
performance to CRF-based model on ACE05, while enjoys significantly higher
efficiency.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 05:28:16 GMT'}]",2020-10-27,"[['Huang', 'Kung-Hsiang', ''], ['Peng', 'Nanyun', '']]"
1369116,2010.12786,Huda Khayrallah,"Huda Khayrallah, Jo\~ao Sedoc","Measuring the `I don't know' Problem through the Lens of Gricean
  Quantity",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We consider the intrinsic evaluation of neural generative dialog models
through the lens of Grices Maxims of Conversation (1975). Based on the maxim of
Quantity (be informative), we propose Relative Utterance Quantity (RUQ) to
diagnose the `I don't know' problem. The RUQ diagnostic compares the model
score of a generic response to that of the reference response. We find that for
reasonable baseline models, `I don't know' is preferred over the reference more
than half the time, but this can be mitigated with hyperparameter tuning.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 05:16:36 GMT'}]",2020-10-27,"[['Khayrallah', 'Huda', ''], ['Sedoc', 'João', '']]"
1369138,2010.12808,Xiaodong Yu,"Xiaodong Yu, Wenpeng Yin, Dan Roth",Paired Representation Learning for Event and Entity Coreference,"9 pages, 2 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Co-reference of Events and of Entities are commonly formulated as binary
classification problems, given a pair of events or entities as input. Earlier
work addressed the main challenge in these problems -- the representation of
each element in the input pair by: (i) modelling the representation of one
element (event or entity) without considering the other element in the pair;
(ii) encoding all attributes of one element (e.g., arguments of an event) into
a single non-interpretable vector, thus losing the ability to compare
cross-element attributes. In this work we propose paired representation
learning (PairedRL) for coreference resolution. Given a pair of elements
(Events or Entities) our model treats the pair's sentences as a single sequence
so that each element in the pair learns its representation by encoding its own
context as well the other element's context. In addition, when representing
events, PairedRL is structured in that it represents the event's arguments to
facilitate their individual contribution to the final prediction. As we show,
in both (within-document & cross-document) event and entity coreference
benchmarks, our unified approach, PairedRL, outperforms prior state of the art
systems with a large margin.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 06:55:52 GMT'}]",2020-10-27,"[['Yu', 'Xiaodong', ''], ['Yin', 'Wenpeng', ''], ['Roth', 'Dan', '']]"
1369114,2010.12784,Vikram Gupta,"Vikram Gupta, Haoyue Shi, Kevin Gimpel, Mrinmaya Sachan","Clustering Contextualized Representations of Text for Unsupervised
  Syntax Induction",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We explore clustering of contextualized text representations for two
unsupervised syntax induction tasks: part of speech induction (POSI) and
constituency labelling (CoLab). We propose a deep embedded clustering approach
which jointly transforms these representations into a lower dimension cluster
friendly space and clusters them. We further enhance these representations by
augmenting them with task-specific representations. We also explore the
effectiveness of multilingual representations for different tasks and
languages. With this work, we establish the first strong baselines for
unsupervised syntax induction using contextualized text representations. We
report competitive performance on 45-tag POSI, state-of-the-art performance on
12-tag POSI across 10 languages, and competitive results on CoLab.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 05:06:29 GMT'}]",2020-10-27,"[['Gupta', 'Vikram', ''], ['Shi', 'Haoyue', ''], ['Gimpel', 'Kevin', ''], ['Sachan', 'Mrinmaya', '']]"
1369142,2010.12812,Zexuan Zhong,Zexuan Zhong and Danqi Chen,A Frustratingly Easy Approach for Joint Entity and Relation Extraction,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  End-to-end relation extraction aims to identify named entities and extract
relations between them simultaneously. Most recent work models these two
subtasks jointly, either by unifying them in one structured prediction
framework, or multi-task learning through shared representations. In this work,
we describe a very simple approach for joint entity and relation extraction,
and establish the new state-of-the-art on standard benchmarks (ACE04, ACE05,
and SciERC). Our approach essentially builds on two independent pre-trained
encoders and merely uses the entity model to provide input features for the
relation model. Through a series of careful examinations, we validate the
importance of learning distinct contextual representations for entities and
relations, fusing entity information at the input layer of the relation model,
and incorporating global context. Finally, we also present an efficient
approximation to our approach which requires only one pass of both encoders at
inference time, obtaining a 8-16$\times$ speedup with a small accuracy drop.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 07:14:01 GMT'}]",2020-10-27,"[['Zhong', 'Zexuan', ''], ['Chen', 'Danqi', '']]"
1369130,2010.12800,Xinliang (Frederick) Zhang,"Xinliang Frederick Zhang, Heming Sun, Xiang Yue, Emmett Jesrani, Simon
  Lin, Huan Sun",COUGH: A Challenge Dataset and Models for COVID-19 FAQ Retrieval,,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present a large challenging dataset, COUGH, for COVID-19 FAQ retrieval.
Specifically, similar to a standard FAQ dataset, COUGH consists of three parts:
FAQ Bank, User Query Bank and Annotated Relevance Set. FAQ Bank contains ~16K
FAQ items scraped from 55 credible websites (e.g., CDC and WHO). For
evaluation, we introduce User Query Bank and Annotated Relevance Set, where the
former contains 1201 human-paraphrased queries while the latter contains ~32
human-annotated FAQ items for each query. We analyze COUGH by testing different
FAQ retrieval models built on top of BM25 and BERT, among which the best model
achieves 0.29 under P@5, indicating that the dataset presents a great challenge
for future research. Our dataset is freely available at
https://github.com/sunlab-osu/covid-faq.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 06:30:59 GMT'}]",2020-10-27,"[['Zhang', 'Xinliang Frederick', ''], ['Sun', 'Heming', ''], ['Yue', 'Xiang', ''], ['Jesrani', 'Emmett', ''], ['Lin', 'Simon', ''], ['Sun', 'Huan', '']]"
1369100,2010.12770,Jianpeng Cheng J,"Jianpeng Cheng, Devang Agrawal, Hector Martinez Alonso, Shruti
  Bhargava, Joris Driesen, Federico Flego, Dain Kaplan, Dimitri Kartsaklis, Lin
  Li, Dhivya Piraviperumal, Jason D Williams, Hong Yu, Diarmuid O Seaghdha,
  Anders Johannsen",Conversational Semantic Parsing for Dialog State Tracking,Publish as a conference paper at EMNLP 2020,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  We consider a new perspective on dialog state tracking (DST), the task of
estimating a user's goal through the course of a dialog. By formulating DST as
a semantic parsing task over hierarchical representations, we can incorporate
semantic compositionality, cross-domain knowledge sharing and co-reference. We
present TreeDST, a dataset of 27k conversations annotated with tree-structured
dialog states and system acts. We describe an encoder-decoder framework for DST
with hierarchical representations, which leads to 20% improvement over
state-of-the-art DST approaches that operate on a flat meaning space of
slot-value pairs.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 04:10:32 GMT'}]",2020-10-27,"[['Cheng', 'Jianpeng', ''], ['Agrawal', 'Devang', ''], ['Alonso', 'Hector Martinez', ''], ['Bhargava', 'Shruti', ''], ['Driesen', 'Joris', ''], ['Flego', 'Federico', ''], ['Kaplan', 'Dain', ''], ['Kartsaklis', 'Dimitri', ''], ['Li', 'Lin', ''], ['Piraviperumal', 'Dhivya', ''], ['Williams', 'Jason D', ''], ['Yu', 'Hong', ''], ['Seaghdha', 'Diarmuid O', ''], ['Johannsen', 'Anders', '']]"
1369110,2010.12780,Yan Zeng,Yan Zeng and Jian-Yun Nie,Open-Domain Dialogue Generation Based on Pre-trained Language Models,"[v0], 10 pages, 4 figures",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pre-trained language models have been successfully used in response
generation for open-domain dialogue. Four main frameworks have been proposed:
(1) Transformer-ED using Transformer encoder and decoder separately for source
and target sentences; (2) Transformer-Dec using Transformer decoder for both
source and target sentences; (3) Transformer-MLM using Transformer decoder that
applies bi-directional attention on the source side and left-to-right attention
on the target side with masked language model objective; and (4) Transformer-AR
that uses auto-regressive objective instead. In this study, we compare these
frameworks on 3 datasets, and our comparison reveals that the best framework
uses bidirectional attention on the source side and does not separate encoder
and decoder. We also examine model discrepancy, and our experiments confirm
that the performance of a model is directly impacted by the underlying
discrepancies. We then propose two correction methods to reduce the
discrepancies, and both improve the model performance. These results show that
discrepancies is an important factor to consider when we use a pre-trained
model, and a reduction in discrepancies can lead to improved performance.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 04:52:28 GMT'}]",2020-10-27,"[['Zeng', 'Yan', ''], ['Nie', 'Jian-Yun', '']]"
1369109,2010.12779,Aida Mostafazadeh Davani,"Aida Mostafazadeh Davani, Ali Omrani, Brendan Kennedy, Mohammad Atari,
  Xiang Ren, Morteza Dehghani","Fair Hate Speech Detection through Evaluation of Social Group
  Counterfactuals",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Approaches for mitigating bias in supervised models are designed to reduce
models' dependence on specific sensitive features of the input data, e.g.,
mentioned social groups. However, in the case of hate speech detection, it is
not always desirable to equalize the effects of social groups because of their
essential role in distinguishing outgroup-derogatory hate, such that particular
types of hateful rhetoric carry the intended meaning only when contextualized
around certain social group tokens. Counterfactual token fairness for a
mentioned social group evaluates the model's predictions as to whether they are
the same for (a) the actual sentence and (b) a counterfactual instance, which
is generated by changing the mentioned social group in the sentence. Our
approach assures robust model predictions for counterfactuals that imply
similar meaning as the actual sentence. To quantify the similarity of a
sentence and its counterfactual, we compare their likelihood score calculated
by generative language models. By equalizing model behaviors on each sentence
and its counterfactuals, we mitigate bias in the proposed model while
preserving the overall classification performance.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 04:51:47 GMT'}]",2020-10-27,"[['Davani', 'Aida Mostafazadeh', ''], ['Omrani', 'Ali', ''], ['Kennedy', 'Brendan', ''], ['Atari', 'Mohammad', ''], ['Ren', 'Xiang', ''], ['Dehghani', 'Morteza', '']]"
1369107,2010.12777,Hyung Won Chung,"Hyung Won Chung, Dan Garrette, Kiat Chuan Tan, Jason Riesa",Improving Multilingual Models with Language-Clustered Vocabularies,Published in the main conference of EMNLP 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  State-of-the-art multilingual models depend on vocabularies that cover all of
the languages the model will expect to see at inference time, but the standard
methods for generating those vocabularies are not ideal for massively
multilingual applications. In this work, we introduce a novel procedure for
multilingual vocabulary generation that combines the separately trained
vocabularies of several automatically derived language clusters, thus balancing
the trade-off between cross-lingual subword sharing and language-specific
vocabularies. Our experiments show improvements across languages on key
multilingual benchmark tasks TyDi QA (+2.9 F1), XNLI (+2.1\%), and WikiAnn NER
(+2.8 F1) and factor of 8 reduction in out-of-vocabulary rate, all without
increasing the size of the model or data.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 04:49:15 GMT'}]",2020-10-27,"[['Chung', 'Hyung Won', ''], ['Garrette', 'Dan', ''], ['Tan', 'Kiat Chuan', ''], ['Riesa', 'Jason', '']]"
1369106,2010.12776,Yanda Chen,"Yanda Chen (1), Md Arafat Sultan (2), Vittorio Castelli (2) ((1)
  Department of Computer Science, Columbia University, (2) IBM Research AI,
  T.J. Watson Research Center, New York, USA)",Improved Synthetic Training for Reading Comprehension,"11 pages, 2 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automatically generated synthetic training examples have been shown to
improve performance in machine reading comprehension (MRC). Compared to human
annotated gold standard data, synthetic training data has unique properties,
such as high availability at the possible expense of quality. In view of such
differences, in this paper, we explore novel applications of synthetic examples
to MRC. Our proposed pre-training and knowledge distillation strategies show
significant improvements over existing methods. In a particularly surprising
discovery, we observe that synthetic distillation often yields students that
can outperform the teacher model.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 04:41:30 GMT'}]",2020-10-27,"[['Chen', 'Yanda', ''], ['Sultan', 'Md Arafat', ''], ['Castelli', 'Vittorio', '']]"
1253799,2003.03444,Yuval Pinter,Yuval Pinter and Cassandra L. Jacobs and Max Bittker,NYTWIT: A Dataset of Novel Words in the New York Times,COLING 2020,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We present the New York Times Word Innovation Types dataset, or NYTWIT, a
collection of over 2,500 novel English words published in the New York Times
between November 2017 and March 2019, manually annotated for their class of
novelty (such as lexical derivation, dialectal variation, blending, or
compounding). We present baseline results for both uncontextual and contextual
prediction of novelty class, showing that there is room for improvement even
for state-of-the-art NLP systems. We hope this resource will prove useful for
linguists and NLP practitioners by providing a real-world environment of novel
word appearance.
","[{'version': 'v1', 'created': 'Fri, 6 Mar 2020 21:19:44 GMT'}, {'version': 'v2', 'created': 'Tue, 26 May 2020 03:54:35 GMT'}, {'version': 'v3', 'created': 'Fri, 23 Oct 2020 18:54:48 GMT'}]",2020-10-27,"[['Pinter', 'Yuval', ''], ['Jacobs', 'Cassandra L.', ''], ['Bittker', 'Max', '']]"
1369103,2010.12773,Xiang Deng,"Xiang Deng, Ahmed Hassan Awadallah, Christopher Meek, Oleksandr
  Polozov, Huan Sun, Matthew Richardson",Structure-Grounded Pretraining for Text-to-SQL,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Learning to capture text-table alignment is essential for table related tasks
like text-to-SQL. The model needs to correctly recognize natural language
references to columns and values and to ground them in the given database
schema. In this paper, we present a novel weakly supervised Structure-Grounded
pretraining framework (StruG) for text-to-SQL that can effectively learn to
capture text-table alignment based on a parallel text-table corpus. We identify
a set of novel prediction tasks: column grounding, value grounding and
column-value mapping, and train them using weak supervision without requiring
complex SQL annotation. Additionally, to evaluate the model under a more
realistic setting, we create a new evaluation set Spider-Realistic based on
Spider with explicit mentions of column names removed, and adopt two existing
single-database text-to-SQL datasets. StruG significantly outperforms
BERT-LARGE on Spider and the realistic evaluation sets, while bringing
consistent improvement on the large-scale WikiSQL benchmark.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 04:35:35 GMT'}]",2020-10-27,"[['Deng', 'Xiang', ''], ['Awadallah', 'Ahmed Hassan', ''], ['Meek', 'Christopher', ''], ['Polozov', 'Oleksandr', ''], ['Sun', 'Huan', ''], ['Richardson', 'Matthew', '']]"
1369085,2010.12755,Xinyu Zhao,"Xinyu Zhao, Shih-ting Lin, Greg Durrett",Effective Distant Supervision for Temporal Relation Extraction,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A principal barrier to training temporal relation extraction models in new
domains is the lack of varied, high quality examples and the challenge of
collecting more. We present a method of automatically collecting
distantly-supervised examples of temporal relations. We scrape and
automatically label event pairs where the temporal relations are made explicit
in text, then mask out those explicit cues, forcing a model trained on this
data to learn other signals. We demonstrate that a pre-trained Transformer
model is able to transfer from the weakly labeled examples to human-annotated
benchmarks in both zero-shot and few-shot settings, and that the masking scheme
is important in improving generalization.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 03:17:31 GMT'}]",2020-10-27,"[['Zhao', 'Xinyu', ''], ['Lin', 'Shih-ting', ''], ['Durrett', 'Greg', '']]"
1369143,2010.12813,Kevin Lin,"Catherine Chen, Kevin Lin, Dan Klein",Inducing Taxonomic Knowledge from Pretrained Transformers,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present a method for inducing taxonomic trees from pretrained
transformers. Given a set of input terms, we assign a score for the likelihood
that each pair of terms forms a parent-child relation. To produce a tree from
pairwise parent-child edge scores, we treat this as a graph optimization
problem and output the maximum spanning tree. We train the model by finetuning
it on parent-child relations from subtrees of WordNet and test on
non-overlapping subtrees. In addition, we incorporate semi-structured
definitions from the web to further improve performance. On the task of
inducing subtrees of WordNet, the model achieves 66.0 ancestor F_1, a 10.4
point absolute increase over the previous best published result on this task.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 07:16:21 GMT'}]",2020-10-27,"[['Chen', 'Catherine', ''], ['Lin', 'Kevin', ''], ['Klein', 'Dan', '']]"
1369101,2010.12771,Yixin Liu,"Yixin Liu, Graham Neubig, John Wieting",On Learning Text Style Transfer with Direct Rewards,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In most cases, the lack of parallel corpora makes it impossible to directly
train supervised models for text style transfer task. In this paper, we explore
training algorithms that instead optimize reward functions that explicitly
consider different aspects of the style-transferred outputs. In particular, we
leverage semantic similarity metrics originally used for fine-tuning neural
machine translation models to explicitly assess the preservation of content
between system outputs and input texts. We also investigate the potential
weaknesses of the existing automatic metrics and propose efficient strategies
of using these metrics for training. The experimental results show that our
model provides significant gains in both automatic and human evaluation over
strong baselines, indicating the effectiveness of our proposed methods and
training strategies.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 04:30:02 GMT'}]",2020-10-27,"[['Liu', 'Yixin', ''], ['Neubig', 'Graham', ''], ['Wieting', 'John', '']]"
1369087,2010.12757,Kai Sun,"Kai Sun, Seungwhan Moon, Paul Crook, Stephen Roller, Becka Silvert,
  Bing Liu, Zhiguang Wang, Honglei Liu, Eunjoon Cho, Claire Cardie",Adding Chit-Chats to Enhance Task-Oriented Dialogues,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The existing dialogue corpora and models are typically designed under two
disjoint motives: while task-oriented systems focus on achieving functional
goals (e.g., booking hotels), open-domain chatbots aim at making socially
engaging conversations. In this work, we propose to integrate both types of
systems by Adding Chit-Chats to ENhance Task-ORiented dialogues (ACCENTOR),
with the goal of making virtual assistant conversations more engaging and
interactive. Specifically, we propose a flexible approach for generating
diverse chit-chat responses to augment task-oriented dialogues with minimal
annotation effort. We then present our new chit-chat annotations to 23.8K
dialogues from the popular task-oriented datasets (Schema-Guided Dialogue and
MultiWOZ 2.1) and demonstrate their advantage over the originals via human
evaluation. Lastly, we propose three new models for ACCENTOR explicitly trained
to predict user goals and to generate contextually relevant chit-chat
responses. Automatic and human evaluations show that, compared with the
state-of-the-art task-oriented baseline, our models can code-switch between
task and chit-chat to be more engaging, interesting, knowledgeable, and
humanlike, while maintaining competitive task performance.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 03:22:43 GMT'}]",2020-10-27,"[['Sun', 'Kai', ''], ['Moon', 'Seungwhan', ''], ['Crook', 'Paul', ''], ['Roller', 'Stephen', ''], ['Silvert', 'Becka', ''], ['Liu', 'Bing', ''], ['Wang', 'Zhiguang', ''], ['Liu', 'Honglei', ''], ['Cho', 'Eunjoon', ''], ['Cardie', 'Claire', '']]"
1369088,2010.12758,Zhiyu Chen,"Zhiyu Chen, Honglei Liu, Hu Xu, Seungwhan Moon, Hao Zhou, Bing Liu","NUANCED: Natural Utterance Annotation for Nuanced Conversation with
  Estimated Distributions",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Existing conversational systems are mostly agent-centric, which assumes the
user utterances would closely follow the system ontology (for NLU or dialogue
state tracking). However, in real-world scenarios, it is highly desirable that
the users can speak freely in their own way. It is extremely hard, if not
impossible, for the users to adapt to the unknown system ontology. In this
work, we attempt to build a user-centric dialogue system. As there is no clean
mapping for a user's free form utterance to an ontology, we first model the
user preferences as estimated distributions over the system ontology and map
the users' utterances to such distributions. Learning such a mapping poses new
challenges on reasoning over existing knowledge, ranging from factoid
knowledge, commonsense knowledge to the users' own situations. To this end, we
build a new dataset named NUANCED that focuses on such realistic settings for
conversational recommendation. Collected via dialogue simulation and
paraphrasing, NUANCED contains 5.1k dialogues, 26k turns of high-quality user
responses. We conduct experiments, showing both the usefulness and challenges
of our problem setting. We believe NUANCED can serve as a valuable resource to
push existing research from the agent-centric system to the user-centric
system. The code and data will be made publicly available.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 03:23:14 GMT'}]",2020-10-27,"[['Chen', 'Zhiyu', ''], ['Liu', 'Honglei', ''], ['Xu', 'Hu', ''], ['Moon', 'Seungwhan', ''], ['Zhou', 'Hao', ''], ['Liu', 'Bing', '']]"
1369092,2010.12762,Sarah Wiegreffe,"Sarah Wiegreffe, Ana Marasovic, Noah A. Smith",Measuring Association Between Labels and Free-Text Rationales,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Interpretable NLP has taking increasing interest in ensuring that
explanations are faithful to the model's decision-making process. This property
is crucial for machine learning researchers and practitioners using
explanations to better understand models. While prior work focuses primarily on
extractive rationales (a subset of the input elements), we investigate their
less-studied counterpart: free-text natural language rationales. We demonstrate
that existing models for faithful interpretability do not extend cleanly to
tasks where free-text rationales are needed. We turn to models that jointly
predict and rationalize, a common class of models for free-text rationalization
whose faithfulness is not yet established. We propose measurements of
label-rationale association, a necessary property of faithful rationales, for
these models. Using our measurements, we show that a state-of-the-art joint
model based on T5 has strengths and weaknesses for producing faithful
rationales.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 03:40:56 GMT'}]",2020-10-27,"[['Wiegreffe', 'Sarah', ''], ['Marasovic', 'Ana', ''], ['Smith', 'Noah A.', '']]"
1369094,2010.12764,Rodolfo Corona,"Rodolfo Corona, Daniel Fried, Coline Devin, Dan Klein, Trevor Darrell",Modularity Improves Out-of-Domain Instruction Following,,,,,cs.CL cs.AI cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a modular architecture for following natural language instructions
that describe sequences of diverse subgoals, such as navigating to landmarks or
picking up objects. Standard, non-modular, architectures used in instruction
following do not exploit subgoal compositionality and often struggle on
out-of-distribution tasks and environments. In our approach, subgoal modules
each carry out natural language instructions for a specific subgoal type. A
sequence of modules to execute is chosen by learning to segment the
instructions and predicting a subgoal type for each segment. When compared to
standard sequence-to-sequence approaches on ALFRED, a challenging instruction
following benchmark, we find that modularization improves generalization to
environments unseen in training and to novel tasks.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 03:48:45 GMT'}]",2020-10-27,"[['Corona', 'Rodolfo', ''], ['Fried', 'Daniel', ''], ['Devin', 'Coline', ''], ['Klein', 'Dan', ''], ['Darrell', 'Trevor', '']]"
1369150,2010.12820,Emily Sheng,"Emily Sheng, Kai-Wei Chang, Premkumar Natarajan, Nanyun Peng","""Nice Try, Kiddo"": Ad Hominems in Dialogue Systems",14 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Ad hominem attacks are those that attack some feature of a person's character
instead of the position the person is maintaining. As a form of toxic and
abusive language, ad hominems contain harmful language that could further
amplify the skew of power inequality for marginalized populations. Since
dialogue systems are designed to respond directly to user input, it is
important to study ad hominems in these system responses. In this work, we
propose categories of ad hominems that allow us to analyze human and dialogue
system responses to Twitter posts. We specifically compare responses to Twitter
posts about marginalized communities (#BlackLivesMatter, #MeToo) and other
topics (#Vegan, #WFH). Furthermore, we propose a constrained decoding technique
that uses salient $n$-gram similarity to apply soft constraints to top-$k$
sampling and can decrease the amount of ad hominems generated by dialogue
systems. Our results indicate that 1) responses composed by both humans and
DialoGPT contain more ad hominems for discussions around marginalized
communities versus other topics, 2) different amounts of ad hominems in the
training data can influence the likelihood of the model generating ad hominems,
and 3) we can thus carefully choose training data and use constrained decoding
techniques to decrease the amount of ad hominems generated by dialogue systems.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 07:37:49 GMT'}]",2020-10-27,"[['Sheng', 'Emily', ''], ['Chang', 'Kai-Wei', ''], ['Natarajan', 'Premkumar', ''], ['Peng', 'Nanyun', '']]"
1369211,2010.12881,Arturo Oncevay,Arturo Oncevay and Kervy Rivas Rojas,Revisiting Neural Language Modelling with Syllables,"5 pages (main paper), 4 pages of Appendix",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language modelling is regularly analysed at word, subword or character units,
but syllables are seldom used. Syllables provide shorter sequences than
characters, they can be extracted with rules, and their segmentation typically
requires less specialised effort than identifying morphemes. We reconsider
syllables for an open-vocabulary generation task in 20 languages. We use
rule-based syllabification methods for five languages and address the rest with
a hyphenation tool, which behaviour as syllable proxy is validated. With a
comparable perplexity, we show that syllables outperform characters, annotated
morphemes and unsupervised subwords. Finally, we also study the overlapping of
syllables concerning other subword pieces and discuss some limitations and
opportunities.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 11:44:41 GMT'}]",2020-10-27,"[['Oncevay', 'Arturo', ''], ['Rojas', 'Kervy Rivas', '']]"
1369155,2010.12825,Rochelle Choenni,"Rochelle Choenni, Ekaterina Shutova","Cross-neutralising: Probing for joint encoding of linguistic information
  in multilingual models",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Multilingual sentence encoders are widely used to transfer NLP models across
languages. The success of this transfer is, however, dependent on the model's
ability to encode the patterns of cross-lingual similarity and variation. Yet,
little is known as to how these models are able to do this. We propose a simple
method to study how relationships between languages are encoded in two
state-of-the-art multilingual models (i.e. M-BERT and XLM-R). The results
provide insight into their information sharing mechanisms and suggest that
linguistic properties are encoded jointly across typologically-similar
languages in these models.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 07:55:32 GMT'}]",2020-10-27,"[['Choenni', 'Rochelle', ''], ['Shutova', 'Ekaterina', '']]"
1369161,2010.12831,Liunian Harold Li,"Liunian Harold Li, Haoxuan You, Zhecan Wang, Alireza Zareian, Shih-Fu
  Chang, Kai-Wei Chang","Weakly-supervised VisualBERT: Pre-training without Parallel Images and
  Captions",,,,,cs.CL cs.CV cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pre-trained contextual vision-and-language (V&L) models have brought
impressive performance improvement on various benchmarks. However, the paired
text-image data required for pre-training are hard to collect and scale up. We
investigate if a strong V&L representation model can be learned without
text-image pairs. We propose Weakly-supervised VisualBERT with the key idea of
conducting ""mask-and-predict"" pre-training on language-only and image-only
corpora. Additionally, we introduce the object tags detected by an object
recognition model as anchor points to bridge two modalities. Evaluation on four
V&L benchmarks shows that Weakly-supervised VisualBERT achieves similar
performance with a model pre-trained with paired data. Besides, pre-training on
more image-only data further improves a model that already has access to
aligned data, suggesting the possibility of utilizing billions of raw images
available to enhance V&L models.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 08:17:54 GMT'}]",2020-10-27,"[['Li', 'Liunian Harold', ''], ['You', 'Haoxuan', ''], ['Wang', 'Zhecan', ''], ['Zareian', 'Alireza', ''], ['Chang', 'Shih-Fu', ''], ['Chang', 'Kai-Wei', '']]"
1369164,2010.12834,Saadia Gabriel,"Saadia Gabriel, Asli Celikyilmaz, Rahul Jha, Yejin Choi, Jianfeng Gao",Go Figure! A Meta Evaluation of Factuality in Summarization,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Text generation models can generate factually inconsistent text containing
distorted or fabricated facts about the source text. Recent work has focused on
building evaluation models to verify the factual correctness of semantically
constrained text generation tasks such as document summarization. While the
field of factuality evaluation is growing fast, we don't have well-defined
criteria for measuring the effectiveness, generalizability, reliability, or
sensitivity of the factuality metrics. Focusing on these aspects, in this
paper, we introduce a meta-evaluation framework for evaluating factual
consistency metrics. We introduce five necessary, common-sense conditions for
effective factuality metrics and experiment with nine recent factuality metrics
using synthetic and human-labeled factuality data from short news, long news
and dialogue summarization domains. Our framework enables assessing the
efficiency of any new factual consistency metric on a variety of dimensions
over multiple summarization domains and can be easily extended with new
meta-evaluation criteria. We also present our conclusions towards standardizing
the factuality evaluation metrics.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 08:30:20 GMT'}]",2020-10-27,"[['Gabriel', 'Saadia', ''], ['Celikyilmaz', 'Asli', ''], ['Jha', 'Rahul', ''], ['Choi', 'Yejin', ''], ['Gao', 'Jianfeng', '']]"
1369166,2010.12836,Alexander Fabbri,"Alexander R. Fabbri, Simeng Han, Haoyuan Li, Haoran Li, Marjan
  Ghazvininejad, Shafiq Joty, Dragomir Radev, Yashar Mehdad","Improving Zero and Few-Shot Abstractive Summarization with Intermediate
  Fine-tuning and Data Augmentation",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Models pretrained with self-supervised objectives on large text corpora
achieve state-of-the-art performance on text summarization tasks. However,
these models are typically fine-tuned on hundreds of thousands of data points,
an infeasible requirement when applying summarization to new, niche domains. In
this work, we introduce a general method, called WikiTransfer, for fine-tuning
pretrained models for summarization in an unsupervised, dataset-specific manner
which makes use of characteristics of the target dataset such as the length and
abstractiveness of the desired summaries. We achieve state-of-the-art,
zero-shot abstractive summarization performance on the CNN-DailyMail dataset
and demonstrate the effectiveness of our approach on three additional, diverse
datasets. The models fine-tuned in this unsupervised manner are more robust to
noisy data and also achieve better few-shot performance using 10 and 100
training examples. We perform ablation studies on the effect of the components
of our unsupervised fine-tuning data and analyze the performance of these
models in few-shot scenarios along with data augmentation techniques using both
automatic and human evaluation.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 08:36:49 GMT'}]",2020-10-27,"[['Fabbri', 'Alexander R.', ''], ['Han', 'Simeng', ''], ['Li', 'Haoyuan', ''], ['Li', 'Haoran', ''], ['Ghazvininejad', 'Marjan', ''], ['Joty', 'Shafiq', ''], ['Radev', 'Dragomir', ''], ['Mehdad', 'Yashar', '']]"
1369083,2010.12753,Ben Zhou,"Ben Zhou and Kyle Richardson and Qiang Ning and Tushar Khot and Ashish
  Sabharwal and Dan Roth",Temporal Reasoning on Implicit Events from Distant Supervision,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Existing works on temporal reasoning among events described in text focus on
modeling relationships between explicitly mentioned events and do not handle
event end time effectively. However, human readers can infer from natural
language text many implicit events that help them better understand the
situation and, consequently, better reason about time. This work proposes a new
crowd-sourced dataset, TRACIE, which evaluates systems' understanding of
implicit events - events that are not mentioned explicitly in the text but can
be inferred from it. This is done via textual entailment instances querying
both start and end times of events. We show that TRACIE is challenging for
state-of-the-art language models. Our proposed model, SymTime, exploits distant
supervision signals from the text itself and reasons over events' start time
and duration to infer events' end time points. We show that our approach
improves over baseline language models, gaining 5% on the i.i.d. split and 9%
on an out-of-distribution test split. Our approach is also general to other
annotation schemes, gaining 2%-8% on MATRES, an extrinsic temporal relation
benchmark.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 03:12:27 GMT'}]",2020-10-27,"[['Zhou', 'Ben', ''], ['Richardson', 'Kyle', ''], ['Ning', 'Qiang', ''], ['Khot', 'Tushar', ''], ['Sabharwal', 'Ashish', ''], ['Roth', 'Dan', '']]"
1369174,2010.12844,Sahisnu Mazumder,"Sahisnu Mazumder, Oriana Riva",FLIN: A Flexible Natural Language Interface for Web Navigation,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  AI assistants have started carrying out tasks on a user's behalf by
interacting directly with the web. However, training an interface that maps
natural language (NL) commands to web actions is challenging for existing
semantic parsing approaches due to the variable and unknown set of actions that
characterize websites. We propose FLIN, a natural language interface for web
navigation that maps NL commands to concept-level actions rather than low-level
UI interactions, thus being able to flexibly adapt to different websites and
handle their transient nature. We frame this as a ranking problem where, given
a user command and a webpage, FLIN learns to score the most appropriate
navigation instruction (involving action and parameter values). To train and
evaluate FLIN, we collect a dataset using nine popular websites from three
different domains. Quantitative results show that FLIN is capable of adapting
to new websites in a given domain.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 09:11:26 GMT'}]",2020-10-27,"[['Mazumder', 'Sahisnu', ''], ['Riva', 'Oriana', '']]"
1369180,2010.12850,Semih Yavuz,"Shiyang Li, Semih Yavuz, Kazuma Hashimoto, Jia Li, Tong Niu, Nazneen
  Rajani, Xifeng Yan, Yingbo Zhou and Caiming Xiong","CoCo: Controllable Counterfactuals for Evaluating Dialogue State
  Trackers",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Dialogue state trackers have made significant progress on benchmark datasets,
but their generalization capability to novel and realistic scenarios beyond the
held-out conversations is less understood. We propose controllable
counterfactuals (CoCo) to bridge this gap and evaluate dialogue state tracking
(DST) models on novel scenarios, i.e., would the system successfully tackle the
request if the user responded differently but still consistently with the
dialogue flow? CoCo leverages turn-level belief states as counterfactual
conditionals to produce novel conversation scenarios in two steps: (i)
counterfactual goal generation at turn-level by dropping and adding slots
followed by replacing slot values, (ii) counterfactual conversation generation
that is conditioned on (i) and consistent with the dialogue flow. Evaluating
state-of-the-art DST models on MultiWOZ dataset with CoCo-generated
counterfactuals results in a significant performance drop of up to 30.8% (from
49.4% to 18.6%) in absolute joint goal accuracy. In comparison, widely used
techniques like paraphrasing only affect the accuracy by at most 2%. Human
evaluations show that CoCo-generated conversations perfectly reflect the
underlying user goal with more than 95% accuracy and are as human-like as the
original conversations, further strengthening its reliability and promise to be
adopted as part of the robustness evaluation of DST models.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 09:39:35 GMT'}]",2020-10-27,"[['Li', 'Shiyang', ''], ['Yavuz', 'Semih', ''], ['Hashimoto', 'Kazuma', ''], ['Li', 'Jia', ''], ['Niu', 'Tong', ''], ['Rajani', 'Nazneen', ''], ['Yan', 'Xifeng', ''], ['Zhou', 'Yingbo', ''], ['Xiong', 'Caiming', '']]"
1369184,2010.12854,Tushar Khot,Shih-Ting Lin and Ashish Sabharwal and Tushar Khot,ReadOnce Transformers: Reusable Representations of Text for Transformers,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While large-scale language models are extremely effective when directly
fine-tuned on many end-tasks, such models learn to extract information and
solve the task simultaneously from end-task supervision. This is wasteful, as
the general problem of gathering information from a document is mostly
task-independent and need not be re-learned from scratch each time. Moreover,
once the information has been captured in a computable representation, it can
now be re-used across examples, leading to faster training and evaluation of
models. We present a transformer-based approach, ReadOnce Transformers, that is
trained to build such information-capturing representations of text. Our model
compresses the document into a variable-length task-independent representation
that can now be re-used in different examples and tasks, thereby requiring a
document to only be read once. Additionally, we extend standard text-to-text
models to consume our ReadOnce Representations along with text to solve
multiple downstream tasks. We show our task-independent representations can be
used for multi-hop QA, abstractive QA, and summarization. We observe 2x-5x
speedups compared to standard text-to-text models, while also being able to
handle long documents that would normally exceed the length limit of current
models.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 09:53:16 GMT'}]",2020-10-27,"[['Lin', 'Shih-Ting', ''], ['Sabharwal', 'Ashish', ''], ['Khot', 'Tushar', '']]"
1369188,2010.12858,Benjamin Muller,"Benjamin Muller and Antonis Anastasopoulos and Beno\^it Sagot and
  Djam\'e Seddah","When Being Unseen from mBERT is just the Beginning: Handling New
  Languages With Multilingual Language Models",,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Transfer learning based on pretraining language models on a large amount of
raw data has become a new norm to reach state-of-the-art performance in NLP.
Still, it remains unclear how this approach should be applied for unseen
languages that are not covered by any available large-scale multilingual
language model and for which only a small amount of raw data is generally
available. In this work, by comparing multilingual and monolingual models, we
show that such models behave in multiple ways on unseen languages. Some
languages greatly benefit from transfer learning and behave similarly to
closely related high resource languages whereas others apparently do not.
Focusing on the latter, we show that this failure to transfer is largely
related to the impact of the script used to write such languages.
Transliterating those languages improves very significantly the ability of
large-scale multilingual language models on downstream tasks.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 10:15:03 GMT'}]",2020-10-27,"[['Muller', 'Benjamin', ''], ['Anastasopoulos', 'Antonis', ''], ['Sagot', 'Benoît', ''], ['Seddah', 'Djamé', '']]"
1369159,2010.12829,Juan Pino,"Chau Tran, Changhan Wang, Yuqing Tang, Yun Tang, Juan Pino, Xian Li","Cross-Modal Transfer Learning for Multilingual Speech-to-Text
  Translation",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose an effective approach to utilize pretrained speech and text models
to perform speech-to-text translation (ST). Our recipe to achieve cross-modal
and cross-lingual transfer learning (XMTL) is simple and generalizable: using
an adaptor module to bridge the modules pretrained in different modalities, and
an efficient finetuning step which leverages the knowledge from pretrained
modules yet making it work on a drastically different downstream task. With
this approach, we built a multilingual speech-to-text translation model with
pretrained audio encoder (wav2vec) and multilingual text decoder (mBART), which
achieves new state-of-the-art on CoVoST 2 ST benchmark [1] for English into 15
languages as well as 6 Romance languages into English with on average +2.8 BLEU
and +3.9 BLEU, respectively. On low-resource languages (with less than 10 hours
training data), our approach significantly improves the quality of
speech-to-text translation with +9.0 BLEU on Portuguese-English and +5.2 BLEU
on Dutch-English.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 08:15:08 GMT'}]",2020-10-27,"[['Tran', 'Chau', ''], ['Wang', 'Changhan', ''], ['Tang', 'Yuqing', ''], ['Tang', 'Yun', ''], ['Pino', 'Juan', ''], ['Li', 'Xian', '']]"
1369158,2010.12828,Haoyu Zhang,"Haoyu Zhang, Dingkun Long, Guangwei Xu, Pengjun Xie, Fei Huang, Ji
  Wang","Keyphrase Extraction with Dynamic Graph Convolutional Networks and
  Diversified Inference",11 pages,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Keyphrase extraction (KE) aims to summarize a set of phrases that accurately
express a concept or a topic covered in a given document. Recently,
Sequence-to-Sequence (Seq2Seq) based generative framework is widely used in KE
task, and it has obtained competitive performance on various benchmarks. The
main challenges of Seq2Seq methods lie in acquiring informative latent document
representation and better modeling the compositionality of the target
keyphrases set, which will directly affect the quality of generated keyphrases.
In this paper, we propose to adopt the Dynamic Graph Convolutional Networks
(DGCN) to solve the above two problems simultaneously. Concretely, we explore
to integrate dependency trees with GCN for latent representation learning.
Moreover, the graph structure in our model is dynamically modified during the
learning process according to the generated keyphrases. To this end, our
approach is able to explicitly learn the relations within the keyphrases
collection and guarantee the information interchange between encoder and
decoder in both directions. Extensive experiments on various KE benchmark
datasets demonstrate the effectiveness of our approach.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 08:11:23 GMT'}]",2020-10-27,"[['Zhang', 'Haoyu', ''], ['Long', 'Dingkun', ''], ['Xu', 'Guangwei', ''], ['Xie', 'Pengjun', ''], ['Huang', 'Fei', ''], ['Wang', 'Ji', '']]"
1369151,2010.12821,Hyung Won Chung,"Hyung Won Chung, Thibault F\'evry, Henry Tsai, Melvin Johnson,
  Sebastian Ruder",Rethinking embedding coupling in pre-trained language models,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We re-evaluate the standard practice of sharing weights between input and
output embeddings in state-of-the-art pre-trained language models. We show that
decoupled embeddings provide increased modeling flexibility, allowing us to
significantly improve the efficiency of parameter allocation in the input
embedding of multilingual models. By reallocating the input embedding
parameters in the Transformer layers, we achieve dramatically better
performance on standard natural language understanding tasks with the same
number of parameters during fine-tuning. We also show that allocating
additional capacity to the output embedding provides benefits to the model that
persist through the fine-tuning stage even though the output embedding is
discarded after pre-training. Our analysis shows that larger output embeddings
prevent the model's last layers from overspecializing to the pre-training task
and encourage Transformer representations to be more general and more
transferable to other tasks and languages. Harnessing these findings, we are
able to train models that achieve strong performance on the XTREME benchmark
without increasing the number of parameters at the fine-tuning stage.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 07:43:00 GMT'}]",2020-10-27,"[['Chung', 'Hyung Won', ''], ['Févry', 'Thibault', ''], ['Tsai', 'Henry', ''], ['Johnson', 'Melvin', ''], ['Ruder', 'Sebastian', '']]"
1369198,2010.12868,Yongchang Hao,"Yongchang Hao, Shilin He, Wenxiang Jiao, Zhaopeng Tu, Michael Lyu and
  Xing Wang","Multi-Task Learning with Shared Encoder for Non-Autoregressive Machine
  Translation",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Non-Autoregressive machine Translation (NAT) models have demonstrated
significant inference speedup but suffer from inferior translation accuracy.
The common practice to tackle the problem is transferring the Autoregressive
machine Translation (AT) knowledge to NAT models, e.g., with knowledge
distillation. In this work, we hypothesize and empirically verify that AT and
NAT encoders capture different linguistic properties and representations of
source sentences. Therefore, we propose to adopt the multi-task learning to
transfer the AT knowledge to NAT models through the encoder sharing.
Specifically, we take the AT model as an auxiliary task to enhance NAT model
performance. Experimental results on WMT14 English->German and WMT16
English->Romanian datasets show that the proposed multi-task NAT achieves
significant improvements over the baseline NAT models. In addition,
experimental results demonstrate that our multi-task NAT is complementary to
the standard knowledge transfer method, knowledge distillation. Code is
publicly available at https://github.com/yongchanghao/multi-task-nat
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 11:00:58 GMT'}]",2020-10-27,"[['Hao', 'Yongchang', ''], ['He', 'Shilin', ''], ['Jiao', 'Wenxiang', ''], ['Tu', 'Zhaopeng', ''], ['Lyu', 'Michael', ''], ['Wang', 'Xing', '']]"
1369202,2010.12872,Aaron Chan,"Mrigank Raman, Siddhant Agarwal, Peifeng Wang, Aaron Chan, Hansen
  Wang, Sungchul Kim, Ryan Rossi, Handong Zhao, Nedim Lipka, Xiang Ren","Learning to Deceive Knowledge Graph Augmented Models via Targeted
  Perturbation","13 pages, 9 figures",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Symbolic knowledge (e.g., entities, relations, and facts in a knowledge
graph) has become an increasingly popular component of neural-symbolic models
applied to machine learning tasks, such as question answering and recommender
systems. Besides improving downstream performance, these symbolic structures
(and their associated attention weights) are often used to help explain the
model's predictions and provide ""insights"" to practitioners. In this paper, we
question the faithfulness of such symbolic explanations. We demonstrate that,
through a learned strategy (or even simple heuristics), one can produce
deceptively perturbed symbolic structures which maintain the downstream
performance of the original structure while significantly deviating from the
original semantics. In particular, we train a reinforcement learning policy to
manipulate relation types or edge connections in a knowledge graph, such that
the resulting downstream performance is maximally preserved. Across multiple
models and tasks, our approach drastically alters knowledge graphs with little
to no drop in performance. These results raise doubts about the faithfulness of
explanations provided by learned symbolic structures and the reliability of
current neural-symbolic models in leveraging symbolic knowledge.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 11:04:45 GMT'}]",2020-10-27,"[['Raman', 'Mrigank', ''], ['Agarwal', 'Siddhant', ''], ['Wang', 'Peifeng', ''], ['Chan', 'Aaron', ''], ['Wang', 'Hansen', ''], ['Kim', 'Sungchul', ''], ['Rossi', 'Ryan', ''], ['Zhao', 'Handong', ''], ['Lipka', 'Nedim', ''], ['Ren', 'Xiang', '']]"
1369203,2010.12873,Jun Yan,"Jun Yan, Mrigank Raman, Tianyu Zhang, Ryan Rossi, Handong Zhao,
  Sungchul Kim, Nedim Lipka, Xiang Ren",Learning Contextualized Knowledge Structures for Commonsense Reasoning,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, neural-symbolic architectures have achieved success on commonsense
reasoning through effectively encoding relational structures retrieved from
external knowledge graphs (KGs) and obtained state-of-the-art results in tasks
such as (commonsense) question answering and natural language inference.
However, these methods rely on quality and contextualized knowledge structures
(i.e., fact triples) that are retrieved at the pre-processing stage but
overlook challenges caused by incompleteness of a KG, limited expressiveness of
its relations, and retrieved facts irrelevant to the reasoning context. In this
paper, we present a novel neural-symbolic model, named Hybrid Graph Network
(HGN), which jointly generates feature representations for new triples (as a
complement to existing edges in the KG), determines the relevance of the
triples to the reasoning context, and learns graph module parameters for
encoding the relational information. Our model learns a compact graph structure
(comprising both extracted and generated edges) through filtering edges that
are unhelpful to the reasoning process. We show marked improvement on three
commonsense reasoning benchmarks and demonstrate the superiority of the learned
graph structures with user studies.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 11:09:16 GMT'}]",2020-10-27,"[['Yan', 'Jun', ''], ['Raman', 'Mrigank', ''], ['Zhang', 'Tianyu', ''], ['Rossi', 'Ryan', ''], ['Zhao', 'Handong', ''], ['Kim', 'Sungchul', ''], ['Lipka', 'Nedim', ''], ['Ren', 'Xiang', '']]"
1369212,2010.12882,Mingyang Chen,"Mingyang Chen, Wen Zhang, Zonggang Yuan, Yantao Jia, Huajun Chen",FedE: Embedding Knowledge Graphs in Federated Setting,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Knowledge graphs (KGs) consisting of triples are always incomplete, so it's
important to do Knowledge Graph Completion (KGC) by predicting missing triples.
Multi-Source KG is a common situation in real KG applications which can be
viewed as a set of related individual KGs where different KGs contains
relations of different aspects of entities. It's intuitive that, for each
individual KG, its completion could be greatly contributed by the triples
defined and labeled in other ones. However, because of the data privacy and
sensitivity, a set of relevant knowledge graphs cannot complement each other's
KGC by just collecting data from different knowledge graphs together.
Therefore, in this paper, we introduce federated setting to keep their privacy
without triple transferring between KGs and apply it in embedding knowledge
graph, a typical method which have proven effective for KGC in the past decade.
We propose a Federated Knowledge Graph Embedding framework FedE, focusing on
learning knowledge graph embeddings by aggregating locally-computed updates.
Finally, we conduct extensive experiments on datasets derived from KGE
benchmark datasets and results show the effectiveness of our proposed FedE.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 11:52:05 GMT'}]",2020-10-27,"[['Chen', 'Mingyang', ''], ['Zhang', 'Wen', ''], ['Yuan', 'Zonggang', ''], ['Jia', 'Yantao', ''], ['Chen', 'Huajun', '']]"
1369214,2010.12884,Ximing Lu,"Ximing Lu, Peter West, Rowan Zellers, Ronan Le Bras, Chandra
  Bhagavatula, Yejin Choi","NeuroLogic Decoding: (Un)supervised Neural Text Generation with
  Predicate Logic Constraints",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Conditional text generation often requires lexical constraints, i.e., which
words should or shouldn't be included in the output text. While the dominant
recipe for conditional text generation has been large-scale pretrained language
models that are finetuned on the task-specific training data, such models do
not learn to follow the underlying constraints reliably, even when supervised
with large amounts of task-specific examples.
  We propose NeuroLogic Decoding, a simple yet effective algorithm that enables
neural language models -- supervised or not -- to generate fluent text while
satisfying complex lexical constraints. Our approach is powerful yet efficient.
It handles any set of lexical constraints that is expressible under predicate
logic, while its asymptotic runtime is equivalent to conventional beam search.
  Empirical results on four benchmarks show that NeuroLogic Decoding
outperforms previous approaches, including algorithms that handle a subset of
our constraints. Moreover, we find that unsupervised models with NeuroLogic
Decoding often outperform supervised models with conventional decoding, even
when the latter is based on considerably larger networks. Our results suggest
the limit of large-scale neural networks for fine-grained controllable
generation and the promise of inference-time algorithms.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 11:55:22 GMT'}]",2020-10-27,"[['Lu', 'Ximing', ''], ['West', 'Peter', ''], ['Zellers', 'Rowan', ''], ['Bras', 'Ronan Le', ''], ['Bhagavatula', 'Chandra', ''], ['Choi', 'Yejin', '']]"
1369157,2010.12827,Amane Sugiyama,Amane Sugiyama and Naoki Yoshinaga,"Context-aware Decoder for Neural Machine Translation using a Target-side
  Document-Level Language Model",Under Review,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Although many context-aware neural machine translation models have been
proposed to incorporate contexts in translation, most of those models are
trained end-to-end on parallel documents aligned in sentence-level. Because
only a few domains (and language pairs) have such document-level parallel data,
we cannot perform accurate context-aware translation in most domains. We
therefore present a simple method to turn a sentence-level translation model
into a context-aware model by incorporating a document-level language model
into the decoder. Our context-aware decoder is built upon only a sentence-level
parallel corpora and monolingual corpora; thus no document-level parallel data
is needed. In a theoretical viewpoint, the core part of this work is the novel
representation of contextual information using point-wise mutual information
between context and the current sentence. We show the effectiveness of our
approach in three language pairs, English to French, English to Russian, and
Japanese to English, by evaluation in \textsc{bleu} and contrastive tests for
context-aware translation.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 08:06:18 GMT'}]",2020-10-27,"[['Sugiyama', 'Amane', ''], ['Yoshinaga', 'Naoki', '']]"
1369215,2010.12885,Tong Niu,"Tong Niu, Semih Yavuz, Yingbo Zhou, Huan Wang, Nitish Shirish Keskar,
  Caiming Xiong",Unsupervised Paraphrase Generation via Dynamic Blocking,10 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose Dynamic Blocking, a decoding algorithm which enables large-scale
pretrained autoregressive models (such as BART, T5, GPT-2 and XLNet) to
generate high-quality paraphrases in an unsupervised setting. In order to
obtain an alternative surface form, whenever the language model emits a token
that is present in the source sequence, we prevent the model from generating
the subsequent source token for the next time step. We show that our approach
achieves state-of-the-art results on benchmark datasets when compared to
previous unsupervised approaches, and is even comparable with strong
supervised, in-domain models. We also propose a new automatic metric based on
self-BLEU and BERTscore which not only discourages the model from copying the
input through, but also evaluates text similarity based on distributed
representations, hence avoiding reliance on exact keyword matching. In
addition, we demonstrate that our model generalizes across languages without
any additional training.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 11:55:28 GMT'}]",2020-10-27,"[['Niu', 'Tong', ''], ['Yavuz', 'Semih', ''], ['Zhou', 'Yingbo', ''], ['Wang', 'Huan', ''], ['Keskar', 'Nitish Shirish', ''], ['Xiong', 'Caiming', '']]"
1369242,2010.12912,Camilo Thorne,Camilo Thorne and Saber Akhondi,Word Embeddings for Chemical Patent Natural Language Processing,"Extended version of an extended abstract presented (and reviewed) at
  the Latinx Workshop at ICML 2020",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  We evaluate chemical patent word embeddings against known biomedical
embeddings and show that they outperform the latter extrinsically and
intrinsically. We also show that using contextualized embeddings can induce
predictive models of reasonable performance for this domain over a relatively
small gold standard.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 15:03:20 GMT'}]",2020-10-27,"[['Thorne', 'Camilo', ''], ['Akhondi', 'Saber', '']]"
1369249,2010.12919,Reid Pryzant,"Reid Pryzant, Dallas Card, Dan Jurafsky, Victor Veitch, Dhanya Sridhar",Causal Effects of Linguistic Properties,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We consider the problem of estimating the causal effects of linguistic
properties on downstream outcomes. For example, does writing a complaint
politely lead to a faster response time? How much will a positive product
review increase sales? This paper focuses on two challenges related to the
problem. First, we formalize the causal quantity of interest as the effect of a
writer's intent, and establish the assumptions necessary to identify this from
observational data. Second, in practice we only have access to noisy proxies
for these linguistic properties---e.g., predictions from classifiers and
lexicons. We propose an estimator for this setting and prove that its bias is
bounded when we perform an adjustment for the text. The method leverages (1) a
pre-trained language model (BERT) to adjust for the text, and (2) distant
supervision to improve the quality of noisy proxies. We show that our algorithm
produces better causal estimates than related methods on two datasets:
predicting the effect of music review sentiment on sales, and complaint
politeness on response time.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 15:43:37 GMT'}]",2020-10-27,"[['Pryzant', 'Reid', ''], ['Card', 'Dallas', ''], ['Jurafsky', 'Dan', ''], ['Veitch', 'Victor', ''], ['Sridhar', 'Dhanya', '']]"
1369255,2010.12925,Camilo Thorne,Dhruba Pujary and Camilo Thorne and Wilker Aziz,Disease Normalization with Graph Embeddings,"This is a pre-print of a paper to appear in the proceedings of the
  IntelliSys 2020 conference",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  The detection and normalization of diseases in biomedical texts are key
biomedical natural language processing tasks. Disease names need not only be
identified, but also normalized or linked to clinical taxonomies describing
diseases such as MeSH. In this paper we describe deep learning methods that
tackle both tasks. We train and test our methods on the known NCBI disease
benchmark corpus. We propose to represent disease names by leveraging MeSH's
graphical structure together with the lexical information available in the
taxonomy using graph embeddings. We also show that combining neural named
entity recognition models with our graph-based entity linking methods via
multitask learning leads to improved disease recognition in the NCBI corpus.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 16:25:05 GMT'}]",2020-10-27,"[['Pujary', 'Dhruba', ''], ['Thorne', 'Camilo', ''], ['Aziz', 'Wilker', '']]"
1369156,2010.12826,Felix Faltings,"Felix Faltings and Michel Galley and Gerold Hintz and Chris Brockett
  and Chris Quirk and Jianfeng Gao and Bill Dolan",Text Editing by Command,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A prevailing paradigm in neural text generation is one-shot generation, where
text is produced in a single step. The one-shot setting is inadequate, however,
when the constraints the user wishes to impose on the generated text are
dynamic, especially when authoring longer documents. We address this limitation
with an interactive text generation setting in which the user interacts with
the system by issuing commands to edit existing text. To this end, we propose a
novel text editing task, and introduce WikiDocEdits, a dataset of
single-sentence edits crawled from Wikipedia. We show that our Interactive
Editor, a transformer-based model trained on this dataset, outperforms
baselines and obtains positive results in both automatic and human evaluations.
We present empirical and qualitative analyses of this model's performance.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 08:00:30 GMT'}]",2020-10-27,"[['Faltings', 'Felix', ''], ['Galley', 'Michel', ''], ['Hintz', 'Gerold', ''], ['Brockett', 'Chris', ''], ['Quirk', 'Chris', ''], ['Gao', 'Jianfeng', ''], ['Dolan', 'Bill', '']]"
1369201,2010.12871,Zein Shaheen,"Zein Shaheen, Gerhard Wohlgenannt, Erwin Filtz",Large Scale Legal Text Classification Using Transformer Models,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large multi-label text classification is a challenging Natural Language
Processing (NLP) problem that is concerned with text classification for
datasets with thousands of labels. We tackle this problem in the legal domain,
where datasets, such as JRC-Acquis and EURLEX57K labeled with the EuroVoc
vocabulary were created within the legal information systems of the European
Union. The EuroVoc taxonomy includes around 7000 concepts. In this work, we
study the performance of various recent transformer-based models in combination
with strategies such as generative pretraining, gradual unfreezing and
discriminative learning rates in order to reach competitive classification
performance, and present new state-of-the-art results of 0.661 (F1) for
JRC-Acquis and 0.754 for EURLEX57K. Furthermore, we quantify the impact of
individual steps, such as language model fine-tuning or gradual unfreezing in
an ablation study, and provide reference dataset splits created with an
iterative stratification algorithm.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 11:03:01 GMT'}]",2020-10-27,"[['Shaheen', 'Zein', ''], ['Wohlgenannt', 'Gerhard', ''], ['Filtz', 'Erwin', '']]"
1369072,2010.12742,Zhiqiang Hu,"Zhiqiang Hu, Roy Ka-Wei Lee, Charu C. Aggarwal",Text Style Transfer: A Review and Experiment Evaluation,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The stylistic properties of text have intrigued computational linguistics
researchers in recent years. Specifically, researchers have investigated the
Text Style Transfer (TST) task, which aims to change the stylistic properties
of the text while retaining its style independent content. Over the last few
years, many novel TST algorithms have been developed, while the industry has
leveraged these algorithms to enable exciting TST applications. The field of
TST research has burgeoned because of this symbiosis. This article aims to
provide a comprehensive review of recent research efforts on text style
transfer. More concretely, we create a taxonomy to organize the TST models and
provide a comprehensive summary of the state of the art. We review the existing
evaluation methodologies for TST tasks and conduct a large-scale
reproducibility study where we experimentally benchmark 19 state-of-the-art TST
algorithms on two publicly available datasets. Finally, we expand on current
trends and provide new perspectives on the new and exciting developments in the
TST field.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 02:02:58 GMT'}]",2020-10-27,"[['Hu', 'Zhiqiang', ''], ['Lee', 'Roy Ka-Wei', ''], ['Aggarwal', 'Charu C.', '']]"
1369194,2010.12864,Xisen Jin,"Xisen Jin, Francesco Barbieri, Aida Mostafazadeh Davani, Brendan
  Kennedy, Leonardo Neves, Xiang Ren",Efficiently Mitigating Classification Bias via Transfer Learning,10 pages,,,,cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Prediction bias in machine learning models refers to unintended model
behaviors that discriminate against inputs mentioning or produced by certain
groups; for example, hate speech classifiers predict more false positives for
neutral text mentioning specific social groups. Mitigating bias for each task
or domain is inefficient, as it requires repetitive model training, data
annotation (e.g., demographic information), and evaluation. In pursuit of a
more accessible solution, we propose the Upstream Bias Mitigation for
Downstream Fine-Tuning (UBM) framework, which mitigate one or multiple bias
factors in downstream classifiers by transfer learning from an upstream model.
In the upstream bias mitigation stage, explanation regularization and
adversarial training are applied to mitigate multiple bias factors. In the
downstream fine-tuning stage, the classifier layer of the model is
re-initialized, and the entire model is fine-tuned to downstream tasks in
potentially novel domains without any further bias mitigation. We expect
downstream classifiers to be less biased by transfer learning from de-biased
upstream models. We conduct extensive experiments varying the similarity
between the source and target data, as well as varying the number of dimensions
of bias (e.g., discrimination against specific social groups or dialects). Our
results indicate the proposed UBM framework can effectively reduce bias in
downstream classifiers.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 10:36:11 GMT'}]",2020-10-27,"[['Jin', 'Xisen', ''], ['Barbieri', 'Francesco', ''], ['Davani', 'Aida Mostafazadeh', ''], ['Kennedy', 'Brendan', ''], ['Neves', 'Leonardo', ''], ['Ren', 'Xiang', '']]"
1369060,2010.12730,Gustavo Aguilar,"Gustavo Aguilar, Bryan McCann, Tong Niu, Nazneen Rajani, Nitish
  Keskar, Thamar Solorio","Char2Subword: Extending the Subword Embedding Space from Pre-trained
  Models Using Robust Character Compositionality",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Byte-pair encoding (BPE) is a ubiquitous algorithm in the subword
tokenization process of language models. BPE provides multiple benefits, such
as handling the out-of-vocabulary problem and reducing vocabulary sparsity.
However, this process is defined from the pre-training data statistics, making
the tokenization on different domains susceptible to infrequent spelling
sequences (e.g., misspellings as in social media or character-level adversarial
attacks). On the other hand, pure character-level models, though robust to
misspellings, often lead to unreasonably large sequence lengths and make it
harder for the model to learn meaningful contiguous characters. To alleviate
these challenges, we propose a character-based subword transformer module
(char2subword) that learns the subword embedding table in pre-trained models
like BERT. Our char2subword module builds representations from characters out
of the subword vocabulary, and it can be used as a drop-in replacement of the
subword embedding table. The module is robust to character-level alterations
such as misspellings, word inflection, casing, and punctuation. We integrate it
further with BERT through pre-training while keeping BERT transformer
parameters fixed. We show our method's effectiveness by outperforming a vanilla
multilingual BERT on the linguistic code-switching evaluation (LinCE)
benchmark.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 01:08:28 GMT'}]",2020-10-27,"[['Aguilar', 'Gustavo', ''], ['McCann', 'Bryan', ''], ['Niu', 'Tong', ''], ['Rajani', 'Nazneen', ''], ['Keskar', 'Nitish', ''], ['Solorio', 'Thamar', '']]"
1368943,2010.12613,Julia Siekiera,"Julia Siekiera, Marius K\""oppel, Edwin Simpson, Kevin Stowe, Iryna
  Gurevych, Stefan Kramer",Ranking Creative Language Characteristics in Small Data Scenarios,"10 pages, 3 figures",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The ability to rank creative natural language provides an important general
tool for downstream language understanding and generation. However, current
deep ranking models require substantial amounts of labeled data that are
difficult and expensive to obtain for different domains, languages and creative
characteristics. A recent neural approach, the DirectRanker, promises to reduce
the amount of training data needed but its application to text isn't fully
explored. We therefore adapt the DirectRanker to provide a new deep model for
ranking creative language with small data. We compare DirectRanker with a
Bayesian approach, Gaussian process preference learning (GPPL), which has
previously been shown to work well with sparse data. Our experiments with
sparse training data show that while the performance of standard neural ranking
approaches collapses with small training datasets, DirectRanker remains
effective. We find that combining DirectRanker with GPPL increases performance
across different settings by leveraging the complementary benefits of both
models. Our combined approach outperforms the previous state-of-the-art on
humor and metaphor novelty tasks, increasing Spearman's $\rho$ by 14% and 16%
on average.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 18:57:47 GMT'}]",2020-10-27,"[['Siekiera', 'Julia', ''], ['Köppel', 'Marius', ''], ['Simpson', 'Edwin', ''], ['Stowe', 'Kevin', ''], ['Gurevych', 'Iryna', ''], ['Kramer', 'Stefan', '']]"
1369267,2010.12937,Arun Kumar Singh,"Arun Kumar Singh, Sushant Dave, Dr. Prathosh A. P., Prof. Brejesh Lall
  and Shresth Mehta","A Benchmark Corpus and Neural Approach for Sanskrit Derivative Nouns
  Analysis","6 pages, 2 figures, EACL 2021 Submission",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents first benchmark corpus of Sanskrit Pratyaya (suffix) and
inflectional words (padas) formed due to suffixes along with neural network
based approaches to process the formation and splitting of inflectional words.
Inflectional words spans the primary and secondary derivative nouns as the
scope of current work. Pratyayas are an important dimension of morphological
analysis of Sanskrit texts. There have been Sanskrit Computational Linguistics
tools for processing and analyzing Sanskrit texts. Unfortunately there has not
been any work to standardize & validate these tools specifically for derivative
nouns analysis. In this work, we prepared a Sanskrit suffix benchmark corpus
called Pratyaya-Kosh to evaluate the performance of tools. We also present our
own neural approach for derivative nouns analysis while evaluating the same on
most prominent Sanskrit Morphological Analysis tools. This benchmark will be
freely dedicated and available to researchers worldwide and we hope it will
motivate all to improve morphological analysis in Sanskrit Language.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 17:22:44 GMT'}]",2020-10-27,"[['Singh', 'Arun Kumar', ''], ['Dave', 'Sushant', ''], ['P.', 'Dr. Prathosh A.', ''], ['Lall', 'Prof. Brejesh', ''], ['Mehta', 'Shresth', '']]"
1237621,2002.00198,Kun Zhou,"Kun Zhou, Berrak Sisman, Haizhou Li","Transforming Spectrum and Prosody for Emotional Voice Conversion with
  Non-Parallel Training Data","accepted by Speaker Odyssey 2020 in Tokyo, Japan",,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Emotional voice conversion aims to convert the spectrum and prosody to change
the emotional patterns of speech, while preserving the speaker identity and
linguistic content. Many studies require parallel speech data between different
emotional patterns, which is not practical in real life. Moreover, they often
model the conversion of fundamental frequency (F0) with a simple linear
transform. As F0 is a key aspect of intonation that is hierarchical in nature,
we believe that it is more adequate to model F0 in different temporal scales by
using wavelet transform. We propose a CycleGAN network to find an optimal
pseudo pair from non-parallel training data by learning forward and inverse
mappings simultaneously using adversarial and cycle-consistency losses. We also
study the use of continuous wavelet transform (CWT) to decompose F0 into ten
temporal scales, that describes speech prosody at different time resolution,
for effective F0 conversion. Experimental results show that our proposed
framework outperforms the baselines both in objective and subjective
evaluations.
","[{'version': 'v1', 'created': 'Sat, 1 Feb 2020 12:36:55 GMT'}, {'version': 'v2', 'created': 'Mon, 6 Apr 2020 12:43:26 GMT'}, {'version': 'v3', 'created': 'Tue, 7 Apr 2020 07:25:24 GMT'}, {'version': 'v4', 'created': 'Wed, 13 May 2020 05:21:37 GMT'}, {'version': 'v5', 'created': 'Sat, 24 Oct 2020 06:37:42 GMT'}]",2020-10-27,"[['Zhou', 'Kun', ''], ['Sisman', 'Berrak', ''], ['Li', 'Haizhou', '']]"
1368751,2010.12421,Jose Camacho-Collados,"Francesco Barbieri and Jose Camacho-Collados and Leonardo Neves and
  Luis Espinosa-Anke","TweetEval: Unified Benchmark and Comparative Evaluation for Tweet
  Classification","Findings of EMNLP 2020. TweetEval benchmark available at
  https://github.com/cardiffnlp/tweeteval",,,,cs.CL cs.SI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The experimental landscape in natural language processing for social media is
too fragmented. Each year, new shared tasks and datasets are proposed, ranging
from classics like sentiment analysis to irony detection or emoji prediction.
Therefore, it is unclear what the current state of the art is, as there is no
standardized evaluation protocol, neither a strong set of baselines trained on
such domain-specific data. In this paper, we propose a new evaluation framework
(TweetEval) consisting of seven heterogeneous Twitter-specific classification
tasks. We also provide a strong set of baselines as starting point, and compare
different language modeling pre-training strategies. Our initial experiments
show the effectiveness of starting off with existing pre-trained generic
language models, and continue training them on Twitter corpora.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 14:11:04 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 09:14:54 GMT'}]",2020-10-27,"[['Barbieri', 'Francesco', ''], ['Camacho-Collados', 'Jose', ''], ['Neves', 'Leonardo', ''], ['Espinosa-Anke', 'Luis', '']]"
1368264,2010.11934,Colin Raffel,"Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou,
  Aditya Siddhant, Aditya Barua, Colin Raffel",mT5: A massively multilingual pre-trained text-to-text transformer,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The recent ""Text-to-Text Transfer Transformer"" (T5) leveraged a unified
text-to-text format and scale to attain state-of-the-art results on a wide
variety of English-language NLP tasks. In this paper, we introduce mT5, a
multilingual variant of T5 that was pre-trained on a new Common Crawl-based
dataset covering 101 languages. We describe the design and modified training of
mT5 and demonstrate its state-of-the-art performance on many multilingual
benchmarks. All of the code and model checkpoints used in this work are
publicly available.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 17:58:14 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 21:25:28 GMT'}]",2020-10-27,"[['Xue', 'Linting', ''], ['Constant', 'Noah', ''], ['Roberts', 'Adam', ''], ['Kale', 'Mihir', ''], ['Al-Rfou', 'Rami', ''], ['Siddhant', 'Aditya', ''], ['Barua', 'Aditya', ''], ['Raffel', 'Colin', '']]"
1368186,2010.11856,Akari Asai,"Akari Asai, Jungo Kasai, Jonathan H. Clark, Kenton Lee, Eunsol Choi
  and Hannaneh Hajishirzi",XOR QA: Cross-lingual Open-Retrieval Question Answering,"Our data and code are available at
  https://nlp.cs.washington.edu/xorqa",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Multilingual question answering tasks typically assume answers exist in the
same language as the question. Yet in practice, many languages face both
information scarcity---where languages have few reference articles---and
information asymmetry---where questions reference concepts from other cultures.
This work extends open-retrieval question answering to a cross-lingual setting
enabling questions from one language to be answered via answer content from
another language. We construct a large-scale dataset built on questions from
TyDi QA lacking same-language answers. Our task formulation, called
Cross-lingual Open Retrieval Question Answering (XOR QA), includes 40k
information-seeking questions from across 7 diverse non-English languages.
Based on this dataset, we introduce three new tasks that involve cross-lingual
document retrieval using multi-lingual and English resources. We establish
baselines with state-of-the-art machine translation systems and cross-lingual
pretrained models. Experimental results suggest that XOR QA is a challenging
task that will facilitate the development of novel techniques for multilingual
question answering. Our data and code are available at
https://nlp.cs.washington.edu/xorqa.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 16:47:17 GMT'}, {'version': 'v2', 'created': 'Sat, 24 Oct 2020 10:00:22 GMT'}]",2020-10-27,"[['Asai', 'Akari', ''], ['Kasai', 'Jungo', ''], ['Clark', 'Jonathan H.', ''], ['Lee', 'Kenton', ''], ['Choi', 'Eunsol', ''], ['Hajishirzi', 'Hannaneh', '']]"
1367758,2010.11428,Qiujia Li,"Qiujia Li, David Qiu, Yu Zhang, Bo Li, Yanzhang He, Philip C.
  Woodland, Liangliang Cao, Trevor Strohman","Confidence Estimation for Attention-based Sequence-to-sequence Models
  for Speech Recognition",Submitted to ICASSP 2021,,,,eess.AS cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  For various speech-related tasks, confidence scores from a speech recogniser
are a useful measure to assess the quality of transcriptions. In traditional
hidden Markov model-based automatic speech recognition (ASR) systems,
confidence scores can be reliably obtained from word posteriors in decoding
lattices. However, for an ASR system with an auto-regressive decoder, such as
an attention-based sequence-to-sequence model, computing word posteriors is
difficult. An obvious alternative is to use the decoder softmax probability as
the model confidence. In this paper, we first examine how some commonly used
regularisation methods influence the softmax-based confidence scores and study
the overconfident behaviour of end-to-end models. Then we propose a lightweight
and effective approach named confidence estimation module (CEM) on top of an
existing end-to-end ASR model. Experiments on LibriSpeech show that CEM can
mitigate the overconfidence problem and can produce more reliable confidence
scores with and without shallow fusion of a language model. Further analysis
shows that CEM generalises well to speech from a moderately mismatched domain
and can potentially improve downstream tasks such as semi-supervised learning.
","[{'version': 'v1', 'created': 'Thu, 22 Oct 2020 04:02:27 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 18:49:07 GMT'}]",2020-10-27,"[['Li', 'Qiujia', ''], ['Qiu', 'David', ''], ['Zhang', 'Yu', ''], ['Li', 'Bo', ''], ['He', 'Yanzhang', ''], ['Woodland', 'Philip C.', ''], ['Cao', 'Liangliang', ''], ['Strohman', 'Trevor', '']]"
1367634,2010.11304,Wenxuan Zhou,"Wenxuan Zhou, Kevin Huang, Tengyu Ma, Jing Huang","Document-Level Relation Extraction with Adaptive Thresholding and
  Localized Context Pooling",Code available at https://github.com/wzhouad/ATLOP,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Document-level relation extraction (RE) poses new challenges compared to its
sentence-level RE counterpart. One document commonly contains multiple entity
pairs, and one entity pair occurs multiple times in the document associated
with multiple possible relations. In this paper, we propose two novel
techniques, adaptive thresholding and localized context pooling, to solve the
multilabel and multi-entity problems. The adaptive thresholding replaces the
global threshold for multi-label classification in the prior work by a
learnable entities-dependent threshold. The localized context pooling directly
transfers attention from pre-trained language models to locate relevant context
that is useful to decide the relation. We experiment on three document-level RE
benchmark datasets: DocRED, a recently released large-scale RE dataset, and two
datasets CDR and GDA in the biomedical domain. Our ATLOP (Adaptive Thresholding
and Localized cOntext Pooling) model achieves an F1 score of 63.4; and also
significantly outperforms existing models on both CDR and GDA.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 20:41:23 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 21:18:24 GMT'}]",2020-10-27,"[['Zhou', 'Wenxuan', ''], ['Huang', 'Kevin', ''], ['Ma', 'Tengyu', ''], ['Huang', 'Jing', '']]"
1367328,2010.10998,Aditya Kalyanpur,"Aditya Kalyanpur, Or Biran, Tom Breloff, Jennifer Chu-Carroll, Ariel
  Diertani, Owen Rambow, Mark Sammons",Open-Domain Frame Semantic Parsing Using Transformers,11 pages,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Frame semantic parsing is a complex problem which includes multiple
underlying subtasks. Recent approaches have employed joint learning of subtasks
(such as predicate and argument detection), and multi-task learning of related
tasks (such as syntactic and semantic parsing). In this paper, we explore
multi-task learning of all subtasks with transformer-based models. We show that
a purely generative encoder-decoder architecture handily beats the previous
state of the art in FrameNet 1.7 parsing, and that a mixed decoding multi-task
approach achieves even better performance. Finally, we show that the multi-task
model also outperforms recent state of the art systems for PropBank SRL parsing
on the CoNLL 2012 benchmark.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 13:38:04 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Oct 2020 23:37:12 GMT'}]",2020-10-27,"[['Kalyanpur', 'Aditya', ''], ['Biran', 'Or', ''], ['Breloff', 'Tom', ''], ['Chu-Carroll', 'Jennifer', ''], ['Diertani', 'Ariel', ''], ['Rambow', 'Owen', ''], ['Sammons', 'Mark', '']]"
1366264,2010.09934,Chengzhi Zhang,Yingyi Zhang and Chengzhi Zhang,Enhancing Keyphrase Extraction from Microblogs using Human Reading Time,,"Journal of the Association for Information Science and
  Technology,2021",10.1002/ASI.24430,,cs.CL cs.HC cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The premise of manual keyphrase annotation is to read the corresponding
content of an annotated object. Intuitively, when we read, more important words
will occupy a longer reading time. Hence, by leveraging human reading time, we
can find the salient words in the corresponding content. However, previous
studies on keyphrase extraction ignore human reading features. In this article,
we aim to leverage human reading time to extract keyphrases from microblog
posts. There are two main tasks in this study. One is to determine how to
measure the time spent by a human on reading a word. We use eye fixation
durations extracted from an open source eye-tracking corpus (OSEC). Moreover,
we propose strategies to make eye fixation duration more effective on keyphrase
extraction. The other task is to determine how to integrate human reading time
into keyphrase extraction models. We propose two novel neural network models.
The first is a model in which the human reading time is used as the ground
truth of the attention mechanism. In the second model, we use human reading
time as the external feature. Quantitative and qualitative experiments show
that our proposed models yield better performance than the baseline models on
two microblog datasets.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 00:18:44 GMT'}, {'version': 'v2', 'created': 'Sun, 25 Oct 2020 11:24:18 GMT'}]",2020-10-27,"[['Zhang', 'Yingyi', ''], ['Zhang', 'Chengzhi', '']]"
1365563,2010.09233,Dang Pham Nhu Hai,"Dang Pham, Tuan M.V.Le",Auto-Encoding Variational Bayes for Inferring Topics and Visualization,"Accepted at the 28th International Conference on Computational
  Linguistics (COLING 2020)",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Visualization and topic modeling are widely used approaches for text
analysis. Traditional visualization methods find low-dimensional
representations of documents in the visualization space (typically 2D or 3D)
that can be displayed using a scatterplot. In contrast, topic modeling aims to
discover topics from text, but for visualization, one needs to perform a
post-hoc embedding using dimensionality reduction methods. Recent approaches
propose using a generative model to jointly find topics and visualization,
allowing the semantics to be infused in the visualization space for a
meaningful interpretation. A major challenge that prevents these methods from
being used practically is the scalability of their inference algorithms. We
present, to the best of our knowledge, the first fast Auto-Encoding Variational
Bayes based inference method for jointly inferring topics and visualization.
Since our method is black box, it can handle model changes efficiently with
little mathematical rederivation effort. We demonstrate the efficiency and
effectiveness of our method on real-world large datasets and compare it with
existing baselines.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 05:57:11 GMT'}, {'version': 'v2', 'created': 'Sun, 25 Oct 2020 19:37:56 GMT'}]",2020-10-27,"[['Pham', 'Dang', ''], ['Le', 'Tuan M. V.', '']]"
1365524,2010.09194,Pan Xie,"Pan Xie, Zhi Cui, Xiuyin Chen, Xiaohui Hu, Jianwei Cui, Bin Wang","Infusing Sequential Information into Conditional Masked Translation
  Model with Self-Review Mechanism",accepted to coling 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Non-autoregressive models generate target words in a parallel way, which
achieve a faster decoding speed but at the sacrifice of translation accuracy.
To remedy a flawed translation by non-autoregressive models, a promising
approach is to train a conditional masked translation model (CMTM), and refine
the generated results within several iterations. Unfortunately, such approach
hardly considers the \textit{sequential dependency} among target words, which
inevitably results in a translation degradation. Hence, instead of solely
training a Transformer-based CMTM, we propose a Self-Review Mechanism to infuse
sequential information into it. Concretely, we insert a left-to-right mask to
the same decoder of CMTM, and then induce it to autoregressively review whether
each generated word from CMTM is supposed to be replaced or kept. The
experimental results (WMT14 En$\leftrightarrow$De and WMT16
En$\leftrightarrow$Ro) demonstrate that our model uses dramatically less
training computations than the typical CMTM, as well as outperforms several
state-of-the-art non-autoregressive models by over 1 BLEU. Through knowledge
distillation, our model even surpasses a typical left-to-right Transformer
model, while significantly speeding up decoding.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 03:38:56 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 13:22:06 GMT'}]",2020-10-27,"[['Xie', 'Pan', ''], ['Cui', 'Zhi', ''], ['Chen', 'Xiuyin', ''], ['Hu', 'Xiaohui', ''], ['Cui', 'Jianwei', ''], ['Wang', 'Bin', '']]"
1364910,2010.08580,Zeyu Liu,"Chuanrong Li, Lin Shengshuo, Leo Z. Liu, Xinyi Wu, Xuhui Zhou, Shane
  Steinert-Threlkeld","Linguistically-Informed Transformations (LIT): A Method forAutomatically
  Generating Contrast Sets",Appears at EMNLP BlackboxNLP Workshop 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Although large-scale pretrained language models, such as BERT and RoBERTa,
have achieved superhuman performance on in-distribution test sets, their
performance suffers on out-of-distribution test sets (e.g., on contrast sets).
Building contrast sets often re-quires human-expert annotation, which is
expensive and hard to create on a large scale. In this work, we propose a
Linguistically-Informed Transformation (LIT) method to automatically generate
contrast sets, which enables practitioners to explore linguistic phenomena of
interests as well as compose different phenomena. Experimenting with our method
on SNLI and MNLI shows that current pretrained language models, although being
claimed to contain sufficient linguistic knowledge, struggle on our
automatically generated contrast sets. Furthermore, we improve models'
performance on the contrast sets by apply-ing LIT to augment the training data,
without affecting performance on the original data.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 18:23:05 GMT'}, {'version': 'v2', 'created': 'Sun, 25 Oct 2020 01:39:23 GMT'}]",2020-10-27,"[['Li', 'Chuanrong', ''], ['Shengshuo', 'Lin', ''], ['Liu', 'Leo Z.', ''], ['Wu', 'Xinyi', ''], ['Zhou', 'Xuhui', ''], ['Steinert-Threlkeld', 'Shane', '']]"
1364763,2010.08433,Andrey Kormilitzin,"Andrey Kormilitzin, Nemanja Vaci, Qiang Liu, Hao Ni, Goran Nenadic,
  Alejo Nevado-Holgado",An efficient representation of chronological events in medical texts,"4 pages, 2 figures, 7 tables",,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this work we addressed the problem of capturing sequential information
contained in longitudinal electronic health records (EHRs). Clinical notes,
which is a particular type of EHR data, are a rich source of information and
practitioners often develop clever solutions how to maximise the sequential
information contained in free-texts. We proposed a systematic methodology for
learning from chronological events available in clinical notes. The proposed
methodological {\it path signature} framework creates a non-parametric
hierarchical representation of sequential events of any type and can be used as
features for downstream statistical learning tasks. The methodology was
developed and externally validated using the largest in the UK secondary care
mental health EHR data on a specific task of predicting survival risk of
patients diagnosed with Alzheimer's disease. The signature-based model was
compared to a common survival random forest model. Our results showed a
15.4$\%$ increase of risk prediction AUC at the time point of 20 months after
the first admission to a specialist memory clinic and the signature method
outperformed the baseline mixed-effects model by 13.2 $\%$.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 14:54:29 GMT'}, {'version': 'v2', 'created': 'Sat, 24 Oct 2020 21:52:03 GMT'}]",2020-10-27,"[['Kormilitzin', 'Andrey', ''], ['Vaci', 'Nemanja', ''], ['Liu', 'Qiang', ''], ['Ni', 'Hao', ''], ['Nenadic', 'Goran', ''], ['Nevado-Holgado', 'Alejo', '']]"
1364576,2010.08246,Johannes Bjerva,"Johannes Bjerva and Elizabeth Salesky and Sabrina J. Mielke and Aditi
  Chaudhary and Giuseppe G. A. Celano and Edoardo M. Ponti and Ekaterina
  Vylomova and Ryan Cotterell and Isabelle Augenstein",SIGTYP 2020 Shared Task: Prediction of Typological Features,SigTyp 2020 Shared Task Description Paper @ EMNLP 2020,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Typological knowledge bases (KBs) such as WALS (Dryer and Haspelmath, 2013)
contain information about linguistic properties of the world's languages. They
have been shown to be useful for downstream applications, including
cross-lingual transfer learning and linguistic probing. A major drawback
hampering broader adoption of typological KBs is that they are sparsely
populated, in the sense that most languages only have annotations for some
features, and skewed, in that few features have wide coverage. As typological
features often correlate with one another, it is possible to predict them and
thus automatically populate typological KBs, which is also the focus of this
shared task. Overall, the task attracted 8 submissions from 5 teams, out of
which the most successful methods make use of such feature correlations.
However, our error analysis reveals that even the strongest submitted systems
struggle with predicting feature values for languages where few features are
known.
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 08:47:24 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 07:29:45 GMT'}]",2020-10-27,"[['Bjerva', 'Johannes', ''], ['Salesky', 'Elizabeth', ''], ['Mielke', 'Sabrina J.', ''], ['Chaudhary', 'Aditi', ''], ['Celano', 'Giuseppe G. A.', ''], ['Ponti', 'Edoardo M.', ''], ['Vylomova', 'Ekaterina', ''], ['Cotterell', 'Ryan', ''], ['Augenstein', 'Isabelle', '']]"
1359306,2010.02976,Albert Webson,"Albert Webson, Zhizhong Chen, Carsten Eickhoff, Ellie Pavlick","Are ""Undocumented Workers"" the Same as ""Illegal Aliens""? Disentangling
  Denotation and Connotation in Vector Spaces","Published at EMNLP 2020. Recorded talk available at
  https://youtu.be/V2pdS6Y_8n0 . Code and data available at
  https://github.com/awebson/congressional_adversary",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In politics, neologisms are frequently invented for partisan objectives. For
example, ""undocumented workers"" and ""illegal aliens"" refer to the same group of
people (i.e., they have the same denotation), but they carry clearly different
connotations. Examples like these have traditionally posed a challenge to
reference-based semantic theories and led to increasing acceptance of
alternative theories (e.g., Two-Factor Semantics) among philosophers and
cognitive scientists. In NLP, however, popular pretrained models encode both
denotation and connotation as one entangled representation. In this study, we
propose an adversarial neural network that decomposes a pretrained
representation as independent denotation and connotation representations. For
intrinsic interpretability, we show that words with the same denotation but
different connotations (e.g., ""immigrants"" vs. ""aliens"", ""estate tax"" vs.
""death tax"") move closer to each other in denotation space while moving further
apart in connotation space. For extrinsic application, we train an information
retrieval system with our disentangled representations and show that the
denotation vectors improve the viewpoint diversity of document rankings.
","[{'version': 'v1', 'created': 'Tue, 6 Oct 2020 19:09:03 GMT'}, {'version': 'v2', 'created': 'Sun, 25 Oct 2020 15:43:44 GMT'}]",2020-10-27,"[['Webson', 'Albert', ''], ['Chen', 'Zhizhong', ''], ['Eickhoff', 'Carsten', ''], ['Pavlick', 'Ellie', '']]"
1357359,2010.01029,Chengjin Xu,"Chengjin Xu, Mojtaba Nayyeri, Fouad Alkhoury, Hamed Shariat Yazdi,
  Jens Lehmann",TeRo: A Time-aware Knowledge Graph Embedding via Temporal Rotation,This paper is accepted by COLING2020,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In the last few years, there has been a surge of interest in learning
representations of entitiesand relations in knowledge graph (KG). However, the
recent availability of temporal knowledgegraphs (TKGs) that contain time
information for each fact created the need for reasoning overtime in such TKGs.
In this regard, we present a new approach of TKG embedding, TeRo, which defines
the temporal evolution of entity embedding as a rotation from the initial time
to the currenttime in the complex vector space. Specially, for facts involving
time intervals, each relation isrepresented as a pair of dual complex
embeddings to handle the beginning and the end of therelation, respectively. We
show our proposed model overcomes the limitations of the existing KG embedding
models and TKG embedding models and has the ability of learning and
inferringvarious relation patterns over time. Experimental results on four
different TKGs show that TeRo significantly outperforms existing
state-of-the-art models for link prediction. In addition, we analyze the effect
of time granularity on link prediction over TKGs, which as far as we know
hasnot been investigated in previous literature.
","[{'version': 'v1', 'created': 'Fri, 2 Oct 2020 14:35:27 GMT'}, {'version': 'v2', 'created': 'Sat, 24 Oct 2020 22:42:26 GMT'}]",2020-10-27,"[['Xu', 'Chengjin', ''], ['Nayyeri', 'Mojtaba', ''], ['Alkhoury', 'Fouad', ''], ['Yazdi', 'Hamed Shariat', ''], ['Lehmann', 'Jens', '']]"
1354770,2009.13267,Pedram Rooshenas,"Subhajit Naskar, Amirmohammad Rooshenas, Simeng Sun, Mohit Iyyer,
  Andrew McCallum","Energy-Based Reranking: Improving Neural Machine Translation Using
  Energy-Based Models",,,,,cs.CL cs.LG stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The discrepancy between maximum likelihood estimation (MLE) and task measures
such as BLEU score has been studied before for autoregressive neural machine
translation (NMT) and resulted in alternative training algorithms (Ranzato et
al., 2016; Norouzi et al., 2016; Shen et al., 2016; Wu et al., 2018). However,
MLE training remains the de facto approach for autoregressive NMT because of
its computational efficiency and stability. Despite this mismatch between the
training objective and task measure, we notice that the samples drawn from an
MLE-based trained NMT support the desired distribution -- there are samples
with much higher BLEU score comparing to the beam decoding output. To benefit
from this observation, we train an energy-based model to mimic the behavior of
the task measure (i.e., the energy-based model assigns lower energy to samples
with higher BLEU score), which is resulted in a re-ranking algorithm based on
the samples drawn from NMT: energy-based re-ranking (EBR). Our EBR consistently
improves the performance of the Transformer-based NMT: +3 BLEU points on
Sinhala-English, +2.0 BLEU points on IWSLT'17 French-English, and +1.7 BLEU
points on WMT'19 German-English tasks.
","[{'version': 'v1', 'created': 'Sun, 20 Sep 2020 02:50:52 GMT'}, {'version': 'v2', 'created': 'Sat, 24 Oct 2020 04:57:59 GMT'}]",2020-10-27,"[['Naskar', 'Subhajit', ''], ['Rooshenas', 'Amirmohammad', ''], ['Sun', 'Simeng', ''], ['Iyyer', 'Mohit', ''], ['McCallum', 'Andrew', '']]"
1353847,2009.12344,"Tommi Gr\""ondahl","Mika Juuti, Tommi Gr\""ondahl, Adrian Flanagan and N. Asokan","A little goes a long way: Improving toxic language classification
  despite data scarcity",To appear in Findings of ACL: EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Detection of some types of toxic language is hampered by extreme scarcity of
labeled training data. Data augmentation - generating new synthetic data from a
labeled seed dataset - can help. The efficacy of data augmentation on toxic
language classification has not been fully explored. We present the first
systematic study on how data augmentation techniques impact performance across
toxic language classifiers, ranging from shallow logistic regression
architectures to BERT - a state-of-the-art pre-trained Transformer network. We
compare the performance of eight techniques on very scarce seed datasets. We
show that while BERT performed the best, shallow classifiers performed
comparably when trained on data augmented with a combination of three
techniques, including GPT-2-generated sentences. We discuss the interplay of
performance and computational overhead, which can inform the choice of
techniques under different constraints.
","[{'version': 'v1', 'created': 'Fri, 25 Sep 2020 17:04:17 GMT'}, {'version': 'v2', 'created': 'Sat, 24 Oct 2020 19:31:34 GMT'}]",2020-10-27,"[['Juuti', 'Mika', ''], ['Gröndahl', 'Tommi', ''], ['Flanagan', 'Adrian', ''], ['Asokan', 'N.', '']]"
1352187,2009.10684,Bruno Taill\'e,"Bruno Taill\'e, Vincent Guigue, Geoffrey Scoutheeten and Patrick
  Gallinari",Let's Stop Incorrect Comparisons in End-to-end Relation Extraction!,Accepted at EMNLP 2020,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite efforts to distinguish three different evaluation setups (Bekoulis et
al., 2018), numerous end-to-end Relation Extraction (RE) articles present
unreliable performance comparison to previous work. In this paper, we first
identify several patterns of invalid comparisons in published papers and
describe them to avoid their propagation. We then propose a small empirical
study to quantify the impact of the most common mistake and evaluate it leads
to overestimating the final RE performance by around 5% on ACE05. We also seize
this opportunity to study the unexplored ablations of two recent developments:
the use of language model pretraining (specifically BERT) and span-level NER.
This meta-analysis emphasizes the need for rigor in the report of both the
evaluation setting and the datasets statistics and we call for unifying the
evaluation setting in end-to-end RE.
","[{'version': 'v1', 'created': 'Tue, 22 Sep 2020 16:59:15 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 16:43:35 GMT'}]",2020-10-27,"[['Taillé', 'Bruno', ''], ['Guigue', 'Vincent', ''], ['Scoutheeten', 'Geoffrey', ''], ['Gallinari', 'Patrick', '']]"
1350056,2009.08553,Yuning Mao,"Yuning Mao, Pengcheng He, Xiaodong Liu, Yelong Shen, Jianfeng Gao,
  Jiawei Han, Weizhu Chen",Generation-Augmented Retrieval for Open-domain Question Answering,"Added experiments with a generative reader. Current performance:
  EM=41.8 (43.8 +DPR) on NQ and 62.7 on Trivia with BERT-base (extractive);
  EM=38.1 (45.3 +DPR) on NQ and 61.8 on Trivia with BART-large (generative)",,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Conventional sparse retrieval methods such as TF-IDF and BM25 are simple and
efficient, but solely rely on lexical overlap without semantic matching. Recent
dense retrieval methods learn latent representations to tackle the lexical
mismatch problem, while being more computationally expensive and insufficient
for exact matching as they embed the text sequence into a single vector with
limited capacity. In this paper, we present Generation-Augmented Retrieval
(GAR), a query expansion method that augments a query with relevant contexts
through text generation. We demonstrate on open-domain question answering that
the generated contexts significantly enrich the semantics of the queries and
thus GAR with sparse representations (BM25) achieves comparable or better
performance than the state-of-the-art dense methods such as DPR
\cite{karpukhin2020dense}. We show that generating various contexts of a query
is beneficial as fusing their results consistently yields better retrieval
accuracy. Moreover, as sparse and dense representations are often
complementary, GAR can be easily combined with DPR to achieve even better
performance. Furthermore, GAR achieves the state-of-the-art performance on the
Natural Questions and TriviaQA datasets under the extractive setting when
equipped with an extractive reader, and consistently outperforms other
retrieval methods when the same generative reader is used.
","[{'version': 'v1', 'created': 'Thu, 17 Sep 2020 23:08:01 GMT'}, {'version': 'v2', 'created': 'Sat, 24 Oct 2020 03:23:27 GMT'}]",2020-10-27,"[['Mao', 'Yuning', ''], ['He', 'Pengcheng', ''], ['Liu', 'Xiaodong', ''], ['Shen', 'Yelong', ''], ['Gao', 'Jianfeng', ''], ['Han', 'Jiawei', ''], ['Chen', 'Weizhu', '']]"
1347990,2009.06487,Chengyu Wang,"Chengyu Wang, Mengli Cheng, Xu Hu, Jun Huang","EasyASR: A Distributed Machine Learning Platform for End-to-end
  Automatic Speech Recognition",aaai 2021 demo paper,,,,cs.CL cs.AI cs.DC cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present EasyASR, a distributed machine learning platform for training and
serving large-scale Automatic Speech Recognition (ASR) models, as well as
collecting and processing audio data at scale. Our platform is built upon the
Machine Learning Platform for AI of Alibaba Cloud. Its main functionality is to
support efficient learning and inference for end-to-end ASR models on
distributed GPU clusters. It allows users to learn ASR models with either
pre-defined or user-customized network architectures via simple user interface.
On EasyASR, we have produced state-of-the-art results over several public
datasets for Mandarin speech recognition.
","[{'version': 'v1', 'created': 'Mon, 14 Sep 2020 14:47:02 GMT'}, {'version': 'v2', 'created': 'Sat, 24 Oct 2020 09:44:27 GMT'}]",2020-10-27,"[['Wang', 'Chengyu', ''], ['Cheng', 'Mengli', ''], ['Hu', 'Xu', ''], ['Huang', 'Jun', '']]"
1347389,2009.05886,Dylan Slack,Gavin Kerrigan and Dylan Slack and Jens Tuyls,Differentially Private Language Models Benefit from Public Pre-training,,,,,cs.LG cs.CL cs.CR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language modeling is a keystone task in natural language processing. When
training a language model on sensitive information, differential privacy (DP)
allows us to quantify the degree to which our private data is protected.
However, training algorithms which enforce differential privacy often lead to
degradation in model quality. We study the feasibility of learning a language
model which is simultaneously high-quality and privacy preserving by tuning a
public base model on a private corpus. We find that DP fine-tuning boosts the
performance of language models in the private domain, making the training of
such models possible.
","[{'version': 'v1', 'created': 'Sun, 13 Sep 2020 00:50:44 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 16:04:43 GMT'}]",2020-10-27,"[['Kerrigan', 'Gavin', ''], ['Slack', 'Dylan', ''], ['Tuyls', 'Jens', '']]"
1368953,2010.12623,Wenhu Chen,"Liangming Pan, Wenhu Chen, Wenhan Xiong, Min-Yen Kan, William Yang
  Wang",Unsupervised Multi-hop Question Answering by Question Generation,Technical Report,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Obtaining training data for Multi-hop Question Answering (QA) is extremely
time-consuming and resource-intensive. To address this, we propose the problem
of \textit{unsupervised} multi-hop QA, assuming that no human-labeled multi-hop
question-answer pairs are available. We propose MQA-QG, an unsupervised
question answering framework that can generate human-like multi-hop training
pairs from both homogeneous and heterogeneous data sources. Our model generates
questions by first selecting or generating relevant information from each data
source and then integrating the multiple information to form a multi-hop
question. We find that we can train a competent multi-hop QA model with only
generated data. The F1 gap between the unsupervised and fully-supervised models
is less than 20 in both the HotpotQA and the HybridQA dataset. Further
experiments reveal that an unsupervised pretraining with the QA data generated
by our model would greatly reduce the demand for human-annotated training data
for multi-hop QA.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 19:13:47 GMT'}]",2020-10-27,"[['Pan', 'Liangming', ''], ['Chen', 'Wenhu', ''], ['Xiong', 'Wenhan', ''], ['Kan', 'Min-Yen', ''], ['Wang', 'William Yang', '']]"
1369071,2010.12741,Jo\~ao Sedoc,"Seolhwa Lee, Heuiseok Lim, Jo\~ao Sedoc",An Evaluation Protocol for Generative Conversational Systems,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  There is a multitude of novel generative models for open-domain
conversational systems; however, there is no systematic evaluation of different
systems. Systematic comparisons require consistency in experimental design,
evaluation sets, conversational systems and their outputs, and statistical
analysis. We lay out a protocol for the evaluation of conversational models
using head-to-head pairwise comparison. We analyze ten recent models that claim
state-of-the-art performance using a paired head-to-head performance
(win-loss-tie) on five evaluation datasets. Our findings show that DialoGPT and
Blender are superior systems using Bradley-Terry model and TrueSkill ranking
methods. These findings demonstrate the feasibility of our protocol to evaluate
conversational agents and evaluation sets. Finally, we make all code and
evaluations publicly available for researchers to compare their model to other
state-of-the-art dialog models.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 01:59:49 GMT'}]",2020-10-27,"[['Lee', 'Seolhwa', ''], ['Lim', 'Heuiseok', ''], ['Sedoc', 'João', '']]"
1368956,2010.12626,Laure Thompson,"Laure Thompson, David Mimno",Topic Modeling with Contextualized Word Representation Clusters,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Clustering token-level contextualized word representations produces output
that shares many similarities with topic models for English text collections.
Unlike clusterings of vocabulary-level word embeddings, the resulting models
more naturally capture polysemy and can be used as a way of organizing
documents. We evaluate token clusterings trained from several different output
layers of popular contextualized language models. We find that BERT and GPT-2
produce high quality clusterings, but RoBERTa does not. These cluster models
are simple, reliable, and can perform as well as, if not better than, LDA topic
models, maintaining high topic quality even when the number of topics is large
relative to the size of the local collection.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 19:16:59 GMT'}]",2020-10-27,"[['Thompson', 'Laure', ''], ['Mimno', 'David', '']]"
1368964,2010.12634,Yusen Zhang,"Yusen Zhang, Xiangyu Dong, Shuaichen Chang, Tao Yu, Peng Shi and Rui
  Zhang","Did You Ask a Good Question? A Cross-Domain Question Intention
  Classification Benchmark for Text-to-SQL","8 pages, 2 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Neural models have achieved significant results on the text-to-SQL task, in
which most current work assumes all the input questions are legal and generates
a SQL query for any input. However, in the real scenario, users can input any
text that may not be able to be answered by a SQL query. In this work, we
propose TriageSQL, the first cross-domain text-to-SQL question intention
classification benchmark that requires models to distinguish four types of
unanswerable questions from answerable questions. The baseline RoBERTa model
achieves a 60% F1 score on the test set, demonstrating the need for further
improvement on this task. Our dataset is available at
https://github.com/chatc/TriageSQL.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 19:36:57 GMT'}]",2020-10-27,"[['Zhang', 'Yusen', ''], ['Dong', 'Xiangyu', ''], ['Chang', 'Shuaichen', ''], ['Yu', 'Tao', ''], ['Shi', 'Peng', ''], ['Zhang', 'Rui', '']]"
1369059,2010.12729,Adina Williams,"Adina Williams, Tristan Thrush, Douwe Kiela",ANLIzing the Adversarial Natural Language Inference Dataset,"33 pages, 1 figure, 24 tables",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We perform an in-depth error analysis of Adversarial NLI (ANLI), a recently
introduced large-scale human-and-model-in-the-loop natural language inference
dataset collected over multiple rounds. We propose a fine-grained annotation
scheme of the different aspects of inference that are responsible for the gold
classification labels, and use it to hand-code all three of the ANLI
development sets. We use these annotations to answer a variety of interesting
questions: which inference types are most common, which models have the highest
performance on each reasoning type, and which types are the most challenging
for state of-the-art models? We hope that our annotations will enable more
fine-grained evaluation of models trained on ANLI, provide us with a deeper
understanding of where models fail and succeed, and help us determine how to
train better models in future.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 01:03:51 GMT'}]",2020-10-27,"[['Williams', 'Adina', ''], ['Thrush', 'Tristan', ''], ['Kiela', 'Douwe', '']]"
1369055,2010.12725,Peter Shaw,"Peter Shaw, Ming-Wei Chang, Panupong Pasupat, Kristina Toutanova","Compositional Generalization and Natural Language Variation: Can a
  Semantic Parsing Approach Handle Both?",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Sequence-to-sequence models excel at handling natural language variation, but
have been shown to struggle with out-of-distribution compositional
generalization. This has motivated new specialized architectures with stronger
compositional biases, but most of these approaches have only been evaluated on
synthetically-generated datasets, which are not representative of natural
language variation. In this work we ask: can we develop a semantic parsing
approach that handles both natural language variation and compositional
generalization? To better assess this capability, we propose new train and test
splits of non-synthetic datasets. We demonstrate that strong existing semantic
parsing approaches do not yet perform well across a broad set of evaluations.
We also propose NQG-T5, a hybrid model that combines a high-precision
grammar-based approach with a pre-trained sequence-to-sequence model. It
outperforms existing approaches across several compositional generalization
challenges, while also being competitive with the state-of-the-art on standard
evaluations. While still far from solving this problem, our study highlights
the importance of diverse evaluations and the open challenge of handling both
compositional generalization and natural language variation in semantic
parsing.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 00:38:27 GMT'}]",2020-10-27,"[['Shaw', 'Peter', ''], ['Chang', 'Ming-Wei', ''], ['Pasupat', 'Panupong', ''], ['Toutanova', 'Kristina', '']]"
1369053,2010.12723,Yuning Mao,"Yuning Mao, Xiang Ren, Heng Ji, Jiawei Han","Constrained Abstractive Summarization: Preserving Factual Consistency
  with Constrained Generation",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Summaries generated by abstractive summarization are supposed to only contain
statements entailed by the source documents. However, state-of-the-art
abstractive methods are still prone to hallucinate content inconsistent with
the source documents. In this paper, we propose constrained abstractive
summarization (CAS), a general setup that preserves the factual consistency of
abstractive summarization by specifying tokens as constraints that must be
present in the summary. We explore the feasibility of using lexically
constrained decoding, a technique applicable to any abstractive method with
beam search decoding, to fulfill CAS and conduct experiments in two scenarios:
(1) Standard summarization without human involvement, where keyphrase
extraction is used to extract constraints from source documents; (2)
Interactive summarization with human feedback, which is simulated by taking
missing tokens in the reference summaries as constraints. Automatic and human
evaluations on two benchmark datasets demonstrate that CAS improves the quality
of abstractive summaries, especially on factual consistency. In particular, we
observe up to 11.2 ROUGE-2 gains when several ground-truth tokens are used as
constraints in the interactive summarization scenario.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 00:27:44 GMT'}]",2020-10-27,"[['Mao', 'Yuning', ''], ['Ren', 'Xiang', ''], ['Ji', 'Heng', ''], ['Han', 'Jiawei', '']]"
1369049,2010.12719,Falcon Dai,Falcon Z. Dai,Word2vec Conjecture and A Limitative Result,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Being inspired by the success of \texttt{word2vec}
\citep{mikolov2013distributed} in capturing analogies, we study the conjecture
that analogical relations can be represented by vector spaces. Unlike many
previous works that focus on the distributional semantic aspect of
\texttt{word2vec}, we study the purely \emph{representational} question: can
\emph{all} semantic word-word relations be represented by differences (or
directions) of vectors? We call this the word2vec conjecture and point out some
of its desirable implications. However, we will exhibit a class of relations
that cannot be represented in this way, thus falsifying the conjecture and
establishing a limitative result for the representability of semantic relations
by vector spaces over fields of characteristic 0, e.g., real or complex
numbers.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 00:14:04 GMT'}]",2020-10-27,"[['Dai', 'Falcon Z.', '']]"
1369042,2010.12712,Shuguang Chen,"Shuguang Chen, Gustavo Aguilar, Leonardo Neves, Thamar Solorio","A Caption Is Worth A Thousand Images: Investigating Image Captions for
  Multimodal Named Entity Recognition","8 pages, 2 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Multimodal named entity recognition (MNER) requires to bridge the gap between
language understanding and visual context. Due to advances in natural language
processing (NLP) and computer vision (CV), many neural techniques have been
proposed to incorporate images into the NER task. In this work, we conduct a
detailed analysis of current state-of-the-art fusion techniques for MNER and
describe scenarios where adding information from the image does not always
result in boosts in performance. We also study the use of captions as a way to
enrich the context for MNER. We provide extensive empirical analysis and an
ablation study on three datasets from popular social platforms to expose the
situations where the approach is beneficial.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 23:41:51 GMT'}]",2020-10-27,"[['Chen', 'Shuguang', ''], ['Aguilar', 'Gustavo', ''], ['Neves', 'Leonardo', ''], ['Solorio', 'Thamar', '']]"
1369040,2010.12710,Maria Phillips,"Debajyoti Datta, Maria Phillips, Jennifer Chiu, Ginger S. Watson,
  James P. Bywater, Laura Barnes, and Donald Brown","Improving Classification through Weak Supervision in Context-specific
  Conversational Agent Development for Teacher Education",Preprint: Under Review,,,,cs.CL cs.CY cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Machine learning techniques applied to the Natural Language Processing (NLP)
component of conversational agent development show promising results for
improved accuracy and quality of feedback that a conversational agent can
provide. The effort required to develop an educational scenario specific
conversational agent is time consuming as it requires domain experts to label
and annotate noisy data sources such as classroom videos. Previous approaches
to modeling annotations have relied on labeling thousands of examples and
calculating inter-annotator agreement and majority votes in order to model the
necessary scenarios. This method, while proven successful, ignores individual
annotator strengths in labeling a data point and under-utilizes examples that
do not have a majority vote for labeling. We propose using a multi-task weak
supervision method combined with active learning to address these concerns.
This approach requires less labeling than traditional methods and shows
significant improvements in precision, efficiency, and time-requirements than
the majority vote method (Ratner 2019). We demonstrate the validity of this
method on the Google Jigsaw data set and then propose a scenario to apply this
method using the Instructional Quality Assessment(IQA) to define the categories
for labeling. We propose using probabilistic modeling of annotator labeling to
generate active learning examples to further label the data. Active learning is
able to iteratively improve the training performance and accuracy of the
original classification model. This approach combines state-of-the art labeling
techniques of weak supervision and active learning to optimize results in the
educational domain and could be further used to lessen the data requirements
for expanded scenarios within the education domain through transfer learning.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 23:39:40 GMT'}]",2020-10-27,"[['Datta', 'Debajyoti', ''], ['Phillips', 'Maria', ''], ['Chiu', 'Jennifer', ''], ['Watson', 'Ginger S.', ''], ['Bywater', 'James P.', ''], ['Barnes', 'Laura', ''], ['Brown', 'Donald', '']]"
1369037,2010.12707,Dorottya Demszky,"Dorottya Demszky, Devyani Sharma, Jonathan H. Clark, Vinodkumar
  Prabhakaran, Jacob Eisenstein",Learning to Recognize Dialect Features,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Linguists characterize dialects by the presence, absence, and frequency of
dozens of interpretable features. Detecting these features in text has
applications to social science and dialectology, and can be used to assess the
robustness of natural language processing systems to dialect differences. For
most dialects, large-scale annotated corpora for these features are
unavailable, making it difficult to train recognizers. Linguists typically
define dialect features by providing a small number of minimal pairs, which are
paired examples distinguished only by whether the feature is present, while
holding everything else constant. In this paper, we present two multitask
learning architectures for recognizing dialect features, both based on
pretrained transformers. We evaluate these models on two test sets of Indian
English, annotated for a total of 22 dialect features. We find these models
learn to recognize many features with high accuracy; crucially, a few minimal
pairs can be nearly as effective for training as thousands of labeled examples.
We also demonstrate the downstream applicability of our dialect feature
detection model as a dialect density measure and as a dialect classifier.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 23:25:00 GMT'}]",2020-10-27,"[['Demszky', 'Dorottya', ''], ['Sharma', 'Devyani', ''], ['Clark', 'Jonathan H.', ''], ['Prabhakaran', 'Vinodkumar', ''], ['Eisenstein', 'Jacob', '']]"
1369029,2010.12699,"Stefan Gr\""unewald","Stefan Gr\""unewald, Annemarie Friedrich, Jonas Kuhn","Graph-Based Universal Dependency Parsing in the Age of the Transformer:
  What Works, and What Doesn't",14 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Current state-of-the-art graph-based dependency parsers differ on various
dimensions. Among others, these include (a) the choice of pre-trained word
embeddings or language models used for representing token, (b) training setups
performing only parsing or additional tasks such as part-of-speech-tagging, and
(c) their mechanism of constructing trees or graphs from edge scores. Because
of this, it is difficult to estimate the impact of these architectural
decisions when comparing parsers.
  In this paper, we perform a series of experiments on STEPS, a new modular
graph-based parser for basic and enhanced Universal Dependencies, analyzing the
effects of architectural configurations. We find that pre-trained embeddings
have by far the greatest and most clear-cut impact on parser performance. The
choice of factorized vs. unfactorized architectures and a multi-task training
setup affect parsing accuracy in more subtle ways, depending on target language
and output representation (trees vs. graphs). Our parser achieves new
state-of-the-art results for a wide range of languages on both basic as well as
enhanced Universal Dependencies, using a unified and comparatively simple
architecture for both parsing tasks.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 22:58:26 GMT'}]",2020-10-27,"[['Grünewald', 'Stefan', ''], ['Friedrich', 'Annemarie', ''], ['Kuhn', 'Jonas', '']]"
1369024,2010.12694,Sayali Kulkarni,"Sayali Kulkarni, Sheide Chammas, Wan Zhu, Fei Sha, Eugene Ie","AQuaMuSe: Automatically Generating Datasets for Query-Based
  Multi-Document Summarization",,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Summarization is the task of compressing source document(s) into coherent and
succinct passages. This is a valuable tool to present users with concise and
accurate sketch of the top ranked documents related to their queries.
Query-based multi-document summarization (qMDS) addresses this pervasive need,
but the research is severely limited due to lack of training and evaluation
datasets as existing single-document and multi-document summarization datasets
are inadequate in form and scale. We propose a scalable approach called
AQuaMuSe to automatically mine qMDS examples from question answering datasets
and large document corpora. Our approach is unique in the sense that it can
general a dual dataset -- for extractive and abstractive summaries both. We
publicly release a specific instance of an AQuaMuSe dataset with 5,519
query-based summaries, each associated with an average of 6 input documents
selected from an index of 355M documents from Common Crawl. Extensive
evaluation of the dataset along with baseline summarization model experiments
are provided.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 22:38:18 GMT'}]",2020-10-27,"[['Kulkarni', 'Sayali', ''], ['Chammas', 'Sheide', ''], ['Zhu', 'Wan', ''], ['Sha', 'Fei', ''], ['Ie', 'Eugene', '']]"
1369023,2010.12693,Nadezhda Chirkova,Nadezhda Chirkova,Neural Code Completion with Anonymized Variable Names,,,,,cs.SE cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Source code processing heavily relies on the methods widely used in natural
language processing (NLP), but involves specifics that need to be taken into
account to achieve higher quality. An example of this specificity is that
renaming variables does not change the semantics of what the code does. In this
work, we develop a recurrent architecture that processes code with all variable
names anonymized, i. e. replaced with unique placeholders. The proposed
architecture outperforms standard NLP baselines on code completion task by a
large margin in the anonymized setting, and improves the base model in the
non-anonymized setting, being ensembled with it.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 22:32:11 GMT'}]",2020-10-27,"[['Chirkova', 'Nadezhda', '']]"
1369018,2010.12688,Oshin Agarwal,"Oshin Agarwal, Heming Ge, Siamak Shakeri, Rami Al-Rfou","Large Scale Knowledge Graph Based Synthetic Corpus Generation for
  Knowledge-Enhanced Language Model Pre-training",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Generating natural sentences from Knowledge Graph (KG) triples, known as
Data-To-Text Generation, is a task with many datasets for which numerous
complex systems have been developed. However, no prior work has attempted to
perform this generation at scale by converting an entire KG into natural text.
In this paper, we verbalize the entire Wikidata KG, and create a KG-Text
aligned corpus in the training process. We discuss the challenges in
verbalizing an entire KG versus verbalizing smaller datasets. We further show
that verbalizing an entire KG can be used to integrate structured and natural
language data. In contrast to the many architectures that have been developed
to integrate the structural differences between these two sources, our approach
converts the KG into the same format as natural text allowing it to be
seamlessly plugged into existing natural language systems. We evaluate this
approach by augmenting the retrieval corpus in REALM and showing improvements,
both on the LAMA knowledge probe and open domain QA.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 22:14:50 GMT'}]",2020-10-27,"[['Agarwal', 'Oshin', ''], ['Ge', 'Heming', ''], ['Shakeri', 'Siamak', ''], ['Al-Rfou', 'Rami', '']]"
1369014,2010.12684,Valentin Hofmann,"Valentin Hofmann, Janet B. Pierrehumbert, Hinrich Sch\""utze",Dynamic Contextualized Word Embeddings,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Static word embeddings that represent words by a single vector cannot capture
the variability of word meaning in different linguistic and extralinguistic
contexts. Building on prior work on contextualized and dynamic word embeddings,
we introduce dynamic contextualized word embeddings that represent words as a
function of both linguistic and extralinguistic context. Based on a pretrained
language model (PLM), dynamic contextualized word embeddings model time and
social space jointly, which makes them attractive for various tasks in the
computational social sciences. We highlight potential applications by means of
qualitative and quantitative analyses.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 22:02:40 GMT'}]",2020-10-27,"[['Hofmann', 'Valentin', ''], ['Pierrehumbert', 'Janet B.', ''], ['Schütze', 'Hinrich', '']]"
1369013,2010.12683,Jyun-Yu Jiang,"Jyun-Yu Jiang, Chenyan Xiong, Chia-Jung Lee and Wei Wang",Long Document Ranking with Query-Directed Sparse Transformer,"Accepted by EMNLP 2020, 12 pages, 5 figures",,,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The computing cost of transformer self-attention often necessitates breaking
long documents to fit in pretrained models in document ranking tasks. In this
paper, we design Query-Directed Sparse attention that induces IR-axiomatic
structures in transformer self-attention. Our model, QDS-Transformer, enforces
the principle properties desired in ranking: local contextualization,
hierarchical representation, and query-oriented proximity matching, while it
also enjoys efficiency from sparsity. Experiments on one fully supervised and
three few-shot TREC document ranking benchmarks demonstrate the consistent and
robust advantage of QDS-Transformer over previous approaches, as they either
retrofit long documents into BERT or use sparse attention without emphasizing
IR principles. We further quantify the computing complexity and demonstrates
that our sparse attention with TVM implementation is twice more efficient than
the fully-connected self-attention. All source codes, trained model, and
predictions of this work are available at
https://github.com/hallogameboy/QDS-Transformer.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 21:57:56 GMT'}]",2020-10-27,"[['Jiang', 'Jyun-Yu', ''], ['Xiong', 'Chenyan', ''], ['Lee', 'Chia-Jung', ''], ['Wang', 'Wei', '']]"
1369011,2010.12681,Armineh Nourbakhsh,"Natraj Raman, Armineh Nourbakhsh, Sameena Shah, Manuela Veloso",Robust Document Representations using Latent Topics and Metadata,"9 pages, 7 figures",,,,cs.CL cs.AI cs.LG cs.NE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Task specific fine-tuning of a pre-trained neural language model using a
custom softmax output layer is the de facto approach of late when dealing with
document classification problems. This technique is not adequate when labeled
examples are not available at training time and when the metadata artifacts in
a document must be exploited. We address these challenges by generating
document representations that capture both text and metadata artifacts in a
task agnostic manner. Instead of traditional auto-regressive or auto-encoding
based training, our novel self-supervised approach learns a soft-partition of
the input space when generating text embeddings. Specifically, we employ a
pre-learned topic model distribution as surrogate labels and construct a loss
function based on KL divergence. Our solution also incorporates metadata
explicitly rather than just augmenting them with text. The generated document
embeddings exhibit compositional characteristics and are directly used by
downstream classification tasks to create decision boundaries from a small
number of labeled examples, thereby eschewing complicated recognition methods.
We demonstrate through extensive evaluation that our proposed cross-model
fusion solution outperforms several competitive baselines on multiple datasets.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 21:52:38 GMT'}]",2020-10-27,"[['Raman', 'Natraj', ''], ['Nourbakhsh', 'Armineh', ''], ['Shah', 'Sameena', ''], ['Veloso', 'Manuela', '']]"
1369006,2010.12676,Chunchuan Lyu Mr.,"Chunchuan Lyu, Shay B. Cohen, Ivan Titov","A Differentiable Relaxation of Graph Segmentation and Alignment for AMR
  Parsing",,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Abstract Meaning Representations (AMR) are a broad-coverage semantic
formalism which represents sentence meaning as a directed acyclic graph. To
train most AMR parsers, one needs to segment the graph into subgraphs and align
each such subgraph to a word in a sentence; this is normally done at
preprocessing, relying on hand-crafted rules. In contrast, we treat both
alignment and segmentation as latent variables in our model and induce them as
part of end-to-end training.
  As marginalizing over the structured latent variables is infeasible, we use
the variational autoencoding framework.
  To ensure end-to-end differentiable optimization, we introduce a continuous
differentiable relaxation of the segmentation and alignment problems. We
observe that inducing segmentation yields substantial gains over using a
`greedy' segmentation heuristic. The performance of our method also approaches
that of a model that relies on \citet{Lyu2018AMRPA}'s segmentation rules, which
were hand-crafted to handle individual AMR constructions.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 21:22:50 GMT'}]",2020-10-27,"[['Lyu', 'Chunchuan', ''], ['Cohen', 'Shay B.', ''], ['Titov', 'Ivan', '']]"
1369005,2010.12675,David Gaddy,"David Gaddy, Alex Kouzemtchenko, Pavan Kumar Reddy, Prateek Kolhar,
  and Rushin Shah",Overcoming Conflicting Data for Model Updates,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we explore how to use a small amount of new data to update a
model when the desired output for some examples has changed. When making
updates in this way, one potential problem that arises is the presence of
conflicting data, or out-of-date labels in the original training set. To
evaluate the impact of this problem, we propose an experimental setup for
simulating changes to a neural semantic parser. We show that the presence of
conflicting data greatly hinders learning of an update, then explore several
methods to mitigate its effect. Our methods lead to large improvements in model
accuracy compared to a naive mixing strategy, and our best method closes 86% of
the accuracy gap between this baseline and an oracle upper bound.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 21:19:03 GMT'}]",2020-10-27,"[['Gaddy', 'David', ''], ['Kouzemtchenko', 'Alex', ''], ['Reddy', 'Pavan Kumar', ''], ['Kolhar', 'Prateek', ''], ['Shah', 'Rushin', '']]"
1369003,2010.12673,Liang Lu,"Liang Lu, Zhong Meng, Naoyuki Kanda, Jinyu Li, and Yifan Gong","On Minimum Word Error Rate Training of the Hybrid Autoregressive
  Transducer","5 pages, submitted to ICASSP 2021",,,,cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Hybrid Autoregressive Transducer (HAT) is a recently proposed end-to-end
acoustic model that extends the standard Recurrent Neural Network Transducer
(RNN-T) for the purpose of the external language model (LM) fusion. In HAT, the
blank probability and the label probability are estimated using two separate
probability distributions, which provides a more accurate solution for internal
LM score estimation, and thus works better when combining with an external LM.
Previous work mainly focuses on HAT model training with the negative
log-likelihood loss, while in this paper, we study the minimum word error rate
(MWER) training of HAT -- a criterion that is closer to the evaluation metric
for speech recognition, and has been successfully applied to other types of
end-to-end models such as sequence-to-sequence (S2S) and RNN-T models. From
experiments with around 30,000 hours of training data, we show that MWER
training can improve the accuracy of HAT models, while at the same time,
improving the robustness of the model against the decoding hyper-parameters
such as length normalization and decoding beam during inference.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 21:16:30 GMT'}]",2020-10-27,"[['Lu', 'Liang', ''], ['Meng', 'Zhong', ''], ['Kanda', 'Naoyuki', ''], ['Li', 'Jinyu', ''], ['Gong', 'Yifan', '']]"
1368988,2010.12658,Cheng Zhang,"Cheng Zhang, Yicheng Sun, Hejia Chen, Jie Wang",Generating Adequate Distractors for Multiple-Choice Questions,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents a novel approach to automatic generation of adequate
distractors for a given question-answer pair (QAP) generated from a given
article to form an adequate multiple-choice question (MCQ). Our method is a
combination of part-of-speech tagging, named-entity tagging, semantic-role
labeling, regular expressions, domain knowledge bases, word embeddings, word
edit distance, WordNet, and other algorithms. We use the US SAT (Scholastic
Assessment Test) practice reading tests as a dataset to produce QAPs and
generate three distractors for each QAP to form an MCQ. We show that, via
experiments and evaluations by human judges, each MCQ has at least one adequate
distractor and 84\% of MCQs have three adequate distractors.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 20:47:58 GMT'}]",2020-10-27,"[['Zhang', 'Cheng', ''], ['Sun', 'Yicheng', ''], ['Chen', 'Hejia', ''], ['Wang', 'Jie', '']]"
1368982,2010.12652,Orhan Firat,"Mahdis Mahdieh, Mia Xu Chen, Yuan Cao, Orhan Firat",Rapid Domain Adaptation for Machine Translation with Monolingual Data,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  One challenge of machine translation is how to quickly adapt to unseen
domains in face of surging events like COVID-19, in which case timely and
accurate translation of in-domain information into multiple languages is
critical but little parallel data is available yet. In this paper, we propose
an approach that enables rapid domain adaptation from the perspective of
unsupervised translation. Our proposed approach only requires in-domain
monolingual data and can be quickly applied to a preexisting translation system
trained on general domain, reaching significant gains on in-domain translation
quality with little or no drop on general-domain. We also propose an effective
procedure of simultaneous adaptation for multiple domains and languages. To the
best of our knowledge, this is the first attempt that aims to address
unsupervised multilingual domain adaptation.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 20:31:37 GMT'}]",2020-10-27,"[['Mahdieh', 'Mahdis', ''], ['Chen', 'Mia Xu', ''], ['Cao', 'Yuan', ''], ['Firat', 'Orhan', '']]"
1368973,2010.12643,Jacopo Staiano,"Arij Riabi, Thomas Scialom, Rachel Keraron, Beno\^it Sagot, Djam\'e
  Seddah, Jacopo Staiano","Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question
  Answering",7 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Coupled with the availability of large scale datasets, deep learning
architectures have enabled rapid progress on the Question Answering task.
However, most of those datasets are in English, and the performances of
state-of-the-art multilingual models are significantly lower when evaluated on
non-English data. Due to high data collection costs, it is not realistic to
obtain annotated data for each language one desires to support.
  We propose a method to improve the Cross-lingual Question Answering
performance without requiring additional annotated data, leveraging Question
Generation models to produce synthetic samples in a cross-lingual fashion. We
show that the proposed method allows to significantly outperform the baselines
trained on English data only. We report a new state-of-the-art on four
multilingual datasets: MLQA, XQuAD, SQuAD-it and PIAF (fr).
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 20:09:01 GMT'}]",2020-10-27,"[['Riabi', 'Arij', ''], ['Scialom', 'Thomas', ''], ['Keraron', 'Rachel', ''], ['Sagot', 'Benoît', ''], ['Seddah', 'Djamé', ''], ['Staiano', 'Jacopo', '']]"
1368969,2010.12639,Jesse Thomason,"Shurjo Banerjee, Jesse Thomason, Jason J. Corso","The RobotSlang Benchmark: Dialog-guided Robot Localization and
  Navigation",Conference on Robot Learning 2020,,,,cs.RO cs.AI cs.CL cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Autonomous robot systems for applications from search and rescue to assistive
guidance should be able to engage in natural language dialog with people. To
study such cooperative communication, we introduce Robot Simultaneous
Localization and Mapping with Natural Language (RobotSlang), a benchmark of 169
natural language dialogs between a human Driver controlling a robot and a human
Commander providing guidance towards navigation goals. In each trial, the pair
first cooperates to localize the robot on a global map visible to the
Commander, then the Driver follows Commander instructions to move the robot to
a sequence of target objects. We introduce a Localization from Dialog History
(LDH) and a Navigation from Dialog History (NDH) task where a learned agent is
given dialog and visual observations from the robot platform as input and must
localize in the global map or navigate towards the next target object,
respectively. RobotSlang is comprised of nearly 5k utterances and over 1k
minutes of robot camera and control streams. We present an initial model for
the NDH task, and show that an agent trained in simulation can follow the
RobotSlang dialog-based navigation instructions for controlling a physical
robot platform. Code and data are available at https://umrobotslang.github.io/.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 19:58:17 GMT'}]",2020-10-27,"[['Banerjee', 'Shurjo', ''], ['Thomason', 'Jesse', ''], ['Corso', 'Jason J.', '']]"
1368968,2010.12638,Hao Cheng,"Hao Cheng, Xiaodong Liu, Lis Pereira, Yaoliang Yu, Jianfeng Gao","Posterior Differential Regularization with f-divergence for Improving
  Model Robustness",,,,,cs.CL cs.LG stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We address the problem of enhancing model robustness through regularization.
Specifically, we focus on methods that regularize the model posterior
difference between clean and noisy inputs. Theoretically, we provide a
connection of two recent methods, Jacobian Regularization and Virtual
Adversarial Training, under this framework. Additionally, we generalize the
posterior differential regularization to the family of $f$-divergences and
characterize the overall regularization framework in terms of Jacobian matrix.
Empirically, we systematically compare those regularizations and standard BERT
training on a diverse set of tasks to provide a comprehensive profile of their
effect on model in-domain and out-of-domain generalization. For both fully
supervised and semi-supervised settings, our experiments show that regularizing
the posterior differential with $f$-divergence can result in well-improved
model robustness. In particular, with a proper $f$-divergence, a BERT-base
model can achieve comparable generalization as its BERT-large counterpart for
in-domain, adversarial and domain shift scenarios, indicating the great
potential of the proposed framework for boosting model generalization for NLP
models.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 19:58:01 GMT'}]",2020-10-27,"[['Cheng', 'Hao', ''], ['Liu', 'Xiaodong', ''], ['Pereira', 'Lis', ''], ['Yu', 'Yaoliang', ''], ['Gao', 'Jianfeng', '']]"
1368967,2010.12637,Dhivya Chandrasekaran,Dhivya Chandrasekaran and Vijay Mago,Domain Specific Complex Sentence (DCSC) Semantic Similarity Dataset,"12 pages, 4 figures, submitted to ""IEEE Transactions on Knowledge and
  Data Engineering",,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Semantic textual similarity is one of the open research challenges in the
field of Natural Language Processing. Extensive research has been carried out
in this field and near-perfect results are achieved by recent transformed based
models in existing benchmark datasets like STS dataset and SICK dataset. In
this paper, we study the sentences in these datasets and analyze the
sensitivity of various word embeddings with respect to the complexity of the
sentences. We propose a new benchmark dataset -- the Domain Specific Complex
Sentences (DSCS) dataset comprising of 50 sentence pairs with associated
semantic similarity values provided by 15 human annotators. Readability
analysis is performed to highlight the increase in complexity of the sentences
in the existing benchmark datasets and those in the proposed dataset. Further,
we perform a comparative analysis of the performance of various word embeddings
and the results justify the hypothesis that the performance of the word
embeddings decrease with an increase in complexity of the sentences.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 19:55:11 GMT'}]",2020-10-27,"[['Chandrasekaran', 'Dhivya', ''], ['Mago', 'Vijay', '']]"
1368957,2010.12627,Tobias Eder,"Tobias Eder, Viktor Hangya, Alexander Fraser",Anchor-based Bilingual Word Embeddings for Low-Resource Languages,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Bilingual word embeddings (BWEs) are useful for many cross-lingual
applications, such as bilingual lexicon induction (BLI) and cross-lingual
transfer learning. While recent methods have led to good quality BWEs for
different language pairs using only weak bilingual signals, they still rely on
an abundance of monolingual training data in both languages for their
performance. This becomes a problem especially in the case of low resource
languages where neither parallel bilingual corpora nor large monolingual
training data are available. This paper proposes a new approach for building
BWEs in which the vector space of the high resource source language is used as
a starting point for training an embedding space for the low resource target
language. By using the source vectors as anchors the vector spaces are
automatically aligned. We evaluate the resulting BWEs on BLI and show the
proposed method outperforms previous approaches in the low-resource setting by
a large margin. We show strong results on the standard English-German test pair
(using German to simulate low resource). We also show we can build useful BWEs
for English-Hiligaynon, a true low-resource language, where previous approaches
failed.
","[{'version': 'v1', 'created': 'Fri, 23 Oct 2020 19:17:00 GMT'}]",2020-10-27,"[['Eder', 'Tobias', ''], ['Hangya', 'Viktor', ''], ['Fraser', 'Alexander', '']]"
1369270,2010.12940,Arun Kumar Singh,"Sushant Dave, Arun Kumar Singh, Dr. Prathosh A. P. and Prof. Brejesh
  Lall","Neural Compound-Word (Sandhi) Generation and Splitting in Sanskrit
  Language","6 pages, 3 figures, CODS-COMAD 2021, IIIT Bangalore, India",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper describes neural network based approaches to the process of the
formation and splitting of word-compounding, respectively known as the Sandhi
and Vichchhed, in Sanskrit language. Sandhi is an important idea essential to
morphological analysis of Sanskrit texts. Sandhi leads to word transformations
at word boundaries. The rules of Sandhi formation are well defined but complex,
sometimes optional and in some cases, require knowledge about the nature of the
words being compounded. Sandhi split or Vichchhed is an even more difficult
task given its non uniqueness and context dependence. In this work, we propose
the route of formulating the problem as a sequence to sequence prediction task,
using modern deep learning techniques. Being the first fully data driven
technique, we demonstrate that our model has an accuracy better than the
existing methods on multiple standard datasets, despite not using any
additional lexical or morphological resources. The code is being made available
at https://github.com/IITD-DataScience/Sandhi_Prakarana
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 18:02:40 GMT'}]",2020-10-27,"[['Dave', 'Sushant', ''], ['Singh', 'Arun Kumar', ''], ['P.', 'Dr. Prathosh A.', ''], ['Lall', 'Prof. Brejesh', '']]"
1279698,2004.14928,Christos Baziotis,"Christos Baziotis, Barry Haddow, Alexandra Birch",Language Model Prior for Low-Resource Neural Machine Translation,Accepted at EMNLP 2020. Camera-ready version,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The scarcity of large parallel corpora is an important obstacle for neural
machine translation. A common solution is to exploit the knowledge of language
models (LM) trained on abundant monolingual data. In this work, we propose a
novel approach to incorporate a LM as prior in a neural translation model (TM).
Specifically, we add a regularization term, which pushes the output
distributions of the TM to be probable under the LM prior, while avoiding wrong
predictions when the TM ""disagrees"" with the LM. This objective relates to
knowledge distillation, where the LM can be viewed as teaching the TM about the
target language. The proposed approach does not compromise decoding speed,
because the LM is used only at training time, unlike previous work that
requires it during inference. We present an analysis of the effects that
different methods have on the distributions of the TM. Results on two
low-resource machine translation datasets show clear improvements even with
limited monolingual data.
","[{'version': 'v1', 'created': 'Thu, 30 Apr 2020 16:29:56 GMT'}, {'version': 'v2', 'created': 'Wed, 21 Oct 2020 21:39:55 GMT'}, {'version': 'v3', 'created': 'Mon, 26 Oct 2020 08:56:46 GMT'}]",2020-10-27,"[['Baziotis', 'Christos', ''], ['Haddow', 'Barry', ''], ['Birch', 'Alexandra', '']]"
1369971,2010.13641,Timo Schick,"Timo Schick, Helmut Schmid, Hinrich Sch\""utze","Automatically Identifying Words That Can Serve as Labels for Few-Shot
  Text Classification",To appear at COLING 2020,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A recent approach for few-shot text classification is to convert textual
inputs to cloze questions that contain some form of task description, process
them with a pretrained language model and map the predicted words to labels.
Manually defining this mapping between words and labels requires both domain
expertise and an understanding of the language model's abilities. To mitigate
this issue, we devise an approach that automatically finds such a mapping given
small amounts of training data. For a number of tasks, the mapping found by our
approach performs almost as well as hand-crafted label-to-word mappings.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 14:56:22 GMT'}]",2020-10-27,"[['Schick', 'Timo', ''], ['Schmid', 'Helmut', ''], ['Schütze', 'Hinrich', '']]"
1369734,2010.13404,Rifat Rahman,Rifat Rahman,"Robust and Consistent Estimation of Word Embedding for Bangla Language
  by fine-tuning Word2Vec Model","6 pages, 8 figures, submitted to 23rd International Conference of
  Computer and Information Technology (ICCIT). IEEE, 2020",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Word embedding or vector representation of word holds syntactical and
semantic characteristics of word which can be an informative feature for any
machine learning based models of natural language processing. There are several
deep learning based models for the vectorization of words like word2vec,
fasttext, gensim, glove etc. In this study, we analysis word2vec model for
learning word vectors by tuning different hyper-parameters and present the most
effective word embedding for Bangla language. For testing the performances of
different word embeddings induced by fine-tuning of word2vec model, we perform
both intrinsic and extrinsic evaluations. We cluster the word vectors to
examine the relational similarity of words and also use different word
embeddings as the feature of news article classifier for extrinsic evaluation.
From our experiment, we discover that the word vectors with 300 dimension,
generated from 'skip-gram' method of word2vec model using the sliding window
size of 4, are giving the most robust vector representations for Bangla
language.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 08:00:48 GMT'}]",2020-10-27,"[['Rahman', 'Rifat', '']]"
1369745,2010.13415,Yucheng Wang,"Yucheng Wang, Bowen Yu, Yueyang Zhang, Tingwen Liu, Hongsong Zhu and
  Limin Sun","TPLinker: Single-stage Joint Extraction of Entities and Relations
  Through Token Pair Linking",COLING 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Extracting entities and relations from unstructured text has attracted
increasing attention in recent years but remains challenging, due to the
intrinsic difficulty in identifying overlapping relations with shared entities.
Prior works show that joint learning can result in a noticeable performance
gain. However, they usually involve sequential interrelated steps and suffer
from the problem of exposure bias. At training time, they predict with the
ground truth conditions while at inference it has to make extraction from
scratch. This discrepancy leads to error accumulation. To mitigate the issue,
we propose in this paper a one-stage joint extraction model, namely, TPLinker,
which is capable of discovering overlapping relations sharing one or both
entities while immune from the exposure bias. TPLinker formulates joint
extraction as a token pair linking problem and introduces a novel handshaking
tagging scheme that aligns the boundary tokens of entity pairs under each
relation type. Experiment results show that TPLinker performs significantly
better on overlapping and multiple relation extraction, and achieves
state-of-the-art performance on two public datasets.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 08:35:06 GMT'}]",2020-10-27,"[['Wang', 'Yucheng', ''], ['Yu', 'Bowen', ''], ['Zhang', 'Yueyang', ''], ['Liu', 'Tingwen', ''], ['Zhu', 'Hongsong', ''], ['Sun', 'Limin', '']]"
1281590,2005.01795,Kundan Krishna,"Kundan Krishna, Sopan Khosla, Jeffrey P. Bigham, Zachary C. Lipton",Generating SOAP Notes from Doctor-Patient Conversations,,,,,cs.CL cs.AI cs.LG stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Following each patient visit, physicians must draft a detailed clinical
summary called a SOAP note. Moreover, with electronic health records, these
notes must be digitized. Despite the benefits of this documentation, their
creation remains an onerous process, contributing to increasing physician
burnout. In this paper, we present the first study to evaluate complete
pipelines to train summarization models to generate these notes from
conversations between physicians and patients. We benefit from a dataset that,
along with transcripts and paired SOAP notes, consists of annotations marking
noteworthy utterances that support each summary sentence. We decompose the
problem into extractive and abstractive subtasks, exploring a spectrum of
approaches according to how much they demand from each component. We observe
that the performance improves constantly as the extractive subtask is made more
complex - an observation that we also replicate on the well-known AMI meeting
summarization dataset. Our best performing method first (i) extracts noteworthy
utterances via multi-label classification, assigning each to summary
section(s); (ii) clusters noteworthy utterances on a per-section basis; and
(iii) generates the summary sentences by conditioning on the corresponding
cluster and the subsection of the SOAP sentence to be generated. Compared to an
end-to-end approach that generates the full SOAP note from the full
conversation, our approach improves by around 8 ROUGE-1 points.
","[{'version': 'v1', 'created': 'Mon, 4 May 2020 19:10:26 GMT'}, {'version': 'v2', 'created': 'Sat, 24 Oct 2020 04:09:10 GMT'}]",2020-10-27,"[['Krishna', 'Kundan', ''], ['Khosla', 'Sopan', ''], ['Bigham', 'Jeffrey P.', ''], ['Lipton', 'Zachary C.', '']]"
1369845,2010.13515,Andrea Asperti,Andrea Asperti and Stefano Dal Bianco,Syllabification of the Divine Comedy,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We provide a syllabification algorithm for the Divine Comedy using techniques
from probabilistic and constraint programming. We particularly focus on the
synalephe, addressed in terms of the ""propensity"" of a word to take part in a
synalephe with adjacent words. We jointly provide an online vocabulary
containing, for each word, information about its syllabification, the location
of the tonic accent, and the aforementioned synalephe propensity, on the left
and right sides. The algorithm is intrinsically nondeterministic, producing
different possible syllabifications for each verse, with different likelihoods;
metric constraints relative to accents on the 10th, 4th and 6th syllables are
used to further reduce the solution space. The most likely syllabification is
hence returned as output. We believe that this work could be a major milestone
for a lot of different investigations. From the point of view of digital
humanities it opens new perspectives on computer assisted analysis of digital
sources, comprising automated detection of anomalous and problematic cases,
metric clustering of verses and their categorization, or more foundational
investigations addressing e.g. the phonetic roles of consonants and vowels.
From the point of view of text processing and deep learning, information about
syllabification and the location of accents opens a wide range of exciting
perspectives, from the possibility of automatic learning syllabification of
words and verses, to the improvement of generative models, aware of metric
issues, and more respectful of the expected musicality.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 12:14:14 GMT'}]",2020-10-27,"[['Asperti', 'Andrea', ''], ['Bianco', 'Stefano Dal', '']]"
1369874,2010.13544,Zhenzhen Li,"Zhenzhen Li, Jian-Yun Nie, Benyou Wang, Pan Du, Yuhan Zhang, Lixin
  Zou, and Dongsheng Li","Meta-Learning for Neural Relation Classification with Distant
  Supervision","10 pages, 7 figures; corrected one encoding error in CIKM pdf","In Proceedings of CIKM, pp. 815-824. 2020",10.1145/3340531.3412039,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Distant supervision provides a means to create a large number of weakly
labeled data at low cost for relation classification. However, the resulting
labeled instances are very noisy, containing data with wrong labels. Many
approaches have been proposed to select a subset of reliable instances for
neural model training, but they still suffer from noisy labeling problem or
underutilization of the weakly-labeled data. To better select more reliable
training instances, we introduce a small amount of manually labeled data as
reference to guide the selection process. In this paper, we propose a
meta-learning based approach, which learns to reweight noisy training data
under the guidance of reference data. As the clean reference data is usually
very small, we propose to augment it by dynamically distilling the most
reliable elite instances from the noisy data. Experiments on several datasets
demonstrate that the reference data can effectively guide the selection of
training data, and our augmented approach consistently improves the performance
of relation classification comparing to the existing state-of-the-art methods.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 12:52:28 GMT'}]",2020-10-27,"[['Li', 'Zhenzhen', ''], ['Nie', 'Jian-Yun', ''], ['Wang', 'Benyou', ''], ['Du', 'Pan', ''], ['Zhang', 'Yuhan', ''], ['Zou', 'Lixin', ''], ['Li', 'Dongsheng', '']]"
1369886,2010.13556,Yu Zhang,"Yu Zhang, Xiusi Chen, Yu Meng, Jiawei Han","Hierarchical Metadata-Aware Document Categorization under Weak
  Supervision",9 pages; Accepted to WSDM 2021,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Categorizing documents into a given label hierarchy is intuitively appealing
due to the ubiquity of hierarchical topic structures in massive text corpora.
Although related studies have achieved satisfying performance in fully
supervised hierarchical document classification, they usually require massive
human-annotated training data and only utilize text information. However, in
many domains, (1) annotations are quite expensive where very few training
samples can be acquired; (2) documents are accompanied by metadata information.
Hence, this paper studies how to integrate the label hierarchy, metadata, and
text signals for document categorization under weak supervision. We develop
HiMeCat, an embedding-based generative framework for our task. Specifically, we
propose a novel joint representation learning module that allows simultaneous
modeling of category dependencies, metadata information and textual semantics,
and we introduce a data augmentation module that hierarchically synthesizes
training documents to complement the original, small-scale training set. Our
experiments demonstrate a consistent improvement of HiMeCat over competitive
baselines and validate the contribution of our representation learning and data
augmentation modules.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 13:07:56 GMT'}]",2020-10-27,"[['Zhang', 'Yu', ''], ['Chen', 'Xiusi', ''], ['Meng', 'Yu', ''], ['Han', 'Jiawei', '']]"
1369915,2010.13585,Reza Marzban,"Reza Marzban, Christopher John Crick",Interpreting convolutional networks trained on textual data,"9 pages, 6 figures, 5 tables",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  There have been many advances in the artificial intelligence field due to the
emergence of deep learning. In almost all sub-fields, artificial neural
networks have reached or exceeded human-level performance. However, most of the
models are not interpretable. As a result, it is hard to trust their decisions,
especially in life and death scenarios. In recent years, there has been a
movement toward creating explainable artificial intelligence, but most work to
date has concentrated on image processing models, as it is easier for humans to
perceive visual patterns. There has been little work in other fields like
natural language processing. In this paper, we train a convolutional model on
textual data and analyze the global logic of the model by studying its filter
values. In the end, we find the most important words in our corpus to our
models logic and remove the rest (95%). New models trained on just the 5% most
important words can achieve the same performance as the original model while
reducing training time by more than half. Approaches such as this will help us
to understand NLP models, explain their decisions according to their word
choices, and improve them by finding blind spots and biases.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 20:12:05 GMT'}]",2020-10-27,"[['Marzban', 'Reza', ''], ['Crick', 'Christopher John', '']]"
1369918,2010.13588,Ozan Caglayan,"Ozan Caglayan, Pranava Madhyastha, Lucia Specia","Curious Case of Language Generation Evaluation Metrics: A Cautionary
  Tale","7 pages, accepted to COLING 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automatic evaluation of language generation systems is a well-studied problem
in Natural Language Processing. While novel metrics are proposed every year, a
few popular metrics remain as the de facto metrics to evaluate tasks such as
image captioning and machine translation, despite their known limitations. This
is partly due to ease of use, and partly because researchers expect to see them
and know how to interpret them. In this paper, we urge the community for more
careful consideration of how they automatically evaluate their models by
demonstrating important failure cases on multiple datasets, language pairs and
tasks. Our experiments show that metrics (i) usually prefer system outputs to
human-authored texts, (ii) can be insensitive to correct translations of rare
words, (iii) can yield surprisingly high scores when given a single sentence as
system output for the entire test set.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 13:57:20 GMT'}]",2020-10-27,"[['Caglayan', 'Ozan', ''], ['Madhyastha', 'Pranava', ''], ['Specia', 'Lucia', '']]"
1305141,2006.10627,Qian Liu,"Qian Liu, Shengnan An, Jian-Guang Lou, Bei Chen, Zeqi Lin, Yan Gao,
  Bin Zhou, Nanning Zheng, Dongmei Zhang",Compositional Generalization by Learning Analytical Expressions,To appear in NeurIPS 2020 (Spotlight),,,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Compositional generalization is a basic and essential intellective capability
of human beings, which allows us to recombine known parts readily. However,
existing neural network based models have been proven to be extremely deficient
in such a capability. Inspired by work in cognition which argues
compositionality can be captured by variable slots with symbolic functions, we
present a refreshing view that connects a memory-augmented neural model with
analytical expressions, to achieve compositional generalization. Our model
consists of two cooperative neural modules, Composer and Solver, fitting well
with the cognitive argument while being able to be trained in an end-to-end
manner via a hierarchical reinforcement learning algorithm. Experiments on the
well-known benchmark SCAN demonstrate that our model seizes a great ability of
compositional generalization, solving all challenges addressed by previous
works with 100% accuracies.
","[{'version': 'v1', 'created': 'Thu, 18 Jun 2020 15:50:57 GMT'}, {'version': 'v2', 'created': 'Sat, 24 Oct 2020 03:47:49 GMT'}]",2020-10-27,"[['Liu', 'Qian', ''], ['An', 'Shengnan', ''], ['Lou', 'Jian-Guang', ''], ['Chen', 'Bei', ''], ['Lin', 'Zeqi', ''], ['Gao', 'Yan', ''], ['Zhou', 'Bin', ''], ['Zheng', 'Nanning', ''], ['Zhang', 'Dongmei', '']]"
1306638,2006.12124,Anne Wu,"Anne Wu, Changhan Wang, Juan Pino, Jiatao Gu",Self-Supervised Representations Improve End-to-End Speech Translation,Accepted to INTERSPEECH 2020,,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  End-to-end speech-to-text translation can provide a simpler and smaller
system but is facing the challenge of data scarcity. Pre-training methods can
leverage unlabeled data and have been shown to be effective on data-scarce
settings. In this work, we explore whether self-supervised pre-trained speech
representations can benefit the speech translation task in both high- and
low-resource settings, whether they can transfer well to other languages, and
whether they can be effectively combined with other common methods that help
improve low-resource end-to-end speech translation such as using a pre-trained
high-resource speech recognition system. We demonstrate that self-supervised
pre-trained features can consistently improve the translation performance, and
cross-lingual transfer allows to extend to a variety of languages without or
with little tuning.
","[{'version': 'v1', 'created': 'Mon, 22 Jun 2020 10:28:38 GMT'}, {'version': 'v2', 'created': 'Sun, 25 Oct 2020 03:31:15 GMT'}]",2020-10-27,"[['Wu', 'Anne', ''], ['Wang', 'Changhan', ''], ['Pino', 'Juan', ''], ['Gu', 'Jiatao', '']]"
1369967,2010.13637,Peng Gao,"Peng Gao, Fei Shao, Xiaoyuan Liu, Xusheng Xiao, Zheng Qin, Fengyuan
  Xu, Prateek Mittal, Sanjeev R. Kulkarni, Dawn Song",Enabling Efficient Cyber Threat Hunting With Cyber Threat Intelligence,,,,,cs.CR cs.CL cs.DB,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Log-based cyber threat hunting has emerged as an important solution to
counter sophisticated cyber attacks. However, existing approaches require
non-trivial efforts of manual query construction and have overlooked the rich
external knowledge about threat behaviors provided by open-source Cyber Threat
Intelligence (OSCTI). To bridge the gap, we propose EffHunter, a system that
facilitates cyber threat hunting in computer systems using OSCTI. Built upon
mature system auditing frameworks, EffHunter provides (1) an unsupervised,
light-weight, and accurate NLP pipeline that extracts structured threat
behaviors from unstructured OSCTI text, (2) a concise and expressive
domain-specific query language, TBQL, to hunt for malicious system activities,
(3) a query synthesis mechanism that automatically synthesizes a TBQL query for
threat hunting from the extracted threat behaviors, and (4) an efficient query
execution engine to search the big audit logging data. Evaluations on a broad
set of attack cases demonstrate the accuracy and efficiency of EffHunter in
enabling practical threat hunting.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 14:54:01 GMT'}]",2020-10-27,"[['Gao', 'Peng', ''], ['Shao', 'Fei', ''], ['Liu', 'Xiaoyuan', ''], ['Xiao', 'Xusheng', ''], ['Qin', 'Zheng', ''], ['Xu', 'Fengyuan', ''], ['Mittal', 'Prateek', ''], ['Kulkarni', 'Sanjeev R.', ''], ['Song', 'Dawn', '']]"
1369988,2010.13658,Baosong Yang,"Tianchi Bi and Liang Yao and Baosong Yang and Haibo Zhang and Weihua
  Luo and Boxing Chen","Constraint Translation Candidates: A Bridge between Neural Query
  Translation and Cross-lingual Information Retrieval",SIGIR eCom 2020,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Query translation (QT) is a key component in cross-lingual information
retrieval system (CLIR). With the help of deep learning, neural machine
translation (NMT) has shown promising results on various tasks. However, NMT is
generally trained with large-scale out-of-domain data rather than in-domain
query translation pairs. Besides, the translation model lacks a mechanism at
the inference time to guarantee the generated words to match the search index.
The two shortages of QT result in readable texts for human but inadequate
candidates for the downstream retrieval task. In this paper, we propose a novel
approach to alleviate these problems by limiting the open target vocabulary
search space of QT to a set of important words mined from search index
database. The constraint translation candidates are employed at both of
training and inference time, thus guiding the translation model to learn and
generate well performing target queries. The proposed methods are exploited and
examined in a real-word CLIR system--Aliexpress e-Commerce search engine.
Experimental results demonstrate that our approach yields better performance on
both translation quality and retrieval accuracy than the strong NMT baseline.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 15:27:51 GMT'}]",2020-10-27,"[['Bi', 'Tianchi', ''], ['Yao', 'Liang', ''], ['Yang', 'Baosong', ''], ['Zhang', 'Haibo', ''], ['Luo', 'Weihua', ''], ['Chen', 'Boxing', '']]"
1369989,2010.13659,Baosong Yang,"Liang Yao and Baosong Yang and Haibo Zhang and Weihua Luo and Boxing
  Chen","Exploiting Neural Query Translation into Cross Lingual Information
  Retrieval",SIGIR eCom 2020,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As a crucial role in cross-language information retrieval (CLIR), query
translation has three main challenges: 1) the adequacy of translation; 2) the
lack of in-domain parallel training data; and 3) the requisite of low latency.
To this end, existing CLIR systems mainly exploit statistical-based machine
translation (SMT) rather than the advanced neural machine translation (NMT),
limiting the further improvements on both translation and retrieval quality. In
this paper, we investigate how to exploit neural query translation model into
CLIR system. Specifically, we propose a novel data augmentation method that
extracts query translation pairs according to user clickthrough data, thus to
alleviate the problem of domain-adaptation in NMT. Then, we introduce an
asynchronous strategy which is able to leverage the advantages of the real-time
in SMT and the veracity in NMT. Experimental results reveal that the proposed
approach yields better retrieval quality than strong baselines and can be well
applied into a real-world CLIR system, i.e. Aliexpress e-Commerce search
engine. Readers can examine and test their cases on our website:
https://aliexpress.com .
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 15:28:19 GMT'}]",2020-10-27,"[['Yao', 'Liang', ''], ['Yang', 'Baosong', ''], ['Zhang', 'Haibo', ''], ['Luo', 'Weihua', ''], ['Chen', 'Boxing', '']]"
1370004,2010.13674,Christina Niklaus,"Thiemo Wambsganss, Christina Niklaus, Matthias S\""ollner, Siegfried
  Handschuh, Jan Marco Leimeister",A Corpus for Argumentative Writing Support in German,"to be published in The 28th International Conference on Computational
  Linguistics (COLING 2020)",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we present a novel annotation approach to capture claims and
premises of arguments and their relations in student-written persuasive peer
reviews on business models in German language. We propose an annotation scheme
based on annotation guidelines that allows to model claims and premises as well
as support and attack relations for capturing the structure of argumentative
discourse in student-written peer reviews. We conduct an annotation study with
three annotators on 50 persuasive essays to evaluate our annotation scheme. The
obtained inter-rater agreement of $\alpha=0.57$ for argument components and
$\alpha=0.49$ for argumentative relations indicates that the proposed
annotation scheme successfully guides annotators to moderate agreement.
Finally, we present our freely available corpus of 1,000 persuasive
student-written peer reviews on business models and our annotation guidelines
to encourage future research on the design and development of argumentative
writing support systems for students.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 15:52:12 GMT'}]",2020-10-27,"[['Wambsganss', 'Thiemo', ''], ['Niklaus', 'Christina', ''], ['Söllner', 'Matthias', ''], ['Handschuh', 'Siegfried', ''], ['Leimeister', 'Jan Marco', '']]"
1370018,2010.13688,Alexander Kalinowski,"Alexander Kalinowski, Yuan An","A Survey of Embedding Space Alignment Methods for Language and Knowledge
  Graphs","27 pages, 2 figures",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Neural embedding approaches have become a staple in the fields of computer
vision, natural language processing, and more recently, graph analytics. Given
the pervasive nature of these algorithms, the natural question becomes how to
exploit the embedding spaces to map, or align, embeddings of different data
sources. To this end, we survey the current research landscape on word,
sentence and knowledge graph embedding algorithms. We provide a classification
of the relevant alignment techniques and discuss benchmark datasets used in
this field of research. By gathering these diverse approaches into a singular
survey, we hope to further motivate research into alignment of embedding spaces
of varied data types and sources.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 16:08:13 GMT'}]",2020-10-27,"[['Kalinowski', 'Alexander', ''], ['An', 'Yuan', '']]"
1279583,2004.14813,Liying Cheng,"Liying Cheng, Dekun Wu, Lidong Bing, Yan Zhang, Zhanming Jie, Wei Lu,
  Luo Si",ENT-DESC: Entity Description Generation by Exploring Knowledge Graph,"11 pages, 6 figures, accepted by EMNLP 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Previous works on knowledge-to-text generation take as input a few RDF
triples or key-value pairs conveying the knowledge of some entities to generate
a natural language description. Existing datasets, such as WIKIBIO, WebNLG, and
E2E, basically have a good alignment between an input triple/pair set and its
output text. However, in practice, the input knowledge could be more than
enough, since the output description may only cover the most significant
knowledge. In this paper, we introduce a large-scale and challenging dataset to
facilitate the study of such a practical scenario in KG-to-text. Our dataset
involves retrieving abundant knowledge of various types of main entities from a
large knowledge graph (KG), which makes the current graph-to-sequence models
severely suffer from the problems of information loss and parameter explosion
while generating the descriptions. We address these challenges by proposing a
multi-graph structure that is able to represent the original graph information
more comprehensively. Furthermore, we also incorporate aggregation methods that
learn to extract the rich graph information. Extensive experiments demonstrate
the effectiveness of our model architecture.
","[{'version': 'v1', 'created': 'Thu, 30 Apr 2020 14:16:19 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 07:33:32 GMT'}]",2020-10-27,"[['Cheng', 'Liying', ''], ['Wu', 'Dekun', ''], ['Bing', 'Lidong', ''], ['Zhang', 'Yan', ''], ['Jie', 'Zhanming', ''], ['Lu', 'Wei', ''], ['Si', 'Luo', '']]"
1295328,2006.00814,Maha Elbayad,"Maha Elbayad, Michael Ustaszewski, Emmanuelle Esperan\c{c}a-Rodier,
  Francis Brunet Manquat, Laurent Besacier","Online Versus Offline NMT Quality: An In-depth Analysis on
  English-German and German-English",Accepted at COLING 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We conduct in this work an evaluation study comparing offline and online
neural machine translation architectures. Two sequence-to-sequence models:
convolutional Pervasive Attention (Elbayad et al. 2018) and attention-based
Transformer (Vaswani et al. 2017) are considered. We investigate, for both
architectures, the impact of online decoding constraints on the translation
quality through a carefully designed human evaluation on English-German and
German-English language pairs, the latter being particularly sensitive to
latency constraints. The evaluation results allow us to identify the strengths
and shortcomings of each model when we shift to the online setup.
","[{'version': 'v1', 'created': 'Mon, 1 Jun 2020 09:43:54 GMT'}, {'version': 'v2', 'created': 'Sat, 24 Oct 2020 13:36:00 GMT'}]",2020-10-27,"[['Elbayad', 'Maha', ''], ['Ustaszewski', 'Michael', ''], ['Esperança-Rodier', 'Emmanuelle', ''], ['Manquat', 'Francis Brunet', ''], ['Besacier', 'Laurent', '']]"
1369303,2010.12973,Andros Tjandra,"Andros Tjandra, Ruoming Pang, Yu Zhang, Shigeki Karita","Unsupervised Learning of Disentangled Speech Content and Style
  Representation",Submitted to ICASSP 2021,,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present an approach for unsupervised learning of speech representation
disentangling contents and styles. Our model consists of: (1) a local encoder
that captures per-frame information; (2) a global encoder that captures
per-utterance information; and (3) a conditional decoder that reconstructs
speech given local and global latent variables. Our experiments show that (1)
the local latent variables encode speech contents, as reconstructed speech can
be recognized by ASR with low word error rates (WER), even with a different
global encoding; (2) the global latent variables encode speaker style, as
reconstructed speech shares speaker identity with the source utterance of the
global encoding. Additionally, we demonstrate an useful application from our
pre-trained model, where we can train a speaker recognition model from the
global latent variables and achieve high accuracy by fine-tuning with as few
data as one label per speaker.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 20:16:03 GMT'}]",2020-10-27,"[['Tjandra', 'Andros', ''], ['Pang', 'Ruoming', ''], ['Zhang', 'Yu', ''], ['Karita', 'Shigeki', '']]"
1279693,2004.14923,Arturo Oncevay,"Arturo Oncevay, Barry Haddow, Alexandra Birch","Bridging Linguistic Typology and Multilingual Machine Translation with
  Multi-View Language Representations",Accepted at EMNLP 2020. Camera-ready version,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Sparse language vectors from linguistic typology databases and learned
embeddings from tasks like multilingual machine translation have been
investigated in isolation, without analysing how they could benefit from each
other's language characterisation. We propose to fuse both views using singular
vector canonical correlation analysis and study what kind of information is
induced from each source. By inferring typological features and language
phylogenies, we observe that our representations embed typology and strengthen
correlations with language relationships. We then take advantage of our
multi-view language vector space for multilingual machine translation, where we
achieve competitive overall translation accuracy in tasks that require
information about language similarities, such as language clustering and
ranking candidates for multilingual transfer. With our method, which is also
released as a tool, we can easily project and assess new languages without
expensive retraining of massive multilingual or ranking models, which are major
disadvantages of related approaches.
","[{'version': 'v1', 'created': 'Thu, 30 Apr 2020 16:25:39 GMT'}, {'version': 'v2', 'created': 'Sun, 25 Oct 2020 20:51:46 GMT'}]",2020-10-27,"[['Oncevay', 'Arturo', ''], ['Haddow', 'Barry', ''], ['Birch', 'Alexandra', '']]"
1286997,2005.07202,Shoya Wada,"Shoya Wada, Toshihiro Takeda, Shiro Manabe, Shozo Konishi, Jun
  Kamohara, and Yasushi Matsumura","A pre-training technique to localize medical BERT and to enhance
  biomedical BERT","We made the pre-trained weights of ouBioBERT and the source code for
  fine-tuning freely available at
  https://github.com/sy-wada/blue_benchmark_with_transformers",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Bidirectional Encoder Representations from Transformers (BERT) models for
medical specialties, such as BioBERT and clinicalBERT, have significantly
improved in performing biomedical text mining tasks and have enabled extracting
valuable information from biomedical literature; however, only English speakers
benefit due to the significant scarcity of high-quality medical documents, such
as PubMed, in each language. Therefore, we propose a method to train a
high-performance BERT model using a small corpus. We introduce the method to
train a BERT model on a small medical corpus both in English and in Japanese,
and we present the evaluation of each model in terms of the biomedical language
understanding evaluation (BLUE) benchmark and the medical document
classification task in Japanese, respectively. After confirming their
satisfactory performances, we applied our method to develop a model comparable
to the publicly available models. OuBioBERT, short for Bidirectional Encoder
Representations from Transformers for Biomedical Text Mining by Osaka
University, achieved the best score in terms of the BLUE benchmark. The total
score is 1.1 points above that of BioBERT and 0.3 points above that of the
ablated model trained without our proposed method. This proposed technique is
an effective approach to develop localized medical BERT models and to enhance
domain-specific models in the biomedical domain.
","[{'version': 'v1', 'created': 'Thu, 14 May 2020 18:00:01 GMT'}, {'version': 'v2', 'created': 'Sun, 25 Oct 2020 04:22:24 GMT'}]",2020-10-27,"[['Wada', 'Shoya', ''], ['Takeda', 'Toshihiro', ''], ['Manabe', 'Shiro', ''], ['Konishi', 'Shozo', ''], ['Kamohara', 'Jun', ''], ['Matsumura', 'Yasushi', '']]"
1369982,2010.13652,Thomas Winters,"Thomas Winters, Pieter Delobelle",Dutch Humor Detection by Generating Negative Examples,"Accepted at the Proceedings of the 32st Benelux Conference on
  Artificial Intelligence (BNAIC 2020) and the 29th Belgian Dutch Conference on
  Machine Learning (Benelearn 2020)",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Detecting if a text is humorous is a hard task to do computationally, as it
usually requires linguistic and common sense insights. In machine learning,
humor detection is usually modeled as a binary classification task, trained to
predict if the given text is a joke or another type of text. Rather than using
completely different non-humorous texts, we propose using text generation
algorithms for imitating the original joke dataset to increase the difficulty
for the learning algorithm. We constructed several different joke and non-joke
datasets to test the humor detection abilities of different language
technologies. In particular, we compare the humor detection capabilities of
classic neural network approaches with the state-of-the-art Dutch language
model RobBERT. In doing so, we create and compare the first Dutch humor
detection systems. We found that while other language models perform well when
the non-jokes came from completely different domains, RobBERT was the only one
that was able to distinguish jokes from generated negative examples. This
performance illustrates the usefulness of using text generation to create
negative datasets for humor recognition, and also shows that transformer models
are a large step forward in humor detection.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 15:15:10 GMT'}]",2020-10-27,"[['Winters', 'Thomas', ''], ['Delobelle', 'Pieter', '']]"
1369721,2010.13391,Amir Pouran Ben Veyseh,"Amir Pouran Ben Veyseh, Tuan Ngo Nguyen, Thien Huu Nguyen","Graph Transformer Networks with Syntactic and Semantic Structures for
  Event Argument Extraction",accepted at EMNLP 2020 findings,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The goal of Event Argument Extraction (EAE) is to find the role of each
entity mention for a given event trigger word. It has been shown in the
previous works that the syntactic structures of the sentences are helpful for
the deep learning models for EAE. However, a major problem in such prior works
is that they fail to exploit the semantic structures of the sentences to induce
effective representations for EAE. Consequently, in this work, we propose a
novel model for EAE that exploits both syntactic and semantic structures of the
sentences with the Graph Transformer Networks (GTNs) to learn more effective
sentence structures for EAE. In addition, we introduce a novel inductive bias
based on information bottleneck to improve generalization of the EAE models.
Extensive experiments are performed to demonstrate the benefits of the proposed
model, leading to state-of-the-art performance for EAE on standard datasets.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 07:41:40 GMT'}]",2020-10-27,"[['Veyseh', 'Amir Pouran Ben', ''], ['Nguyen', 'Tuan Ngo', ''], ['Nguyen', 'Thien Huu', '']]"
1369787,2010.13457,Henry Turner,"Henry Turner, Giulio Lovisotto and Ivan Martinovic","Speaker Anonymization with Distribution-Preserving X-Vector Generation
  for the VoicePrivacy Challenge 2020",,,,,cs.SD cs.CL cs.CR eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we present a Distribution-Preserving Voice Anonymization
technique, as our submission to the VoicePrivacy Challenge 2020. We notice that
the challenge baseline system generates fake X-vectors which are very similar
to each other, significantly more so than those extracted from organic
speakers. This difference arises from averaging many X-vectors from a pool of
speakers in the anonymization processs, causing a loss of information. We
propose a new method to generate fake X-vectors which overcomes these
limitations by preserving the distributional properties of X-vectors and their
intra-similarity. We use population data to learn the properties of the
X-vector space, before fitting a generative model which we use to sample fake
X-vectors. We show how this approach generates X-vectors that more closely
follow the expected intra-similarity distribution of organic speaker X-vectors.
Our method can be easily integrated with others as the anonymization component
of the system and removes the need to distribute a pool of speakers to use
during the anonymization. Our approach leads to an increase in EER of up to
16.8\% in males and 8.4\% in females in scenarios where enrollment and trial
utterances are anonymized versus the baseline solution, demonstrating the
diversity of our generated voices.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 09:53:56 GMT'}]",2020-10-27,"[['Turner', 'Henry', ''], ['Lovisotto', 'Giulio', ''], ['Martinovic', 'Ivan', '']]"
1369712,2010.13382,Young Jin Kim,Young Jin Kim and Hany Hassan Awadalla,"FastFormers: Highly Efficient Transformer Models for Natural Language
  Understanding",Accepted to SustaiNLP 2020 at EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Transformer-based models are the state-of-the-art for Natural Language
Understanding (NLU) applications. Models are getting bigger and better on
various tasks. However, Transformer models remain computationally challenging
since they are not efficient at inference-time compared to traditional
approaches. In this paper, we present FastFormers, a set of recipes to achieve
efficient inference-time performance for Transformer-based models on various
NLU tasks. We show how carefully utilizing knowledge distillation, structured
pruning and numerical optimization can lead to drastic improvements on
inference efficiency. We provide effective recipes that can guide practitioners
to choose the best settings for various NLU tasks and pretrained models.
Applying the proposed recipes to the SuperGLUE benchmark, we achieve from 9.8x
up to 233.9x speed-up compared to out-of-the-box models on CPU. On GPU, we also
achieve up to 12.4x speed-up with the presented methods. We show that
FastFormers can drastically reduce cost of serving 100 million requests from
4,223 USD to just 18 USD on an Azure F16s_v2 instance. This translates to a
sustainable runtime by reducing energy consumption 6.9x - 125.8x according to
the metrics used in the SustaiNLP 2020 shared task.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 07:25:15 GMT'}]",2020-10-27,"[['Kim', 'Young Jin', ''], ['Awadalla', 'Hany Hassan', '']]"
1369339,2010.13009,Jianguo Zhang,"Jian-Guo Zhang, Kazuma Hashimoto, Wenhao Liu, Chien-Sheng Wu, Yao Wan,
  Philip S. Yu, Richard Socher, Caiming Xiong","Discriminative Nearest Neighbor Few-Shot Intent Detection by
  Transferring Natural Language Inference","19 pages, accepted by EMNLP 2020 main conference as a long paper.
  Code will be available at https://github.com/salesforce/DNNC-few-shot-intent",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Intent detection is one of the core components of goal-oriented dialog
systems, and detecting out-of-scope (OOS) intents is also a practically
important skill. Few-shot learning is attracting much attention to mitigate
data scarcity, but OOS detection becomes even more challenging. In this paper,
we present a simple yet effective approach, discriminative nearest neighbor
classification with deep self-attention. Unlike softmax classifiers, we
leverage BERT-style pairwise encoding to train a binary classifier that
estimates the best matched training example for a user input. We propose to
boost the discriminative ability by transferring a natural language inference
(NLI) model. Our extensive experiments on a large-scale multi-domain intent
detection task show that our method achieves more stable and accurate in-domain
and OOS detection accuracy than RoBERTa-based classifiers and embedding-based
nearest neighbor approaches. More notably, the NLI transfer enables our 10-shot
model to perform competitively with 50-shot or even full-shot classifiers,
while we can keep the inference time constant by leveraging a faster embedding
retrieval model.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 00:39:32 GMT'}]",2020-10-27,"[['Zhang', 'Jian-Guo', ''], ['Hashimoto', 'Kazuma', ''], ['Liu', 'Wenhao', ''], ['Wu', 'Chien-Sheng', ''], ['Wan', 'Yao', ''], ['Yu', 'Philip S.', ''], ['Socher', 'Richard', ''], ['Xiong', 'Caiming', '']]"
1369358,2010.13028,Sayyed Zahiri,Sayyed M. Zahiri and Ali Ahmadvand,"CRAB: Class Representation Attentive BERT for Hate Speech Identification
  in Social Media",,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In recent years, social media platforms have hosted an explosion of hate
speech and objectionable content. The urgent need for effective automatic hate
speech detection models have drawn remarkable investment from companies and
researchers. Social media posts are generally short and their semantics could
drastically be altered by even a single token. Thus, it is crucial for this
task to learn context-aware input representations, and consider relevancy
scores between input embeddings and class representations as an additional
signal. To accommodate these needs, this paper introduces CRAB (Class
Representation Attentive BERT), a neural model for detecting hate speech in
social media. The model benefits from two semantic representations: (i)
trainable token-wise and sentence-wise class representations, and (ii)
contextualized input embeddings from state-of-the-art BERT encoder. To
investigate effectiveness of CRAB, we train our model on Twitter data and
compare it against strong baselines. Our results show that CRAB achieves 1.89%
relative improved Macro-averaged F1 over state-of-the-art baseline. The results
of this research open an opportunity for the future research on automated
abusive behavior detection in social media
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 04:11:30 GMT'}]",2020-10-27,"[['Zahiri', 'Sayyed M.', ''], ['Ahmadvand', 'Ali', '']]"
1328086,2008.00364,Qian Li,"Qian Li, Hao Peng, Jianxin Li, Congying Xia, Renyu Yang, Lichao Sun,
  Philip S. Yu, Lifang He",A Survey on Text Classification: From Shallow to Deep Learning,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Text classification is the most fundamental and essential task in natural
language processing. The last decade has seen a surge of research in this area
due to the unprecedented success of deep learning. Numerous methods, datasets,
and evaluation metrics have been proposed in the literature, raising the need
for a comprehensive and updated survey. This paper fills the gap by reviewing
the state of the art approaches from 1961 to 2020, focusing on models from
shallow to deep learning. We create a taxonomy for text classification
according to the text involved and the models used for feature extraction and
classification. We then discuss each of these categories in detail, dealing
with both the technical developments and benchmark datasets that support tests
of predictions. A comprehensive comparison between different techniques, as
well as identifying the pros and cons of various evaluation metrics are also
provided in this survey. Finally, we conclude by summarizing key implications,
future research directions, and the challenges facing the research area.
","[{'version': 'v1', 'created': 'Sun, 2 Aug 2020 00:09:03 GMT'}, {'version': 'v2', 'created': 'Tue, 4 Aug 2020 06:13:59 GMT'}, {'version': 'v3', 'created': 'Sun, 11 Oct 2020 04:15:57 GMT'}, {'version': 'v4', 'created': 'Tue, 13 Oct 2020 07:05:36 GMT'}, {'version': 'v5', 'created': 'Mon, 26 Oct 2020 02:46:42 GMT'}]",2020-10-27,"[['Li', 'Qian', ''], ['Peng', 'Hao', ''], ['Li', 'Jianxin', ''], ['Xia', 'Congying', ''], ['Yang', 'Renyu', ''], ['Sun', 'Lichao', ''], ['Yu', 'Philip S.', ''], ['He', 'Lifang', '']]"
1369361,2010.13031,Jian Du,"Xiaoying Li, Suyuan Peng, Jian Du","Towards Medical Knowmetrics: Representing and Computing Medical
  Knowledge using Semantic Predications as the Knowledge Unit and the
  Uncertainty as the Knowledge Context",,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  In China, Prof. Hongzhou Zhao and Zeyuan Liu are the pioneers of the concept
""knowledge unit"" and ""knowmetrics"" for measuring knowledge. However, the
definition of ""computable knowledge object"" remains controversial so far in
different fields. For example, it is defined as 1) quantitative scientific
concept in natural science and engineering, 2) knowledge point in the field of
education research, and 3) semantic predications, i.e.,
Subject-Predicate-Object (SPO) triples in biomedical fields. The Semantic
MEDLINE Database (SemMedDB), a high-quality public repository of SPO triples
extracted from medical literature, provides a basic data infrastructure for
measuring medical knowledge. In general, the study of extracting SPO triples as
computable knowledge unit from unstructured scientific text has been
overwhelmingly focusing on scientific knowledge per se. Since the SPO triples
would be possibly extracted from hypothetical, speculative statements or even
conflicting and contradictory assertions, the knowledge status (i.e., the
uncertainty), which serves as an integral and critical part of scientific
knowledge has been largely overlooked. This article aims to put forward a
framework for Medical Knowmetrics using the SPO triples as the knowledge unit
and the uncertainty as the knowledge context. The lung cancer publications
dataset is used to validate the proposed framework. The uncertainty of medical
knowledge and how its status evolves over time indirectly reflect the strength
of competing knowledge claims, and the probability of certainty for a given SPO
triple. We try to discuss the new insights using the uncertainty-centric
approaches to detect research fronts, and identify knowledge claims with high
certainty level, in order to improve the efficacy of knowledge-driven decision
support.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 04:27:43 GMT'}]",2020-10-27,"[['Li', 'Xiaoying', ''], ['Peng', 'Suyuan', ''], ['Du', 'Jian', '']]"
1369370,2010.13040,Zhaoning Li,Zhaoning Li and Jiangtao Ren,Fine-tuning ERNIE for chest abnormal imaging signs extraction,"30 pages, 5 figures, 8 tables",J. Biomed. Inform. 108 (2020),10.1016/j.jbi.2020.103492,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Chest imaging reports describe the results of chest radiography procedures.
Automatic extraction of abnormal imaging signs from chest imaging reports has a
pivotal role in clinical research and a wide range of downstream medical tasks.
However, there are few studies on information extraction from Chinese chest
imaging reports. In this paper, we formulate chest abnormal imaging sign
extraction as a sequence tagging and matching problem. On this basis, we
propose a transferred abnormal imaging signs extractor with pretrained ERNIE as
the backbone, named EASON (fine-tuning ERNIE with CRF for Abnormal Signs
ExtractiON), which can address the problem of data insufficiency. In addition,
to assign the attributes (the body part and degree) to corresponding abnormal
imaging signs from the results of the sequence tagging model, we design a
simple but effective tag2relation algorithm based on the nature of chest
imaging report text. We evaluate our method on the corpus provided by a medical
big data company, and the experimental results demonstrate that our method
achieves significant and consistent improvement compared to other baselines.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 05:18:14 GMT'}]",2020-10-27,"[['Li', 'Zhaoning', ''], ['Ren', 'Jiangtao', '']]"
1369377,2010.13047,Hirofumi Inaguma,"Hirofumi Inaguma, Yosuke Higuchi, Kevin Duh, Tatsuya Kawahara, Shinji
  Watanabe","Orthros: Non-autoregressive End-to-end Speech Translation with
  Dual-decoder",,,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Fast inference speed is an important goal towards real-world deployment of
speech translation (ST) systems. End-to-end (E2E) models based on the
encoder-decoder architecture are more suitable for this goal than traditional
cascaded systems, but their effectiveness regarding decoding speed has not been
explored so far. Inspired by recent progress in non-autoregressive (NAR)
methods in text-based translation, which generates target tokens in parallel by
eliminating conditional dependencies, we study the problem of NAR decoding for
E2E-ST. We propose a novel NAR E2E-ST framework, Orthoros, in which both NAR
and autoregressive (AR) decoders are jointly trained on the shared speech
encoder. The latter is used for selecting better translation among various
length candidates generated from the former, which dramatically improves the
effectiveness of a large length beam with negligible overhead. We further
investigate effective length prediction methods from speech inputs and the
impact of vocabulary sizes. Experiments on four benchmarks show the
effectiveness of the proposed method in improving inference speed while
maintaining competitive translation quality compared to state-of-the-art AR
E2E-ST systems.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 06:35:30 GMT'}]",2020-10-27,"[['Inaguma', 'Hirofumi', ''], ['Higuchi', 'Yosuke', ''], ['Duh', 'Kevin', ''], ['Kawahara', 'Tatsuya', ''], ['Watanabe', 'Shinji', '']]"
1369719,2010.13389,Amir Pouran Ben Veyseh,"Amir Pouran Ben Veyseh, Nasim Nour, Franck Dernoncourt, Quan Hung
  Tran, Dejing Dou, Thien Huu Nguyen","Improving Aspect-based Sentiment Analysis with Gated Graph Convolutional
  Networks and Syntax-based Regulation",accepted at EMNLP 2020 findings,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Aspect-based Sentiment Analysis (ABSA) seeks to predict the sentiment
polarity of a sentence toward a specific aspect. Recently, it has been shown
that dependency trees can be integrated into deep learning models to produce
the state-of-the-art performance for ABSA. However, these models tend to
compute the hidden/representation vectors without considering the aspect terms
and fail to benefit from the overall contextual importance scores of the words
that can be obtained from the dependency tree for ABSA. In this work, we
propose a novel graph-based deep learning model to overcome these two issues of
the prior work on ABSA. In our model, gate vectors are generated from the
representation vectors of the aspect terms to customize the hidden vectors of
the graph-based models toward the aspect terms. In addition, we propose a
mechanism to obtain the importance scores for each word in the sentences based
on the dependency trees that are then injected into the model to improve the
representation vectors for ABSA. The proposed model achieves the
state-of-the-art performance on three benchmark datasets.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 07:36:24 GMT'}]",2020-10-27,"[['Veyseh', 'Amir Pouran Ben', ''], ['Nour', 'Nasim', ''], ['Dernoncourt', 'Franck', ''], ['Tran', 'Quan Hung', ''], ['Dou', 'Dejing', ''], ['Nguyen', 'Thien Huu', '']]"
1369387,2010.13057,Sathvik Nair,"Sathvik Nair, Mahesh Srinivasan, Stephan Meylan","Contextualized Word Embeddings Encode Aspects of Human-Like Word Sense
  Knowledge","To appear in proceedings of the Cognitive Aspects of the Lexicon
  Workshop at the 28th International Conference on Computational Linguistics
  (COLING)",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Understanding context-dependent variation in word meanings is a key aspect of
human language comprehension supported by the lexicon. Lexicographic resources
(e.g., WordNet) capture only some of this context-dependent variation; for
example, they often do not encode how closely senses, or discretized word
meanings, are related to one another. Our work investigates whether recent
advances in NLP, specifically contextualized word embeddings, capture
human-like distinctions between English word senses, such as polysemy and
homonymy. We collect data from a behavioral, web-based experiment, in which
participants provide judgments of the relatedness of multiple WordNet senses of
a word in a two-dimensional spatial arrangement task. We find that
participants' judgments of the relatedness between senses are correlated with
distances between senses in the BERT embedding space. Homonymous senses (e.g.,
bat as mammal vs. bat as sports equipment) are reliably more distant from one
another in the embedding space than polysemous ones (e.g., chicken as animal
vs. chicken as meat). Our findings point towards the potential utility of
continuous-space representations of sense meanings.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 07:56:52 GMT'}]",2020-10-27,"[['Nair', 'Sathvik', ''], ['Srinivasan', 'Mahesh', ''], ['Meylan', 'Stephan', '']]"
1369392,2010.13062,Zhixiang Li,"Mengzhe Li, Yudan Wang, Ying Zhao and Zhixiang Li","Transgender Community Sentiment Analysis from Social Media Data: A
  Natural Language Processing Approach","5 pages, 1 figures",,,,cs.CL,http://creativecommons.org/publicdomain/zero/1.0/,"  Transgender community is experiencing a huge disparity in mental health
conditions compared with the general population. Interpreting the social medial
data posted by transgender people may help us understand the sentiments of
these sexual minority groups better and apply early interventions. In this
study, we manually categorize 300 social media comments posted by transgender
people to the sentiment of negative, positive, and neutral. 5 machine learning
algorithms and 2 deep neural networks are adopted to build sentiment analysis
classifiers based on the annotated data. Results show that our annotations are
reliable with a high Cohen's Kappa score over 0.8 across all three classes.
LSTM model yields an optimal performance of accuracy over 0.85 and AUC of
0.876. Our next step will focus on using advanced natural language processing
algorithms on a larger annotated dataset.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 08:13:34 GMT'}]",2020-10-27,"[['Li', 'Mengzhe', ''], ['Wang', 'Yudan', ''], ['Zhao', 'Ying', ''], ['Li', 'Zhixiang', '']]"
1369379,2010.13049,Gongqi Lin,"Gongqi Lin, Yuan Miao, Xiaoyong Yang, Wenwu Ou, Lizhen Cui, Wei Guo,
  Chunyan Miao",Commonsense knowledge adversarial dataset that challenges ELECTRA,To appear in ICARCV2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Commonsense knowledge is critical in human reading comprehension. While
machine comprehension has made significant progress in recent years, the
ability in handling commonsense knowledge remains limited. Synonyms are one of
the most widely used commonsense knowledge. Constructing adversarial dataset is
an important approach to find weak points of machine comprehension models and
support the design of solutions. To investigate machine comprehension models'
ability in handling the commonsense knowledge, we created a Question and Answer
Dataset with common knowledge of Synonyms (QADS). QADS are questions generated
based on SQuAD 2.0 by applying commonsense knowledge of synonyms. The synonyms
are extracted from WordNet. Words often have multiple meanings and synonyms. We
used an enhanced Lesk algorithm to perform word sense disambiguation to
identify synonyms for the context. ELECTRA achieves the state-of-art result on
the SQuAD 2.0 dataset in 2019. With scale, ELECTRA can achieve similar
performance as BERT does. However, QADS shows that ELECTRA has little ability
to handle commonsense knowledge of synonyms. In our experiment, ELECTRA-small
can achieve 70% accuracy on SQuAD 2.0, but only 20% on QADS. ELECTRA-large did
not perform much better. Its accuracy on SQuAD 2.0 is 88% but dropped
significantly to 26% on QADS. In our earlier experiments, BERT, although also
failed badly on QADS, was not as bad as ELECTRA. The result shows that even
top-performing NLP models have little ability to handle commonsense knowledge
which is essential in reading comprehension.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 07:17:45 GMT'}]",2020-10-27,"[['Lin', 'Gongqi', ''], ['Miao', 'Yuan', ''], ['Yang', 'Xiaoyong', ''], ['Ou', 'Wenwu', ''], ['Cui', 'Lizhen', ''], ['Guo', 'Wei', ''], ['Miao', 'Chunyan', '']]"
1369600,2010.13270,Yosuke Higuchi,"Yosuke Higuchi, Hirofumi Inaguma, Shinji Watanabe, Tetsuji Ogawa,
  Tetsunori Kobayashi",Improved Mask-CTC for Non-Autoregressive End-to-End ASR,Submitted to ICASSP2021,,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  For real-world deployment of automatic speech recognition (ASR), the system
is desired to be capable of fast inference while relieving the requirement of
computational resources. The recently proposed end-to-end ASR system based on
mask-predict with connectionist temporal classification (CTC), Mask-CTC,
fulfills this demand by generating tokens in a non-autoregressive fashion.
While Mask-CTC achieves remarkably fast inference speed, its recognition
performance falls behind that of conventional autoregressive (AR) systems. To
boost the performance of Mask-CTC, we first propose to enhance the encoder
network architecture by employing a recently proposed architecture called
Conformer. Next, we propose new training and decoding methods by introducing
auxiliary objective to predict the length of a partial target sequence, which
allows the model to delete or insert tokens during inference. Experimental
results on different ASR tasks show that the proposed approaches improve
Mask-CTC significantly, outperforming a standard CTC model (15.5% $\rightarrow$
9.1% WER on WSJ). Moreover, Mask-CTC now achieves competitive results to AR
models with no degradation of inference speed ($<$ 0.1 RTF using CPU). We also
show a potential application of Mask-CTC to end-to-end speech translation.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 01:22:35 GMT'}]",2020-10-27,"[['Higuchi', 'Yosuke', ''], ['Inaguma', 'Hirofumi', ''], ['Watanabe', 'Shinji', ''], ['Ogawa', 'Tetsuji', ''], ['Kobayashi', 'Tetsunori', '']]"
1321824,2007.10310,Changhan Wang,"Changhan Wang, Anne Wu, Juan Pino",CoVoST 2 and Massively Multilingual Speech-to-Text Translation,,,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Speech translation has recently become an increasingly popular topic of
research, partly due to the development of benchmark datasets. Nevertheless,
current datasets cover a limited number of languages. With the aim to foster
research in massive multilingual speech translation and speech translation for
low resource language pairs, we release CoVoST 2, a large-scale multilingual
speech translation corpus covering translations from 21 languages into English
and from English into 15 languages. This represents the largest open dataset
available to date from total volume and language coverage perspective. Data
sanity checks provide evidence about the quality of the data, which is released
under CC0 license. We also provide extensive speech recognition, bilingual and
multilingual machine translation and speech translation baselines with
open-source implementation.
","[{'version': 'v1', 'created': 'Mon, 20 Jul 2020 17:53:35 GMT'}, {'version': 'v2', 'created': 'Thu, 20 Aug 2020 17:53:10 GMT'}, {'version': 'v3', 'created': 'Sat, 24 Oct 2020 06:07:01 GMT'}]",2020-10-27,"[['Wang', 'Changhan', ''], ['Wu', 'Anne', ''], ['Pino', 'Juan', '']]"
1369708,2010.13378,Amir Pouran Ben Veyseh,"Amir Pouran Ben Veyseh, Nasim Nouri, Franck Dernoncourt, Dejing Dou,
  Thien Huu Nguyen","Introducing Syntactic Structures into Target Opinion Word Extraction
  with Deep Learning",accepted at EMNLP 2020 main conference,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Targeted opinion word extraction (TOWE) is a sub-task of aspect based
sentiment analysis (ABSA) which aims to find the opinion words for a given
aspect-term in a sentence. Despite their success for TOWE, the current deep
learning models fail to exploit the syntactic information of the sentences that
have been proved to be useful for TOWE in the prior research. In this work, we
propose to incorporate the syntactic structures of the sentences into the deep
learning models for TOWE, leveraging the syntax-based opinion possibility
scores and the syntactic connections between the words. We also introduce a
novel regularization technique to improve the performance of the deep learning
models based on the representation distinctions between the words in TOWE. The
proposed model is extensively analyzed and achieves the state-of-the-art
performance on four benchmark datasets.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 07:13:17 GMT'}]",2020-10-27,"[['Veyseh', 'Amir Pouran Ben', ''], ['Nouri', 'Nasim', ''], ['Dernoncourt', 'Franck', ''], ['Dou', 'Dejing', ''], ['Nguyen', 'Thien Huu', '']]"
1274534,2004.09764,Fang Xianghong,"Xianghong Fang and Haoli Bai and Zenglin Xu and Michael Lyu and Irwin
  King",Discrete Auto-regressive Variational Attention Models for Text Modeling,"10 pages, 4 figures",,,,cs.LG cs.CL stat.ML,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Variational autoencoders (VAEs) have been widely applied for text modeling.
In practice, however, they are troubled by two challenges: information
underrepresentation and posterior collapse. The former arises as only the last
hidden state of LSTM encoder is transformed into the latent space, which is
generally insufficient to summarize the data. The latter is a long-standing
problem during the training of VAEs as the optimization is trapped to a
disastrous local optimum. In this paper, we propose Discrete Auto-regressive
Variational Attention Model (DAVAM) to address the challenges. Specifically, we
introduce an auto-regressive variational attention approach to enrich the
latent space by effectively capturing the semantic dependency from the input.
We further design discrete latent space for the variational attention and
mathematically show that our model is free from posterior collapse. Extensive
experiments on language modeling tasks demonstrate the superiority of DAVAM
against several VAE counterparts.
","[{'version': 'v1', 'created': 'Tue, 21 Apr 2020 05:49:04 GMT'}, {'version': 'v2', 'created': 'Sun, 25 Oct 2020 08:02:24 GMT'}]",2020-10-27,"[['Fang', 'Xianghong', ''], ['Bai', 'Haoli', ''], ['Xu', 'Zenglin', ''], ['Lyu', 'Michael', ''], ['King', 'Irwin', '']]"
1326856,2007.15342,Ramon Ferrer i Cancho,"Ramon Ferrer-i-Cancho, Carlos G\'omez-Rodr\'iguez, Juan Luis Esteban
  and Llu\'is Alemany-Puig",The optimality of syntactic dependency distances,"results on the zeta score have been corrected; format of the article
  has changed; some figures/tables have been resized; typos corrected",,,,cs.CL cs.DM physics.soc-ph,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  It is often stated that human languages, as other biological systems, are
shaped by cost-cutting pressures but, to what extent? Attempts to quantify the
degree of optimality of languages by means of an optimality score have been
scarce and focused mostly on English. Here we recast the problem of the
optimality of the word order of a sentence as an optimization problem on a
spatial network where the vertices are words, arcs indicate syntactic
dependencies and the space is defined by the linear order of the words in the
sentence. We introduce a new score to quantify the cognitive pressure to reduce
the distance between linked words in a sentence. The analysis of sentences from
93 languages representing 19 linguistic families reveals that half of languages
are optimized to a 70% or more. The score indicates that distances are not
significantly reduced in a few languages and confirms two theoretical
predictions, i.e. that longer sentences are more optimized and that distances
are more likely to be longer than expected by chance in short sentences. We
present a new hierarchical ranking of languages by their degree of
optimization. The statistical advantages of the new score call for a
reevaluation of the evolution of dependency distance over time in languages as
well as the relationship between dependency distance and linguistic competence.
Finally, the principles behind the design of the score can be extended to
develop more powerful normalizations of topological distances or physical
distances in more dimensions.
","[{'version': 'v1', 'created': 'Thu, 30 Jul 2020 09:40:41 GMT'}, {'version': 'v2', 'created': 'Sun, 25 Oct 2020 22:15:22 GMT'}]",2020-10-27,"[['Ferrer-i-Cancho', 'Ramon', ''], ['Gómez-Rodríguez', 'Carlos', ''], ['Esteban', 'Juan Luis', ''], ['Alemany-Puig', 'Lluís', '']]"
1369522,2010.13192,Alexandra Chronopoulou,"Alexandra Chronopoulou, Dario Stojanovski, Viktor Hangya, Alexander
  Fraser","The LMU Munich System for the WMT 2020 Unsupervised Machine Translation
  Shared Task",WMT Unsupervised Shared Task 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper describes the submission of LMU Munich to the WMT 2020
unsupervised shared task, in two language directions, German<->Upper Sorbian.
Our core unsupervised neural machine translation (UNMT) system follows the
strategy of Chronopoulou et al. (2020), using a monolingual pretrained language
generation model (on German) and fine-tuning it on both German and Upper
Sorbian, before initializing a UNMT model, which is trained with online
backtranslation. Pseudo-parallel data obtained from an unsupervised statistical
machine translation (USMT) system is used to fine-tune the UNMT model. We also
apply BPE-Dropout to the low resource (Upper Sorbian) data to obtain a more
robust system. We additionally experiment with residual adapters and find them
useful in the Upper Sorbian->German direction. We explore sampling during
backtranslation and curriculum learning to use SMT translations in a more
principled way. Finally, we ensemble our best-performing systems and reach a
BLEU score of 32.4 on German->Upper Sorbian and 35.2 on Upper Sorbian->German.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 19:04:03 GMT'}]",2020-10-27,"[['Chronopoulou', 'Alexandra', ''], ['Stojanovski', 'Dario', ''], ['Hangya', 'Viktor', ''], ['Fraser', 'Alexander', '']]"
1280356,2005.00561,Anna Rogers,"Sai Prasanna, Anna Rogers, Anna Rumshisky","When BERT Plays the Lottery, All Tickets Are Winning",EMNLP 2020 camera-ready,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Transformer-based models were shown to be reducible to a smaller number
of self-attention heads and layers. We consider this phenomenon from the
perspective of the lottery ticket hypothesis, using both structured and
magnitude pruning. For fine-tuned BERT, we show that (a) it is possible to find
subnetworks achieving performance that is comparable with that of the full
model, and (b) similarly-sized subnetworks sampled from the rest of the model
perform worse. Strikingly, with structured pruning even the worst possible
subnetworks remain highly trainable, indicating that most pre-trained BERT
weights are potentially useful. We also study the ""good"" subnetworks to see if
their success can be attributed to superior linguistic knowledge, but find them
unstable, and not explained by meaningful self-attention patterns.
","[{'version': 'v1', 'created': 'Fri, 1 May 2020 18:24:42 GMT'}, {'version': 'v2', 'created': 'Sat, 24 Oct 2020 10:15:27 GMT'}]",2020-10-27,"[['Prasanna', 'Sai', ''], ['Rogers', 'Anna', ''], ['Rumshisky', 'Anna', '']]"
1369498,2010.13168,Tenzin Singhay Bhotia,"Vaibhav Kumar, Tenzin Singhay Bhotia, Vaibhav Kumar","Fair Embedding Engine: A Library for Analyzing and Mitigating Gender
  Bias in Word Embeddings","6 pages, 3 figures",,,,cs.CL cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Non-contextual word embedding models have been shown to inherit human-like
stereotypical biases of gender, race and religion from the training corpora. To
counter this issue, a large body of research has emerged which aims to mitigate
these biases while keeping the syntactic and semantic utility of embeddings
intact. This paper describes Fair Embedding Engine (FEE), a library for
analysing and mitigating gender bias in word embeddings. FEE combines various
state of the art techniques for quantifying, visualising and mitigating gender
bias in word embeddings under a standard abstraction. FEE will aid
practitioners in fast track analysis of existing debiasing methods on their
embedding models. Further, it will allow rapid prototyping of new methods by
evaluating their performance on a suite of standard metrics.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 17:31:12 GMT'}]",2020-10-27,"[['Kumar', 'Vaibhav', ''], ['Bhotia', 'Tenzin Singhay', ''], ['Kumar', 'Vaibhav', '']]"
1369458,2010.13128,Mokanarangan Thayaparan,"Mokanarangan Thayaparan, Marco Valentino, Andr\'e Freitas","ExplanationLP: Abductive Reasoning for Explainable Science Question
  Answering",,,,,cs.AI cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a novel approach for answering and explaining multiple-choice
science questions by reasoning on grounding and abstract inference chains. This
paper frames question answering as an abductive reasoning problem, constructing
plausible explanations for each choice and then selecting the candidate with
the best explanation as the final answer. Our system, ExplanationLP, elicits
explanations by constructing a weighted graph of relevant facts for each
candidate answer and extracting the facts that satisfy certain structural and
semantic constraints. To extract the explanations, we employ a linear
programming formalism designed to select the optimal subgraph. The graphs'
weighting function is composed of a set of parameters, which we fine-tune to
optimize answer selection performance. We carry out our experiments on the
WorldTree and ARC-Challenge corpus to empirically demonstrate the following
conclusions: (1) Grounding-Abstract inference chains provides the semantic
control to perform explainable abductive reasoning (2) Efficiency and
robustness in learning with a fewer number of parameters by outperforming
contemporary explainable and transformer-based approaches in a similar setting
(3) Generalisability by outperforming SOTA explainable approaches on general
science question sets.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 14:49:24 GMT'}]",2020-10-27,"[['Thayaparan', 'Mokanarangan', ''], ['Valentino', 'Marco', ''], ['Freitas', 'André', '']]"
1369435,2010.13105,Gyuwan Kim,"Seongbin Kim, Gyuwan Kim, Seongjin Shin, Sangmin Lee","Two-stage Textual Knowledge Distillation to Speech Encoder for Spoken
  Language Understanding","Preprint; 5 pages, 1 figure",,,,cs.CL cs.LG cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  End-to-end approaches open a new way for more accurate and efficient spoken
language understanding (SLU) systems by alleviating the drawbacks of
traditional pipeline systems. Previous works exploit textual information for an
SLU model via pre-training with automatic speech recognition or fine-tuning
with knowledge distillation. To utilize textual information more effectively,
this work proposes a two-stage textual knowledge distillation method that
matches utterance-level representations and predicted logits of two modalities
during pre-training and fine-tuning, sequentially. We use vq-wav2vec BERT as a
speech encoder because it captures general and rich features. Furthermore, we
improve the performance, especially in a low-resource scenario, with data
augmentation methods by randomly masking spans of discrete audio tokens and
contextualized hidden representations. Consequently, we push the
state-of-the-art on the Fluent Speech Commands, achieving 99.7% test accuracy
in the full dataset setting and 99.5% in the 10% subset setting. Throughout the
ablation studies, we empirically verify that all used methods are crucial to
the final performance, providing the best practice for spoken language
understanding. Code to reproduce our results will be available upon
publication.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 12:36:05 GMT'}]",2020-10-27,"[['Kim', 'Seongbin', ''], ['Kim', 'Gyuwan', ''], ['Shin', 'Seongjin', ''], ['Lee', 'Sangmin', '']]"
1267434,2004.02664,Qingyu Zhou,"Qingyu Zhou, Furu Wei, Ming Zhou","At Which Level Should We Extract? An Empirical Analysis on Extractive
  Document Summarization",To appear at COLING 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Extractive methods have been proven effective in automatic document
summarization. Previous works perform this task by identifying informative
contents at sentence level. However, it is unclear whether performing
extraction at sentence level is the best solution. In this work, we show that
unnecessity and redundancy issues exist when extracting full sentences, and
extracting sub-sentential units is a promising alternative. Specifically, we
propose extracting sub-sentential units based on the constituency parsing tree.
A neural extractive model which leverages the sub-sentential information and
extracts them is presented. Extensive experiments and analyses show that
extracting sub-sentential units performs competitively comparing to full
sentence extraction under the evaluation of both automatic and human
evaluations. Hopefully, our work could provide some inspiration of the basic
extraction units in extractive summarization for future research.
","[{'version': 'v1', 'created': 'Mon, 6 Apr 2020 13:35:10 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 08:35:19 GMT'}]",2020-10-27,"[['Zhou', 'Qingyu', ''], ['Wei', 'Furu', ''], ['Zhou', 'Ming', '']]"
1370795,2010.14465,Marta R. Costa-juss\`a,Marta R. Costa-juss\`a and Christine Basta and Gerard I. G\'allego,Evaluating Gender Bias in Speech Translation,"Preprint, Submitted to ICASSP 2021",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The scientific community is more and more aware of the necessity to embrace
pluralism and consistently represent major and minor social groups. In this
direction, there is an urgent need to provide evaluation sets and protocols to
measure existing biases in our automatic systems. This paper introduces WinoST,
a new freely available challenge set for evaluating gender bias in speech
translation. WinoST is the speech version of WinoMT which is an MT challenge
set and both follow an evaluation protocol to measure gender accuracy. Using a
state-of-the-art end-to-end speech translation system, we report the gender
bias evaluation on 4 language pairs, and we show that gender accuracy in speech
translation is more than 23% lower than in MT.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 17:24:27 GMT'}]",2020-10-28,"[['Costa-jussà', 'Marta R.', ''], ['Basta', 'Christine', ''], ['Gállego', 'Gerard I.', '']]"
1370809,2010.14479,Sugat Chaturvedi,"Rochana Chaturvedi, Sugat Chaturvedi",It's All in the Name: A Character Based Approach To Infer Religion,,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Demographic inference from text has received a surge of attention in the
field of natural language processing in the last decade. In this paper, we use
personal names to infer religion in South Asia - where religion is a salient
social division, and yet, disaggregated data on it remains scarce. Existing
work predicts religion using dictionary based method, and therefore, can not
classify unseen names. We use character based models which learn character
patterns and, therefore, can classify unseen names as well with high accuracy.
These models are also much faster and can easily be scaled to large data sets.
We improve our classifier by combining the name of an individual with that of
their parent/spouse and achieve remarkably high accuracy. Finally, we trace the
classification decisions of a convolutional neural network model using
layer-wise relevance propagation which can explain the predictions of complex
non-linear classifiers and circumvent their purported black box nature. We show
how character patterns learned by the classifier are rooted in the linguistic
origins of names.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 17:38:11 GMT'}]",2020-10-28,"[['Chaturvedi', 'Rochana', ''], ['Chaturvedi', 'Sugat', '']]"
960680,1803.10547,Nurendra Choudhary,"Nurendra Choudhary, Rajat Singh, Ishita Bindlish and Manish
  Shrivastava",Neural Network Architecture for Credibility Assessment of Textual Claims,"Best Paper Award at 19th International Conference on Computational
  Linguistics and Intelligent Text Processing, March 2018, Hanoi, Vietnam",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Text articles with false claims, especially news, have recently become
aggravating for the Internet users. These articles are in wide circulation and
readers face difficulty discerning fact from fiction. Previous work on
credibility assessment has focused on factual analysis and linguistic features.
The task's main challenge is the distinction between the features of true and
false articles. In this paper, we propose a novel approach called Credibility
Outcome (CREDO) which aims at scoring the credibility of an article in an open
domain setting.
  CREDO consists of different modules for capturing various features
responsible for the credibility of an article. These features includes
credibility of the article's source and author, semantic similarity between the
article and related credible articles retrieved from a knowledge base, and
sentiments conveyed by the article. A neural network architecture learns the
contribution of each of these modules to the overall credibility of an article.
Experiments on Snopes dataset reveals that CREDO outperforms the
state-of-the-art approaches based on linguistic features.
","[{'version': 'v1', 'created': 'Wed, 28 Mar 2018 11:50:32 GMT'}, {'version': 'v2', 'created': 'Fri, 30 Mar 2018 10:42:04 GMT'}, {'version': 'v3', 'created': 'Mon, 26 Oct 2020 21:30:25 GMT'}]",2020-10-28,"[['Choudhary', 'Nurendra', ''], ['Singh', 'Rajat', ''], ['Bindlish', 'Ishita', ''], ['Shrivastava', 'Manish', '']]"
1370811,2010.14481,Biao Zhang,"Biao Zhang, Ivan Titov, Rico Sennrich",Fast Interleaved Bidirectional Sequence Generation,"WMT2020, source code is at
  https://github.com/bzhangGo/zero/tree/master/docs/interleaved_bidirectional_transformer",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Independence assumptions during sequence generation can speed up inference,
but parallel generation of highly inter-dependent tokens comes at a cost in
quality. Instead of assuming independence between neighbouring tokens
(semi-autoregressive decoding, SA), we take inspiration from bidirectional
sequence generation and introduce a decoder that generates target words from
the left-to-right and right-to-left directions simultaneously. We show that we
can easily convert a standard architecture for unidirectional decoding into a
bidirectional decoder by simply interleaving the two directions and adapting
the word positions and self-attention masks. Our interleaved bidirectional
decoder (IBDecoder) retains the model simplicity and training efficiency of the
standard Transformer, and on five machine translation tasks and two document
summarization tasks, achieves a decoding speedup of ~2X compared to
autoregressive decoding with comparable quality. Notably, it outperforms
left-to-right SA because the independence assumptions in IBDecoder are more
felicitous. To achieve even higher speedups, we explore hybrid models where we
either simultaneously predict multiple neighbouring tokens per direction, or
perform multi-directional decoding by partitioning the target sequence. These
methods achieve speedups to 4X-11X across different tasks at the cost of <1
BLEU or <0.5 ROUGE (on average). Source code is released at
https://github.com/bzhangGo/zero.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 17:38:51 GMT'}]",2020-10-28,"[['Zhang', 'Biao', ''], ['Titov', 'Ivan', ''], ['Sennrich', 'Rico', '']]"
1246301,2002.08878,Clement Moulin-Frier,Cl\'ement Moulin-Frier and Pierre-Yves Oudeyer,"Multi-Agent Reinforcement Learning as a Computational Tool for Language
  Evolution Research: Historical Context and Future Challenges",,"Challenges and Opportunities for Multi-Agent Reinforcement
  Learning (COMARL AAAI 2020-2021), AAAI Spring Symposium Series, Stanford
  University, Palo Alto, California, USA",,,cs.MA cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Computational models of emergent communication in agent populations are
currently gaining interest in the machine learning community due to recent
advances in Multi-Agent Reinforcement Learning (MARL). Current contributions
are however still relatively disconnected from the earlier theoretical and
computational literature aiming at understanding how language might have
emerged from a prelinguistic substance. The goal of this paper is to position
recent MARL contributions within the historical context of language evolution
research, as well as to extract from this theoretical and computational
background a few challenges for future research.
","[{'version': 'v1', 'created': 'Thu, 20 Feb 2020 17:26:46 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 13:54:46 GMT'}]",2020-10-28,"[['Moulin-Frier', 'Clément', ''], ['Oudeyer', 'Pierre-Yves', '']]"
1352508,2009.11005,Khang Nguyen,Khang Phuoc-Quy Nguyen and Kiet Van Nguyen,"Exploiting Vietnamese Social Media Characteristics for Textual Emotion
  Recognition in Vietnamese","6 pages, 9 tables, 2 figures of table, conference",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Textual emotion recognition has been a promising research topic in recent
years. Many researchers aim to build more accurate and robust emotion detection
systems. In this paper, we conduct several experiments to indicate how data
pre-processing affects a machine learning method on textual emotion
recognition. These experiments are performed on the Vietnamese Social Media
Emotion Corpus (UIT-VSMEC) as the benchmark dataset. We explore Vietnamese
social media characteristics to propose different pre-processing techniques,
and key-clause extraction with emotional context to improve the machine
performance on UIT-VSMEC. Our experimental evaluation shows that with
appropriate pre-processing techniques based on Vietnamese social media
characteristics, Multinomial Logistic Regression (MLR) achieves the best
F1-score of 64.40%, a significant improvement of 4.66% over the CNN model built
by the authors of UIT-VSMEC (59.74%).
","[{'version': 'v1', 'created': 'Wed, 23 Sep 2020 08:49:39 GMT'}, {'version': 'v2', 'created': 'Fri, 25 Sep 2020 15:46:49 GMT'}, {'version': 'v3', 'created': 'Tue, 27 Oct 2020 14:39:40 GMT'}]",2020-10-28,"[['Nguyen', 'Khang Phuoc-Quy', ''], ['Van Nguyen', 'Kiet', '']]"
1280128,2005.00333,Edoardo Maria Ponti,"Edoardo Maria Ponti, Goran Glava\v{s}, Olga Majewska, Qianchu Liu,
  Ivan Vuli\'c and Anna Korhonen",XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In order to simulate human language capacity, natural language processing
systems must be able to reason about the dynamics of everyday situations,
including their possible causes and effects. Moreover, they should be able to
generalise the acquired world knowledge to new languages, modulo cultural
differences. Advances in machine reasoning and cross-lingual transfer depend on
the availability of challenging evaluation benchmarks. Motivated by both
demands, we introduce Cross-lingual Choice of Plausible Alternatives (XCOPA), a
typologically diverse multilingual dataset for causal commonsense reasoning in
11 languages, which includes resource-poor languages like Eastern Apur\'imac
Quechua and Haitian Creole. We evaluate a range of state-of-the-art models on
this novel dataset, revealing that the performance of current methods based on
multilingual pretraining and zero-shot fine-tuning falls short compared to
translation-based transfer. Finally, we propose strategies to adapt
multilingual models to out-of-sample resource-lean languages where only a small
corpus or a bilingual dictionary is available, and report substantial
improvements over the random baseline. The XCOPA dataset is freely available at
github.com/cambridgeltl/xcopa.
","[{'version': 'v1', 'created': 'Fri, 1 May 2020 12:22:33 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 23:23:58 GMT'}]",2020-10-28,"[['Ponti', 'Edoardo Maria', ''], ['Glavaš', 'Goran', ''], ['Majewska', 'Olga', ''], ['Liu', 'Qianchu', ''], ['Vulić', 'Ivan', ''], ['Korhonen', 'Anna', '']]"
1353816,2009.12313,Iacer Calixto,Victor Milewski and Marie-Francine Moens and Iacer Calixto,Are scene graphs good enough to improve Image Captioning?,"Published at AACL-IJCNLP 2020. 12 pages, 5 figures",,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Many top-performing image captioning models rely solely on object features
computed with an object detection model to generate image descriptions.
However, recent studies propose to directly use scene graphs to introduce
information about object relations into captioning, hoping to better describe
interactions between objects. In this work, we thoroughly investigate the use
of scene graphs in image captioning. We empirically study whether using
additional scene graph encoders can lead to better image descriptions and
propose a conditional graph attention network (C-GAT), where the image
captioning decoder state is used to condition the graph updates. Finally, we
determine to what extent noise in the predicted scene graphs influence caption
quality. Overall, we find no significant difference between models that use
scene graph features and models that only use object detection features across
different captioning metrics, which suggests that existing scene graph
generation models are still too noisy to be useful in image captioning.
Moreover, although the quality of predicted scene graphs is very low in
general, when using high quality scene graphs we obtain gains of up to 3.3
CIDEr compared to a strong Bottom-Up Top-Down baseline. We open source code to
reproduce all our experiments in
https://github.com/iacercalixto/butd-image-captioning.
","[{'version': 'v1', 'created': 'Fri, 25 Sep 2020 16:09:08 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 17:55:55 GMT'}]",2020-10-28,"[['Milewski', 'Victor', ''], ['Moens', 'Marie-Francine', ''], ['Calixto', 'Iacer', '']]"
1370778,2010.14448,Xavier Ferrer Aran,"Xavier Ferrer-Aran, Tom van Nuenen, Natalia Criado, Jose M. Such",Discovering and Interpreting Conceptual Biases in Online Communities,,,,,cs.CL cs.AI cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language carries implicit human biases, functioning both as a reflection and
a perpetuation of stereotypes that people carry with them. Recently, ML-based
NLP methods such as word embeddings have been shown to learn such language
biases with striking accuracy. This capability of word embeddings has been
successfully exploited as a tool to quantify and study human biases. However,
previous studies only consider a predefined set of conceptual biases to attest
(e.g., whether gender is more or less associated with particular jobs), or just
discover biased words without helping to understand their meaning at the
conceptual level. As such, these approaches are either unable to find
conceptual biases that have not been defined in advance, or the biases they
find are difficult to interpret and study. This makes existing approaches
unsuitable to discover and interpret biases in online communities, as such
communities may carry different biases than those in mainstream culture. This
paper proposes a general, data-driven approach to automatically discover and
help interpret conceptual biases encoded in word embeddings. We apply this
approach to study the conceptual biases present in the language used in online
communities and experimentally show the validity and stability of our method.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 17:07:12 GMT'}]",2020-10-28,"[['Ferrer-Aran', 'Xavier', ''], ['van Nuenen', 'Tom', ''], ['Criado', 'Natalia', ''], ['Such', 'Jose M.', '']]"
1370794,2010.14464,Lukasz Borchmann,"{\L}ukasz Borchmann, Dawid Jurkiewicz, Filip Grali\'nski, Tomasz
  G\'orecki","Dynamic Boundary Time Warping for Sub-sequence Matching with Few
  Examples",,,,,cs.DS cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The paper presents a novel method of finding a fragment in a long temporal
sequence similar to the set of shorter sequences. We are the first to propose
an algorithm for such a search that does not rely on computing the average
sequence from query examples. Instead, we use query examples as is, utilizing
all of them simultaneously. The introduced method based on the Dynamic Time
Warping (DTW) technique is suited explicitly for few-shot query-by-example
retrieval tasks. We evaluate it on two different few-shot problems from the
field of Natural Language Processing. The results show it either outperforms
baselines and previous approaches or achieves comparable results when a low
number of examples is available.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 17:23:18 GMT'}]",2020-10-28,"[['Borchmann', 'Łukasz', ''], ['Jurkiewicz', 'Dawid', ''], ['Graliński', 'Filip', ''], ['Górecki', 'Tomasz', '']]"
998122,1807.00914,Edoardo Maria Ponti,"Edoardo Maria Ponti, Helen O'Horan, Yevgeni Berzak, Ivan Vuli\'c, Roi
  Reichart, Thierry Poibeau, Ekaterina Shutova, Anna Korhonen","Modeling Language Variation and Universals: A Survey on Typological
  Linguistics for Natural Language Processing",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Linguistic typology aims to capture structural and semantic variation across
the world's languages. A large-scale typology could provide excellent guidance
for multilingual Natural Language Processing (NLP), particularly for languages
that suffer from the lack of human labeled resources. We present an extensive
literature survey on the use of typological information in the development of
NLP techniques. Our survey demonstrates that to date, the use of information in
existing typological databases has resulted in consistent but modest
improvements in system performance. We show that this is due to both intrinsic
limitations of databases (in terms of coverage and feature granularity) and
under-employment of the typological features included in them. We advocate for
a new approach that adapts the broad and discrete nature of typological
categories to the contextual and continuous nature of machine learning
algorithms used in contemporary NLP. In particular, we suggest that such
approach could be facilitated by recent developments in data-driven induction
of typological knowledge.
","[{'version': 'v1', 'created': 'Mon, 2 Jul 2018 22:09:59 GMT'}, {'version': 'v2', 'created': 'Wed, 27 Feb 2019 19:55:28 GMT'}, {'version': 'v3', 'created': 'Mon, 26 Oct 2020 23:23:45 GMT'}]",2020-10-28,"[['Ponti', 'Edoardo Maria', ''], [""O'Horan"", 'Helen', ''], ['Berzak', 'Yevgeni', ''], ['Vulić', 'Ivan', ''], ['Reichart', 'Roi', ''], ['Poibeau', 'Thierry', ''], ['Shutova', 'Ekaterina', ''], ['Korhonen', 'Anna', '']]"
1355762,2009.14259,Peter Jansen,Peter A. Jansen,"Visually-Grounded Planning without Vision: Language Models Infer
  Detailed Plans from High-level Instructions","Accepted to Findings of EMNLP. V2: corrected typo Table 1; margins
  Table 3",,,,cs.CL cs.CV,http://creativecommons.org/licenses/by/4.0/,"  The recently proposed ALFRED challenge task aims for a virtual robotic agent
to complete complex multi-step everyday tasks in a virtual home environment
from high-level natural language directives, such as ""put a hot piece of bread
on a plate"". Currently, the best-performing models are able to complete less
than 5% of these tasks successfully. In this work we focus on modeling the
translation problem of converting natural language directives into detailed
multi-step sequences of actions that accomplish those goals in the virtual
environment. We empirically demonstrate that it is possible to generate gold
multi-step plans from language directives alone without any visual input in 26%
of unseen cases. When a small amount of visual information is incorporated,
namely the starting location in the virtual environment, our best-performing
GPT-2 model successfully generates gold command sequences in 58% of cases. Our
results suggest that contextualized language models may provide strong visual
semantic planning modules for grounded virtual agents.
","[{'version': 'v1', 'created': 'Tue, 29 Sep 2020 18:52:39 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 19:16:00 GMT'}]",2020-10-28,"[['Jansen', 'Peter A.', '']]"
776112,1610.00765,Edoardo Maria Ponti,"Edoardo Maria Ponti, Elisabetta Jezek, Bernardo Magnini","Distributed Representations of Lexical Sets and Prototypes in Causal
  Alternation Verbs","5 pages, 4 figures, accepted at: Third Italian Conference on
  Computational Linguistics (CLIC-it). 5-6 December 2016, Napoli (Italy)",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Lexical sets contain the words filling an argument slot of a verb, and are in
part determined by selectional preferences. The purpose of this paper is to
unravel the properties of lexical sets through distributional semantics. We
investigate 1) whether lexical set behave as prototypical categories with a
centre and a periphery; 2) whether they are polymorphic, i.e. composed by
subcategories; 3) whether the distance between lexical sets of different
arguments is explanatory of verb properties. In particular, our case study are
lexical sets of causative-inchoative verbs in Italian. Having studied several
vector models, we find that 1) based on spatial distance from the centroid,
object fillers are scattered uniformly across the category, whereas
intransitive subject fillers lie on its edge; 2) a correlation exists between
the amount of verb senses and that of clusters discovered automatically,
especially for intransitive subjects; 3) the distance between the centroids of
object and intransitive subject is correlated with other properties of verbs,
such as their cross-lingual tendency to appear in the intransitive pattern
rather than transitive one. This paper is noncommittal with respect to the
hypothesis that this connection is underpinned by a semantic reason, namely the
spontaneity of the event denoted by the verb.
","[{'version': 'v1', 'created': 'Mon, 3 Oct 2016 21:50:27 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 23:48:14 GMT'}]",2020-10-28,"[['Ponti', 'Edoardo Maria', ''], ['Jezek', 'Elisabetta', ''], ['Magnini', 'Bernardo', '']]"
1362519,2010.06189,Zhengbao Jiang,"Zhengbao Jiang, Antonios Anastasopoulos, Jun Araki, Haibo Ding, Graham
  Neubig","X-FACTR: Multilingual Factual Knowledge Retrieval from Pretrained
  Language Models",EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language models (LMs) have proven surprisingly successful at capturing
factual knowledge by completing cloze-style fill-in-the-blank questions such as
""Punta Cana is located in _."" However, while knowledge is both written and
queried in many languages, studies on LMs' factual representation ability have
almost invariably been performed on English. To assess factual knowledge
retrieval in LMs in different languages, we create a multilingual benchmark of
cloze-style probes for 23 typologically diverse languages. To properly handle
language variations, we expand probing methods from single- to multi-word
entities, and develop several decoding algorithms to generate multi-token
predictions. Extensive experimental results provide insights about how well (or
poorly) current state-of-the-art LMs perform at this task in languages with
more or fewer available resources. We further propose a code-switching-based
method to improve the ability of multilingual LMs to access knowledge, and
verify its effectiveness on several benchmark languages. Benchmark data and
code have been released at https://x-factr.github.io.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 05:29:56 GMT'}, {'version': 'v2', 'created': 'Wed, 14 Oct 2020 22:23:17 GMT'}, {'version': 'v3', 'created': 'Tue, 27 Oct 2020 15:30:03 GMT'}]",2020-10-28,"[['Jiang', 'Zhengbao', ''], ['Anastasopoulos', 'Antonios', ''], ['Araki', 'Jun', ''], ['Ding', 'Haibo', ''], ['Neubig', 'Graham', '']]"
1362726,2010.06396,Ekta Sood,"Ekta Sood, Simon Tannert, Diego Frassinelli, Andreas Bulling and Ngoc
  Thang Vu","Interpreting Attention Models with Human Visual Attention in Machine
  Reading Comprehension",CoNLL 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While neural networks with attention mechanisms have achieved superior
performance on many natural language processing tasks, it remains unclear to
which extent learned attention resembles human visual attention. In this paper,
we propose a new method that leverages eye-tracking data to investigate the
relationship between human visual attention and neural attention in machine
reading comprehension. To this end, we introduce a novel 23 participant eye
tracking dataset - MQA-RC, in which participants read movie plots and answered
pre-defined questions. We compare state of the art networks based on long
short-term memory (LSTM), convolutional neural models (CNN) and XLNet
Transformer architectures. We find that higher similarity to human attention
and performance significantly correlates to the LSTM and CNN models. However,
we show this relationship does not hold true for the XLNet models -- despite
the fact that the XLNet performs best on this challenging task. Our results
suggest that different architectures seem to learn rather different neural
attention strategies and similarity of neural to human attention does not
guarantee best performance.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 13:51:57 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 14:47:51 GMT'}]",2020-10-28,"[['Sood', 'Ekta', ''], ['Tannert', 'Simon', ''], ['Frassinelli', 'Diego', ''], ['Bulling', 'Andreas', ''], ['Vu', 'Ngoc Thang', '']]"
1364221,2010.07891,Ekta Sood,"Ekta Sood, Simon Tannert, Philipp Mueller, Andreas Bulling","Improving Natural Language Processing Tasks with Human Gaze-Guided
  Neural Attention",NeurIPS 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A lack of corpora has so far limited advances in integrating human gaze data
as a supervisory signal in neural attention mechanisms for natural language
processing(NLP). We propose a novel hybrid text saliency model(TSM) that, for
the first time, combines a cognitive model of reading with explicit human gaze
supervision in a single machine learning framework. On four different corpora
we demonstrate that our hybrid TSM duration predictions are highly correlated
with human gaze ground truth. We further propose a novel joint modeling
approach to integrate TSM predictions into the attention layer of a network
designed for a specific upstream NLP task without the need for any
task-specific human gaze data. We demonstrate that our joint model outperforms
the state of the art in paraphrase generation on the Quora Question Pairs
corpus by more than 10% in BLEU-4 and achieves state of the art performance for
sentence compression on the challenging Google Sentence Compression corpus. As
such, our work introduces a practical approach for bridging between data-driven
and cognitive models and demonstrates a new way to integrate human gaze-guided
neural attention into NLP tasks.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 17:14:09 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 16:16:18 GMT'}]",2020-10-28,"[['Sood', 'Ekta', ''], ['Tannert', 'Simon', ''], ['Mueller', 'Philipp', ''], ['Bulling', 'Andreas', '']]"
1177919,1909.07881,Palakorn Achananuparp,"Helena Lee, Palakorn Achananuparp, Yue Liu, Ee-Peng Lim, Lav R.
  Varshney","Estimating Glycemic Impact of Cooking Recipes via Online Crowdsourcing
  and Machine Learning","To appear in the Proceedings of Digital Public Health 2019 as short
  paper",,10.1145/3357729.3357748,,cs.CY cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Consumption of diets with low glycemic impact is highly recommended for
diabetics and pre-diabetics as it helps maintain their blood glucose levels.
However, laboratory analysis of dietary glycemic potency is time-consuming and
expensive. In this paper, we explore a data-driven approach utilizing online
crowdsourcing and machine learning to estimate the glycemic impact of cooking
recipes. We show that a commonly used healthiness metric may not always be
effective in determining recipes suitable for diabetics, thus emphasizing the
importance of the glycemic-impact estimation task. Our best classification
model, trained on nutritional and crowdsourced data obtained from Amazon
Mechanical Turk (AMT), can accurately identify recipes which are unhealthful
for diabetics.
","[{'version': 'v1', 'created': 'Tue, 17 Sep 2019 15:14:51 GMT'}]",2020-10-28,"[['Lee', 'Helena', ''], ['Achananuparp', 'Palakorn', ''], ['Liu', 'Yue', ''], ['Lim', 'Ee-Peng', ''], ['Varshney', 'Lav R.', '']]"
1299720,2006.05206,Jayden Macklin-Cordes,"Jayden L. Macklin-Cordes, Erich R. Round",Re-evaluating phoneme frequencies,"29pp (3 figures, 3 tables). This article has been provisionally
  accepted for publication (Frontiers in Psychology, Language Sciences).
  Supplementary information, data and code available at
  http://doi.org/10.5281/zenodo.3886212",,10.3389/fpsyg.2020.570895,,cs.CL physics.soc-ph stat.AP,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Causal processes can give rise to distinctive distributions in the linguistic
variables that they affect. Consequently, a secure understanding of a
variable's distribution can hold a key to understanding the forces that have
causally shaped it. A storied distribution in linguistics has been Zipf's law,
a kind of power law. In the wake of a major debate in the sciences around
power-law hypotheses and the unreliability of earlier methods of evaluating
them, here we re-evaluate the distributions claimed to characterize phoneme
frequencies. We infer the fit of power laws and three alternative distributions
to 166 Australian languages, using a maximum likelihood framework. We find
evidence supporting earlier results, but also nuancing them and increasing our
understanding of them. Most notably, phonemic inventories appear to have a
Zipfian-like frequency structure among their most-frequent members (though
perhaps also a lognormal structure) but a geometric (or exponential) structure
among the least-frequent. We compare these new insights the kinds of causal
processes that affect the evolution of phonemic inventories over time, and
identify a potential account for why, despite there being an important role for
phonetic substance in phonemic change, we could still expect inventories with
highly diverse phonetic content to share similar distributions of phoneme
frequencies. We conclude with priorities for future work in this promising
program of research.
","[{'version': 'v1', 'created': 'Tue, 9 Jun 2020 12:05:10 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 03:56:14 GMT'}]",2020-10-28,"[['Macklin-Cordes', 'Jayden L.', ''], ['Round', 'Erich R.', '']]"
1367182,2010.10852,Huy To Quoc,"Huy Quoc To, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen, Anh Gia-Tuan
  Nguyen","Gender Prediction Based on Vietnamese Names with Machine Learning
  Techniques","6 pages, 6 figures",,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  As biological gender is one of the aspects of presenting individual human,
much work has been done on gender classification based on people names. The
proposals for English and Chinese languages are tremendous; still, there have
been few works done for Vietnamese so far. We propose a new dataset for gender
prediction based on Vietnamese names. This dataset comprises over 26,000 full
names annotated with genders. This dataset is available on our website for
research purposes. In addition, this paper describes six machine learning
algorithms (Support Vector Machine, Multinomial Naive Bayes, Bernoulli Naive
Bayes, Decision Tree, Random Forrest and Logistic Regression) and a deep
learning model (LSTM) with fastText word embedding for gender prediction on
Vietnamese names. We create a dataset and investigate the impact of each name
component on detecting gender. As a result, the best F1-score that we have
achieved is up to 96\% on LSTM model and we generate a web API based on our
trained model.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 09:25:48 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 02:21:32 GMT'}, {'version': 'v3', 'created': 'Tue, 27 Oct 2020 01:29:35 GMT'}]",2020-10-28,"[['To', 'Huy Quoc', ''], ['Van Nguyen', 'Kiet', ''], ['Nguyen', 'Ngan Luu-Thuy', ''], ['Nguyen', 'Anh Gia-Tuan', '']]"
1236866,2001.11453,Edoardo Maria Ponti,"Edoardo M. Ponti, Ivan Vuli\'c, Ryan Cotterell, Marinela Parovic, Roi
  Reichart and Anna Korhonen","Parameter Space Factorization for Zero-Shot Learning across Tasks and
  Languages",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Most combinations of NLP tasks and language varieties lack in-domain examples
for supervised training because of the paucity of annotated data. How can
neural models make sample-efficient generalizations from task--language
combinations with available data to low-resource ones? In this work, we propose
a Bayesian generative model for the space of neural parameters. We assume that
this space can be factorized into latent variables for each language and each
task. We infer the posteriors over such latent variables based on data from
seen task--language combinations through variational inference. This enables
zero-shot classification on unseen combinations at prediction time. For
instance, given training data for named entity recognition (NER) in Vietnamese
and for part-of-speech (POS) tagging in Wolof, our model can perform accurate
predictions for NER in Wolof. In particular, we experiment with a typologically
diverse sample of 33 languages from 4 continents and 11 families, and show that
our model yields comparable or better results than state-of-the-art, zero-shot
cross-lingual transfer methods. Moreover, we demonstrate that approximate
Bayesian model averaging results in smoother predictive distributions, whose
entropy strongly correlates with accuracy. Hence, the proposed framework also
offers robust estimates of uncertainty.
","[{'version': 'v1', 'created': 'Thu, 30 Jan 2020 16:58:56 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 23:30:01 GMT'}]",2020-10-28,"[['Ponti', 'Edoardo M.', ''], ['Vulić', 'Ivan', ''], ['Cotterell', 'Ryan', ''], ['Parovic', 'Marinela', ''], ['Reichart', 'Roi', ''], ['Korhonen', 'Anna', '']]"
1304040,2006.09526,Chau Tran,"Chau Tran, Yuqing Tang, Xian Li, Jiatao Gu",Cross-lingual Retrieval for Iterative Self-Supervised Training,,NeurIPS 2020,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent studies have demonstrated the cross-lingual alignment ability of
multilingual pretrained language models. In this work, we found that the
cross-lingual alignment can be further improved by training seq2seq models on
sentence pairs mined using their own encoder outputs. We utilized these
findings to develop a new approach -- cross-lingual retrieval for iterative
self-supervised training (CRISS), where mining and training processes are
applied iteratively, improving cross-lingual alignment and translation ability
at the same time. Using this method, we achieved state-of-the-art unsupervised
machine translation results on 9 language directions with an average
improvement of 2.4 BLEU, and on the Tatoeba sentence retrieval task in the
XTREME benchmark on 16 languages with an average improvement of 21.5% in
absolute accuracy. Furthermore, CRISS also brings an additional 1.8 BLEU
improvement on average compared to mBART, when finetuned on supervised machine
translation downstream tasks.
","[{'version': 'v1', 'created': 'Tue, 16 Jun 2020 21:30:51 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Oct 2020 23:25:31 GMT'}]",2020-10-28,"[['Tran', 'Chau', ''], ['Tang', 'Yuqing', ''], ['Li', 'Xian', ''], ['Gu', 'Jiatao', '']]"
1367362,2010.11032,Leshem Choshen,"Leshem Choshen, Dmitry Nikolaev, Yevgeni Berzak, Omri Abend",Classifying Syntactic Errors in Learner Language,CoNLL 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present a method for classifying syntactic errors in learner language,
namely errors whose correction alters the morphosyntactic structure of a
sentence.
  The methodology builds on the established Universal Dependencies syntactic
representation scheme, and provides complementary information to other
error-classification systems.
  Unlike existing error classification methods, our method is applicable across
languages, which we showcase by producing a detailed picture of syntactic
errors in learner English and learner Russian. We further demonstrate the
utility of the methodology for analyzing the outputs of leading Grammatical
Error Correction (GEC) systems.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 14:28:22 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 14:58:14 GMT'}]",2020-10-28,"[['Choshen', 'Leshem', ''], ['Nikolaev', 'Dmitry', ''], ['Berzak', 'Yevgeni', ''], ['Abend', 'Omri', '']]"
1370769,2010.14439,Bill Yuchen Lin,"Bill Yuchen Lin, Haitian Sun, Bhuwan Dhingra, Manzil Zaheer, Xiang
  Ren, William W. Cohen",Differentiable Open-Ended Commonsense Reasoning,Work in progress. Project page: https://yuchenlin.xyz/opencsr/,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Current commonsense reasoning research mainly focuses on developing models
that use commonsense knowledge to answer multiple-choice questions. However,
systems designed to answer multiple-choice questions may not be useful in
applications that do not provide a small list of possible candidate answers to
choose from. As a step towards making commonsense reasoning research more
realistic, we propose to study open-ended commonsense reasoning (OpenCSR) --
the task of answering a commonsense question without any pre-defined choices,
using as a resource only a corpus of commonsense facts written in natural
language. The task is challenging due to a much larger decision space, and
because many commonsense questions require multi-hop reasoning. We propose an
efficient differentiable model for multi-hop reasoning over knowledge facts,
named DrFact. We evaluate our approach on a collection of re-formatted,
open-ended versions of popular tests targeting commonsense reasoning, and show
that our approach outperforms strong baseline methods by a large margin.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 10:07:00 GMT'}]",2020-10-28,"[['Lin', 'Bill Yuchen', ''], ['Sun', 'Haitian', ''], ['Dhingra', 'Bhuwan', ''], ['Zaheer', 'Manzil', ''], ['Ren', 'Xiang', ''], ['Cohen', 'William W.', '']]"
1329286,2008.01564,Bruce Lee,"Bruce W. Lee, Jason Hyung-Jong Lee","LXPER Index: a curriculum-specific text readability assessment model for
  EFL students in Korea","8 pages, 2 figures, 7 tables",,10.14569/IJACSA.2020.0110801,,cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Automatic readability assessment is one of the most important applications of
Natural Language Processing (NLP) in education. Since automatic readability
assessment allows the fast selection of appropriate reading material for
readers at all levels of proficiency, it can be particularly useful for the
English education of English as Foreign Language (EFL) students around the
world. Most readability assessment models are developed for the native readers
of English and have low accuracy for texts in the non-native English Language
Training (ELT) curriculum. We introduce LXPER Index, which is a readability
assessment model for non-native EFL readers in the ELT curriculum of Korea. Our
experiments show that our new model, trained with CoKEC-text (Text Corpus of
the Korean ELT Curriculum), significantly improves the accuracy of automatic
readability assessment for texts in the Korean ELT curriculum.
","[{'version': 'v1', 'created': 'Sat, 1 Aug 2020 11:55:03 GMT'}]",2020-10-28,"[['Lee', 'Bruce W.', ''], ['Lee', 'Jason Hyung-Jong', '']]"
1280414,2005.00619,Gabriel Ilharco,"Gabriel Ilharco, Rowan Zellers, Ali Farhadi, Hannaneh Hajishirzi","Probing Contextual Language Models for Common Ground with Visual
  Representations",,,,,cs.CL cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While large-scale contextual language models have enjoyed great success
recently, much remains to be understood about what is encoded in their
representations. In this work, we characterize how contextual representations
of concrete nouns extracted by trained language models relate to the physical
properties of the objects they refer to. Our approach uses a probing model that
examines how effective these language representations are in discerning between
different visual representations. We show that many recent language models
yield representations that are useful in retrieving semantically aligned image
patches, and explore the role of context in this process. Much weaker results
are found in control experiments, attesting the selectivity of the probe. All
examined models greatly under-perform humans in retrieval, highlighting
substantial room for future progress. Altogether, our findings shed new
empirical insights on language grounding and its materialization in contextual
language models.
","[{'version': 'v1', 'created': 'Fri, 1 May 2020 21:28:28 GMT'}, {'version': 'v2', 'created': 'Tue, 6 Oct 2020 17:19:20 GMT'}, {'version': 'v3', 'created': 'Fri, 23 Oct 2020 22:12:40 GMT'}, {'version': 'v4', 'created': 'Tue, 27 Oct 2020 16:40:01 GMT'}]",2020-10-28,"[['Ilharco', 'Gabriel', ''], ['Zellers', 'Rowan', ''], ['Farhadi', 'Ali', ''], ['Hajishirzi', 'Hannaneh', '']]"
1370672,2010.14342,Guanyi Chen,"Guanyi Chen, Yinhe Zheng, Yupei Du",Listener's Social Identity Matters in Personalised Response Generation,Long paper accepted at INLG 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Personalised response generation enables generating human-like responses by
means of assigning the generator a social identity. However, pragmatics theory
suggests that human beings adjust the way of speaking based on not only who
they are but also whom they are talking to. In other words, when modelling
personalised dialogues, it might be favourable if we also take the listener's
social identity into consideration. To validate this idea, we use gender as a
typical example of a social variable to investigate how the listener's identity
influences the language used in Chinese dialogues on social media. Also, we
build personalised generators. The experiment results demonstrate that the
listener's identity indeed matters in the language use of responses and that
the response generator can capture such differences in language use. More
interestingly, by additionally modelling the listener's identity, the
personalised response generator performs better in its own identity.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 14:57:21 GMT'}]",2020-10-28,"[['Chen', 'Guanyi', ''], ['Zheng', 'Yinhe', ''], ['Du', 'Yupei', '']]"
1370434,2010.14104,"Bj\""orn Bebensee","Bj\""orn Bebensee, Byoung-Tak Zhang",Co-attentional Transformers for Story-Based Video Understanding,"10 pages, 2 figures, submitted to ICASSP 2021",,,,cs.CV cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Inspired by recent trends in vision and language learning, we explore
applications of attention mechanisms for visio-lingual fusion within an
application to story-based video understanding. Like other video-based QA
tasks, video story understanding requires agents to grasp complex temporal
dependencies. However, as it focuses on the narrative aspect of video it also
requires understanding of the interactions between different characters, as
well as their actions and their motivations. We propose a novel co-attentional
transformer model to better capture long-term dependencies seen in visual
stories such as dramas and measure its performance on the video question
answering task. We evaluate our approach on the recently introduced DramaQA
dataset which features character-centered video story understanding questions.
Our model outperforms the baseline model by 8 percentage points overall, at
least 4.95 and up to 12.8 percentage points on all difficulty levels and
manages to beat the winner of the DramaQA challenge.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 07:17:09 GMT'}]",2020-10-28,"[['Bebensee', 'Björn', ''], ['Zhang', 'Byoung-Tak', '']]"
1370601,2010.14271,Ming Gong,"Junhao Liu, Linjun Shou, Jian Pei, Ming Gong, Min Yang, Daxin Jiang","Cross-lingual Machine Reading Comprehension with Language Branch
  Knowledge Distillation",Accepted as long paper in COLING 2020,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Cross-lingual Machine Reading Comprehension (CLMRC) remains a challenging
problem due to the lack of large-scale annotated datasets in low-source
languages, such as Arabic, Hindi, and Vietnamese. Many previous approaches use
translation data by translating from a rich-source language, such as English,
to low-source languages as auxiliary supervision. However, how to effectively
leverage translation data and reduce the impact of noise introduced by
translation remains onerous. In this paper, we tackle this challenge and
enhance the cross-lingual transferring performance by a novel augmentation
approach named Language Branch Machine Reading Comprehension (LBMRC). A
language branch is a group of passages in one single language paired with
questions in all target languages. We train multiple machine reading
comprehension (MRC) models proficient in individual language based on LBMRC.
Then, we devise a multilingual distillation approach to amalgamate knowledge
from multiple language branch models to a single model for all target
languages. Combining the LBMRC and multilingual distillation can be more robust
to the data noises, therefore, improving the model's cross-lingual ability.
Meanwhile, the produced single multilingual model is applicable to all target
languages, which saves the cost of training, inference, and maintenance for
multiple models. Extensive experiments on two CLMRC benchmarks clearly show the
effectiveness of our proposed method.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 13:12:17 GMT'}]",2020-10-28,"[['Liu', 'Junhao', ''], ['Shou', 'Linjun', ''], ['Pei', 'Jian', ''], ['Gong', 'Ming', ''], ['Yang', 'Min', ''], ['Jiang', 'Daxin', '']]"
1370144,2010.13814,Constantin Orasan,"Hadeel Saadany, Constantin Orasan","Is it Great or Terrible? Preserving Sentiment in Neural Machine
  Translation of Arabic Reviews",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Since the advent of Neural Machine Translation (NMT) approaches there has
been a tremendous improvement in the quality of automatic translation. However,
NMT output still lacks accuracy in some low-resource languages and sometimes
makes major errors that need extensive post-editing. This is particularly
noticeable with texts that do not follow common lexico-grammatical standards,
such as user generated content (UGC). In this paper we investigate the
challenges involved in translating book reviews from Arabic into English, with
particular focus on the errors that lead to incorrect translation of sentiment
polarity. Our study points to the special characteristics of Arabic UGC,
examines the sentiment transfer errors made by Google Translate of Arabic UGC
to English, analyzes why the problem occurs, and proposes an error typology
specific of the translation of Arabic UGC. Our analysis shows that the output
of online translation tools of Arabic UGC can either fail to transfer the
sentiment at all by producing a neutral target text, or completely flips the
sentiment polarity of the target word or phrase and hence delivers a wrong
affect message. We address this problem by fine-tuning an NMT model with
respect to sentiment polarity showing that this approach can significantly help
with correcting sentiment errors detected in the online translation of Arabic
UGC.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 18:01:52 GMT'}]",2020-10-28,"[['Saadany', 'Hadeel', ''], ['Orasan', 'Constantin', '']]"
1370169,2010.13839,Subhajit Chaudhury,"Thomas Carta, Subhajit Chaudhury, Kartik Talamadupula and Michiaki
  Tatsubori","VisualHints: A Visual-Lingual Environment for Multimodal Reinforcement
  Learning",Code is available at http://ibm.biz/VisualHints,,,,cs.LG cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present VisualHints, a novel environment for multimodal reinforcement
learning (RL) involving text-based interactions along with visual hints
(obtained from the environment). Real-life problems often demand that agents
interact with the environment using both natural language information and
visual perception towards solving a goal. However, most traditional RL
environments either solve pure vision-based tasks like Atari games or
video-based robotic manipulation; or entirely use natural language as a mode of
interaction, like Text-based games and dialog systems. In this work, we aim to
bridge this gap and unify these two approaches in a single environment for
multimodal RL. We introduce an extension of the TextWorld cooking environment
with the addition of visual clues interspersed throughout the environment. The
goal is to force an RL agent to use both text and visual features to predict
natural language action commands for solving the final task of cooking a meal.
We enable variations and difficulties in our environment to emulate various
interactive real-world scenarios. We present a baseline multimodal agent for
solving such problems using CNN-based feature extraction from visual hints and
LSTMs for textual feature extraction. We believe that our proposed
visual-lingual environment will facilitate novel problem settings for the RL
community.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 18:51:02 GMT'}]",2020-10-28,"[['Carta', 'Thomas', ''], ['Chaudhury', 'Subhajit', ''], ['Talamadupula', 'Kartik', ''], ['Tatsubori', 'Michiaki', '']]"
1370186,2010.13856,Ciprian Chelba,"Ciprian Chelba, Junpei Zhou, Yuezhang (Music) Li, Hideto Kazawa, Jeff
  Klingner, Mengmeng Niu","Data Troubles in Sentence Level Confidence Estimation for Machine
  Translation",,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The paper investigates the feasibility of confidence estimation for neural
machine translation models operating at the high end of the performance
spectrum. As a side product of the data annotation process necessary for
building such models we propose sentence level accuracy $SACC$ as a simple,
self-explanatory evaluation metric for quality of translation.
  Experiments on two different annotator pools, one comprised of non-expert
(crowd-sourced) and one of expert (professional) translators show that $SACC$
can vary greatly depending on the translation proficiency of the annotators,
despite the fact that both pools are about equally reliable according to
Krippendorff's alpha metric; the relatively low values of inter-annotator
agreement confirm the expectation that sentence-level binary labeling $good$ /
$needs\ work$ for translation out of context is very hard.
  For an English-Spanish translation model operating at $SACC = 0.89$ according
to a non-expert annotator pool we can derive a confidence estimate that labels
0.5-0.6 of the $good$ translations in an ""in-domain"" test set with 0.95
Precision. Switching to an expert annotator pool decreases $SACC$ dramatically:
$0.61$ for English-Spanish, measured on the exact same data as above. This
forces us to lower the CE model operating point to 0.9 Precision while labeling
correctly about 0.20-0.25 of the $good$ translations in the data.
  We find surprising the extent to which CE depends on the level of proficiency
of the annotator pool used for labeling the data. This leads to an important
recommendation we wish to make when tackling CE modeling in practice: it is
critical to match the end-user expectation for translation quality in the
desired domain with the demands of annotators assigning binary quality labels
to CE training data.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 19:20:29 GMT'}]",2020-10-28,"[['Chelba', 'Ciprian', '', 'Music'], ['Zhou', 'Junpei', '', 'Music'], ['Yuezhang', '', '', 'Music'], ['Li', '', ''], ['Kazawa', 'Hideto', ''], ['Klingner', 'Jeff', ''], ['Niu', 'Mengmeng', '']]"
1256634,2003.06279,Diego Amancio,Laura V. C. Quispe and Jorge A. V. Tohalino and Diego R. Amancio,"Using word embeddings to improve the discriminability of co-occurrence
  text networks",,,10.1016/j.physa.2020.125344,,cs.CL cs.SI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Word co-occurrence networks have been employed to analyze texts both in the
practical and theoretical scenarios. Despite the relative success in several
applications, traditional co-occurrence networks fail in establishing links
between similar words whenever they appear distant in the text. Here we
investigate whether the use of word embeddings as a tool to create virtual
links in co-occurrence networks may improve the quality of classification
systems. Our results revealed that the discriminability in the stylometry task
is improved when using Glove, Word2Vec and FastText. In addition, we found that
optimized results are obtained when stopwords are not disregarded and a simple
global thresholding strategy is used to establish virtual links. Because the
proposed approach is able to improve the representation of texts as complex
networks, we believe that it could be extended to study other natural language
processing tasks. Likewise, theoretical languages studies could benefit from
the adopted enriched representation of word co-occurrence networks.
","[{'version': 'v1', 'created': 'Fri, 13 Mar 2020 13:35:44 GMT'}]",2020-10-28,"[['Quispe', 'Laura V. C.', ''], ['Tohalino', 'Jorge A. V.', ''], ['Amancio', 'Diego R.', '']]"
1369939,2010.13609,Dumitru-Clementin Cercel,"Mircea-Adrian Tanase, Dumitru-Clementin Cercel and Costin-Gabriel
  Chiru","UPB at SemEval-2020 Task 12: Multilingual Offensive Language Detection
  on Social Media by Fine-tuning a Variety of BERT-based Models",,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Offensive language detection is one of the most challenging problem in the
natural language processing field, being imposed by the rising presence of this
phenomenon in online social media. This paper describes our Transformer-based
solutions for identifying offensive language on Twitter in five languages
(i.e., English, Arabic, Danish, Greek, and Turkish), which was employed in
Subtask A of the Offenseval 2020 shared task. Several neural architectures
(i.e., BERT, mBERT, Roberta, XLM-Roberta, and ALBERT), pre-trained using both
single-language and multilingual corpora, were fine-tuned and compared using
multiple combinations of datasets. Finally, the highest-scoring models were
used for our submissions in the competition, which ranked our team 21st of 85,
28th of 53, 19th of 39, 16th of 37, and 10th of 46 for English, Arabic, Danish,
Greek, and Turkish, respectively.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 14:28:29 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 09:21:21 GMT'}]",2020-10-28,"[['Tanase', 'Mircea-Adrian', ''], ['Cercel', 'Dumitru-Clementin', ''], ['Chiru', 'Costin-Gabriel', '']]"
1370200,2010.13870,Leon Bergen,"Charles Yu, Ryan Sie, Nico Tedeschi, Leon Bergen",Word Frequency Does Not Predict Grammatical Knowledge in Language Models,EMNLP 2020,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Neural language models learn, to varying degrees of accuracy, the grammatical
properties of natural languages. In this work, we investigate whether there are
systematic sources of variation in the language models' accuracy. Focusing on
subject-verb agreement and reflexive anaphora, we find that certain nouns are
systematically understood better than others, an effect which is robust across
grammatical tasks and different language models. Surprisingly, we find that
across four orders of magnitude, corpus frequency is unrelated to a noun's
performance on grammatical tasks. Finally, we find that a novel noun's
grammatical properties can be few-shot learned from various types of training
data. The results present a paradox: there should be less variation in
grammatical performance than is actually observed.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 19:51:36 GMT'}]",2020-10-28,"[['Yu', 'Charles', ''], ['Sie', 'Ryan', ''], ['Tedeschi', 'Nico', ''], ['Bergen', 'Leon', '']]"
1370208,2010.13878,Suyoun Kim,"Suyoun Kim, Yuan Shangguan, Jay Mahadeokar, Antoine Bruguier,
  Christian Fuegen, Michael L. Seltzer, Duc Le","Improved Neural Language Model Fusion for Streaming Recurrent Neural
  Network Transducer",submitted to ICASSP 2021,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recurrent Neural Network Transducer (RNN-T), like most end-to-end speech
recognition model architectures, has an implicit neural network language model
(NNLM) and cannot easily leverage unpaired text data during training. Previous
work has proposed various fusion methods to incorporate external NNLMs into
end-to-end ASR to address this weakness. In this paper, we propose extensions
to these techniques that allow RNN-T to exploit external NNLMs during both
training and inference time, resulting in 13-18% relative Word Error Rate
improvement on Librispeech compared to strong baselines. Furthermore, our
methods do not incur extra algorithmic latency and allow for flexible
plug-and-play of different NNLMs without re-training. We also share in-depth
analysis to better understand the benefits of the different NNLM fusion
methods. Our work provides a reliable technique for leveraging unpaired text
data to significantly improve RNN-T while keeping the system streamable,
flexible, and lightweight.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 20:10:12 GMT'}]",2020-10-28,"[['Kim', 'Suyoun', ''], ['Shangguan', 'Yuan', ''], ['Mahadeokar', 'Jay', ''], ['Bruguier', 'Antoine', ''], ['Fuegen', 'Christian', ''], ['Seltzer', 'Michael L.', ''], ['Le', 'Duc', '']]"
1370242,2010.13912,Chien-Sheng Wu,Chien-Sheng Wu and Caiming Xiong,Probing Task-Oriented Dialogue Representation from Language Models,EMNLP 2020,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper investigates pre-trained language models to find out which model
intrinsically carries the most informative representation for task-oriented
dialogue tasks. We approach the problem from two aspects: supervised classifier
probe and unsupervised mutual information probe. We fine-tune a feed-forward
layer as the classifier probe on top of a fixed pre-trained language model with
annotated labels in a supervised way. Meanwhile, we propose an unsupervised
mutual information probe to evaluate the mutual dependence between a real
clustering and a representation clustering. The goals of this empirical paper
are to 1) investigate probing techniques, especially from the unsupervised
mutual information aspect, 2) provide guidelines of pre-trained language model
selection for the dialogue research community, 3) find insights of pre-training
factors for dialogue application that may be the key to success.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 21:34:39 GMT'}]",2020-10-28,"[['Wu', 'Chien-Sheng', ''], ['Xiong', 'Caiming', '']]"
1370648,2010.14318,Peidong Wang,"Peidong Wang, Tara N. Sainath, Ron J. Weiss",Multitask Training with Text Data for End-to-End Speech Recognition,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a multitask training method for attention-based end-to-end speech
recognition models to better incorporate language level information. We
regularize the decoder in a sequence-to-sequence architecture by multitask
training it on both the speech recognition task and a next-token prediction
language modeling task. Trained on either the 100 hour subset of LibriSpeech or
the full 960 hour dataset, the proposed method leads to an 11% relative
performance improvement over the baseline and is comparable to language model
shallow fusion, without requiring an additional neural network during decoding.
Analyses of sample output sentences and the word error rate on rare words
demonstrate that the proposed method can incorporate language level information
effectively.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 14:29:28 GMT'}]",2020-10-28,"[['Wang', 'Peidong', ''], ['Sainath', 'Tara N.', ''], ['Weiss', 'Ron J.', '']]"
1252853,2003.02498,Palakorn Achananuparp,"Helena H. Lee, Ke Shu, Palakorn Achananuparp, Philips Kokoh Prasetyo,
  Yue Liu, Ee-Peng Lim, Lav R. Varshney","RecipeGPT: Generative Pre-training Based Cooking Recipe Generation and
  Evaluation System",Accepted to WWW 2020. Demo track paper,,10.1145/3366424.3383536,,cs.CL cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Interests in the automatic generation of cooking recipes have been growing
steadily over the past few years thanks to a large amount of online cooking
recipes. We present RecipeGPT, a novel online recipe generation and evaluation
system. The system provides two modes of text generations: (1) instruction
generation from given recipe title and ingredients; and (2) ingredient
generation from recipe title and cooking instructions. Its back-end text
generation module comprises a generative pre-trained language model GPT-2
fine-tuned on a large cooking recipe dataset. Moreover, the recipe evaluation
module allows the users to conveniently inspect the quality of the generated
recipe contents and store the results for future reference. RecipeGPT can be
accessed online at https://recipegpt.org/.
","[{'version': 'v1', 'created': 'Thu, 5 Mar 2020 09:25:30 GMT'}]",2020-10-28,"[['Lee', 'Helena H.', ''], ['Shu', 'Ke', ''], ['Achananuparp', 'Palakorn', ''], ['Prasetyo', 'Philips Kokoh', ''], ['Liu', 'Yue', ''], ['Lim', 'Ee-Peng', ''], ['Varshney', 'Lav R.', '']]"
1370250,2010.13920,Chien-Sheng Wu,Chien-Sheng Wu and Steven Hoi and Caiming Xiong,Improving Limited Labeled Dialogue State Tracking with Self-Supervision,EMNLP 2020 (findings),,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Existing dialogue state tracking (DST) models require plenty of labeled data.
However, collecting high-quality labels is costly, especially when the number
of domains increases. In this paper, we address a practical DST problem that is
rarely discussed, i.e., learning efficiently with limited labeled data. We
present and investigate two self-supervised objectives: preserving latent
consistency and modeling conversational behavior. We encourage a DST model to
have consistent latent distributions given a perturbed input, making it more
robust to an unseen scenario. We also add an auxiliary utterance generation
task, modeling a potential correlation between conversational behavior and
dialogue states. The experimental results show that our proposed
self-supervised signals can improve joint goal accuracy by 8.95\% when only 1\%
labeled data is used on the MultiWOZ dataset. We can achieve an additional
1.76\% improvement if some unlabeled data is jointly trained as semi-supervised
learning. We analyze and visualize how our proposed self-supervised signals
help the DST task and hope to stimulate future data-efficient DST research.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 21:57:42 GMT'}]",2020-10-28,"[['Wu', 'Chien-Sheng', ''], ['Hoi', 'Steven', ''], ['Xiong', 'Caiming', '']]"
1370274,2010.13944,Khyathi Raghavi Chandu,"Khyathi Raghavi Chandu, Ruo-Ping Dong, Alan Black",Reading Between the Lines: Exploring Infilling in Visual Narratives,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Generating long form narratives such as stories and procedures from multiple
modalities has been a long standing dream for artificial intelligence. In this
regard, there is often crucial subtext that is derived from the surrounding
contexts. The general seq2seq training methods render the models shorthanded
while attempting to bridge the gap between these neighbouring contexts. In this
paper, we tackle this problem by using \textit{infilling} techniques involving
prediction of missing steps in a narrative while generating textual
descriptions from a sequence of images. We also present a new large scale
\textit{visual procedure telling} (ViPT) dataset with a total of 46,200
procedures and around 340k pairwise images and textual descriptions that is
rich in such contextual dependencies. Generating steps using infilling
technique demonstrates the effectiveness in visual procedures with more
coherent texts. We conclusively show a METEOR score of 27.51 on procedures
which is higher than the state-of-the-art on visual storytelling. We also
demonstrate the effects of interposing new text with missing images during
inference. The code and the dataset will be publicly available at
https://visual-narratives.github.io/Visual-Narratives/.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 23:09:09 GMT'}]",2020-10-28,"[['Chandu', 'Khyathi Raghavi', ''], ['Dong', 'Ruo-Ping', ''], ['Black', 'Alan', '']]"
1370312,2010.13982,Hung-Ting Chen,"Hung-Ting Chen, Yu-Chieh Chao, Ta-Hsuan Chao, Wei-Yun Ma",Predict and Use Latent Patterns for Short-Text Conversation,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Many neural network models nowadays have achieved promising performances in
Chit-chat settings. The majority of them rely on an encoder for understanding
the post and a decoder for generating the response. Without given assigned
semantics, the models lack the fine-grained control over responses as the
semantic mapping between posts and responses is hidden on the fly within the
end-to-end manners. Some previous works utilize sampled latent words as a
controllable semantic form to drive the generated response around the work, but
few works attempt to use more complex semantic forms to guide the generation.
In this paper, we propose to use more detailed semantic forms, including latent
responses and part-of-speech sequences sampled from the corresponding
distributions, as the controllable semantics to guide the generation. Our
experimental results show that the richer semantics are not only able to
provide informative and diverse responses, but also increase the overall
performance of response quality, including fluency and coherence.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 01:31:42 GMT'}]",2020-10-28,"[['Chen', 'Hung-Ting', ''], ['Chao', 'Yu-Chieh', ''], ['Chao', 'Ta-Hsuan', ''], ['Ma', 'Wei-Yun', '']]"
1370146,2010.13816,Maarten Sap,"Xinyao Ma, Maarten Sap, Hannah Rashkin, Yejin Choi","PowerTransformer: Unsupervised Controllable Revision for Biased Language
  Correction",EMNLP 2020,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Unconscious biases continue to be prevalent in modern text and media, calling
for algorithms that can assist writers with bias correction. For example, a
female character in a story is often portrayed as passive and powerless (""She
daydreams about being a doctor"") while a man is portrayed as more proactive and
powerful (""He pursues his dream of being a doctor"").
  We formulate *Controllable Debiasing*, a new revision task that aims to
rewrite a given text to correct the implicit and potentially undesirable bias
in character portrayals. We then introduce PowerTransformer as an approach that
debiases text through the lens of connotation frames (Sap et al., 2017), which
encode pragmatic knowledge of implied power dynamics with respect to verb
predicates. One key challenge of our task is the lack of parallel corpora. To
address this challenge, we adopt an unsupervised approach using auxiliary
supervision with related tasks such as paraphrasing and self-supervision based
on a reconstruction loss, building on pretrained language models.
  Through comprehensive experiments based on automatic and human evaluations,
we demonstrate that our approach outperforms ablations and existing methods
from related tasks. Furthermore, we demonstrate the use of PowerTransformer as
a step toward mitigating the well-documented gender bias in character portrayal
in movie scripts.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 18:05:48 GMT'}]",2020-10-28,"[['Ma', 'Xinyao', ''], ['Sap', 'Maarten', ''], ['Rashkin', 'Hannah', ''], ['Choi', 'Yejin', '']]"
1369704,2010.13374,Bruce W. Lee,Bruce W. Lee and Jason Hyung-Jong Lee,"LXPER Index 2.0: Improving Text Readability Assessment for L2 English
  Learners in South Korea","NLP-TEA, Association for Computational Linguistics",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Most text readability assessment models are developed for the native readers
of English and have low accuracy for texts in foreign English Language Training
(ELT) curriculum. In this paper, we investigate a text readability assessment
model for L2 English learners in Korea. In accordance, we improve and expand
the Text Corpus of the Korean ELT curriculum (CoKEC-text). Each text is labeled
with its target grade level. We train our model with CoKEC-text and
significantly improve the accuracy of readability assessment for texts in the
Korean ELT curriculum.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 07:03:14 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 17:04:03 GMT'}]",2020-10-28,"[['Lee', 'Bruce W.', ''], ['Lee', 'Jason Hyung-Jong', '']]"
1159525,1908.01355,Johan Bos,Johan Bos,Separating Argument Structure from Logical Structure in AMR,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The AMR (Abstract Meaning Representation) formalism for representing meaning
of natural language sentences was not designed to deal with scope and
quantifiers. By extending AMR with indices for contexts and formulating
constraints on these contexts, a formalism is derived that makes correct
prediction for inferences involving negation and bound variables. The
attractive core predicate-argument structure of AMR is preserved. The resulting
framework is similar to that of Discourse Representation Theory.
","[{'version': 'v1', 'created': 'Sun, 4 Aug 2019 14:46:35 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 14:54:01 GMT'}]",2020-10-28,"[['Bos', 'Johan', '']]"
1369424,2010.13094,Masahiro Kaneko,Masahiro Kaneko and Danushka Bollegala,Autoencoding Improves Pre-trained Word Embeddings,COLING 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Prior work investigating the geometry of pre-trained word embeddings have
shown that word embeddings to be distributed in a narrow cone and by centering
and projecting using principal component vectors one can increase the accuracy
of a given set of pre-trained word embeddings. However, theoretically, this
post-processing step is equivalent to applying a linear autoencoder to minimise
the squared l2 reconstruction error. This result contradicts prior work (Mu and
Viswanath, 2018) that proposed to remove the top principal components from
pre-trained embeddings. We experimentally verify our theoretical claims and
show that retaining the top principal components is indeed useful for improving
pre-trained word embeddings, without requiring access to additional linguistic
resources or labelled data.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 11:30:05 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 07:51:34 GMT'}]",2020-10-28,"[['Kaneko', 'Masahiro', ''], ['Bollegala', 'Danushka', '']]"
1370585,2010.14255,Jianing Wang,Jianing Wang and Chong Su,"Improving Reinforcement Learning for Neural Relation Extraction with
  Hierarchical Memory Extractor","9 pages, 7 figures, WWW2021 submission paper",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Distant supervision relation extraction (DSRE) is an efficient method to
extract semantic relations on a large-scale heuristic labeling corpus. However,
it usually brings in a massive noisy data. In order to alleviate this problem,
many recent approaches adopt reinforcement learning (RL), which aims to select
correct data autonomously before relation classification. Although these RL
methods outperform conventional multi-instance learning-based methods, there
are still two neglected problems: 1) the existing RL methods ignore the
feedback of noisy data, 2) the reduction of training corpus exacerbates
long-tail problem. In this paper, we propose a novel framework to solve the two
problems mentioned above. Firstly, we design a novel reward function to obtain
feedback from both correct and noisy data. In addition, we use implicit
relations information to improve RL. Secondly, we propose the hierarchical
memory extractor (HME), which utilizes the gating mechanism to share the
semantics from correlative instances between data-rich and data-poor classes.
Moreover, we define a hierarchical weighted ranking loss function to implement
top-down search processing. Extensive experiments conducted on the widely used
NYT dataset show significant improvement over state-of-the-art baseline
methods.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 12:50:27 GMT'}]",2020-10-28,"[['Wang', 'Jianing', ''], ['Su', 'Chong', '']]"
1370565,2010.14235,Yao Lu,"Yao Lu, Yue Dong, Laurent Charlin","Multi-XScience: A Large-scale Dataset for Extreme Multi-document
  Summarization of Scientific Articles",EMNLP 2020,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Multi-document summarization is a challenging task for which there exists
little large-scale datasets. We propose Multi-XScience, a large-scale
multi-document summarization dataset created from scientific articles.
Multi-XScience introduces a challenging multi-document summarization task:
writing the related-work section of a paper based on its abstract and the
articles it references. Our work is inspired by extreme summarization, a
dataset construction protocol that favours abstractive modeling approaches.
Descriptive statistics and empirical results---using several state-of-the-art
models trained on the Multi-XScience dataset---reveal that Multi-XScience is
well suited for abstractive models.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 12:10:19 GMT'}]",2020-10-28,"[['Lu', 'Yao', ''], ['Dong', 'Yue', ''], ['Charlin', 'Laurent', '']]"
1370564,2010.14234,Muvazima Mansoor,"Muvazima Mansoor, Kirthika Gurumurthy, Anantharam R U, V R Badri
  Prasad",Global Sentiment Analysis Of COVID-19 Tweets Over Time,"7 pages, 20 figures, Submitted to ICDSBDA 2020",,,,cs.CL cs.LG cs.SI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The Coronavirus pandemic has affected the normal course of life. People
around the world have taken to social media to express their opinions and
general emotions regarding this phenomenon that has taken over the world by
storm. The social networking site, Twitter showed an unprecedented increase in
tweets related to the novel Coronavirus in a very short span of time. This
paper presents the global sentiment analysis of tweets related to Coronavirus
and how the sentiment of people in different countries has changed over time.
Furthermore, to determine the impact of Coronavirus on daily aspects of life,
tweets related to Work From Home (WFH) and Online Learning were scraped and the
change in sentiment over time was observed. In addition, various Machine
Learning models such as Long Short Term Memory (LSTM) and Artificial Neural
Networks (ANN) were implemented for sentiment classification and their
accuracies were determined. Exploratory data analysis was also performed for a
dataset providing information about the number of confirmed cases on a per-day
basis in a few of the worst-hit countries to provide a comparison between the
change in sentiment with the change in cases since the start of this pandemic
till June 2020.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 12:10:10 GMT'}]",2020-10-28,"[['Mansoor', 'Muvazima', ''], ['Gurumurthy', 'Kirthika', ''], ['U', 'Anantharam R', ''], ['Prasad', 'V R Badri', '']]"
1020672,1809.00656,Larry Moss,Alex Kruckman and Lawrence S. Moss,Exploring the Landscape of Relational Syllogistic Logics,,,10.1017/S1755020320000386,,math.LO cs.CL cs.LO,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper explores relational syllogistic logics, a family of logical
systems related to reasoning about relations in extensions of the classical
syllogistic. These are all decidable logical systems. We prove completeness
theorems and complexity results for a natural subfamily of relational
syllogistic logics, parametrized by constructors for terms and for sentences.
","[{'version': 'v1', 'created': 'Mon, 3 Sep 2018 16:57:54 GMT'}]",2020-10-28,"[['Kruckman', 'Alex', ''], ['Moss', 'Lawrence S.', '']]"
1370563,2010.14233,Ethan Chi,"Ethan A. Chi, Julian Salazar, and Katrin Kirchhoff","Align-Refine: Non-Autoregressive Speech Recognition via Iterative
  Realignment",,,,,eess.AS cs.CL cs.LG cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Non-autoregressive models greatly improve decoding speed over typical
sequence-to-sequence models, but suffer from degraded performance. Infilling
and iterative refinement models make up some of this gap by editing the outputs
of a non-autoregressive model, but are constrained in the edits that they can
make. We propose iterative realignment, where refinements occur over latent
alignments rather than output sequence space. We demonstrate this in speech
recognition with Align-Refine, an end-to-end Transformer-based model which
refines connectionist temporal classification (CTC) alignments to allow
length-changing insertions and deletions. Align-Refine outperforms Imputer and
Mask-CTC, matching an autoregressive baseline on WSJ at 1/14th the real-time
factor and attaining a LibriSpeech test-other WER of 9.0% without an LM. Our
model is strong even in one iteration with a shallower decoder.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 09:35:37 GMT'}]",2020-10-28,"[['Chi', 'Ethan A.', ''], ['Salazar', 'Julian', ''], ['Kirchhoff', 'Katrin', '']]"
831602,1703.08098,Dat Quoc Nguyen,Dat Quoc Nguyen,"A survey of embedding models of entities and relationships for knowledge
  graph completion","In Proceedings of the 14th Workshop on Graph-Based Natural Language
  Processing (TextGraphs 2020); 16 pages, 2 figures, 6 tables",,,,cs.CL cs.AI cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Knowledge graphs (KGs) of real-world facts about entities and their
relationships are useful resources for a variety of natural language processing
tasks. However, because knowledge graphs are typically incomplete, it is useful
to perform knowledge graph completion or link prediction, i.e. predict whether
a relationship not in the knowledge graph is likely to be true. This paper
serves as a comprehensive survey of embedding models of entities and
relationships for knowledge graph completion, summarizing up-to-date
experimental results on standard benchmark datasets and pointing out potential
future research directions.
","[{'version': 'v1', 'created': 'Thu, 23 Mar 2017 15:15:26 GMT'}, {'version': 'v2', 'created': 'Tue, 28 Mar 2017 15:28:08 GMT'}, {'version': 'v3', 'created': 'Sat, 3 Feb 2018 04:39:45 GMT'}, {'version': 'v4', 'created': 'Tue, 9 Apr 2019 02:26:26 GMT'}, {'version': 'v5', 'created': 'Sat, 27 Apr 2019 13:33:30 GMT'}, {'version': 'v6', 'created': 'Fri, 28 Feb 2020 07:06:36 GMT'}, {'version': 'v7', 'created': 'Wed, 22 Apr 2020 11:58:35 GMT'}, {'version': 'v8', 'created': 'Mon, 10 Aug 2020 08:35:07 GMT'}, {'version': 'v9', 'created': 'Tue, 27 Oct 2020 04:11:25 GMT'}]",2020-10-28,"[['Nguyen', 'Dat Quoc', '']]"
1370453,2010.14123,Viet Lai,"Viet Dac Lai, Tuan Ngo Nguyen, Thien Huu Nguyen","Event Detection: Gate Diversity and Syntactic Importance Scoresfor Graph
  Convolution Neural Networks",EMNLP 2020,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Recent studies on event detection (ED) haveshown that the syntactic
dependency graph canbe employed in graph convolution neural net-works (GCN) to
achieve state-of-the-art per-formance. However, the computation of thehidden
vectors in such graph-based models isagnostic to the trigger candidate words,
po-tentially leaving irrelevant information for thetrigger candidate for event
prediction. In addi-tion, the current models for ED fail to exploitthe overall
contextual importance scores of thewords, which can be obtained via the
depen-dency tree, to boost the performance. In thisstudy, we propose a novel
gating mechanismto filter noisy information in the hidden vec-tors of the GCN
models for ED based on theinformation from the trigger candidate. Wealso
introduce novel mechanisms to achievethe contextual diversity for the gates and
theimportance score consistency for the graphsand models in ED. The experiments
show thatthe proposed model achieves state-of-the-artperformance on two ED
datasets
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 08:28:28 GMT'}]",2020-10-28,"[['Lai', 'Viet Dac', ''], ['Nguyen', 'Tuan Ngo', ''], ['Nguyen', 'Thien Huu', '']]"
1370314,2010.13984,Siwon Kim,"Siwon Kim, Jihun Yi, Eunji Kim, and Sungroh Yoon",Interpretation of NLP models through input marginalization,"10 pages, 5 figures, to be published in the 2020 Conference on
  Empirical Methods in Natural Language Processing (EMNLP 2020)",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  To demystify the ""black box"" property of deep neural networks for natural
language processing (NLP), several methods have been proposed to interpret
their predictions by measuring the change in prediction probability after
erasing each token of an input. Since existing methods replace each token with
a predefined value (i.e., zero), the resulting sentence lies out of the
training data distribution, yielding misleading interpretations. In this study,
we raise the out-of-distribution problem induced by the existing interpretation
methods and present a remedy; we propose to marginalize each token out. We
interpret various NLP models trained for sentiment analysis and natural
language inference using the proposed method.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 01:40:41 GMT'}]",2020-10-28,"[['Kim', 'Siwon', ''], ['Yi', 'Jihun', ''], ['Kim', 'Eunji', ''], ['Yoon', 'Sungroh', '']]"
1370156,2010.13826,Cheng-I Lai,"Cheng-I Lai, Yung-Sung Chuang, Hung-Yi Lee, Shang-Wen Li, James Glass","Semi-Supervised Spoken Language Understanding via Self-Supervised Speech
  and Language Model Pretraining",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Much recent work on Spoken Language Understanding (SLU) is limited in at
least one of three ways: models were trained on oracle text input and neglected
ASR errors, models were trained to predict only intents without the slot
values, or models were trained on a large amount of in-house data. In this
paper, we propose a clean and general framework to learn semantics directly
from speech with semi-supervision from transcribed or untranscribed speech to
address these issues. Our framework is built upon pretrained end-to-end (E2E)
ASR and self-supervised language models, such as BERT, and fine-tuned on a
limited amount of target SLU data. We study two semi-supervised settings for
the ASR component: supervised pretraining on transcribed speech, and
unsupervised pretraining by replacing the ASR encoder with self-supervised
speech representations, such as wav2vec. In parallel, we identify two essential
criteria for evaluating SLU models: environmental noise-robustness and E2E
semantics evaluation. Experiments on ATIS show that our SLU framework with
speech as input can perform on par with those using oracle text as input in
semantics understanding, even though environmental noise is present and a
limited amount of labeled semantics data is available for training.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 18:21:27 GMT'}]",2020-10-28,"[['Lai', 'Cheng-I', ''], ['Chuang', 'Yung-Sung', ''], ['Lee', 'Hung-Yi', ''], ['Li', 'Shang-Wen', ''], ['Glass', 'James', '']]"
1370432,2010.14102,Wen Wu,"Wen Wu, Chao Zhang, Philip C. Woodland","Emotion recognition by fusing time synchronous and time asynchronous
  representations",,,,,cs.CL cs.LG cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, a novel two-branch neural network model structure is proposed
for multimodal emotion recognition, which consists of a time synchronous branch
(TSB) and a time asynchronous branch (TAB). To capture correlations between
each word and its acoustic realisation, the TSB combines speech and text
modalities at each input window frame and then does pooling across time to form
a single embedding vector. The TAB, by contrast, provides cross-utterance
information by integrating sentence text embeddings from a number of context
utterances into another embedding vector. The final emotion classification uses
both the TSB and the TAB embeddings. Experimental results on the IEMOCAP
dataset demonstrate that the two-branch structure achieves state-of-the-art
results in 4-way classification with all common test setups. When using
automatic speech recognition (ASR) output instead of manually transcribed
reference text, it is shown that the cross-utterance information considerably
improves the robustness against ASR errors. Furthermore, by incorporating an
extra class for all the other emotions, the final 5-way classification system
with ASR hypotheses can be viewed as a prototype for more realistic emotion
recognition systems.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 07:14:31 GMT'}]",2020-10-28,"[['Wu', 'Wen', ''], ['Zhang', 'Chao', ''], ['Woodland', 'Philip C.', '']]"
1370391,2010.14061,Yan Zeng,Yan Zeng and Jian-Yun Nie,"Multi-Domain Dialogue State Tracking -- A Purely Transformer-Based
  Generative Approach","[v0], 8 pages, 3 figures. arXiv admin note: text overlap with
  arXiv:2010.11137",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We investigate the problem of multi-domain Dialogue State Tracking (DST) with
open vocabulary. Existing approaches exploit BERT encoder and copy-based RNN
decoder, where the encoder first predicts the state operation, and then the
decoder generates new slot values. However, in this stacked encoder-decoder
structure, the operation prediction objective only affects the BERT encoder and
the value generation objective mainly affects the RNN decoder. In this paper,
we propose a purely Transformer-based framework that uses BERT as both encoder
and decoder. In so doing, the operation prediction objective and the value
generation objective can jointly optimize our model for DST. At the decoding
step, we re-use the hidden states of the encoder in the self-attention
mechanism of the corresponding decoder layer to construct a flat model
structure for effective parameter updating. Experimental results show that our
approach substantially outperforms the existing state-of-the-art framework, and
it also achieves very competitive performance to the best ontology-based
approaches.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 04:54:52 GMT'}]",2020-10-28,"[['Zeng', 'Yan', ''], ['Nie', 'Jian-Yun', '']]"
1370372,2010.14042,Kasturi Bhattacharjee,"Kasturi Bhattacharjee, Miguel Ballesteros, Rishita Anubhai, Smaranda
  Muresan, Jie Ma, Faisal Ladhak, Yaser Al-Onaizan","To BERT or Not to BERT: Comparing Task-specific and Task-agnostic
  Semi-Supervised Approaches for Sequence Tagging","Accepted in the Proceedings of 2020 Conference on Empirical Methods
  in Natural Language Processing (EMNLP
  2020)(https://2020.emnlp.org/papers/main)",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Leveraging large amounts of unlabeled data using Transformer-like
architectures, like BERT, has gained popularity in recent times owing to their
effectiveness in learning general representations that can then be further
fine-tuned for downstream tasks to much success. However, training these models
can be costly both from an economic and environmental standpoint. In this work,
we investigate how to effectively use unlabeled data: by exploring the
task-specific semi-supervised approach, Cross-View Training (CVT) and comparing
it with task-agnostic BERT in multiple settings that include domain and task
relevant English data. CVT uses a much lighter model architecture and we show
that it achieves similar performance to BERT on a set of sequence tagging
tasks, with lesser financial and environmental impact.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 04:03:47 GMT'}]",2020-10-28,"[['Bhattacharjee', 'Kasturi', ''], ['Ballesteros', 'Miguel', ''], ['Anubhai', 'Rishita', ''], ['Muresan', 'Smaranda', ''], ['Ma', 'Jie', ''], ['Ladhak', 'Faisal', ''], ['Al-Onaizan', 'Yaser', '']]"
1370359,2010.14029,Runxin Xu,"Runxin Xu, Zhuo Zhi, Jun Cao, Mingxuan Wang, Lei Li",Volctrans Parallel Corpus Filtering System for WMT 2020,WMT 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we describe our submissions to the WMT20 shared task on
parallel corpus filtering and alignment for low-resource conditions. The task
requires the participants to align potential parallel sentence pairs out of the
given document pairs, and score them so that low-quality pairs can be filtered.
Our system, Volctrans, is made of two modules, i.e., a mining module and a
scoring module. Based on the word alignment model, the mining module adopts an
iterative mining strategy to extract latent parallel sentences. In the scoring
module, an XLM-based scorer provides scores, followed by reranking mechanisms
and ensemble. Our submissions outperform the baseline by 3.x/2.x and 2.x/2.x
for km-en and ps-en on From Scratch/Fine-Tune conditions, which is the highest
among all submissions.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 03:20:04 GMT'}]",2020-10-28,"[['Xu', 'Runxin', ''], ['Zhi', 'Zhuo', ''], ['Cao', 'Jun', ''], ['Wang', 'Mingxuan', ''], ['Li', 'Lei', '']]"
1370321,2010.13991,Wei Zou,"Dongwei Jiang, Wubo Li, Miao Cao, Ruixiong Zhang, Wei Zou, Kun Han,
  Xiangang Li","Speech SIMCLR: Combining Contrastive and Reconstruction Objective for
  Self-supervised Speech Representation Learning",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Self-supervised visual pretraining has shown significant progress recently.
Among those methods, SimCLR greatly advanced the state of the art in
self-supervised and semi-supervised learning on ImageNet. The input feature
representations for speech and visual tasks are both continuous, so it is
natural to consider applying similar objective on speech representation
learning. In this paper, we propose Speech SimCLR, a new self-supervised
objective for speech representation learning. During training, Speech SimCLR
applies augmentation on raw speech and its spectrogram. Its objective is the
combination of contrastive loss that maximizes agreement between differently
augmented samples in the latent space and reconstruction loss of input
representation. The proposed method achieved competitive results on speech
emotion recognition and speech recognition. When used as feature extractor, our
best model achieved 5.89% word error rate on LibriSpeech test-clean set using
LibriSpeech 960 hours as pretraining data and LibriSpeech train-clean-100 set
as fine-tuning data, which is the lowest error rate obtained in this setup to
the best of our knowledge.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 02:09:06 GMT'}]",2020-10-28,"[['Jiang', 'Dongwei', ''], ['Li', 'Wubo', ''], ['Cao', 'Miao', ''], ['Zhang', 'Ruixiong', ''], ['Zou', 'Wei', ''], ['Han', 'Kun', ''], ['Li', 'Xiangang', '']]"
1339591,2008.11869,Xinsong Zhang,Xinsong Zhang and Hang Li,AMBERT: A Pre-trained Language Model with Multi-Grained Tokenization,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pre-trained language models such as BERT have exhibited remarkable
performances in many tasks in natural language understanding (NLU). The tokens
in the models are usually fine-grained in the sense that for languages like
English they are words or sub-words and for languages like Chinese they are
characters. In English, for example, there are multi-word expressions which
form natural lexical units and thus the use of coarse-grained tokenization also
appears to be reasonable. In fact, both fine-grained and coarse-grained
tokenizations have advantages and disadvantages for learning of pre-trained
language models. In this paper, we propose a novel pre-trained language model,
referred to as AMBERT (A Multi-grained BERT), on the basis of both fine-grained
and coarse-grained tokenizations. For English, AMBERT takes both the sequence
of words (fine-grained tokens) and the sequence of phrases (coarse-grained
tokens) as input after tokenization, employs one encoder for processing the
sequence of words and the other encoder for processing the sequence of the
phrases, utilizes shared parameters between the two encoders, and finally
creates a sequence of contextualized representations of the words and a
sequence of contextualized representations of the phrases. Experiments have
been conducted on benchmark datasets for Chinese and English, including CLUE,
GLUE, SQuAD and RACE. The results show that AMBERT outperforms the existing
best performing models in almost all cases, particularly the improvements are
significant for Chinese.
","[{'version': 'v1', 'created': 'Thu, 27 Aug 2020 00:23:48 GMT'}, {'version': 'v2', 'created': 'Tue, 1 Sep 2020 05:29:27 GMT'}, {'version': 'v3', 'created': 'Tue, 27 Oct 2020 06:53:33 GMT'}]",2020-10-28,"[['Zhang', 'Xinsong', ''], ['Li', 'Hang', '']]"
1279334,2004.14564,Brian Thompson,Brian Thompson and Matt Post,"Automatic Machine Translation Evaluation in Many Languages via Zero-Shot
  Paraphrasing",EMNLP2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We frame the task of machine translation evaluation as one of scoring machine
translation output with a sequence-to-sequence paraphraser, conditioned on a
human reference. We propose training the paraphraser as a multilingual NMT
system, treating paraphrasing as a zero-shot translation task (e.g., Czech to
Czech). This results in the paraphraser's output mode being centered around a
copy of the input sequence, which represents the best case scenario where the
MT system output matches a human reference. Our method is simple and intuitive,
and does not require human judgements for training. Our single model (trained
in 39 languages) outperforms or statistically ties with all prior metrics on
the WMT 2019 segment-level shared metrics task in all languages (excluding
Gujarati where the model had no training data). We also explore using our model
for the task of quality estimation as a metric--conditioning on the source
instead of the reference--and find that it significantly outperforms every
submission to the WMT 2019 shared task on quality estimation in every language
pair.
","[{'version': 'v1', 'created': 'Thu, 30 Apr 2020 03:32:34 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 23:54:02 GMT'}]",2020-10-29,"[['Thompson', 'Brian', ''], ['Post', 'Matt', '']]"
1187463,1910.03544,Jianguo Zhang,"Jian-Guo Zhang, Kazuma Hashimoto, Chien-Sheng Wu, Yao Wan, Philip S.
  Yu, Richard Socher, Caiming Xiong","Find or Classify? Dual Strategy for Slot-Value Predictions on
  Multi-Domain Dialog State Tracking","14 pages, accepted at the 9th Joint Conference on Lexical and
  Computational Semantics (*SEM 2020). This version fixes small errors",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Dialog state tracking (DST) is a core component in task-oriented dialog
systems. Existing approaches for DST mainly fall into one of two categories,
namely, ontology-based and ontology-free methods. An ontology-based method
selects a value from a candidate-value list for each target slot, while an
ontology-free method extracts spans from dialog contexts. Recent work
introduced a BERT-based model to strike a balance between the two methods by
pre-defining categorical and non-categorical slots. However, it is not clear
enough which slots are better handled by either of the two slot types, and the
way to use the pre-trained model has not been well investigated. In this paper,
we propose a simple yet effective dual-strategy model for DST, by adapting a
single BERT-style reading comprehension model to jointly handle both the
categorical and non-categorical slots. Our experiments on the MultiWOZ datasets
show that our method significantly outperforms the BERT-based counterpart,
finding that the key is a deep interaction between the domain-slot and context
information. When evaluated on noisy (MultiWOZ 2.0) and cleaner (MultiWOZ 2.1)
settings, our method performs competitively and robustly across the two
different settings. Our method sets the new state of the art in the noisy
setting, while performing more robustly than the best model in the cleaner
setting. We also conduct a comprehensive error analysis on the dataset,
including the effects of the dual strategy for each slot, to facilitate future
research.
","[{'version': 'v1', 'created': 'Tue, 8 Oct 2019 17:08:39 GMT'}, {'version': 'v2', 'created': 'Thu, 10 Oct 2019 08:04:12 GMT'}, {'version': 'v3', 'created': 'Tue, 29 Sep 2020 08:37:44 GMT'}, {'version': 'v4', 'created': 'Wed, 28 Oct 2020 10:07:01 GMT'}]",2020-10-29,"[['Zhang', 'Jian-Guo', ''], ['Hashimoto', 'Kazuma', ''], ['Wu', 'Chien-Sheng', ''], ['Wan', 'Yao', ''], ['Yu', 'Philip S.', ''], ['Socher', 'Richard', ''], ['Xiong', 'Caiming', '']]"
1342828,2009.01325,Ryan Lowe T.,"Nisan Stiennon, Long Ouyang, Jeff Wu, Daniel M. Ziegler, Ryan Lowe,
  Chelsea Voss, Alec Radford, Dario Amodei, Paul Christiano",Learning to summarize from human feedback,NeurIPS 2020 camera ready,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As language models become more powerful, training and evaluation are
increasingly bottlenecked by the data and metrics used for a particular task.
For example, summarization models are often trained to predict human reference
summaries and evaluated using ROUGE, but both of these metrics are rough
proxies for what we really care about---summary quality. In this work, we show
that it is possible to significantly improve summary quality by training a
model to optimize for human preferences. We collect a large, high-quality
dataset of human comparisons between summaries, train a model to predict the
human-preferred summary, and use that model as a reward function to fine-tune a
summarization policy using reinforcement learning. We apply our method to a
version of the TL;DR dataset of Reddit posts and find that our models
significantly outperform both human reference summaries and much larger models
fine-tuned with supervised learning alone. Our models also transfer to CNN/DM
news articles, producing summaries nearly as good as the human reference
without any news-specific fine-tuning. We conduct extensive analyses to
understand our human feedback dataset and fine-tuned models We establish that
our reward model generalizes to new datasets, and that optimizing our reward
model results in better summaries than optimizing ROUGE according to humans. We
hope the evidence from our paper motivates machine learning researchers to pay
closer attention to how their training loss affects the model behavior they
actually want.
","[{'version': 'v1', 'created': 'Wed, 2 Sep 2020 19:54:41 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 22:19:53 GMT'}]",2020-10-29,"[['Stiennon', 'Nisan', ''], ['Ouyang', 'Long', ''], ['Wu', 'Jeff', ''], ['Ziegler', 'Daniel M.', ''], ['Lowe', 'Ryan', ''], ['Voss', 'Chelsea', ''], ['Radford', 'Alec', ''], ['Amodei', 'Dario', ''], ['Christiano', 'Paul', '']]"
1201327,1911.02733,Xue Mengge,"Xue Mengge, Yu Bowen, Liu Tingwen, Zhang Yue, Meng Erli, Wang Bin",Porous Lattice-based Transformer Encoder for Chinese NER,"9 pages, 4 figures",COLING 2020,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Incorporating lattices into character-level Chinese named entity recognition
is an effective method to exploit explicit word information. Recent works
extend recurrent and convolutional neural networks to model lattice inputs.
However, due to the DAG structure or the variable-sized potential word set for
lattice inputs, these models prevent the convenient use of batched computation,
resulting in serious inefficient. In this paper, we propose a porous
lattice-based transformer encoder for Chinese named entity recognition, which
is capable to better exploit the GPU parallelism and batch the computation
owing to the mask mechanism in transformer. We first investigate the
lattice-aware self-attention coupled with relative position representations to
explore effective word information in the lattice structure. Besides, to
strengthen the local dependencies among neighboring tokens, we propose a novel
porous structure during self-attentional computation processing, in which every
two non-neighboring tokens are connected through a shared pivot node.
Experimental results on four datasets show that our model performs up to 9.47
times faster than state-of-the-art models, while is roughly on a par with its
performance. The source code of this paper can be obtained from
https://github.com/xxx/xxx.
","[{'version': 'v1', 'created': 'Thu, 7 Nov 2019 02:58:17 GMT'}, {'version': 'v2', 'created': 'Fri, 24 Apr 2020 14:46:51 GMT'}, {'version': 'v3', 'created': 'Wed, 28 Oct 2020 12:52:24 GMT'}]",2020-10-29,"[['Mengge', 'Xue', ''], ['Bowen', 'Yu', ''], ['Tingwen', 'Liu', ''], ['Yue', 'Zhang', ''], ['Erli', 'Meng', ''], ['Bin', 'Wang', '']]"
1290078,2005.10283,Bryan Eikema,Bryan Eikema and Wilker Aziz,"Is MAP Decoding All You Need? The Inadequacy of the Mode in Neural
  Machine Translation",COLING 2020 camera-ready,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Recent studies have revealed a number of pathologies of neural machine
translation (NMT) systems. Hypotheses explaining these mostly suggest there is
something fundamentally wrong with NMT as a model or its training algorithm,
maximum likelihood estimation (MLE). Most of this evidence was gathered using
maximum a posteriori (MAP) decoding, a decision rule aimed at identifying the
highest-scoring translation, i.e. the mode. We argue that the evidence
corroborates the inadequacy of MAP decoding more than casts doubt on the model
and its training algorithm. In this work, we show that translation
distributions do reproduce various statistics of the data well, but that beam
search strays from such statistics. We show that some of the known pathologies
and biases of NMT are due to MAP decoding and not to NMT's statistical
assumptions nor MLE. In particular, we show that the most likely translations
under the model accumulate so little probability mass that the mode can be
considered essentially arbitrary. We therefore advocate for the use of decision
rules that take into account the translation distribution holistically. We show
that an approximation to minimum Bayes risk decoding gives competitive results
confirming that NMT models do capture important aspects of translation well in
expectation.
","[{'version': 'v1', 'created': 'Wed, 20 May 2020 18:05:51 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 11:29:52 GMT'}]",2020-10-29,"[['Eikema', 'Bryan', ''], ['Aziz', 'Wilker', '']]"
1303020,2006.08506,Tobias Watzel,"Tobias Watzel, Ludwig K\""urzinger, Lujun Li, Gerhard Rigoll",Regularized Forward-Backward Decoder for Attention Models,,,,,eess.AS cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Nowadays, attention models are one of the popular candidates for speech
recognition. So far, many studies mainly focus on the encoder structure or the
attention module to enhance the performance of these models. However, mostly
ignore the decoder. In this paper, we propose a novel regularization technique
incorporating a second decoder during the training phase. This decoder is
optimized on time-reversed target labels beforehand and supports the standard
decoder during training by adding knowledge from future context. Since it is
only added during training, we are not changing the basic structure of the
network or adding complexity during decoding. We evaluate our approach on the
smaller TEDLIUMv2 and the larger LibriSpeech dataset, achieving consistent
improvements on both of them.
","[{'version': 'v1', 'created': 'Mon, 15 Jun 2020 16:04:16 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 14:00:52 GMT'}]",2020-10-29,"[['Watzel', 'Tobias', ''], ['Kürzinger', 'Ludwig', ''], ['Li', 'Lujun', ''], ['Rigoll', 'Gerhard', '']]"
1295146,2006.00632,Barbara Plank,Alan Ramponi and Barbara Plank,Neural Unsupervised Domain Adaptation in NLP---A Survey,"COLING 2020. Accompanying repository:
  https://github.com/bplank/awesome-neural-adaptation-in-NLP",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Deep neural networks excel at learning from labeled data and achieve
state-of-the-art resultson a wide array of Natural Language Processing tasks.
In contrast, learning from unlabeled data, especially under domain shift,
remains a challenge. Motivated by the latest advances, in this survey we review
neural unsupervised domain adaptation techniques which do not require labeled
target domain data. This is a more challenging yet a more widely applicable
setup. We outline methods, from early traditional non-neural methods to
pre-trained model transfer. We also revisit the notion of domain, and we
uncover a bias in the type of Natural Language Processing tasks which received
most attention. Lastly, we outline future directions, particularly the broader
need for out-of-distribution generalization of future NLP.
","[{'version': 'v1', 'created': 'Sun, 31 May 2020 22:34:14 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 08:24:14 GMT'}]",2020-10-29,"[['Ramponi', 'Alan', ''], ['Plank', 'Barbara', '']]"
1292163,2005.12368,Marija Stepanovi\'c,"Andreas Kirkedal, Marija Stepanovi\'c, Barbara Plank",FT Speech: Danish Parliament Speech Corpus,Accepted at Interspeech 2020,,10.21437/Interspeech.2020-3164,,cs.CL cs.LG cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper introduces FT Speech, a new speech corpus created from the
recorded meetings of the Danish Parliament, otherwise known as the Folketing
(FT). The corpus contains over 1,800 hours of transcribed speech by a total of
434 speakers. It is significantly larger in duration, vocabulary, and amount of
spontaneous speech than the existing public speech corpora for Danish, which
are largely limited to read-aloud and dictation data. We outline design
considerations, including the preprocessing methods and the alignment
procedure. To evaluate the quality of the corpus, we train automatic speech
recognition systems on the new resource and compare them to the systems trained
on the Danish part of Spr\r{a}kbanken, the largest public ASR corpus for Danish
to date. Our baseline results show that we achieve a 14.01 WER on the new
corpus. A combination of FT Speech with in-domain language data provides
comparable results to models trained specifically on Spr\r{a}kbanken, showing
that FT Speech transfers well to this data set. Interestingly, our results
demonstrate that the opposite is not the case. This shows that FT Speech
provides a valuable resource for promoting research on Danish ASR with more
spontaneous speech.
","[{'version': 'v1', 'created': 'Mon, 25 May 2020 19:51:18 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 13:36:44 GMT'}]",2020-10-29,"[['Kirkedal', 'Andreas', ''], ['Stepanović', 'Marija', ''], ['Plank', 'Barbara', '']]"
1364540,2010.08210,Xue Mengge,"Mengge Xue, Bowen Yu, Zhenyu Zhang, Tingwen Liu, Yue Zhang, Bin Wang",Coarse-to-Fine Pre-training for Named Entity Recognition,,EMNLP 2020,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  More recently, Named Entity Recognition hasachieved great advances aided by
pre-trainingapproaches such as BERT. However, currentpre-training techniques
focus on building lan-guage modeling objectives to learn a gen-eral
representation, ignoring the named entity-related knowledge. To this end, we
proposea NER-specific pre-training framework to in-ject coarse-to-fine
automatically mined entityknowledge into pre-trained models. Specifi-cally, we
first warm-up the model via an en-tity span identification task by training it
withWikipedia anchors, which can be deemed asgeneral-typed entities. Then we
leverage thegazetteer-based distant supervision strategy totrain the model
extract coarse-grained typedentities. Finally, we devise a
self-supervisedauxiliary task to mine the fine-grained namedentity knowledge
via clustering.Empiricalstudies on three public NER datasets demon-strate that
our framework achieves significantimprovements against several pre-trained
base-lines, establishing the new state-of-the-art per-formance on three
benchmarks. Besides, weshow that our framework gains promising re-sults without
using human-labeled trainingdata, demonstrating its effectiveness in label-few
and low-resource scenarios
","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 07:39:20 GMT'}]",2020-10-29,"[['Xue', 'Mengge', ''], ['Yu', 'Bowen', ''], ['Zhang', 'Zhenyu', ''], ['Liu', 'Tingwen', ''], ['Zhang', 'Yue', ''], ['Wang', 'Bin', '']]"
1361978,2010.05648,Steffen Eger,Steffen Eger and Yannik Benz,From Hero to Z\'eroe: A Benchmark of Low-Level Adversarial Attacks,"Authors accidentally in wrong order; cannot be undone due to
  conference constraints. Accepted for publication at AACL 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Adversarial attacks are label-preserving modifications to inputs of machine
learning classifiers designed to fool machines but not humans. Natural Language
Processing (NLP) has mostly focused on high-level attack scenarios such as
paraphrasing input texts. We argue that these are less realistic in typical
application scenarios such as in social media, and instead focus on low-level
attacks on the character-level. Guided by human cognitive abilities and human
robustness, we propose the first large-scale catalogue and benchmark of
low-level adversarial attacks, which we dub Z\'eroe, encompassing nine
different attack modes including visual and phonetic adversaries. We show that
RoBERTa, NLP's current workhorse, fails on our attacks. Our dataset provides a
benchmark for testing robustness of future more human-like NLP models.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 12:35:36 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 12:53:05 GMT'}]",2020-10-29,"[['Eger', 'Steffen', ''], ['Benz', 'Yannik', '']]"
1359177,2010.02847,Haiyang Zhang,"Haiyang Zhang, Alison Sneyd and Mark Stevenson","Robustness and Reliability of Gender Bias Assessment in Word Embeddings:
  The Role of Base Pairs",Accepted at AACL-IJCNLP 2020,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  It has been shown that word embeddings can exhibit gender bias, and various
methods have been proposed to quantify this. However, the extent to which the
methods are capturing social stereotypes inherited from the data has been
debated. Bias is a complex concept and there exist multiple ways to define it.
Previous work has leveraged gender word pairs to measure bias and extract
biased analogies. We show that the reliance on these gendered pairs has strong
limitations: bias measures based off of them are not robust and cannot identify
common types of real-world bias, whilst analogies utilising them are unsuitable
indicators of bias. In particular, the well-known analogy ""man is to
computer-programmer as woman is to homemaker"" is due to word similarity rather
than societal bias. This has important implications for work on measuring bias
in embeddings and related work debiasing embeddings.
","[{'version': 'v1', 'created': 'Tue, 6 Oct 2020 16:09:05 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 21:24:16 GMT'}]",2020-10-29,"[['Zhang', 'Haiyang', ''], ['Sneyd', 'Alison', ''], ['Stevenson', 'Mark', '']]"
1356617,2010.00287,Ehsan Doostmohammadi,"Ehsan Doostmohammadi, Minoo Nassajian, Adel Rahimi","Joint Persian Word Segmentation Correction and Zero-Width Non-Joiner
  Recognition Using BERT",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Words are properly segmented in the Persian writing system; in practice,
however, these writing rules are often neglected, resulting in single words
being written disjointedly and multiple words written without any white spaces
between them. This paper addresses the problems of word segmentation and
zero-width non-joiner (ZWNJ) recognition in Persian, which we approach jointly
as a sequence labeling problem. We achieved a macro-averaged F1-score of 92.40%
on a carefully collected corpus of 500 sentences with a high level of
difficulty.
","[{'version': 'v1', 'created': 'Thu, 1 Oct 2020 10:32:17 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 09:40:18 GMT'}]",2020-10-29,"[['Doostmohammadi', 'Ehsan', ''], ['Nassajian', 'Minoo', ''], ['Rahimi', 'Adel', '']]"
1280566,2005.00771,Xiang Li,"Michael Boratko, Xiang Lorraine Li, Rajarshi Das, Tim O'Gorman, Dan
  Le, Andrew McCallum","ProtoQA: A Question Answering Dataset for Prototypical Common-Sense
  Reasoning",First four authors contribute equally,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Given questions regarding some prototypical situation such as Name something
that people usually do before they leave the house for work? a human can easily
answer them via acquired experiences. There can be multiple right answers for
such questions, with some more common for a situation than others. This paper
introduces a new question answering dataset for training and evaluating common
sense reasoning capabilities of artificial intelligence systems in such
prototypical situations. The training set is gathered from an existing set of
questions played in a long-running international game show FAMILY- FEUD. The
hidden evaluation set is created by gathering answers for each question from
100 crowd-workers. We also propose a generative evaluation task where a model
has to output a ranked list of answers, ideally covering all prototypical
answers for a question. After presenting multiple competitive baseline models,
we find that human performance still exceeds model scores on all evaluation
metrics with a meaningful gap, supporting the challenging nature of the task.
","[{'version': 'v1', 'created': 'Sat, 2 May 2020 09:40:05 GMT'}, {'version': 'v2', 'created': 'Tue, 6 Oct 2020 05:35:05 GMT'}, {'version': 'v3', 'created': 'Tue, 27 Oct 2020 21:23:03 GMT'}]",2020-10-29,"[['Boratko', 'Michael', ''], ['Li', 'Xiang Lorraine', ''], ['Das', 'Rajarshi', ''], [""O'Gorman"", 'Tim', ''], ['Le', 'Dan', ''], ['McCallum', 'Andrew', '']]"
1279954,2005.00159,Pratyush Maini,"Pratyush Maini, Keshav Kolluru, Danish Pruthi, Mausam","Why and when should you pool? Analyzing Pooling in Recurrent
  Architectures","Accepted to Findings of EMNLP 2020, to be presented at BlackBoxNLP.
  Updated Version",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pooling-based recurrent neural architectures consistently outperform their
counterparts without pooling. However, the reasons for their enhanced
performance are largely unexamined. In this work, we examine three commonly
used pooling techniques (mean-pooling, max-pooling, and attention), and propose
max-attention, a novel variant that effectively captures interactions among
predictive tokens in a sentence. We find that pooling-based architectures
substantially differ from their non-pooling equivalents in their learning
ability and positional biases--which elucidate their performance benefits. By
analyzing the gradient propagation, we discover that pooling facilitates better
gradient flow compared to BiLSTMs. Further, we expose how BiLSTMs are
positionally biased towards tokens in the beginning and the end of a sequence.
Pooling alleviates such biases. Consequently, we identify settings where
pooling offers large benefits: (i) in low resource scenarios, and (ii) when
important words lie towards the middle of the sentence. Among the pooling
techniques studied, max-attention is the most effective, resulting in
significant performance gains on several text classification tasks.
","[{'version': 'v1', 'created': 'Fri, 1 May 2020 00:47:37 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 02:11:02 GMT'}]",2020-10-29,"[['Maini', 'Pratyush', ''], ['Kolluru', 'Keshav', ''], ['Pruthi', 'Danish', ''], ['Mausam', '', '']]"
1332657,2008.04935,Brian Thompson,Brian Thompson and Matt Post,"Paraphrase Generation as Zero-Shot Multilingual Translation:
  Disentangling Semantic Similarity from Lexical and Syntactic Diversity",WMT2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent work has shown that a multilingual neural machine translation (NMT)
model can be used to judge how well a sentence paraphrases another sentence in
the same language (Thompson and Post, 2020); however, attempting to generate
paraphrases from such a model using standard beam search produces trivial
copies or near copies. We introduce a simple paraphrase generation algorithm
which discourages the production of n-grams that are present in the input. Our
approach enables paraphrase generation in many languages from a single
multilingual NMT model. Furthermore, the amount of lexical diversity between
the input and output can be controlled at generation time. We conduct a human
evaluation to compare our method to a paraphraser trained on the large English
synthetic paraphrase database ParaBank 2 (Hu et al., 2019c) and find that our
method produces paraphrases that better preserve meaning and are more
gramatical, for the same level of lexical diversity. Additional smaller human
assessments demonstrate our approach also works in two non-English languages.
","[{'version': 'v1', 'created': 'Tue, 11 Aug 2020 18:05:34 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 02:54:13 GMT'}]",2020-10-29,"[['Thompson', 'Brian', ''], ['Post', 'Matt', '']]"
1349467,2009.07964,Zhijing Jin,"Xiaoyu Xing, Zhijing Jin, Di Jin, Bingning Wang, Qi Zhang, and
  Xuanjing Huang","Tasty Burgers, Soggy Fries: Probing Aspect Robustness in Aspect-Based
  Sentiment Analysis","EMNLP 2020, long paper",,,,cs.CL cs.IR cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  Aspect-based sentiment analysis (ABSA) aims to predict the sentiment towards
a specific aspect in the text. However, existing ABSA test sets cannot be used
to probe whether a model can distinguish the sentiment of the target aspect
from the non-target aspects. To solve this problem, we develop a simple but
effective approach to enrich ABSA test sets. Specifically, we generate new
examples to disentangle the confounding sentiments of the non-target aspects
from the target aspect's sentiment. Based on the SemEval 2014 dataset, we
construct the Aspect Robustness Test Set (ARTS) as a comprehensive probe of the
aspect robustness of ABSA models. Over 92% data of ARTS show high fluency and
desired sentiment on all aspects by human evaluation. Using ARTS, we analyze
the robustness of nine ABSA models, and observe, surprisingly, that their
accuracy drops by up to 69.73%. We explore several ways to improve aspect
robustness, and find that adversarial training can improve models' performance
on ARTS by up to 32.85%. Our code and new test set are available at
https://github.com/zhijing-jin/ARTS_TestSet
","[{'version': 'v1', 'created': 'Wed, 16 Sep 2020 22:38:18 GMT'}, {'version': 'v2', 'created': 'Wed, 30 Sep 2020 05:36:10 GMT'}, {'version': 'v3', 'created': 'Sun, 4 Oct 2020 15:35:36 GMT'}, {'version': 'v4', 'created': 'Wed, 28 Oct 2020 08:19:36 GMT'}]",2020-10-29,"[['Xing', 'Xiaoyu', ''], ['Jin', 'Zhijing', ''], ['Jin', 'Di', ''], ['Wang', 'Bingning', ''], ['Zhang', 'Qi', ''], ['Huang', 'Xuanjing', '']]"
1303623,2006.09109,Steffen Eger,Steffen Eger and Johannes Daxenberger and Iryna Gurevych,"How to Probe Sentence Embeddings in Low-Resource Languages: On
  Structural Design Choices for Probing Task Evaluation",Accepted for Publication at CONLL 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Sentence encoders map sentences to real valued vectors for use in downstream
applications. To peek into these representations - e.g., to increase
interpretability of their results - probing tasks have been designed which
query them for linguistic knowledge. However, designing probing tasks for
lesser-resourced languages is tricky, because these often lack large-scale
annotated data or (high-quality) dependency parsers as a prerequisite of
probing task design in English. To investigate how to probe sentence embeddings
in such cases, we investigate sensitivity of probing task results to structural
design choices, conducting the first such large scale study. We show that
design choices like size of the annotated probing dataset and type of
classifier used for evaluation do (sometimes substantially) influence probing
outcomes. We then probe embeddings in a multilingual setup with design choices
that lie in a 'stable region', as we identify for English, and find that
results on English do not transfer to other languages. Fairer and more
comprehensive sentence-level probing evaluation should thus be carried out on
multiple languages in the future.
","[{'version': 'v1', 'created': 'Tue, 16 Jun 2020 12:37:50 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 12:38:37 GMT'}]",2020-10-29,"[['Eger', 'Steffen', ''], ['Daxenberger', 'Johannes', ''], ['Gurevych', 'Iryna', '']]"
1139420,1906.07234,Siyuan Feng,"Siyuan Feng, Tan Lee, Zhiyuan Peng","Combining Adversarial Training and Disentangled Speech Representation
  for Robust Zero-Resource Subword Modeling","5 pages, 3 figures, accepted for publication in INTERSPEECH 2019,
  Graz, Austria",,10.21437/Interspeech.2019-1337,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This study addresses the problem of unsupervised subword unit discovery from
untranscribed speech. It forms the basis of the ultimate goal of ZeroSpeech
2019, building text-to-speech systems without text labels. In this work, unit
discovery is formulated as a pipeline of phonetically discriminative feature
learning and unit inference. One major difficulty in robust unsupervised
feature learning is dealing with speaker variation. Here the robustness towards
speaker variation is achieved by applying adversarial training and FHVAE based
disentangled speech representation learning. A comparison of the two approaches
as well as their combination is studied in a DNN-bottleneck feature (DNN-BNF)
architecture. Experiments are conducted on ZeroSpeech 2019 and 2017.
Experimental results on ZeroSpeech 2017 show that both approaches are effective
while the latter is more prominent, and that their combination brings further
marginal improvement in across-speaker condition. Results on ZeroSpeech 2019
show that in the ABX discriminability task, our approaches significantly
outperform the official baseline, and are competitive to or even outperform the
official topline. The proposed unit sequence smoothing algorithm improves
synthesis quality, at a cost of slight decrease in ABX discriminability.
","[{'version': 'v1', 'created': 'Mon, 17 Jun 2019 19:40:46 GMT'}, {'version': 'v2', 'created': 'Wed, 3 Jul 2019 12:22:28 GMT'}, {'version': 'v3', 'created': 'Fri, 9 Aug 2019 15:55:00 GMT'}]",2020-10-29,"[['Feng', 'Siyuan', ''], ['Lee', 'Tan', ''], ['Peng', 'Zhiyuan', '']]"
1371089,2010.14759,Yufang Hou,Yufang Hou,"Fine-grained Information Status Classification Using Discourse
  Context-Aware BERT","accepted at COLING2020. arXiv admin note: substantial text overlap
  with arXiv:1908.04755",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Previous work on bridging anaphora recognition (Hou et al., 2013a) casts the
problem as a subtask of learning fine-grained information status (IS). However,
these systems heavily depend on many hand-crafted linguistic features. In this
paper, we propose a simple discourse context-aware BERT model for fine-grained
IS classification. On the ISNotes corpus (Markert et al., 2012), our model
achieves new state-of-the-art performance on fine-grained IS classification,
obtaining a 4.8 absolute overall accuracy improvement compared to Hou et al.
(2013a). More importantly, we also show an improvement of 10.5 F1 points for
bridging anaphora recognition without using any complex hand-crafted semantic
features designed for capturing the bridging phenomenon. We further analyze the
trained model and find that the most attended signals for each IS category
correspond well to linguistic notions of information status.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 22:30:17 GMT'}]",2020-10-29,"[['Hou', 'Yufang', '']]"
1371128,2010.14798,Shuai Zhang,"Shuai Zhang, Jiangyan Yi, Zhengkun Tian, Ye Bai, Jianhua Tao, Zhengqi
  wen","Decoupling Pronunciation and Language for End-to-end Code-switching
  Automatic Speech Recognition","5 pages, 1 figures",,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite the recent significant advances witnessed in end-to-end (E2E) ASR
system for code-switching, hunger for audio-text paired data limits the further
improvement of the models' performance. In this paper, we propose a decoupled
transformer model to use monolingual paired data and unpaired text data to
alleviate the problem of code-switching data shortage. The model is decoupled
into two parts: audio-to-phoneme (A2P) network and phoneme-to-text (P2T)
network. The A2P network can learn acoustic pattern scenarios using large-scale
monolingual paired data. Meanwhile, it generates multiple phoneme sequence
candidates for single audio data in real-time during the training process. Then
the generated phoneme-text paired data is used to train the P2T network. This
network can be pre-trained with large amounts of external unpaired text data.
By using monolingual data and unpaired text data, the decoupled transformer
model reduces the high dependency on code-switching paired training data of E2E
model to a certain extent. Finally, the two networks are optimized jointly
through attention fusion. We evaluate the proposed method on the public
Mandarin-English code-switching dataset. Compared with our transformer
baseline, the proposed method achieves 18.14% relative mix error rate
reduction.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 07:46:15 GMT'}]",2020-10-29,"[['Zhang', 'Shuai', ''], ['Yi', 'Jiangyan', ''], ['Tian', 'Zhengkun', ''], ['Bai', 'Ye', ''], ['Tao', 'Jianhua', ''], ['wen', 'Zhengqi', '']]"
1371202,2010.14872,Kristian Miok,"Kristian Miok, Gregor Pirs and Marko Robnik-Sikonja",Bayesian Methods for Semi-supervised Text Annotation,"Accepted for COLING 2020, The 14th Linguistic Annotation Workshop",,,,cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Human annotations are an important source of information in the development
of natural language understanding approaches. As under the pressure of
productivity annotators can assign different labels to a given text, the
quality of produced annotations frequently varies. This is especially the case
if decisions are difficult, with high cognitive load, requires awareness of
broader context, or careful consideration of background knowledge. To alleviate
the problem, we propose two semi-supervised methods to guide the annotation
process: a Bayesian deep learning model and a Bayesian ensemble method. Using a
Bayesian deep learning method, we can discover annotations that cannot be
trusted and might require reannotation. A recently proposed Bayesian ensemble
method helps us to combine the annotators' labels with predictions of trained
models. According to the results obtained from three hate speech detection
experiments, the proposed Bayesian methods can improve the annotations and
prediction performance of BERT models.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 10:42:04 GMT'}]",2020-10-29,"[['Miok', 'Kristian', ''], ['Pirs', 'Gregor', ''], ['Robnik-Sikonja', 'Marko', '']]"
1371171,2010.14841,Chengyu Wang,"Yiwu Yao, Yuchao Li, Chengyu Wang, Tianhang Yu, Houjiang Chen,
  Xiaotang Jiang, Jun Yang, Jun Huang, Wei Lin, Hui Shu, Chengfei Lv","INT8 Winograd Acceleration for Conv1D Equipped ASR Models Deployed on
  Mobile Devices",,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The intensive computation of Automatic Speech Recognition (ASR) models
obstructs them from being deployed on mobile devices. In this paper, we present
a novel quantized Winograd optimization pipeline, which combines the
quantization and fast convolution to achieve efficient inference acceleration
on mobile devices for ASR models. To avoid the information loss due to the
combination of quantization and Winograd convolution, a Range-Scaled
Quantization (RSQ) training method is proposed to expand the quantized
numerical range and to distill knowledge from high-precision values. Moreover,
an improved Conv1D equipped DFSMN (ConvDFSMN) model is designed for mobile
deployment. We conduct extensive experiments on both ConvDFSMN and Wav2letter
models. Results demonstrate the models can be effectively optimized with the
proposed pipeline. Especially, Wav2letter achieves 1.48* speedup with an
approximate 0.07% WER decrease on ARMv7-based mobile devices.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 09:25:49 GMT'}]",2020-10-29,"[['Yao', 'Yiwu', ''], ['Li', 'Yuchao', ''], ['Wang', 'Chengyu', ''], ['Yu', 'Tianhang', ''], ['Chen', 'Houjiang', ''], ['Jiang', 'Xiaotang', ''], ['Yang', 'Jun', ''], ['Huang', 'Jun', ''], ['Lin', 'Wei', ''], ['Shu', 'Hui', ''], ['Lv', 'Chengfei', '']]"
1371136,2010.14806,Xiao Pan,"Liwei Wu, Xiao Pan, Zehui Lin, Yaoming Zhu, Mingxuan Wang, Lei Li",The Volctrans Machine Translation System for WMT20,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper describes our VolcTrans system on WMT20 shared news translation
task. We participated in 8 translation directions. Our basic systems are based
on Transformer, with several variants (wider or deeper Transformers, dynamic
convolutions). The final system includes text pre-process, data selection,
synthetic data generation, advanced model ensemble, and multilingual
pre-training.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 08:08:12 GMT'}]",2020-10-29,"[['Wu', 'Liwei', ''], ['Pan', 'Xiao', ''], ['Lin', 'Zehui', ''], ['Zhu', 'Yaoming', ''], ['Wang', 'Mingxuan', ''], ['Li', 'Lei', '']]"
1371134,2010.14804,Benlai Tang,"Zhonghao Li, Benlai Tang, Xiang Yin, Yuan Wan, Ling Xu, Chen Shen,
  Zejun Ma","PPG-based singing voice conversion with adversarial representation
  learning",,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Singing voice conversion (SVC) aims to convert the voice of one singer to
that of other singers while keeping the singing content and melody. On top of
recent voice conversion works, we propose a novel model to steadily convert
songs while keeping their naturalness and intonation. We build an end-to-end
architecture, taking phonetic posteriorgrams (PPGs) as inputs and generating
mel spectrograms. Specifically, we implement two separate encoders: one encodes
PPGs as content, and the other compresses mel spectrograms to supply acoustic
and musical information. To improve the performance on timbre and melody, an
adversarial singer confusion module and a mel-regressive representation
learning module are designed for the model. Objective and subjective
experiments are conducted on our private Chinese singing corpus. Comparing with
the baselines, our methods can significantly improve the conversion performance
in terms of naturalness, melody, and voice similarity. Moreover, our PPG-based
method is proved to be robust for noisy sources.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 08:03:27 GMT'}]",2020-10-29,"[['Li', 'Zhonghao', ''], ['Tang', 'Benlai', ''], ['Yin', 'Xiang', ''], ['Wan', 'Yuan', ''], ['Xu', 'Ling', ''], ['Shen', 'Chen', ''], ['Ma', 'Zejun', '']]"
1371124,2010.14794,Kun Zhou,"Kun Zhou, Berrak Sisman, Rui Liu and Haizhou Li","Seen and Unseen emotional style transfer for voice conversion with a new
  emotional speech dataset",Submitted to ICASSP 2021,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Emotional voice conversion aims to transform emotional prosody in speech
while preserving the linguistic content and speaker identity. Prior studies
show that it is possible to disentangle emotional prosody using an
encoder-decoder network conditioned on discrete representation, such as one-hot
emotion labels. Such networks learn to remember a fixed set of emotional
styles. In this paper, we propose a novel framework based on variational
auto-encoding Wasserstein generative adversarial network (VAW-GAN), which makes
use of a pre-trained speech emotion recognition (SER) model to transfer
emotional style during training and at run-time inference. In this way, the
network is able to transfer both seen and unseen emotional style to a new
utterance. We show that the proposed framework achieves remarkable performance
by consistently outperforming the baseline framework. This paper also marks the
release of an emotional speech dataset (ESD) for voice conversion, which has
multiple speakers and languages.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 07:16:18 GMT'}]",2020-10-29,"[['Zhou', 'Kun', ''], ['Sisman', 'Berrak', ''], ['Liu', 'Rui', ''], ['Li', 'Haizhou', '']]"
1371114,2010.14784,Yuanhao Zhuo,Yuanhao Zhuo,"A Chinese Text Classification Method With Low Hardware Requirement Based
  on Improved Model Concatenation","5 pages, 2 figures, 5 tables",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In order to improve the accuracy performance of Chinese text classification
models with low hardware requirements, an improved concatenation-based model is
designed in this paper, which is a concatenation of 5 different sub-models,
including TextCNN, LSTM, and Bi-LSTM. Compared with the existing ensemble
learning method, for a text classification mission, this model's accuracy is 2%
higher. Meanwhile, the hardware requirements of this model are much lower than
the BERT-based model.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 06:32:41 GMT'}]",2020-10-29,"[['Zhuo', 'Yuanhao', '']]"
1371060,2010.14730,Xiaoyu Kou,"Xiaoyu Kou, Yankai Lin, Yuntao Li, Jiahao Xu, Peng Li, Jie Zhou, Yan
  Zhang",DisenE: Disentangling Knowledge Graph Embeddings,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Knowledge graph embedding (KGE), aiming to embed entities and relations into
low-dimensional vectors, has attracted wide attention recently. However, the
existing research is mainly based on the black-box neural models, which makes
it difficult to interpret the learned representation. In this paper, we
introduce DisenE, an end-to-end framework to learn disentangled knowledge graph
embeddings. Specially, we introduce an attention-based mechanism that enables
the model to explicitly focus on relevant components of entity embeddings
according to a given relation. Furthermore, we introduce two novel regularizers
to encourage each component of the entity representation to independently
reflect an isolated semantic aspect. Experimental results demonstrate that our
proposed DisenE investigates a perspective to address the interpretability of
KGE and is proved to be an effective way to improve the performance of link
prediction tasks. The code and datasets are released on
https://github.com/KXY-PUBLIC/DisenE.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 03:45:19 GMT'}]",2020-10-29,"[['Kou', 'Xiaoyu', ''], ['Lin', 'Yankai', ''], ['Li', 'Yuntao', ''], ['Xu', 'Jiahao', ''], ['Li', 'Peng', ''], ['Zhou', 'Jie', ''], ['Zhang', 'Yan', '']]"
1371055,2010.14725,Ruchao Fan,"Ruchao Fan, Wei Chu, Peng Chang, Jing Xiao","CASS-NAT: CTC Alignment-based Single Step Non-autoregressive Transformer
  for Speech Recognition",Submitted to ICASSP2021,,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a CTC alignment-based single step non-autoregressive transformer
(CASS-NAT) for speech recognition. Specifically, the CTC alignment contains the
information of (a) the number of tokens for decoder input, and (b) the time
span of acoustics for each token. The information are used to extract acoustic
representation for each token in parallel, referred to as token-level acoustic
embedding which substitutes the word embedding in autoregressive transformer
(AT) to achieve parallel generation in decoder. During inference, an
error-based alignment sampling method is proposed to be applied to the CTC
output space, reducing the WER and retaining the parallelism as well.
Experimental results show that the proposed method achieves WERs of 3.8%/9.1%
on Librispeech test clean/other dataset without an external LM, and a CER of
5.8% on Aishell1 Mandarin corpus, respectively1. Compared to the AT baseline,
the CASS-NAT has a performance reduction on WER, but is 51.2x faster in terms
of RTF. When decoding with an oracle CTC alignment, the lower bound of WER
without LM reaches 2.3% on the test-clean set, indicating the potential of the
proposed method.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 03:14:05 GMT'}]",2020-10-29,"[['Fan', 'Ruchao', ''], ['Chu', 'Wei', ''], ['Chang', 'Peng', ''], ['Xiao', 'Jing', '']]"
1272816,2004.08046,Dongyu Ru,"Dongyu Ru, Jiangtao Feng, Lin Qiu, Hao Zhou, Mingxuan Wang, Weinan
  Zhang, Yong Yu, Lei Li","Active Sentence Learning by Adversarial Uncertainty Sampling in Discrete
  Space",Accepted to EMNLP 2020 Findings,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Active learning for sentence understanding aims at discovering informative
unlabeled data for annotation and therefore reducing the demand for labeled
data. We argue that the typical uncertainty sampling method for active learning
is time-consuming and can hardly work in real-time, which may lead to
ineffective sample selection. We propose adversarial uncertainty sampling in
discrete space (AUSDS) to retrieve informative unlabeled samples more
efficiently. AUSDS maps sentences into latent space generated by the popular
pre-trained language models, and discover informative unlabeled text samples
for annotation via adversarial attack. The proposed approach is extremely
efficient compared with traditional uncertainty sampling with more than 10x
speedup. Experimental results on five datasets show that AUSDS outperforms
strong baselines on effectiveness.
","[{'version': 'v1', 'created': 'Fri, 17 Apr 2020 03:12:34 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 04:45:49 GMT'}]",2020-10-29,"[['Ru', 'Dongyu', ''], ['Feng', 'Jiangtao', ''], ['Qiu', 'Lin', ''], ['Zhou', 'Hao', ''], ['Wang', 'Mingxuan', ''], ['Zhang', 'Weinan', ''], ['Yu', 'Yong', ''], ['Li', 'Lei', '']]"
1371050,2010.14720,Songlin Yang,"Songlin Yang, Yong Jiang, Wenjuan Han, Kewei Tu",Second-Order Unsupervised Neural Dependency Parsing,COLING 2020 camera ready,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Most of the unsupervised dependency parsers are based on first-order
probabilistic generative models that only consider local parent-child
information. Inspired by second-order supervised dependency parsing, we
proposed a second-order extension of unsupervised neural dependency models that
incorporate grandparent-child or sibling information. We also propose a novel
design of the neural parameterization and optimization methods of the
dependency models. In second-order models, the number of grammar rules grows
cubically with the increase of vocabulary size, making it difficult to train
lexicalized models that may contain thousands of words. To circumvent this
problem while still benefiting from both second-order parsing and
lexicalization, we use the agreement-based learning framework to jointly train
a second-order unlexicalized model and a first-order lexicalized model.
Experiments on multiple datasets show the effectiveness of our second-order
models compared with recent state-of-the-art methods. Our joint model achieves
a 10% improvement over the previous state-of-the-art parser on the full WSJ
test set
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 03:01:33 GMT'}]",2020-10-29,"[['Yang', 'Songlin', ''], ['Jiang', 'Yong', ''], ['Han', 'Wenjuan', ''], ['Tu', 'Kewei', '']]"
1371037,2010.14707,Yang Qian,"Yang Qian, Yuanchun Jiang, Yidong Chai, Yezheng Liu, Jiansha Sun",TopicModel4J: A Java Package for Topic Models,,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Topic models provide a flexible and principled framework for exploring hidden
structure in high-dimensional co-occurrence data and are commonly used natural
language processing (NLP) of text. In this paper, we design and implement a
Java package, TopicModel4J, which contains 13 kinds of representative
algorithms for fitting topic models. The TopicModel4J in the Java programming
environment provides an easy-to-use interface for data analysts to run the
algorithms, and allow to easily input and output data. In addition, this
package provides a few unstructured text preprocessing techniques, such as
splitting textual data into words, lowercasing the words, preforming
lemmatization and removing the useless characters, URLs and stop words.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 02:33:41 GMT'}]",2020-10-29,"[['Qian', 'Yang', ''], ['Jiang', 'Yuanchun', ''], ['Chai', 'Yidong', ''], ['Liu', 'Yezheng', ''], ['Sun', 'Jiansha', '']]"
1371031,2010.14701,Samuel McCandlish,"Tom Henighan, Jared Kaplan, Mor Katz, Mark Chen, Christopher Hesse,
  Jacob Jackson, Heewoo Jun, Tom B. Brown, Prafulla Dhariwal, Scott Gray, Chris
  Hallacy, Benjamin Mann, Alec Radford, Aditya Ramesh, Nick Ryder, Daniel M.
  Ziegler, John Schulman, Dario Amodei, Sam McCandlish",Scaling Laws for Autoregressive Generative Modeling,"20+15 pages, 30 figures",,,,cs.LG cs.CL cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We identify empirical scaling laws for the cross-entropy loss in four
domains: generative image modeling, video modeling, multimodal
image$\leftrightarrow$text models, and mathematical problem solving. In all
cases autoregressive Transformers smoothly improve in performance as model size
and compute budgets increase, following a power-law plus constant scaling law.
The optimal model size also depends on the compute budget through a power-law,
with exponents that are nearly universal across all data domains.
  The cross-entropy loss has an information theoretic interpretation as
$S($True$) + D_{\mathrm{KL}}($True$||$Model$)$, and the empirical scaling laws
suggest a prediction for both the true data distribution's entropy and the KL
divergence between the true and model distributions. With this interpretation,
billion-parameter Transformers are nearly perfect models of the YFCC100M image
distribution downsampled to an $8\times 8$ resolution, and we can forecast the
model size needed to achieve any given reducible loss (ie $D_{\mathrm{KL}}$) in
nats/image for other resolutions.
  We find a number of additional scaling laws in specific domains: (a) we
identify a scaling relation for the mutual information between captions and
images in multimodal models, and show how to answer the question ""Is a picture
worth a thousand words?""; (b) in the case of mathematical problem solving, we
identify scaling laws for model performance when extrapolating beyond the
training distribution; (c) we finetune generative image models for ImageNet
classification and find smooth scaling of the classification loss and error
rate, even as the generative loss levels off. Taken together, these results
strengthen the case that scaling laws have important implications for neural
network performance, including on downstream tasks.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 02:17:24 GMT'}]",2020-10-29,"[['Henighan', 'Tom', ''], ['Kaplan', 'Jared', ''], ['Katz', 'Mor', ''], ['Chen', 'Mark', ''], ['Hesse', 'Christopher', ''], ['Jackson', 'Jacob', ''], ['Jun', 'Heewoo', ''], ['Brown', 'Tom B.', ''], ['Dhariwal', 'Prafulla', ''], ['Gray', 'Scott', ''], ['Hallacy', 'Chris', ''], ['Mann', 'Benjamin', ''], ['Radford', 'Alec', ''], ['Ramesh', 'Aditya', ''], ['Ryder', 'Nick', ''], ['Ziegler', 'Daniel M.', ''], ['Schulman', 'John', ''], ['Amodei', 'Dario', ''], ['McCandlish', 'Sam', '']]"
1371027,2010.14697,Claire Bowern,Luke Lindemann and Claire Bowern,"Character Entropy in Modern and Historical Texts: Comparison Metrics for
  an Undeciphered Manuscript",,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  This paper outlines the creation of three corpora for multilingual comparison
and analysis of the Voynich manuscript: a corpus of Voynich texts partitioned
by Currier language, scribal hand, and transcription system, a corpus of 294
language samples compiled from Wikipedia, and a corpus of eighteen transcribed
historical texts in eight languages. These corpora will be utilized in
subsequent work by the Voynich Working Group at Yale University.
  We demonstrate the utility of these corpora for studying characteristics of
the Voynich script and language, with an analysis of conditional character
entropy in Voynichese. We discuss the interaction between character entropy and
language, script size and type, glyph compositionality, scribal conventions and
abbreviations, positional character variants, and bigram frequency.
  This analysis characterizes the interaction between script compositionality,
character size, and predictability. We show that substantial manipulations of
glyph composition are not sufficient to align conditional entropy levels with
natural languages. The unusually predictable nature of the Voynichese script is
not attributable to a particular script or transcription system, underlying
language, or substitution cipher. Voynichese is distinct from every comparison
text in our corpora because character placement is highly constrained within
the word, and this may indicate the loss of phonemic distinctions from the
underlying language.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 01:53:59 GMT'}]",2020-10-29,"[['Lindemann', 'Luke', ''], ['Bowern', 'Claire', '']]"
1371008,2010.14678,Amir Pouran Ben Veyseh,"Amir Pouran Ben Veyseh, Franck Dernoncourt, Quan Hung Tran, Thien Huu
  Nguyen","What Does This Acronym Mean? Introducing a New Dataset for Acronym
  Identification and Disambiguation",accepted at COLING 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Acronyms are the short forms of phrases that facilitate conveying lengthy
sentences in documents and serve as one of the mainstays of writing. Due to
their importance, identifying acronyms and corresponding phrases (i.e., acronym
identification (AI)) and finding the correct meaning of each acronym (i.e.,
acronym disambiguation (AD)) are crucial for text understanding. Despite the
recent progress on this task, there are some limitations in the existing
datasets which hinder further improvement. More specifically, limited size of
manually annotated AI datasets or noises in the automatically created acronym
identification datasets obstruct designing advanced high-performing acronym
identification models. Moreover, the existing datasets are mostly limited to
the medical domain and ignore other domains. In order to address these two
limitations, we first create a manually annotated large AI dataset for
scientific domain. This dataset contains 17,506 sentences which is
substantially larger than previous scientific AI datasets. Next, we prepare an
AD dataset for scientific domain with 62,441 samples which is significantly
larger than the previous scientific AD dataset. Our experiments show that the
existing state-of-the-art models fall far behind human-level performance on
both datasets proposed by this work. In addition, we propose a new deep
learning model that utilizes the syntactical structure of the sentence to
expand an ambiguous acronym in a sentence. The proposed model outperforms the
state-of-the-art models on the new AD dataset, providing a strong baseline for
future research on this dataset.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 00:12:36 GMT'}]",2020-10-29,"[['Veyseh', 'Amir Pouran Ben', ''], ['Dernoncourt', 'Franck', ''], ['Tran', 'Quan Hung', ''], ['Nguyen', 'Thien Huu', '']]"
1370995,2010.14665,Yongqiang Wang,"Yongqiang Wang, Yangyang Shi, Frank Zhang, Chunyang Wu, Julian Chan,
  Ching-Feng Yeh, Alex Xiao","Transformer in action: a comparative study of transformer-based acoustic
  models for large scale speech recognition applications",submitted to ICASSP2021,,,,cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we summarize the application of transformer and its streamable
variant, Emformer based acoustic model for large scale speech recognition
applications. We compare the transformer based acoustic models with their LSTM
counterparts on industrial scale tasks. Specifically, we compare Emformer with
latency-controlled BLSTM (LCBLSTM) on medium latency tasks and LSTM on low
latency tasks. On a low latency voice assistant task, Emformer gets 24% to 26%
relative word error rate reductions (WERRs). For medium latency scenarios,
comparing with LCBLSTM with similar model size and latency, Emformer gets
significant WERR across four languages in video captioning datasets with 2-3
times inference real-time factors reduction.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 23:04:21 GMT'}]",2020-10-29,"[['Wang', 'Yongqiang', ''], ['Shi', 'Yangyang', ''], ['Zhang', 'Frank', ''], ['Wu', 'Chunyang', ''], ['Chan', 'Julian', ''], ['Yeh', 'Ching-Feng', ''], ['Xiao', 'Alex', '']]"
1370990,2010.14660,Pierre Dognin,"Pierre L. Dognin, Igor Melnyk, Inkit Padhi, Cicero Nogueira dos
  Santos, Payel Das",DualTKB: A Dual Learning Bridge between Text and Knowledge Base,"Equal Contributions of Authors Pierre L. Dognin, Igor Melnyk, and
  Inkit Padhi. Accepted at EMNLP'20",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this work, we present a dual learning approach for unsupervised text to
path and path to text transfers in Commonsense Knowledge Bases (KBs). We
investigate the impact of weak supervision by creating a weakly supervised
dataset and show that even a slight amount of supervision can significantly
improve the model performance and enable better-quality transfers. We examine
different model architectures, and evaluation metrics, proposing a novel
Commonsense KB completion metric tailored for generative models. Extensive
experimental results show that the proposed method compares very favorably to
the existing baselines. This approach is a viable step towards a more advanced
system for automatic KB construction/expansion and the reverse operation of KB
conversion to coherent textual descriptions.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 22:56:18 GMT'}]",2020-10-29,"[['Dognin', 'Pierre L.', ''], ['Melnyk', 'Igor', ''], ['Padhi', 'Inkit', ''], ['Santos', 'Cicero Nogueira dos', ''], ['Das', 'Payel', '']]"
1370979,2010.14649,Takashi Wada,"Takashi Wada, Tomoharu Iwata, Yuji Matsumoto, Timothy Baldwin, Jey Han
  Lau","Learning Contextualised Cross-lingual Word Embeddings for Extremely
  Low-Resource Languages Using Parallel Corpora",9 pages,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a new approach for learning contextualised cross-lingual word
embeddings based only on a small parallel corpus (e.g. a few hundred sentence
pairs). Our method obtains word embeddings via an LSTM-based encoder-decoder
model that performs bidirectional translation and reconstruction of the input
sentence. Through sharing model parameters among different languages, our model
jointly trains the word embeddings in a common multilingual space. We also
propose a simple method to combine word and subword embeddings to make use of
orthographic similarities across different languages. We base our experiments
on real-world data from endangered languages, namely Yongning Na,
Shipibo-Konibo and Griko. Our experiments on bilingual lexicon induction and
word alignment tasks show that our model outperforms existing methods by a
large margin for most language pairs. These results demonstrate that, contrary
to common belief, an encoder-decoder translation model is beneficial for
learning cross-lingual representations, even in extremely low-resource
scenarios.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 22:24:01 GMT'}]",2020-10-29,"[['Wada', 'Takashi', ''], ['Iwata', 'Tomoharu', ''], ['Matsumoto', 'Yuji', ''], ['Baldwin', 'Timothy', ''], ['Lau', 'Jey Han', '']]"
1370936,2010.14606,Arun Narayanan,"Arun Narayanan, Tara N. Sainath, Ruoming Pang, Jiahui Yu, Chung-Cheng
  Chiu, Rohit Prabhavalkar, Ehsan Variani, Trevor Strohman",Cascaded encoders for unifying streaming and non-streaming ASR,,,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  End-to-end (E2E) automatic speech recognition (ASR) models, by now, have
shown competitive performance on several benchmarks. These models are
structured to either operate in streaming or non-streaming mode. This work
presents cascaded encoders for building a single E2E ASR model that can operate
in both these modes simultaneously. The proposed model consists of streaming
and non-streaming encoders. Input features are first processed by the streaming
encoder; the non-streaming encoder operates exclusively on the output of the
streaming encoder. A single decoder then learns to decode either using the
output of the streaming or the non-streaming encoder. Results show that this
model achieves similar word error rates (WER) as a standalone streaming model
when operating in streaming mode, and obtains 10% -- 27% relative improvement
when operating in non-streaming mode. Our results also show that the proposed
approach outperforms existing E2E two-pass models, especially on long-form
speech.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 20:59:50 GMT'}]",2020-10-29,"[['Narayanan', 'Arun', ''], ['Sainath', 'Tara N.', ''], ['Pang', 'Ruoming', ''], ['Yu', 'Jiahui', ''], ['Chiu', 'Chung-Cheng', ''], ['Prabhavalkar', 'Rohit', ''], ['Variani', 'Ehsan', ''], ['Strohman', 'Trevor', '']]"
1370918,2010.14588,Robert Leaman,Robert Leaman and Zhiyong Lu,"A Comprehensive Dictionary and Term Variation Analysis for COVID-19 and
  SARS-CoV-2",Accepted EMNLP NLP-COVID Workshop,,,,cs.DL cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The number of unique terms in the scientific literature used to refer to
either SARS-CoV-2 or COVID-19 is remarkably large and has continued to increase
rapidly despite well-established standardized terms. This high degree of term
variation makes high recall identification of these important entities
difficult. In this manuscript we present an extensive dictionary of terms used
in the literature to refer to SARS-CoV-2 and COVID-19. We use a rule-based
approach to iteratively generate new term variants, then locate these variants
in a large text corpus. We compare our dictionary to an extensive collection of
terminological resources, demonstrating that our resource provides a
substantial number of additional terms. We use our dictionary to analyze the
usage of SARS-CoV-2 and COVID-19 terms over time and show that the number of
unique terms continues to grow rapidly. Our dictionary is freely available at
https://github.com/ncbi-nlp/CovidTermVar.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 19:51:53 GMT'}]",2020-10-29,"[['Leaman', 'Robert', ''], ['Lu', 'Zhiyong', '']]"
1370917,2010.14587,Jean-Baptiste Lamare,"Jean-Baptiste Lamare, Tobi Olatunji, Li Yao",On the diminishing return of labeling clinical reports,"Accepted at the EMNLP 2020 Clinical NLP workshop, 9 pages + 2 for
  references, 7 figures, 4 tables",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Ample evidence suggests that better machine learning models may be steadily
obtained by training on increasingly larger datasets on natural language
processing (NLP) problems from non-medical domains. Whether the same holds true
for medical NLP has by far not been thoroughly investigated. This work shows
that this is indeed not always the case. We reveal the somehow
counter-intuitive observation that performant medical NLP models may be
obtained with small amount of labeled data, quite the opposite to the common
belief, most likely due to the domain specificity of the problem. We show
quantitatively the effect of training data size on a fixed test set composed of
two of the largest public chest x-ray radiology report datasets on the task of
abnormality classification. The trained models not only make use of the
training data efficiently, but also outperform the current state-of-the-art
rule-based systems by a significant margin.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 19:51:04 GMT'}]",2020-10-29,"[['Lamare', 'Jean-Baptiste', ''], ['Olatunji', 'Tobi', ''], ['Yao', 'Li', '']]"
1370906,2010.14576,Jeniya Tabassum,"Jeniya Tabassum, Sydney Lee, Wei Xu, Alan Ritter","WNUT-2020 Task 1 Overview: Extracting Entities and Relations from Wet
  Lab Protocols",to appear in EMNLP 2020 (WNUT),,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents the results of the wet lab information extraction task at
WNUT 2020. This task consisted of two sub tasks: (1) a Named Entity Recognition
(NER) task with 13 participants and (2) a Relation Extraction (RE) task with 2
participants. We outline the task, data annotation process, corpus statistics,
and provide a high-level overview of the participating systems for each sub
task.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 19:34:53 GMT'}]",2020-10-29,"[['Tabassum', 'Jeniya', ''], ['Lee', 'Sydney', ''], ['Xu', 'Wei', ''], ['Ritter', 'Alan', '']]"
1370898,2010.14568,Kaiyu Yang,"Kaiyu Yang, Jia Deng",Strongly Incremental Constituency Parsing with Graph Neural Networks,Accepted to NeurIPS 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Parsing sentences into syntax trees can benefit downstream applications in
NLP. Transition-based parsers build trees by executing actions in a state
transition system. They are computationally efficient, and can leverage machine
learning to predict actions based on partial trees. However, existing
transition-based parsers are predominantly based on the shift-reduce transition
system, which does not align with how humans are known to parse sentences.
Psycholinguistic research suggests that human parsing is strongly incremental:
humans grow a single parse tree by adding exactly one token at each step. In
this paper, we propose a novel transition system called attach-juxtapose. It is
strongly incremental; it represents a partial sentence using a single tree;
each action adds exactly one token into the partial tree. Based on our
transition system, we develop a strongly incremental parser. At each step, it
encodes the partial tree using a graph neural network and predicts an action.
We evaluate our parser on Penn Treebank (PTB) and Chinese Treebank (CTB). On
PTB, it outperforms existing parsers trained with only constituency trees; and
it performs on par with state-of-the-art parsers that use dependency trees as
additional training data. On CTB, our parser establishes a new state of the
art. Code is available at
https://github.com/princeton-vl/attach-juxtapose-parser.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 19:19:38 GMT'}]",2020-10-29,"[['Yang', 'Kaiyu', ''], ['Deng', 'Jia', '']]"
1370887,2010.14557,Ruizhe Li,"Xiao Li, Guanyi Chen, Chenghua Lin, Ruizhe Li",DGST: a Dual-Generator Network for Text Style Transfer,"Accepted by EMNLP 2020, camera ready version",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose DGST, a novel and simple Dual-Generator network architecture for
text Style Transfer. Our model employs two generators only, and does not rely
on any discriminators or parallel corpus for training. Both quantitative and
qualitative experiments on the Yelp and IMDb datasets show that our model gives
competitive performance compared to several strong baselines with more
complicated architecture designs.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 18:54:51 GMT'}]",2020-10-29,"[['Li', 'Xiao', ''], ['Chen', 'Guanyi', ''], ['Lin', 'Chenghua', ''], ['Li', 'Ruizhe', '']]"
1370864,2010.14534,Marion Bartl,Marion Bartl and Malvina Nissim and Albert Gatt,"Unmasking Contextual Stereotypes: Measuring and Mitigating BERT's Gender
  Bias","10 pages, 4 figures, to appear in Proceedings of the 2nd Workshop on
  Gender Bias in Natural Language Processing at COLING 2020",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Contextualized word embeddings have been replacing standard embeddings as the
representational knowledge source of choice in NLP systems. Since a variety of
biases have previously been found in standard word embeddings, it is crucial to
assess biases encoded in their replacements as well. Focusing on BERT (Devlin
et al., 2018), we measure gender bias by studying associations between
gender-denoting target words and names of professions in English and German,
comparing the findings with real-world workforce statistics. We mitigate bias
by fine-tuning BERT on the GAP corpus (Webster et al., 2018), after applying
Counterfactual Data Substitution (CDS) (Maudslay et al., 2019). We show that
our method of measuring bias is appropriate for languages such as English, but
not for languages with a rich morphology and gender-marking, such as German.
Our results highlight the importance of investigating bias and mitigation
techniques cross-linguistically, especially in view of the current emphasis on
large-scale, multilingual language models.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 18:06:09 GMT'}]",2020-10-29,"[['Bartl', 'Marion', ''], ['Nissim', 'Malvina', ''], ['Gatt', 'Albert', '']]"
1146834,1907.02298,Zi Lin,"Junjie Cao, Zi Lin, Weiwei Sun, Xiaojun Wan","A Comparative Analysis of Knowledge-Intensive and Data-Intensive
  Semantic Parsers",submitted to the journal Computational Linguistics,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We present a phenomenon-oriented comparative analysis of the two dominant
approaches in task-independent semantic parsing: classic, knowledge-intensive
and neural, data-intensive models. To reflect state-of-the-art neural NLP
technologies, we introduce a new target structure-centric parser that can
produce semantic graphs much more accurately than previous data-driven parsers.
We then show that, in spite of comparable performance overall, knowledge- and
data-intensive models produce different types of errors, in a way that can be
explained by their theoretical properties. This analysis leads to new
directions for parser development.
","[{'version': 'v1', 'created': 'Thu, 4 Jul 2019 09:40:27 GMT'}, {'version': 'v2', 'created': 'Thu, 15 Aug 2019 10:36:59 GMT'}, {'version': 'v3', 'created': 'Wed, 28 Oct 2020 08:39:30 GMT'}]",2020-10-29,"[['Cao', 'Junjie', ''], ['Lin', 'Zi', ''], ['Sun', 'Weiwei', ''], ['Wan', 'Xiaojun', '']]"
1247530,2002.10107,Issa Annamoradnejad,"Issa Annamoradnejad, Mohammadamin Fazli, Jafar Habibi",Predicting Subjective Features of Questions of QA Websites using BERT,"5 pages, 4 figures, 2 tables","2020 6th International Conference on Web Research (ICWR), Tehran,
  Iran, 2020, pp. 240-244",10.1109/ICWR49608.2020.9122318,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Community Question-Answering websites, such as StackOverflow and Quora,
expect users to follow specific guidelines in order to maintain content
quality. These systems mainly rely on community reports for assessing contents,
which has serious problems such as the slow handling of violations, the loss of
normal and experienced users' time, the low quality of some reports, and
discouraging feedback to new users. Therefore, with the overall goal of
providing solutions for automating moderation actions in Q&A websites, we aim
to provide a model to predict 20 quality or subjective aspects of questions in
QA websites. To this end, we used data gathered by the CrowdSource team at
Google Research in 2019 and a fine-tuned pre-trained BERT model on our problem.
Based on the evaluation by Mean-Squared-Error (MSE), the model achieved a value
of 0.046 after 2 epochs of training, which did not improve substantially in the
next ones. Results confirm that by simple fine-tuning, we can achieve accurate
models in little time and on less amount of data.
","[{'version': 'v1', 'created': 'Mon, 24 Feb 2020 07:56:02 GMT'}, {'version': 'v2', 'created': 'Wed, 25 Mar 2020 08:10:16 GMT'}, {'version': 'v3', 'created': 'Tue, 30 Jun 2020 13:22:04 GMT'}, {'version': 'v4', 'created': 'Wed, 28 Oct 2020 14:37:39 GMT'}]",2020-10-29,"[['Annamoradnejad', 'Issa', ''], ['Fazli', 'Mohammadamin', ''], ['Habibi', 'Jafar', '']]"
1369332,2010.13002,Sam Shleifer,Sam Shleifer and Alexander M. Rush,Pre-trained Summarization Distillation,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent state-of-the-art approaches to summarization utilize large pre-trained
Transformer models. Distilling these models to smaller student models has
become critically important for practical use; however there are many different
distillation methods proposed by the NLP literature. Recent work on distilling
BERT for classification and regression tasks shows strong performance using
direct knowledge distillation. Alternatively, machine translation practitioners
distill using pseudo-labeling, where a small model is trained on the
translations of a larger model. A third, simpler approach is to 'shrink and
fine-tune' (SFT), which avoids any explicit distillation by copying parameters
to a smaller student model and then fine-tuning. We compare these three
approaches for distillation of Pegasus and BART, the current and former state
of the art, pre-trained summarization models, and find that SFT outperforms
knowledge distillation and pseudo-labeling on the CNN/DailyMail dataset, but
under-performs pseudo-labeling on the more abstractive XSUM dataset. PyTorch
Code and checkpoints of different sizes are available through Hugging Face
transformers here http://tiny.cc/4iy0tz.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 23:15:43 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 04:47:59 GMT'}]",2020-10-29,"[['Shleifer', 'Sam', ''], ['Rush', 'Alexander M.', '']]"
1371221,2010.14891,Mayuko Kori,"Mayuko Kori, Takeshi Tsukada and Naoki Kobayashi",A Cyclic Proof System for HFLN,27 pages,,,,cs.LO cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A cyclic proof system allows us to perform inductive reasoning without
explicit inductions. We propose a cyclic proof system for HFLN, which is a
higher-order predicate logic with natural numbers and alternating fixed-points.
Ours is the first cyclic proof system for a higher-order logic, to our
knowledge. Due to the presence of higher-order predicates and alternating
fixed-points, our cyclic proof system requires a more delicate global condition
on cyclic proofs than the original system of Brotherston and Simpson. We prove
the decidability of checking the global condition and soundness of this system,
and also prove a restricted form of standard completeness for an infinitary
variant of our cyclic proof system. A potential application of our cyclic proof
system is semi-automated verification of higher-order programs, based on
Kobayashi et al.'s recent work on reductions from program verification to HFLN
validity checking.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 11:19:53 GMT'}]",2020-10-29,"[['Kori', 'Mayuko', ''], ['Tsukada', 'Takeshi', ''], ['Kobayashi', 'Naoki', '']]"
1371250,2010.14920,Yuchen Liu,"Yuchen Liu, Junnan Zhu, Jiajun Zhang, and Chengqing Zong",Bridging the Modality Gap for Speech-to-Text Translation,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  End-to-end speech translation aims to translate speech in one language into
text in another language via an end-to-end way. Most existing methods employ an
encoder-decoder structure with a single encoder to learn acoustic
representation and semantic information simultaneously, which ignores the
speech-and-text modality differences and makes the encoder overloaded, leading
to great difficulty in learning such a model. To address these issues, we
propose a Speech-to-Text Adaptation for Speech Translation (STAST) model which
aims to improve the end-to-end model performance by bridging the modality gap
between speech and text. Specifically, we decouple the speech translation
encoder into three parts and introduce a shrink mechanism to match the length
of speech representation with that of the corresponding text transcription. To
obtain better semantic representation, we completely integrate a text-based
translation model into the STAST so that two tasks can be trained in the same
latent space. Furthermore, we introduce a cross-modal adaptation method to
close the distance between speech and text representation. Experimental results
on English-French and English-German speech translation corpora have shown that
our model significantly outperforms strong baselines, and achieves the new
state-of-the-art performance.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 12:33:04 GMT'}]",2020-10-29,"[['Liu', 'Yuchen', ''], ['Zhu', 'Junnan', ''], ['Zhang', 'Jiajun', ''], ['Zong', 'Chengqing', '']]"
1279293,2004.14523,Brian Thompson,Brian Thompson and Philipp Koehn,Exploiting Sentence Order in Document Alignment,EMNLP2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present a simple document alignment method that incorporates sentence
order information in both candidate generation and candidate re-scoring. Our
method results in 61% relative reduction in error compared to the best
previously published result on the WMT16 document alignment shared task. Our
method improves downstream MT performance on web-scraped Sinhala--English
documents from ParaCrawl, outperforming the document alignment method used in
the most recent ParaCrawl release. It also outperforms a comparable corpora
method which uses the same multilingual embeddings, demonstrating that
exploiting sentence order is beneficial even if the end goal is sentence-level
bitext.
","[{'version': 'v1', 'created': 'Thu, 30 Apr 2020 00:11:34 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 01:23:22 GMT'}]",2020-10-29,"[['Thompson', 'Brian', ''], ['Koehn', 'Philipp', '']]"
1371355,2010.15025,Xingchen Song,"Xingchen Song, Zhiyong Wu, Yiheng Huang, Chao Weng, Dan Su, Helen Meng",Non-Autoregressive Transformer ASR with CTC-Enhanced Decoder Input,submitted to ICASSP 2021,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Non-autoregressive (NAR) transformer models have achieved significantly
inference speedup but at the cost of inferior accuracy compared to
autoregressive (AR) models in automatic speech recognition (ASR). Most of the
NAR transformers take a fixed-length sequence filled with MASK tokens or a
redundant sequence copied from encoder states as decoder input, they cannot
provide efficient target-side information thus leading to accuracy degradation.
To address this problem, we propose a CTC-enhanced NAR transformer, which
generates target sequence by refining predictions of the CTC module.
Experimental results show that our method outperforms all previous NAR
counterparts and achieves 50x faster decoding speed than a strong AR baseline
with only 0.0 ~ 0.3 absolute CER degradation on Aishell-1 and Aishell-2
datasets.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 15:00:09 GMT'}]",2020-10-29,"[['Song', 'Xingchen', ''], ['Wu', 'Zhiyong', ''], ['Huang', 'Yiheng', ''], ['Weng', 'Chao', ''], ['Su', 'Dan', ''], ['Meng', 'Helen', '']]"
1371282,2010.14952,Isar Nejadgholi,Svetlana Kiritchenko and Isar Nejadgholi,Towards Ethics by Design in Online Abusive Content Detection,"14 pages, 2 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  To support safety and inclusion in online communications, significant efforts
in NLP research have been put towards addressing the problem of abusive content
detection, commonly defined as a supervised classification task. The research
effort has spread out across several closely related sub-areas, such as
detection of hate speech, toxicity, cyberbullying, etc. There is a pressing
need to consolidate the field under a common framework for task formulation,
dataset design and performance evaluation. Further, despite current
technologies achieving high classification accuracies, several ethical issues
have been revealed. We bring ethical issues to forefront and propose a unified
framework as a two-step process. First, online content is categorized around
personal and identity-related subject matters. Second, severity of abuse is
identified through comparative annotation within each category. The novel
framework is guided by the Ethics by Design principle and is a step towards
building more accurate and trusted models.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 13:10:24 GMT'}]",2020-10-29,"[['Kiritchenko', 'Svetlana', ''], ['Nejadgholi', 'Isar', '']]"
1371444,2010.15114,Kyle Aitken,"Kyle Aitken, Vinay V. Ramasesh, Ankush Garg, Yuan Cao, David Sussillo,
  Niru Maheswaranathan",The geometry of integration in text classification RNNs,"9+19 pages, 30 figures",,,,cs.LG cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite the widespread application of recurrent neural networks (RNNs) across
a variety of tasks, a unified understanding of how RNNs solve these tasks
remains elusive. In particular, it is unclear what dynamical patterns arise in
trained RNNs, and how those patterns depend on the training dataset or task.
This work addresses these questions in the context of a specific natural
language processing task: text classification. Using tools from dynamical
systems analysis, we study recurrent networks trained on a battery of both
natural and synthetic text classification tasks. We find the dynamics of these
trained RNNs to be both interpretable and low-dimensional. Specifically, across
architectures and datasets, RNNs accumulate evidence for each class as they
process the text, using a low-dimensional attractor manifold as the underlying
mechanism. Moreover, the dimensionality and geometry of the attractor manifold
are determined by the structure of the training dataset; in particular, we
describe how simple word-count statistics computed on the training dataset can
be used to predict these properties. Our observations span multiple
architectures and datasets, reflecting a common mechanism RNNs employ to
perform text classification. To the degree that integration of evidence towards
a decision is a common computational primitive, this work lays the foundation
for using dynamical systems techniques to study the inner workings of RNNs.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 17:58:53 GMT'}]",2020-10-29,"[['Aitken', 'Kyle', ''], ['Ramasesh', 'Vinay V.', ''], ['Garg', 'Ankush', ''], ['Cao', 'Yuan', ''], ['Sussillo', 'David', ''], ['Maheswaranathan', 'Niru', '']]"
1371397,2010.15067,Muhammed Tarik Altuncu,"M. Tarik Altuncu, Sophia N. Yaliraki, Mauricio Barahona","Graph-based Topic Extraction from Vector Embeddings of Text Documents:
  Application to a Corpus of News Articles",,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Production of news content is growing at an astonishing rate. To help manage
and monitor the sheer amount of text, there is an increasing need to develop
efficient methods that can provide insights into emerging content areas, and
stratify unstructured corpora of text into `topics' that stem intrinsically
from content similarity. Here we present an unsupervised framework that brings
together powerful vector embeddings from natural language processing with tools
from multiscale graph partitioning that can reveal natural partitions at
different resolutions without making a priori assumptions about the number of
clusters in the corpus. We show the advantages of graph-based clustering
through end-to-end comparisons with other popular clustering and topic
modelling methods, and also evaluate different text vector embeddings, from
classic Bag-of-Words to Doc2Vec to the recent transformers based model Bert.
This comparative work is showcased through an analysis of a corpus of US news
coverage during the presidential election year of 2016.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 16:20:05 GMT'}]",2020-10-29,"[['Altuncu', 'M. Tarik', ''], ['Yaliraki', 'Sophia N.', ''], ['Barahona', 'Mauricio', '']]"
1371420,2010.15090,Vishal Sunder,Vishal Sunder and Eric Fosler-Lussier,"Handling Class Imbalance in Low-Resource Dialogue Systems by Combining
  Few-Shot Classification and Interpolation","5 pages, 4 figures, 3 tables",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Utterance classification performance in low-resource dialogue systems is
constrained by an inevitably high degree of data imbalance in class labels. We
present a new end-to-end pairwise learning framework that is designed
specifically to tackle this phenomenon by inducing a few-shot classification
capability in the utterance representations and augmenting data through an
interpolation of utterance representations. Our approach is a general purpose
training methodology, agnostic to the neural architecture used for encoding
utterances. We show significant improvements in macro-F1 score over standard
cross-entropy training for three different neural architectures, demonstrating
improvements on a Virtual Patient dialogue dataset as well as a low-resourced
emulation of the Switchboard dialogue act classification dataset.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 17:05:24 GMT'}]",2020-10-29,"[['Sunder', 'Vishal', ''], ['Fosler-Lussier', 'Eric', '']]"
1371366,2010.15036,Usman Naseem,"Usman Naseem, Imran Razzak, Shah Khalid Khan, Mukesh Prasad","A Comprehensive Survey on Word Representation Models: From Classical to
  State-Of-The-Art Word Representation Language Models",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Word representation has always been an important research area in the history
of natural language processing (NLP). Understanding such complex text data is
imperative, given that it is rich in information and can be used widely across
various applications. In this survey, we explore different word representation
models and its power of expression, from the classical to modern-day
state-of-the-art word representation language models (LMS). We describe a
variety of text representation methods, and model designs have blossomed in the
context of NLP, including SOTA LMs. These models can transform large volumes of
text into effective vector representations capturing the same semantic
information. Further, such representations can be utilized by various machine
learning (ML) algorithms for a variety of NLP related tasks. In the end, this
survey briefly discusses the commonly used ML and DL based classifiers,
evaluation metrics and the applications of these word embeddings in different
NLP tasks.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 15:15:13 GMT'}]",2020-10-29,"[['Naseem', 'Usman', ''], ['Razzak', 'Imran', ''], ['Khan', 'Shah Khalid', ''], ['Prasad', 'Mukesh', '']]"
1371395,2010.15065,Amir Shanehsazzadeh,"Amir Shanehsazzadeh, David Belanger, David Dohan",Fixed-Length Protein Embeddings using Contextual Lenses,,,,,q-bio.BM cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The Basic Local Alignment Search Tool (BLAST) is currently the most popular
method for searching databases of biological sequences. BLAST compares
sequences via similarity defined by a weighted edit distance, which results in
it being computationally expensive. As opposed to working with edit distance, a
vector similarity approach can be accelerated substantially using modern
hardware or hashing techniques. Such an approach would require fixed-length
embeddings for biological sequences. There has been recent interest in learning
fixed-length protein embeddings using deep learning models under the hypothesis
that the hidden layers of supervised or semi-supervised models could produce
potentially useful vector embeddings. We consider transformer (BERT) protein
language models that are pretrained on the TrEMBL data set and learn
fixed-length embeddings on top of them with contextual lenses. The embeddings
are trained to predict the family a protein belongs to for sequences in the
Pfam database. We show that for nearest-neighbor family classification,
pretraining offers a noticeable boost in performance and that the corresponding
learned embeddings are competitive with BLAST. Furthermore, we show that the
raw transformer embeddings, obtained via static pooling, do not perform well on
nearest-neighbor family classification, which suggests that learning embeddings
in a supervised manner via contextual lenses may be a compute-efficient
alternative to fine-tuning.
","[{'version': 'v1', 'created': 'Thu, 15 Oct 2020 14:54:55 GMT'}]",2020-10-29,"[['Shanehsazzadeh', 'Amir', ''], ['Belanger', 'David', ''], ['Dohan', 'David', '']]"
1267866,2004.03096,Yiming Cui,"Nan Shao, Yiming Cui, Ting Liu, Shijin Wang, Guoping Hu",Is Graph Structure Necessary for Multi-hop Question Answering?,"6 pages, to appear at EMNLP 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, attempting to model texts as graph structure and introducing graph
neural networks to deal with it has become a trend in many NLP research areas.
In this paper, we investigate whether the graph structure is necessary for
multi-hop question answering. Our analysis is centered on HotpotQA. We
construct a strong baseline model to establish that, with the proper use of
pre-trained models, graph structure may not be necessary for multi-hop question
answering. We point out that both graph structure and adjacency matrix are
task-related prior knowledge, and graph-attention can be considered as a
special case of self-attention. Experiments and visualized analysis demonstrate
that graph-attention or the entire graph structure can be replaced by
self-attention or Transformers.
","[{'version': 'v1', 'created': 'Tue, 7 Apr 2020 02:59:42 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 09:29:19 GMT'}]",2020-10-30,"[['Shao', 'Nan', ''], ['Cui', 'Yiming', ''], ['Liu', 'Ting', ''], ['Wang', 'Shijin', ''], ['Hu', 'Guoping', '']]"
1356512,2010.00182,Yang Zhang,"Yang Zhang, Qiang Ma",Dual Attention Model for Citation Recommendation,,,,,cs.IR cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Based on an exponentially increasing number of academic articles, discovering
and citing comprehensive and appropriate resources has become a non-trivial
task. Conventional citation recommender methods suffer from severe information
loss. For example, they do not consider the section of the paper that the user
is writing and for which they need to find a citation, the relatedness between
the words in the local context (the text span that describes a citation), or
the importance on each word from the local context. These shortcomings make
such methods insufficient for recommending adequate citations to academic
manuscripts. In this study, we propose a novel embedding-based neural network
called ""dual attention model for citation recommendation (DACR)"" to recommend
citations during manuscript preparation. Our method adapts embedding of three
dimensions of semantic information: words in the local context, structural
contexts, and the section on which a user is working. A neural network is
designed to maximize the similarity between the embedding of the three input
(local context words, section and structural contexts) and the target citation
appearing in the context. The core of the neural network is composed of
self-attention and additive attention, where the former aims to capture the
relatedness between the contextual words and structural context, and the latter
aims to learn the importance of them. The experiments on real-world datasets
demonstrate the effectiveness of the proposed approach.
","[{'version': 'v1', 'created': 'Thu, 1 Oct 2020 02:41:47 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 11:27:20 GMT'}, {'version': 'v3', 'created': 'Wed, 28 Oct 2020 12:57:58 GMT'}, {'version': 'v4', 'created': 'Thu, 29 Oct 2020 12:31:26 GMT'}]",2020-10-30,"[['Zhang', 'Yang', ''], ['Ma', 'Qiang', '']]"
1371865,2010.15535,Craig Stewart,"Ricardo Rei, Craig Stewart, Catarina Farinha, Alon Lavie",Unbabel's Participation in the WMT20 Metrics Shared Task,WMT Metrics Shared Task 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present the contribution of the Unbabel team to the WMT 2020 Shared Task
on Metrics. We intend to participate on the segment-level, document-level and
system-level tracks on all language pairs, as well as the 'QE as a Metric'
track. Accordingly, we illustrate results of our models in these tracks with
reference to test sets from the previous year. Our submissions build upon the
recently proposed COMET framework: We train several estimator models to regress
on different human-generated quality scores and a novel ranking model trained
on relative ranks obtained from Direct Assessments. We also propose a simple
technique for converting segment-level predictions into a document-level score.
Overall, our systems achieve strong results for all language pairs on previous
test sets and in many cases set a new state-of-the-art.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 12:59:44 GMT'}]",2020-10-30,"[['Rei', 'Ricardo', ''], ['Stewart', 'Craig', ''], ['Farinha', 'Catarina', ''], ['Lavie', 'Alon', '']]"
1371796,2010.15466,Yuyang Nie,"Yuyang Nie, Yuanhe Tian, Yan Song, Xiang Ao, and Xiang Wan","Improving Named Entity Recognition with Attentive Ensemble of Syntactic
  Information","Natural Language Processing. 15 pages, 3 figures, Findings of
  EMNLP-2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Named entity recognition (NER) is highly sensitive to sentential syntactic
and semantic properties where entities may be extracted according to how they
are used and placed in the running text. To model such properties, one could
rely on existing resources to providing helpful knowledge to the NER task; some
existing studies proved the effectiveness of doing so, and yet are limited in
appropriately leveraging the knowledge such as distinguishing the important
ones for particular context. In this paper, we improve NER by leveraging
different types of syntactic information through attentive ensemble, which
functionalizes by the proposed key-value memory networks, syntax attention, and
the gate mechanism for encoding, weighting and aggregating such syntactic
information, respectively. Experimental results on six English and Chinese
benchmark datasets suggest the effectiveness of the proposed model and show
that it outperforms previous studies on all experiment datasets.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 10:25:17 GMT'}]",2020-10-30,"[['Nie', 'Yuyang', ''], ['Tian', 'Yuanhe', ''], ['Song', 'Yan', ''], ['Ao', 'Xiang', ''], ['Wan', 'Xiang', '']]"
1371788,2010.15458,Yuyang Nie,"Yuyang Nie, Yuanhe Tian, Xiang Wan, Yan Song, and Bo Dai","Named Entity Recognition for Social Media Texts with Semantic
  Augmentation","Natural Language Processing. 9 pages, 3 figures. EMNLP-2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Existing approaches for named entity recognition suffer from data sparsity
problems when conducted on short and informal texts, especially user-generated
social media content. Semantic augmentation is a potential way to alleviate
this problem. Given that rich semantic information is implicitly preserved in
pre-trained word embeddings, they are potential ideal resources for semantic
augmentation. In this paper, we propose a neural-based approach to NER for
social media texts where both local (from running text) and augmented semantics
are taken into account. In particular, we obtain the augmented semantic
information from a large-scale corpus, and propose an attentive semantic
augmentation module and a gate module to encode and aggregate such information,
respectively. Extensive experiments are performed on three benchmark datasets
collected from English and Chinese social media platforms, where the results
demonstrate the superiority of our approach to previous studies across all
three datasets.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 10:06:46 GMT'}]",2020-10-30,"[['Nie', 'Yuyang', ''], ['Tian', 'Yuanhe', ''], ['Wan', 'Xiang', ''], ['Song', 'Yan', ''], ['Dai', 'Bo', '']]"
1370914,2010.14584,Aleksandra Edwards Mrs,"Aleksandra Edwards, David Rogers, Jose Camacho-Collados, H\'el\`ene de
  Ribaupierre, Alun Preece","Predicting Themes within Complex Unstructured Texts: A Case Study on
  Safeguarding Reports","10 pages, 5 figures, workshop",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The task of text and sentence classification is associated with the need for
large amounts of labelled training data. The acquisition of high volumes of
labelled datasets can be expensive or unfeasible, especially for
highly-specialised domains for which documents are hard to obtain. Research on
the application of supervised classification based on small amounts of training
data is limited. In this paper, we address the combination of state-of-the-art
deep learning and classification methods and provide an insight into what
combination of methods fit the needs of small, domain-specific, and
terminologically-rich corpora. We focus on a real-world scenario related to a
collection of safeguarding reports comprising learning experiences and
reflections on tackling serious incidents involving children and vulnerable
adults. The relatively small volume of available reports and their use of
highly domain-specific terminology makes the application of automated
approaches difficult. We focus on the problem of automatically identifying the
main themes in a safeguarding report using supervised classification
approaches. Our results show the potential of deep learning models to simulate
subject-expert behaviour even for complex tasks with limited labelled data.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 19:48:23 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 09:15:14 GMT'}]",2020-10-30,"[['Edwards', 'Aleksandra', ''], ['Rogers', 'David', ''], ['Camacho-Collados', 'Jose', ''], ['de Ribaupierre', 'Hélène', ''], ['Preece', 'Alun', '']]"
1371767,2010.15437,Mana Ihori,"Mana Ihori, Ryo Masumura, Naoki Makishima, Tomohiro Tanaka, Akihiko
  Takashima, Shota Orihashi","Memory Attentive Fusion: External Language Model Integration for
  Transformer-based Sequence-to-Sequence Model",Accepted as a short paper at INLG 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents a novel fusion method for integrating an external
language model (LM) into the Transformer based sequence-to-sequence (seq2seq)
model. While paired data are basically required to train the seq2seq model, the
external LM can be trained with only unpaired data. Thus, it is important to
leverage memorized knowledge in the external LM for building the seq2seq model,
since it is hard to prepare a large amount of paired data. However, the
existing fusion methods assume that the LM is integrated with recurrent neural
network-based seq2seq models instead of the Transformer. Therefore, this paper
proposes a fusion method that can explicitly utilize network structures in the
Transformer. The proposed method, called {\bf memory attentive fusion},
leverages the Transformer-style attention mechanism that repeats source-target
attention in a multi-hop manner for reading the memorized knowledge in the LM.
Our experiments on two text-style conversion tasks demonstrate that the
proposed method performs better than conventional fusion methods.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 09:16:23 GMT'}]",2020-10-30,"[['Ihori', 'Mana', ''], ['Masumura', 'Ryo', ''], ['Makishima', 'Naoki', ''], ['Tanaka', 'Tomohiro', ''], ['Takashima', 'Akihiko', ''], ['Orihashi', 'Shota', '']]"
1370901,2010.14571,Isaac Caswell,"Isaac Caswell, Theresa Breiner, Daan van Esch, Ankur Bapna","Language ID in the Wild: Unexpected Challenges on the Path to a
  Thousand-Language Web Text Corpus",Accepted to COLING 2020. 9 pages with 8 page abstract,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Large text corpora are increasingly important for a wide variety of Natural
Language Processing (NLP) tasks, and automatic language identification (LangID)
is a core technology needed to collect such datasets in a multilingual context.
LangID is largely treated as solved in the literature, with models reported
that achieve over 90% average F1 on as many as 1,366 languages. We train LangID
models on up to 1,629 languages with comparable quality on held-out test sets,
but find that human-judged LangID accuracy for web-crawl text corpora created
using these models is only around 5% for many lower-resource languages,
suggesting a need for more robust evaluation. Further analysis revealed a
variety of error modes, arising from domain mismatch, class imbalance, language
similarity, and insufficiently expressive models. We propose two classes of
techniques to mitigate these errors: wordlist-based tunable-precision filters
(for which we release curated lists in about 500 languages) and
transformer-based semi-supervised LangID models, which increase median dataset
precision from 5.5% to 71.2%. These techniques enable us to create an initial
data set covering 100K or more relatively clean sentences in each of 500+
languages, paving the way towards a 1,000-language web text corpus.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 19:29:17 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 15:18:35 GMT'}]",2020-10-30,"[['Caswell', 'Isaac', ''], ['Breiner', 'Theresa', ''], ['van Esch', 'Daan', ''], ['Bapna', 'Ankur', '']]"
1371753,2010.15423,M\=arcis Pinnis,"Rihards Kri\v{s}lauks, M\=arcis Pinnis",Tilde at WMT 2020: News Task Systems,,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  This paper describes Tilde's submission to the WMT2020 shared task on news
translation for both directions of the English-Polish language pair in both the
constrained and the unconstrained tracks. We follow our submissions from the
previous years and build our baseline systems to be morphologically motivated
sub-word unit-based Transformer base models that we train using the Marian
machine translation toolkit. Additionally, we experiment with different
parallel and monolingual data selection schemes, as well as sampled
back-translation. Our final models are ensembles of Transformer base and
Transformer big models that feature right-to-left re-ranking.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 08:59:37 GMT'}]",2020-10-30,"[['Krišlauks', 'Rihards', ''], ['Pinnis', 'Mārcis', '']]"
1371741,2010.15411,Milan Gritta,"Milan Gritta, Gerasimos Lampouras and Ignacio Iacobacci","Conversation Graph: Data Augmentation, Training and Evaluation for
  Non-Deterministic Dialogue Management","Accepted at Transactions of Association of Computational Linguistics
  (to be presented at ACL 2021)",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Task-oriented dialogue systems typically rely on large amounts of
high-quality training data or require complex handcrafted rules. However,
existing datasets are often limited in size considering the complexity of the
dialogues. Additionally, conventional training signal inference is not suitable
for non-deterministic agent behaviour, i.e. considering multiple actions as
valid in identical dialogue states. We propose the Conversation Graph
(ConvGraph), a graph-based representation of dialogues that can be exploited
for data augmentation, multi-reference training and evaluation of
non-deterministic agents. ConvGraph generates novel dialogue paths to augment
data volume and diversity. Intrinsic and extrinsic evaluation across three
datasets shows that data augmentation and/or multi-reference training with
ConvGraph can improve dialogue success rates by up to 6.4%.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 08:23:24 GMT'}]",2020-10-30,"[['Gritta', 'Milan', ''], ['Lampouras', 'Gerasimos', ''], ['Iacobacci', 'Ignacio', '']]"
1371928,2010.15598,Micaela Kaplan,Micaela Kaplan,"May I Ask Who's Calling? Named Entity Recognition on Call Center
  Transcripts for Privacy Law Compliance",The 6th Workshop on Noisy User-generated Text (W-NUT) 2020 at EMNLP,"Proceedings of the 2020 EMNLP Workshop W-NUT: The Sixth Workshop
  on Noisy User-generated Text (2020) 1-6",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We investigate using Named Entity Recognition on a new type of user-generated
text: a call center conversation. These conversations combine problems from
spontaneous speech with problems novel to conversational Automated Speech
Recognition, including incorrect recognition, alongside other common problems
from noisy user-generated text. Using our own corpus with new annotations,
training custom contextual string embeddings, and applying a BiLSTM-CRF, we
match state-of-the-art results on our novel task.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 13:53:42 GMT'}]",2020-10-30,"[['Kaplan', 'Micaela', '']]"
1371696,2010.15366,Sung-Feng Huang,"Sung-Feng Huang, Shun-Po Chuang, Da-Rong Liu, Yi-Chen Chen, Gene-Ping
  Yang, Hung-yi Lee","Self-supervised Pre-training Reduces Label Permutation Instability of
  Speech Separation",submitted to ICASSP2021,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Speech separation has been well-developed while there are still problems
waiting to be solved. The main problem we focus on in this paper is the
frequent label permutation switching of permutation invariant training (PIT).
For N-speaker separation, there would be N! possible label permutations. How to
stably select correct label permutations is a long-standing problem. In this
paper, we utilize self-supervised pre-training to stabilize the label
permutations. Among several types of self-supervised tasks, speech enhancement
based pre-training tasks show significant effectiveness in our experiments.
When using off-the-shelf pre-trained models, training duration could be
shortened to one-third to two-thirds. Furthermore, even taking pre-training
time into account, the entire training process could still be shorter without a
performance drop when using a larger batch size.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 06:07:01 GMT'}]",2020-10-30,"[['Huang', 'Sung-Feng', ''], ['Chuang', 'Shun-Po', ''], ['Liu', 'Da-Rong', ''], ['Chen', 'Yi-Chen', ''], ['Yang', 'Gene-Ping', ''], ['Lee', 'Hung-yi', '']]"
1371690,2010.15360,Shaolei Wang,"Shaolei Wang, Zhongyuan Wang, Wanxiang Che, Ting Liu","Combining Self-Training and Self-Supervised Learning for Unsupervised
  Disfluency Detection",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Most existing approaches to disfluency detection heavily rely on
human-annotated corpora, which is expensive to obtain in practice. There have
been several proposals to alleviate this issue with, for instance,
self-supervised learning techniques, but they still require human-annotated
corpora. In this work, we explore the unsupervised learning paradigm which can
potentially work with unlabeled text corpora that are cheaper and easier to
obtain. Our model builds upon the recent work on Noisy Student Training, a
semi-supervised learning approach that extends the idea of self-training.
Experimental results on the commonly used English Switchboard test set show
that our approach achieves competitive performance compared to the previous
state-of-the-art supervised systems using contextualized word embeddings (e.g.
BERT and ELECTRA).
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 05:29:26 GMT'}]",2020-10-30,"[['Wang', 'Shaolei', ''], ['Wang', 'Zhongyuan', ''], ['Che', 'Wanxiang', ''], ['Liu', 'Ting', '']]"
1348756,2009.07253,Alexander Lin,"Alexander Lin, Jeremy Wohlwend, Howard Chen, and Tao Lei",Autoregressive Knowledge Distillation through Imitation Learning,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The performance of autoregressive models on natural language generation tasks
has dramatically improved due to the adoption of deep, self-attentive
architectures. However, these gains have come at the cost of hindering
inference speed, making state-of-the-art models cumbersome to deploy in
real-world, time-sensitive settings. We develop a compression technique for
autoregressive models that is driven by an imitation learning perspective on
knowledge distillation. The algorithm is designed to address the exposure bias
problem. On prototypical language generation tasks such as translation and
summarization, our method consistently outperforms other distillation
algorithms, such as sequence-level knowledge distillation. Student models
trained with our method attain 1.4 to 4.8 BLEU/ROUGE points higher than those
trained from scratch, while increasing inference speed by up to 14 times in
comparison to the teacher model.
","[{'version': 'v1', 'created': 'Tue, 15 Sep 2020 17:43:02 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 00:40:45 GMT'}]",2020-10-30,"[['Lin', 'Alexander', ''], ['Wohlwend', 'Jeremy', ''], ['Chen', 'Howard', ''], ['Lei', 'Tao', '']]"
1371646,2010.15316,Michal Malyska,"Alister D Costa, Stefan Denkovski, Michal Malyska, Sae Young Moon,
  Brandon Rufino, Zhen Yang, Taylor Killian, Marzyeh Ghassemi",Multiple Sclerosis Severity Classification From Clinical Text,EMNLP 2020 Clinical NLP workshop,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Multiple Sclerosis (MS) is a chronic, inflammatory and degenerative
neurological disease, which is monitored by a specialist using the Expanded
Disability Status Scale (EDSS) and recorded in unstructured text in the form of
a neurology consult note. An EDSS measurement contains an overall ""EDSS"" score
and several functional subscores. Typically, expert knowledge is required to
interpret consult notes and generate these scores. Previous approaches used
limited context length Word2Vec embeddings and keyword searches to predict
scores given a consult note, but often failed when scores were not explicitly
stated. In this work, we present MS-BERT, the first publicly available
transformer model trained on real clinical data other than MIMIC. Next, we
present MSBC, a classifier that applies MS-BERT to generate embeddings and
predict EDSS and functional subscores. Lastly, we explore combining MSBC with
other models through the use of Snorkel to generate scores for unlabelled
consult notes. MSBC achieves state-of-the-art performance on all metrics and
prediction tasks and outperforms the models generated from the Snorkel
ensemble. We improve Macro-F1 by 0.12 (to 0.88) for predicting EDSS and on
average by 0.29 (to 0.63) for predicting functional subscores over previous
Word2Vec CNN and rule-based approaches.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 02:15:23 GMT'}]",2020-10-30,"[['Costa', 'Alister D', ''], ['Denkovski', 'Stefan', ''], ['Malyska', 'Michal', ''], ['Moon', 'Sae Young', ''], ['Rufino', 'Brandon', ''], ['Yang', 'Zhen', ''], ['Killian', 'Taylor', ''], ['Ghassemi', 'Marzyeh', '']]"
1265269,2004.00499,Shengbin Jia,Shengbin Jia,Unique Chinese Linguistic Phenomena,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Linguistics holds unique characteristics of generality, stability, and
nationality, which will affect the formulation of extraction strategies and
should be incorporated into the relation extraction. Chinese open relation
extraction is not well-established, because of the complexity of Chinese
linguistics makes it harder to operate, and the methods for English are not
compatible with that for Chinese. The diversities between Chinese and English
linguistics are mainly reflected in morphology and syntax.
","[{'version': 'v1', 'created': 'Sun, 23 Feb 2020 12:13:48 GMT'}, {'version': 'v2', 'created': 'Fri, 31 Jul 2020 10:00:08 GMT'}, {'version': 'v3', 'created': 'Thu, 29 Oct 2020 06:07:07 GMT'}]",2020-10-30,"[['Jia', 'Shengbin', '']]"
1150762,1907.06226,Jipeng Qiang,Jipeng Qiang and Yun Li and Yi Zhu and Yunhao Yuan and Xindong Wu,Lexical Simplification with Pretrained Encoders,,,,,cs.CL cs.AI cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Lexical simplification (LS) aims to replace complex words in a given sentence
with their simpler alternatives of equivalent meaning. Recently unsupervised
lexical simplification approaches only rely on the complex word itself
regardless of the given sentence to generate candidate substitutions, which
will inevitably produce a large number of spurious candidates. We present a
simple LS approach that makes use of the Bidirectional Encoder Representations
from Transformers (BERT) which can consider both the given sentence and the
complex word during generating candidate substitutions for the complex word.
Specifically, we mask the complex word of the original sentence for feeding
into the BERT to predict the masked token. The predicted results will be used
as candidate substitutions. Despite being entirely unsupervised, experimental
results show that our approach obtains obvious improvement compared with these
baselines leveraging linguistic databases and parallel corpus, outperforming
the state-of-the-art by more than 12 Accuracy points on three well-known
benchmarks.
","[{'version': 'v1', 'created': 'Sun, 14 Jul 2019 14:19:22 GMT'}, {'version': 'v2', 'created': 'Tue, 16 Jul 2019 14:36:41 GMT'}, {'version': 'v3', 'created': 'Tue, 30 Jul 2019 03:36:12 GMT'}, {'version': 'v4', 'created': 'Fri, 16 Aug 2019 01:48:46 GMT'}, {'version': 'v5', 'created': 'Thu, 29 Oct 2020 03:21:25 GMT'}]",2020-10-30,"[['Qiang', 'Jipeng', ''], ['Li', 'Yun', ''], ['Zhu', 'Yi', ''], ['Yuan', 'Yunhao', ''], ['Wu', 'Xindong', '']]"
1371643,2010.15313,Keen You,Keen You and Dan Goldwasser,"""where is this relationship going?"": Understanding Relationship
  Trajectories in Narrative Text",Accepted to *Sem 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We examine a new commonsense reasoning task: given a narrative describing a
social interaction that centers on two protagonists, systems make inferences
about the underlying relationship trajectory. Specifically, we propose two
evaluation tasks: Relationship Outlook Prediction MCQ and Resolution Prediction
MCQ. In Relationship Outlook Prediction, a system maps an interaction to a
relationship outlook that captures how the interaction is expected to change
the relationship. In Resolution Prediction, a system attributes a given
relationship outlook to a particular resolution that explains the outcome.
These two tasks parallel two real-life questions that people frequently ponder
upon as they navigate different social situations: ""where is this relationship
going?"" and ""how did we end up here?"". To facilitate the investigation of human
social relationships through these two tasks, we construct a new dataset,
Social Narrative Tree, which consists of 1250 stories documenting a variety of
daily social interactions. The narratives encode a multitude of social elements
that interweave to give rise to rich commonsense knowledge of how relationships
evolve with respect to social interactions. We establish baseline performances
using language models and the accuracies are significantly lower than human
performance. The results demonstrate that models need to look beyond syntactic
and semantic signals to comprehend complex human relationships.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 02:07:05 GMT'}]",2020-10-30,"[['You', 'Keen', ''], ['Goldwasser', 'Dan', '']]"
1371930,2010.15600,Ciro Garcia Mr,Ciro Ivan Garcia Lopez,Three computational models and its equivalence,,,,,cs.LO cs.CC cs.CL cs.GL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  The study of computability has its origin in Hilbert's conference of 1900,
where an adjacent question, to the ones he asked, is to give a precise
description of the notion of algorithm. In the search for a good definition
arose three independent theories: Turing and the Turing machines, G\""odel and
the recursive functions, Church and the Lambda Calculus.
  Later there were established by Kleene that the classic models of computation
are equivalent. This fact is widely accepted by many textbooks and the proof is
omitted since the proof is tedious and unreadable. We intend to fill this gap
presenting the proof in a modern way, without forgetting the mathematical
details.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 05:55:19 GMT'}]",2020-10-30,"[['Lopez', 'Ciro Ivan Garcia', '']]"
1371983,2010.15653,Niko Moritz,"Niko Moritz, Takaaki Hori, Jonathan Le Roux","Semi-Supervised Speech Recognition via Graph-based Temporal
  Classification",Submitted to ICASSP 2021,,,,cs.LG cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Semi-supervised learning has demonstrated promising results in automatic
speech recognition (ASR) by self-training using a seed ASR model with
pseudo-labels generated for unlabeled data. The effectiveness of this approach
largely relies on the pseudo-label accuracy, for which typically only the
1-best ASR hypothesis is used. However, alternative ASR hypotheses of an N-best
list can provide more accurate labels for an unlabeled speech utterance and
also reflect uncertainties of the seed ASR model. In this paper, we propose a
generalized form of the connectionist temporal classification (CTC) objective
that accepts a graph representation of the training targets. The newly proposed
graph-based temporal classification (GTC) objective is applied for
self-training with WFST-based supervision, which is generated from an N-best
list of pseudo-labels. In this setup, GTC is used to learn not only a temporal
alignment, similarly to CTC, but also a label alignment to obtain the optimal
pseudo-label sequence from the weighted graph. Results show that this approach
can effectively exploit an N-best list of pseudo-labels with associated scores,
outperforming standard pseudo-labeling by a large margin, with ASR results
close to an oracle experiment in which the best hypotheses of the N-best lists
are selected manually.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 14:56:56 GMT'}]",2020-10-30,"[['Moritz', 'Niko', ''], ['Hori', 'Takaaki', ''], ['Roux', 'Jonathan Le', '']]"
1358840,2010.02510,Lily Ou,"Sophie Groenwold, Lily Ou, Aesha Parekh, Samhita Honnavalli, Sharon
  Levy, Diba Mirza, William Yang Wang","Investigating African-American Vernacular English in Transformer-Based
  Text Generation","7 pages, EMNLP 2020",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The growth of social media has encouraged the written use of African American
Vernacular English (AAVE), which has traditionally been used only in oral
contexts. However, NLP models have historically been developed using dominant
English varieties, such as Standard American English (SAE), due to text corpora
availability. We investigate the performance of GPT-2 on AAVE text by creating
a dataset of intent-equivalent parallel AAVE/SAE tweet pairs, thereby isolating
syntactic structure and AAVE- or SAE-specific language for each pair. We
evaluate each sample and its GPT-2 generated text with pretrained sentiment
classifiers and find that while AAVE text results in more classifications of
negative sentiment than SAE, the use of GPT-2 generally increases occurrences
of positive sentiment for both. Additionally, we conduct human evaluation of
AAVE and SAE text generated with GPT-2 to compare contextual rigor and overall
quality.
","[{'version': 'v1', 'created': 'Tue, 6 Oct 2020 06:27:02 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 04:00:46 GMT'}]",2020-10-30,"[['Groenwold', 'Sophie', ''], ['Ou', 'Lily', ''], ['Parekh', 'Aesha', ''], ['Honnavalli', 'Samhita', ''], ['Levy', 'Sharon', ''], ['Mirza', 'Diba', ''], ['Wang', 'William Yang', '']]"
1367089,2010.10759,Yangyang Shi,"Yangyang Shi, Yongqiang Wang, Chunyang Wu, Ching-Feng Yeh, Julian
  Chan, Frank Zhang, Duc Le, Mike Seltzer","Emformer: Efficient Memory Transformer Based Acoustic Model For Low
  Latency Streaming Speech Recognition","5 pages, 2 figures, submitted to ICASSP 2021",,,,cs.SD cs.CL cs.LG eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper proposes an efficient memory transformer Emformer for low latency
streaming speech recognition. In Emformer, the long-range history context is
distilled into an augmented memory bank to reduce self-attention's computation
complexity. A cache mechanism saves the computation for the key and value in
self-attention for the left context. Emformer applies a parallelized block
processing in training to support low latency models. We carry out experiments
on benchmark LibriSpeech data. Under average latency of 960 ms, Emformer gets
WER $2.50\%$ on test-clean and $5.62\%$ on test-other. Comparing with a strong
baseline augmented memory transformer (AM-TRF), Emformer gets $4.6$ folds
training speedup and $18\%$ relative real-time factor (RTF) reduction in
decoding with relative WER reduction $17\%$ on test-clean and $9\%$ on
test-other. For a low latency scenario with an average latency of 80 ms,
Emformer achieves WER $3.01\%$ on test-clean and $7.09\%$ on test-other.
Comparing with the LSTM baseline with the same latency and model size, Emformer
gets relative WER reduction $9\%$ and $16\%$ on test-clean and test-other,
respectively.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 04:38:09 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Oct 2020 19:59:08 GMT'}, {'version': 'v3', 'created': 'Thu, 29 Oct 2020 14:55:59 GMT'}]",2020-10-30,"[['Shi', 'Yangyang', ''], ['Wang', 'Yongqiang', ''], ['Wu', 'Chunyang', ''], ['Yeh', 'Ching-Feng', ''], ['Chan', 'Julian', ''], ['Zhang', 'Frank', ''], ['Le', 'Duc', ''], ['Seltzer', 'Mike', '']]"
1371388,2010.15058,Tomek Korbak,Tomasz Korbak and Julian Zubek and Joanna R\k{a}czaszek-Leonardi,Measuring non-trivial compositionality in emergent communication,"4th Workshop on Emergent Communication, NeurIPS 2020",,,,cs.NE cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Compositionality is an important explanatory target in emergent communication
and language evolution. The vast majority of computational models of
communication account for the emergence of only a very basic form of
compositionality: trivial compositionality. A compositional protocol is
trivially compositional if the meaning of a complex signal (e.g. blue circle)
boils down to the intersection of meanings of its constituents (e.g. the
intersection of the set of blue objects and the set of circles). A protocol is
non-trivially compositional (NTC) if the meaning of a complex signal (e.g.
biggest apple) is a more complex function of the meanings of their
constituents. In this paper, we review several metrics of compositionality used
in emergent communication and experimentally show that most of them fail to
detect NTC - i.e. they treat non-trivial compositionality as a failure of
compositionality. The one exception is tree reconstruction error, a metric
motivated by formal accounts of compositionality. These results emphasise
important limitations of emergent communication research that could hamper
progress on modelling the emergence of NTC.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 16:11:07 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 16:22:44 GMT'}]",2020-10-30,"[['Korbak', 'Tomasz', ''], ['Zubek', 'Julian', ''], ['Rączaszek-Leonardi', 'Joanna', '']]"
1301728,2006.07214,Andre Martins,"Andr\'e F. T. Martins, Ant\'onio Farinhas, Marcos Treviso, Vlad
  Niculae, Pedro M. Q. Aguiar, M\'ario A. T. Figueiredo",Sparse and Continuous Attention Mechanisms,Accepted for spotlight presentation at NeurIPS 2020,,,,cs.LG cs.CL cs.CV stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Exponential families are widely used in machine learning; they include many
distributions in continuous and discrete domains (e.g., Gaussian, Dirichlet,
Poisson, and categorical distributions via the softmax transformation).
Distributions in each of these families have fixed support. In contrast, for
finite domains, there has been recent work on sparse alternatives to softmax
(e.g. sparsemax and alpha-entmax), which have varying support, being able to
assign zero probability to irrelevant categories. This paper expands that work
in two directions: first, we extend alpha-entmax to continuous domains,
revealing a link with Tsallis statistics and deformed exponential families.
Second, we introduce continuous-domain attention mechanisms, deriving efficient
gradient backpropagation algorithms for alpha in {1,2}. Experiments on
attention-based text classification, machine translation, and visual question
answering illustrate the use of continuous attention in 1D and 2D, showing that
it allows attending to time intervals and compact regions.
","[{'version': 'v1', 'created': 'Fri, 12 Jun 2020 14:16:48 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Oct 2020 22:22:38 GMT'}, {'version': 'v3', 'created': 'Thu, 29 Oct 2020 08:39:54 GMT'}]",2020-10-30,"[['Martins', 'André F. T.', ''], ['Farinhas', 'António', ''], ['Treviso', 'Marcos', ''], ['Niculae', 'Vlad', ''], ['Aguiar', 'Pedro M. Q.', ''], ['Figueiredo', 'Mário A. T.', '']]"
1324516,2007.13002,Siyuan Feng,"Siyuan Feng, Odette Scharenborg","Unsupervised Subword Modeling Using Autoregressive Pretraining and
  Cross-Lingual Phone-Aware Modeling","5 pages, 3 figures. Accepted for publication in INTERSPEECH 2020,
  Shanghai, China",,10.21437/Interspeech.2020-1170,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This study addresses unsupervised subword modeling, i.e., learning feature
representations that can distinguish subword units of a language. The proposed
approach adopts a two-stage bottleneck feature (BNF) learning framework,
consisting of autoregressive predictive coding (APC) as a front-end and a
DNN-BNF model as a back-end. APC pretrained features are set as input features
to a DNN-BNF model. A language-mismatched ASR system is used to provide
cross-lingual phone labels for DNN-BNF model training. Finally, BNFs are
extracted as the subword-discriminative feature representation. A second aim of
this work is to investigate the robustness of our approach's effectiveness to
different amounts of training data. The results on Libri-light and the
ZeroSpeech 2017 databases show that APC is effective in front-end feature
pretraining. Our whole system outperforms the state of the art on both
databases. Cross-lingual phone labels for English data by a Dutch ASR
outperform those by a Mandarin ASR, possibly linked to the larger similarity of
Dutch compared to Mandarin with English. Our system is less sensitive to
training data amount when the training data is over 50 hours. APC pretraining
leads to a reduction of needed training material from over 5,000 hours to
around 200 hours with little performance degradation.
","[{'version': 'v1', 'created': 'Sat, 25 Jul 2020 19:41:41 GMT'}, {'version': 'v2', 'created': 'Thu, 6 Aug 2020 19:15:48 GMT'}]",2020-10-30,"[['Feng', 'Siyuan', ''], ['Scharenborg', 'Odette', '']]"
1371596,2010.15266,Abhinav Singh,"Abhinav Singh, Patrick Xia, Guanghui Qin, Mahsa Yarmohammadi, Benjamin
  Van Durme","CopyNext: Explicit Span Copying and Alignment in Sequence to Sequence
  Models",4th Workshop on Structured Prediction for NLP (EMNLP 2020),,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Copy mechanisms are employed in sequence to sequence models (seq2seq) to
generate reproductions of words from the input to the output. These frameworks,
operating at the lexical type level, fail to provide an explicit alignment that
records where each token was copied from. Further, they require contiguous
token sequences from the input (spans) to be copied individually. We present a
model with an explicit token-level copy operation and extend it to copying
entire spans. Our model provides hard alignments between spans in the input and
output, allowing for nontraditional applications of seq2seq, like information
extraction. We demonstrate the approach on Nested Named Entity Recognition,
achieving near state-of-the-art accuracy with an order of magnitude increase in
decoding speed.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 22:45:16 GMT'}]",2020-10-30,"[['Singh', 'Abhinav', ''], ['Xia', 'Patrick', ''], ['Qin', 'Guanghui', ''], ['Yarmohammadi', 'Mahsa', ''], ['Van Durme', 'Benjamin', '']]"
1294236,2005.14441,Xiang Hao,"Xiang Hao, Xiangdong Su, Zhiyu Wang, Qiang Zhang, Huali Xu and
  Guanglai Gao",SNR-Based Teachers-Student Technique for Speech Enhancement,"Published in 2020 IEEE International Conference on Multimedia and
  Expo (ICME 2020)",,10.1109/ICME46284.2020.9102846,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  It is very challenging for speech enhancement methods to achieves robust
performance under both high signal-to-noise ratio (SNR) and low SNR
simultaneously. In this paper, we propose a method that integrates an SNR-based
teachers-student technique and time-domain U-Net to deal with this problem.
Specifically, this method consists of multiple teacher models and a student
model. We first train the teacher models under multiple small-range SNRs that
do not coincide with each other so that they can perform speech enhancement
well within the specific SNR range. Then, we choose different teacher models to
supervise the training of the student model according to the SNR of the
training data. Eventually, the student model can perform speech enhancement
under both high SNR and low SNR. To evaluate the proposed method, we
constructed a dataset with an SNR ranging from -20dB to 20dB based on the
public dataset. We experimentally analyzed the effectiveness of the SNR-based
teachers-student technique and compared the proposed method with several
state-of-the-art methods.
","[{'version': 'v1', 'created': 'Fri, 29 May 2020 08:13:01 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 12:12:20 GMT'}]",2020-10-30,"[['Hao', 'Xiang', ''], ['Su', 'Xiangdong', ''], ['Wang', 'Zhiyu', ''], ['Zhang', 'Qiang', ''], ['Xu', 'Huali', ''], ['Gao', 'Guanglai', '']]"
1294230,2005.14435,Xiang Hao,"Xiang Hao, Shixue Wen, Xiangdong Su, Yun Liu, Guanglai Gao and Xiaofei
  Li",Sub-Band Knowledge Distillation Framework for Speech Enhancement,Published in Interspeech 2020,,10.21437/Interspeech.2020-1539,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In single-channel speech enhancement, methods based on full-band spectral
features have been widely studied. However, only a few methods pay attention to
non-full-band spectral features. In this paper, we explore a knowledge
distillation framework based on sub-band spectral mapping for single-channel
speech enhancement. Specifically, we divide the full frequency band into
multiple sub-bands and pre-train an elite-level sub-band enhancement model
(teacher model) for each sub-band. These teacher models are dedicated to
processing their own sub-bands. Next, under the teacher models' guidance, we
train a general sub-band enhancement model (student model) that works for all
sub-bands. Without increasing the number of model parameters and computational
complexity, the student model's performance is further improved. To evaluate
our proposed method, we conducted a large number of experiments on an
open-source data set. The final experimental results show that the guidance
from the elite-level teacher models dramatically improves the student model's
performance, which exceeds the full-band model by employing fewer parameters.
","[{'version': 'v1', 'created': 'Fri, 29 May 2020 07:55:12 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 12:14:59 GMT'}]",2020-10-30,"[['Hao', 'Xiang', ''], ['Wen', 'Shixue', ''], ['Su', 'Xiangdong', ''], ['Liu', 'Yun', ''], ['Gao', 'Guanglai', ''], ['Li', 'Xiaofei', '']]"
1292684,2005.12889,Ruixiang Cui,"Ruixiang Cui, Daniel Hershcovich",Refining Implicit Argument Annotation for UCCA,DMR 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Predicate-argument structure analysis is a central component in meaning
representations of text. The fact that some arguments are not explicitly
mentioned in a sentence gives rise to ambiguity in language understanding, and
renders it difficult for machines to interpret text correctly. However, only
few resources represent implicit roles for NLU, and existing studies in NLP
only make coarse distinctions between categories of arguments omitted from
linguistic form. This paper proposes a typology for fine-grained implicit
argument annotation on top of Universal Conceptual Cognitive Annotation's
foundational layer. The proposed implicit argument categorisation is driven by
theories of implicit role interpretation and consists of six types: Deictic,
Generic, Genre-based, Type-identifiable, Non-specific, and Iterated-set. We
exemplify our design by revisiting part of the UCCA EWT corpus, providing a new
dataset annotated with the refinement layer, and making a comparative analysis
with other schemes.
","[{'version': 'v1', 'created': 'Tue, 26 May 2020 17:24:15 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 16:07:33 GMT'}]",2020-10-30,"[['Cui', 'Ruixiang', ''], ['Hershcovich', 'Daniel', '']]"
1358810,2010.02480,Cheng-Han Chiang,"Cheng-Han Chiang, Sung-Feng Huang and Hung-yi Lee",Pretrained Language Model Embryology: The Birth of ALBERT,"Accepted to EMNLP 2020, short paper",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While behaviors of pretrained language models (LMs) have been thoroughly
examined, what happened during pretraining is rarely studied. We thus
investigate the developmental process from a set of randomly initialized
parameters to a totipotent language model, which we refer to as the embryology
of a pretrained language model. Our results show that ALBERT learns to
reconstruct and predict tokens of different parts of speech (POS) in different
learning speeds during pretraining. We also find that linguistic knowledge and
world knowledge do not generally improve as pretraining proceeds, nor do
downstream tasks' performance. These findings suggest that knowledge of a
pretrained model varies during pretraining, and having more pretrain steps does
not necessarily provide a model with more comprehensive knowledge. We will
provide source codes and pretrained models to reproduce our results at
https://github.com/d223302/albert-embryology.
","[{'version': 'v1', 'created': 'Tue, 6 Oct 2020 05:15:39 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 00:07:43 GMT'}]",2020-10-30,"[['Chiang', 'Cheng-Han', ''], ['Huang', 'Sung-Feng', ''], ['Lee', 'Hung-yi', '']]"
1201305,1911.02711,Sen Yang,"Sen Yang, Leyang Cui, Jun Xie and Yue Zhang",Making the Best Use of Review Summary for Sentiment Analysis,To be published in COLING-2020,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Sentiment analysis provides a useful overview of customer review contents.
Many review websites allow a user to enter a summary in addition to a full
review. Intuitively, summary information may give additional benefit for review
sentiment analysis. In this paper, we conduct a study to exploit methods for
better use of summary information. We start by finding out that the sentimental
signal distribution of a review and that of its corresponding summary are in
fact complementary to each other. We thus explore various architectures to
better guide the interactions between the two and propose a
hierarchically-refined review-centric attention model. Empirical results show
that our review-centric model can make better use of user-written summaries for
review sentiment analysis, and is also more effective compared to existing
methods when the user summary is replaced with summary generated by an
automatic summarization system.
","[{'version': 'v1', 'created': 'Thu, 7 Nov 2019 01:46:54 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Oct 2020 07:15:01 GMT'}]",2020-10-30,"[['Yang', 'Sen', ''], ['Cui', 'Leyang', ''], ['Xie', 'Jun', ''], ['Zhang', 'Yue', '']]"
1202469,1911.03875,Khalil Mrini,"Khalil Mrini, Franck Dernoncourt, Quan Tran, Trung Bui, Walter Chang,
  Ndapa Nakashole",Rethinking Self-Attention: Towards Interpretability in Neural Parsing,EMNLP 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Attention mechanisms have improved the performance of NLP tasks while
allowing models to remain explainable. Self-attention is currently widely used,
however interpretability is difficult due to the numerous attention
distributions. Recent work has shown that model representations can benefit
from label-specific information, while facilitating interpretation of
predictions. We introduce the Label Attention Layer: a new form of
self-attention where attention heads represent labels. We test our novel layer
by running constituency and dependency parsing experiments and show our new
model obtains new state-of-the-art results for both tasks on both the Penn
Treebank (PTB) and Chinese Treebank. Additionally, our model requires fewer
self-attention layers compared to existing work. Finally, we find that the
Label Attention heads learn relations between syntactic categories and show
pathways to analyze errors.
","[{'version': 'v1', 'created': 'Sun, 10 Nov 2019 08:17:11 GMT'}, {'version': 'v2', 'created': 'Sat, 2 May 2020 04:34:52 GMT'}, {'version': 'v3', 'created': 'Thu, 29 Oct 2020 06:17:11 GMT'}]",2020-10-30,"[['Mrini', 'Khalil', ''], ['Dernoncourt', 'Franck', ''], ['Tran', 'Quan', ''], ['Bui', 'Trung', ''], ['Chang', 'Walter', ''], ['Nakashole', 'Ndapa', '']]"
1217216,1912.05320,Carlos S. Armendariz,"Carlos Santos Armendariz, Matthew Purver, Matej Ul\v{c}ar, Senja
  Pollak, Nikola Ljube\v{s}i\'c, Marko Robnik-\v{S}ikonja, Mark
  Granroth-Wilding, Kristiina Vaik",CoSimLex: A Resource for Evaluating Graded Word Similarity in Context,,"Proceedings of the 12th Language Resources and Evaluation
  Conference (2020) 5878-5886",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  State of the art natural language processing tools are built on
context-dependent word embeddings, but no direct method for evaluating these
representations currently exists. Standard tasks and datasets for intrinsic
evaluation of embeddings are based on judgements of similarity, but ignore
context; standard tasks for word sense disambiguation take account of context
but do not provide continuous measures of meaning similarity. This paper
describes an effort to build a new dataset, CoSimLex, intended to fill this
gap. Building on the standard pairwise similarity task of SimLex-999, it
provides context-dependent similarity measures; covers not only discrete
differences in word sense but more subtle, graded changes in meaning; and
covers not only a well-resourced language (English) but a number of
less-resourced languages. We define the task and evaluation metrics, outline
the dataset collection methodology, and describe the status of the dataset so
far.
","[{'version': 'v1', 'created': 'Wed, 11 Dec 2019 14:02:59 GMT'}, {'version': 'v2', 'created': 'Wed, 18 Dec 2019 10:33:05 GMT'}, {'version': 'v3', 'created': 'Thu, 29 Oct 2020 15:22:27 GMT'}]",2020-10-30,"[['Armendariz', 'Carlos Santos', ''], ['Purver', 'Matthew', ''], ['Ulčar', 'Matej', ''], ['Pollak', 'Senja', ''], ['Ljubešić', 'Nikola', ''], ['Robnik-Šikonja', 'Marko', ''], ['Granroth-Wilding', 'Mark', ''], ['Vaik', 'Kristiina', '']]"
1371555,2010.15225,Dylan Ebert,"Dylan Ebert, Ellie Pavlick",A Visuospatial Dataset for Naturalistic Verb Learning,"9 pages, 3 figures, starsem 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We introduce a new dataset for training and evaluating grounded language
models. Our data is collected within a virtual reality environment and is
designed to emulate the quality of language data to which a pre-verbal child is
likely to have access: That is, naturalistic, spontaneous speech paired with
richly grounded visuospatial context. We use the collected data to compare
several distributional semantics models for verb learning. We evaluate neural
models based on 2D (pixel) features as well as feature-engineered models based
on 3D (symbolic, spatial) features, and show that neither modeling approach
achieves satisfactory performance. Our results are consistent with evidence
from child language acquisition that emphasizes the difficulty of learning
verbs from naive distributional data. We discuss avenues for future work on
cognitively-inspired grounded language learning, and release our corpus with
the intent of facilitating research on the topic.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 20:47:13 GMT'}]",2020-10-30,"[['Ebert', 'Dylan', ''], ['Pavlick', 'Ellie', '']]"
1362681,2010.06351,Fuli Luo,"Fuli Luo, Pengcheng Yang, Shicheng Li, Xuancheng Ren, Xu Sun","CAPT: Contrastive Pre-Training for Learning Denoised Sequence
  Representations",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pre-trained self-supervised models such as BERT have achieved striking
success in learning sequence representations, especially for natural language
processing. These models typically corrupt the given sequences with certain
types of noise, such as masking, shuffling, or substitution, and then try to
recover the original input. However, such pre-training approaches are prone to
learning representations that are covariant with the noise, leading to the
discrepancy between the pre-training and fine-tuning stage. To remedy this, we
present ContrAstive Pre-Training (CAPT) to learn noise invariant sequence
representations. The proposed CAPT encourages the consistency between
representations of the original sequence and its corrupted version via
unsupervised instance-wise training signals. In this way, it not only
alleviates the pretrain-finetune discrepancy induced by the noise of
pre-training, but also aids the pre-trained model in better capturing global
semantics of the input via more effective sentence-level supervision. Different
from most prior work that focuses on a particular modality, comprehensive
empirical evidence on 11 natural language understanding and cross-modal tasks
illustrates that CAPT is applicable for both language and vision-language
tasks, and obtains surprisingly consistent improvement, including 0.6% absolute
gain on GLUE benchmarks and 0.8% absolute increment on NLVR.
","[{'version': 'v1', 'created': 'Tue, 13 Oct 2020 13:08:34 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Oct 2020 09:30:12 GMT'}, {'version': 'v3', 'created': 'Thu, 29 Oct 2020 06:41:07 GMT'}]",2020-10-30,"[['Luo', 'Fuli', ''], ['Yang', 'Pengcheng', ''], ['Li', 'Shicheng', ''], ['Ren', 'Xuancheng', ''], ['Sun', 'Xu', '']]"
1372108,2010.15778,Timo Denk,Timo I. Denk and Ana Peleteiro Ramallo,Contextual BERT: Conditioning the Language Model Using a Global State,"Accepted at the TextGraphs-14 workshop at COLING'2020 - The 28th
  International Conference on Computational Linguistics",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  BERT is a popular language model whose main pre-training task is to fill in
the blank, i.e., predicting a word that was masked out of a sentence, based on
the remaining words. In some applications, however, having an additional
context can help the model make the right prediction, e.g., by taking the
domain or the time of writing into account. This motivates us to advance the
BERT architecture by adding a global state for conditioning on a fixed-sized
context. We present our two novel approaches and apply them to an industry
use-case, where we complete fashion outfits with missing articles, conditioned
on a specific customer. An experimental comparison to other methods from the
literature shows that our methods improve personalization significantly.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 17:25:20 GMT'}]",2020-10-30,"[['Denk', 'Timo I.', ''], ['Ramallo', 'Ana Peleteiro', '']]"
1371581,2010.15251,Marimuthu Kalimuthu,"Marimuthu Kalimuthu, Aditya Mogadala, Marius Mosbach, Dietrich Klakow",Fusion Models for Improved Visual Captioning,"Under review at ""Multi-Modal Deep Learning: Challenges and
  Applications"", ICPR-2020",,,,cs.CV cs.AI cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Visual captioning aims to generate textual descriptions given images.
Traditionally, the captioning models are trained on human annotated datasets
such as Flickr30k and MS-COCO, which are limited in size and diversity. This
limitation hinders the generalization capabilities of these models while also
rendering them to often make mistakes. Language models can, however, be trained
on vast amounts of freely available unlabelled data and have recently emerged
as successful language encoders and coherent text generators. Meanwhile,
several unimodal and multimodal fusion techniques have been proven to work well
for natural language generation and automatic speech recognition. Building on
these recent developments, and with an aim of improving the quality of
generated captions, the contribution of our work in this paper is two-fold:
First, we propose a generic multimodal model fusion framework for caption
generation as well as emendation where we utilize different fusion strategies
to integrate a pretrained Auxiliary Language Model (AuxLM) within the
traditional encoder-decoder visual captioning frameworks. Next, we employ the
same fusion strategies to integrate a pretrained Masked Language Model (MLM),
namely BERT, with a visual captioning model, viz. Show, Attend, and Tell, for
emending both syntactic and semantic errors in captions. Our caption emendation
experiments on three benchmark image captioning datasets, viz. Flickr8k,
Flickr30k, and MSCOCO, show improvements over the baseline, indicating the
usefulness of our proposed multimodal fusion strategies. Further, we perform a
preliminary qualitative analysis on the emended captions and identify error
categories based on the type of corrections.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 21:55:25 GMT'}]",2020-10-30,"[['Kalimuthu', 'Marimuthu', ''], ['Mogadala', 'Aditya', ''], ['Mosbach', 'Marius', ''], ['Klakow', 'Dietrich', '']]"
1372058,2010.15728,Hang Dong,"Hang Dong, V\'ictor Su\'arez-Paniagua, William Whiteley, Honghan Wu","Explainable Automated Coding of Clinical Notes using Hierarchical
  Label-wise Attention Networks and Label Embedding Initialisation","Structured abstract in full text, 17 pages, 5 figures, 4
  supplementary materials (3 extra pages), submitted to Journal of Biomedical
  Informatics",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Diagnostic or procedural coding of clinical notes aims to derive a coded
summary of disease-related information about patients. Such coding is usually
done manually in hospitals but could potentially be automated to improve the
efficiency and accuracy of medical coding. Recent studies on deep learning for
automated medical coding achieved promising performances. However, the
explainability of these models is usually poor, preventing them to be used
confidently in supporting clinical practice. Another limitation is that these
models mostly assume independence among labels, ignoring the complex
correlation among medical codes which can potentially be exploited to improve
the performance. We propose a Hierarchical Label-wise Attention Network (HLAN),
which aimed to interpret the model by quantifying importance (as attention
weights) of words and sentences related to each of the labels. Secondly, we
propose to enhance the major deep learning models with a label embedding (LE)
initialisation approach, which learns a dense, continuous vector representation
and then injects the representation into the final layers and the label-wise
attention layers in the models. We evaluated the methods using three settings
on the MIMIC-III discharge summaries: full codes, top-50 codes, and the UK NHS
COVID-19 shielding codes. Experiments were conducted to compare HLAN and LE
initialisation to the state-of-the-art neural network based methods. HLAN
achieved the best Micro-level AUC and $F_1$ on the top-50 code prediction and
comparable results on the NHS COVID-19 shielding code prediction to other
models. By highlighting the most salient words and sentences for each label,
HLAN showed more meaningful and comprehensive model interpretation compared to
its downgraded baselines and the CNN-based models. LE initialisation
consistently boosted most deep learning models for automated medical coding.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 16:21:26 GMT'}]",2020-10-30,"[['Dong', 'Hang', ''], ['Suárez-Paniagua', 'Víctor', ''], ['Whiteley', 'William', ''], ['Wu', 'Honghan', '']]"
1371932,2010.15602,Junhua Liu,Nachamma Sockalingam and Junhua Liu,Designing learning experiences for online teaching and learning,,,,,cs.CY cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Teaching is about constantly innovating strategies, ways and means to engage
diverse students in active and meaningful learning. In line with this, SUTD
adopts various student-centric teaching and learning teaching methods and
approaches. This means that our graduate/undergraduate instructors have to be
ready to teach using these student student-centric teaching and learning
pedagogies. In this article, I share my experiences of redesigning this
teaching course that is typically conducted face-to-face to a synchronous
online course and also invite one of the participant in this course to reflect
on his experience as a student.
","[{'version': 'v1', 'created': 'Mon, 26 Oct 2020 07:03:49 GMT'}]",2020-10-30,"[['Sockalingam', 'Nachamma', ''], ['Liu', 'Junhua', '']]"
1371479,2010.15149,Yiwei Luo,"Yiwei Luo, Dallas Card, Dan Jurafsky",DeSMOG: Detecting Stance in Media On Global Warming,"9 pages, 6 figures (excluding references and appendices). To appear
  in Findings of EMNLP 2020",Findings of EMNLP 2020,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Citing opinions is a powerful yet understudied strategy in argumentation. For
example, an environmental activist might say, ""Leading scientists agree that
global warming is a serious concern,"" framing a clause which affirms their own
stance (""that global warming is serious"") as an opinion endorsed (""[scientists]
agree"") by a reputable source (""leading""). In contrast, a global warming denier
might frame the same clause as the opinion of an untrustworthy source with a
predicate connoting doubt: ""Mistaken scientists claim [...]."" Our work studies
opinion-framing in the global warming (GW) debate, an increasingly partisan
issue that has received little attention in NLP. We introduce DeSMOG, a dataset
of stance-labeled GW sentences, and train a BERT classifier to study novel
aspects of argumentation in how different sides of a debate represent their own
and each other's opinions. From 56K news articles, we find that similar
linguistic devices for self-affirming and opponent-doubting discourse are used
across GW-accepting and skeptic media, though GW-skeptical media shows more
opponent-doubt. We also find that authors often characterize sources as
hypocritical, by ascribing opinions expressing the author's own view to source
entities known to publicly endorse the opposing view. We release our stance
dataset, model, and lexicons of framing devices for future work on
opinion-framing and the automatic detection of GW stance.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2020 18:01:02 GMT'}]",2020-10-30,"[['Luo', 'Yiwei', ''], ['Card', 'Dallas', ''], ['Jurafsky', 'Dan', '']]"
1371630,2010.15300,Emaad Manzoor,"Emaad Manzoor, Nihar B. Shah",Uncovering Latent Biases in Text: Method and Application to Peer Review,,,,,cs.CL cs.CY cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Quantifying systematic disparities in numerical quantities such as employment
rates and wages between population subgroups provides compelling evidence for
the existence of societal biases. However, biases in the text written for
members of different subgroups (such as in recommendation letters for male and
non-male candidates), though widely reported anecdotally, remain challenging to
quantify. In this work, we introduce a novel framework to quantify bias in text
caused by the visibility of subgroup membership indicators. We develop a
nonparametric estimation and inference procedure to estimate this bias. We then
formalize an identification strategy to causally link the estimated bias to the
visibility of subgroup membership indicators, provided observations from time
periods both before and after an identity-hiding policy change. We identify an
application wherein ""ground truth"" bias can be inferred to evaluate our
framework, instead of relying on synthetic or secondary data. Specifically, we
apply our framework to quantify biases in the text of peer reviews from a
reputed machine learning conference before and after the conference adopted a
double-blind reviewing policy. We show evidence of biases in the review ratings
that serves as ""ground truth"", and show that our proposed framework accurately
detects these biases from the review text without having access to the review
ratings.
","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 01:24:19 GMT'}]",2020-10-30,"[['Manzoor', 'Emaad', ''], ['Shah', 'Nihar B.', '']]"
